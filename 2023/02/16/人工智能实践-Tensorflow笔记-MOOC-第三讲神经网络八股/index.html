<!DOCTYPE html><html lang="zh-Hans"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta name="description" content="人工智能实践-Tensorflow笔记-MOOC-第三讲神经网络八股"><meta name="keywords" content="学习笔记,Tensorflow,TensorflowMOOC"><meta name="author" content="HibisciDai"><meta name="copyright" content="HibisciDai"><title>人工智能实践-Tensorflow笔记-MOOC-第三讲神经网络八股 | HibisciDai</title><link rel="shortcut icon" href="/img/avatar.png"><link rel="stylesheet" href="/css/index.css?version=1.9.0"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/font-awesome@latest/css/font-awesome.min.css?version=1.9.0"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.7.2/css/all.css?version=1.9.0"><meta name="format-detection" content="telephone=no"><meta http-equiv="x-dns-prefetch-control" content="on"><link rel="dns-prefetch" href="https://cdn.jsdelivr.net"><link rel="manifest" href="/manifest.json"><link rel="manifest" href="/manifest.json"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><script src="https://v1.hitokoto.cn/?encode=js&amp;charset=utf-8&amp;select=.footer_custom_text" defer></script><script>var GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: {"path":"search.xml","languages":{"hits_empty":"找不到您查询的内容:${query}"}},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  hexoVersion: '6.1.0'
} </script><meta name="generator" content="Hexo 6.1.0"><link rel="alternate" href="/atom.xml" title="HibisciDai" type="application/atom+xml">
</head><body><canvas class="fireworks"></canvas><i class="fa fa-arrow-right" id="toggle-sidebar" aria-hidden="true"></i><div id="sidebar" data-display="true"><div class="toggle-sidebar-info text-center"><span data-toggle="切换文章详情">切换站点概览</span><hr></div><div class="sidebar-toc"><div class="sidebar-toc__title">目录</div><div class="sidebar-toc__progress"><span class="progress-notice">你已经读了</span><span class="progress-num">0</span><span class="progress-percentage">%</span><div class="sidebar-toc__progress-bar"></div></div><div class="sidebar-toc__content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%AE%9E%E8%B7%B5-Tensorflow%E7%AC%94%E8%AE%B0-MOOC-%E7%AC%AC%E4%B8%89%E8%AE%B2%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%85%AB%E8%82%A1"><span class="toc-number">1.</span> <span class="toc-text">人工智能实践-Tensorflow笔记-MOOC-第三讲神经网络八股</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E6%90%AD%E5%BB%BA%E5%85%AB%E8%82%A1"><span class="toc-number">2.</span> <span class="toc-text">神经网络搭建八股</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%94%A8Tensorflow-API%EF%BC%9A-tf-keras%E6%90%AD%E5%BB%BA%E7%BD%91%E7%BB%9C%E5%85%AB%E8%82%A1"><span class="toc-number">2.1.</span> <span class="toc-text">用Tensorflow API： tf.keras搭建网络八股</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-import"><span class="toc-number">2.1.1.</span> <span class="toc-text">1-import</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-train-test"><span class="toc-number">2.1.2.</span> <span class="toc-text">2-train, test</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-model-tf-keras-models-Sequential"><span class="toc-number">2.1.3.</span> <span class="toc-text">3-model &#x3D; tf.keras.models.Sequential</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-model-compile"><span class="toc-number">2.1.4.</span> <span class="toc-text">4-model.compile</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-model-fit"><span class="toc-number">2.1.5.</span> <span class="toc-text">5-model.fit</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#6-model-summary"><span class="toc-number">2.1.6.</span> <span class="toc-text">6-model.summary</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%87%BD%E6%95%B0%E7%94%A8%E6%B3%95%E4%BB%8B%E7%BB%8D"><span class="toc-number">2.2.</span> <span class="toc-text">函数用法介绍</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#tf-keras-models-Sequential"><span class="toc-number">2.2.1.</span> <span class="toc-text">tf.keras.models.Sequential()</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#model-compile"><span class="toc-number">2.2.2.</span> <span class="toc-text">model.compile()</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#optimizer"><span class="toc-number">2.2.2.1.</span> <span class="toc-text">optimizer</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#loss"><span class="toc-number">2.2.2.2.</span> <span class="toc-text">loss</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Metrics"><span class="toc-number">2.2.2.3.</span> <span class="toc-text">Metrics</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#model-fit"><span class="toc-number">2.2.3.</span> <span class="toc-text">model.fit()</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#model-summary"><span class="toc-number">2.2.4.</span> <span class="toc-text">model.summary()</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#iris%E4%BB%A3%E7%A0%81%E5%A4%8D%E7%8E%B0"><span class="toc-number">3.</span> <span class="toc-text">iris代码复现</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%94%A8Sequential%E6%90%AD%E5%BB%BA%E7%BD%91%E8%B7%AF"><span class="toc-number">3.1.</span> <span class="toc-text">用Sequential搭建网路</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%94%A8%E7%B1%BBClass%E6%90%AD%E5%BB%BA%E7%BD%91%E7%BB%9C"><span class="toc-number">3.2.</span> <span class="toc-text">用类Class搭建网络</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#MNIST%E6%95%B0%E6%8D%AE%E9%9B%86"><span class="toc-number">4.</span> <span class="toc-text">MNIST数据集</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E8%AE%AD%E7%BB%83MNIST%E6%95%B0%E6%8D%AE%E9%9B%86"><span class="toc-number">5.</span> <span class="toc-text">训练MNIST数据集</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BD%BF%E7%94%A8-Sequential-%E5%AE%9E%E7%8E%B0%E6%89%8B%E5%86%99%E6%95%B0%E5%AD%97%E8%AF%86%E5%88%AB"><span class="toc-number">5.1.</span> <span class="toc-text">使用 Sequential 实现手写数字识别</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BD%BF%E7%94%A8-class-%E5%AE%9E%E7%8E%B0%E6%89%8B%E5%86%99%E6%95%B0%E5%AD%97%E8%AF%86%E5%88%AB"><span class="toc-number">5.2.</span> <span class="toc-text">使用 class 实现手写数字识别</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Fashion%E6%95%B0%E6%8D%AE%E9%9B%86"><span class="toc-number">6.</span> <span class="toc-text">Fashion数据集</span></a></li></ol></div></div><div class="author-info hide"><div class="author-info__avatar text-center"><img src="/img/Avatar.png"></div><div class="author-info__name text-center">HibisciDai</div><div class="author-info__description text-center">HibisciDai'Blog</div><hr><div class="author-info-articles"><a class="author-info-articles__archives article-meta" href="/archives"><span class="pull-left">文章</span><span class="pull-right">244</span></a><a class="author-info-articles__tags article-meta" href="/tags"><span class="pull-left">标签</span><span class="pull-right">88</span></a><a class="author-info-articles__categories article-meta" href="/categories"><span class="pull-left">分类</span><span class="pull-right">33</span></a></div><hr><div class="author-info-links"><div class="author-info-links__title text-center">友情链接</div><a class="author-info-links__name text-center" target="_blank" rel="noopener" href="https://github.com/HibisciDai/hexo-theme-melody">HexoTheme-github</a><a class="author-info-links__name text-center" target="_blank" rel="noopener" href="https://molunerfinn.com/">molunerfinn</a></div></div></div><div id="content-outer"><div id="top-container" style="background-image: url(/img/banner2.jpg)"><div id="page-header"><span class="pull-left"> <a id="site-name" href="/">HibisciDai</a></span><i class="fa fa-bars toggle-menu pull-right" aria-hidden="true"></i><span class="pull-right menus">   <a class="site-page" href="/">主页</a><a class="site-page" href="/about">关于我</a><a class="site-page" href="/archives">归档</a><a class="site-page" href="/tags">标签</a><a class="site-page" href="/categories">分类</a><a class="site-page" href="/gallery">相册</a></span><span class="pull-right"><a class="site-page social-icon search"><i class="fa fa-search"></i><span> 搜索</span></a></span></div><div id="post-info"><div id="post-title">人工智能实践-Tensorflow笔记-MOOC-第三讲神经网络八股</div><div id="post-meta"><time class="post-meta__date"><i class="fa fa-calendar" aria-hidden="true"></i> 2023-02-16</time><span class="post-meta__separator">|</span><i class="fa fa-inbox post-meta__icon" aria-hidden="true"></i><a class="post-meta__categories" href="/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/">学习笔记</a><div class="post-meta-wordcount"><span>字数总计: </span><span class="word-count">3.9k</span><span class="post-meta__separator">|</span><span>阅读时长: 17 分钟</span></div></div></div></div><div class="layout" id="content-inner"><article id="post"><div class="article-container" id="post-content"><img src="/2023/02/16/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%AE%9E%E8%B7%B5-Tensorflow%E7%AC%94%E8%AE%B0-MOOC-%E7%AC%AC%E4%B8%89%E8%AE%B2%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%85%AB%E8%82%A1/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%AE%9E%E8%B7%B5-Tensorflow%E7%AC%94%E8%AE%B0-MOOC-%E7%AC%AC%E4%B8%89%E8%AE%B2%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%85%AB%E8%82%A1.png" class="" title="人工智能实践-Tensorflow笔记-MOOC-第三讲神经网络八股">
<p>人工智能实践-Tensorflow笔记-MOOC-第三讲神经网络八股</p>
<span id="more"></span>
<p>[TOC]</p>
<h1 id="人工智能实践-Tensorflow笔记-MOOC-第三讲神经网络八股"><a href="#人工智能实践-Tensorflow笔记-MOOC-第三讲神经网络八股" class="headerlink" title="人工智能实践-Tensorflow笔记-MOOC-第三讲神经网络八股"></a>人工智能实践-Tensorflow笔记-MOOC-第三讲神经网络八股</h1><h1 id="神经网络搭建八股"><a href="#神经网络搭建八股" class="headerlink" title="神经网络搭建八股"></a>神经网络搭建八股</h1><h2 id="用Tensorflow-API：-tf-keras搭建网络八股"><a href="#用Tensorflow-API：-tf-keras搭建网络八股" class="headerlink" title="用Tensorflow API： tf.keras搭建网络八股"></a>用Tensorflow API： tf.keras搭建网络八股</h2><p>六步法</p>
<h3 id="1-import"><a href="#1-import" class="headerlink" title="1-import"></a>1-import</h3><p>第一步： import 相关模块，如 <code>import tensorflow as tf</code>。</p>
<h3 id="2-train-test"><a href="#2-train-test" class="headerlink" title="2-train, test"></a>2-train, test</h3><p>第二步： 指定输入网络的训练集和测试集，如指定训练集的输入 <code>x_train</code> 和标签<br><code>y_train</code>，测试集的输入 <code>x_test</code> 和标签 <code>y_test</code>。</p>
<h3 id="3-model-tf-keras-models-Sequential"><a href="#3-model-tf-keras-models-Sequential" class="headerlink" title="3-model = tf.keras.models.Sequential"></a>3-model = tf.keras.models.Sequential</h3><p>第三步： 逐层搭建网络结构，<code>model = tf.keras.models.Sequential()</code>，相当于走了一遍前向传播。</p>
<h3 id="4-model-compile"><a href="#4-model-compile" class="headerlink" title="4-model.compile"></a>4-model.compile</h3><p>第四步： 在 <code>model.compile()</code> 中配置训练方法，选择训练时使用的优化器、损失函数和最终评价指标。</p>
<h3 id="5-model-fit"><a href="#5-model-fit" class="headerlink" title="5-model.fit"></a>5-model.fit</h3><p>第五步： 在 <code>model.fit()</code> 中执行训练过程，告知训练集和测试集的输入值和标签、每个 <code>batch</code> 的大小（batchsize）和数据集的迭代次数（epoch）。</p>
<h3 id="6-model-summary"><a href="#6-model-summary" class="headerlink" title="6-model.summary"></a>6-model.summary</h3><p>第六步： 使用 <code>model.summary()</code> 打印网络结构，统计参数数目。</p>
<h2 id="函数用法介绍"><a href="#函数用法介绍" class="headerlink" title="函数用法介绍"></a>函数用法介绍</h2><h3 id="tf-keras-models-Sequential"><a href="#tf-keras-models-Sequential" class="headerlink" title="tf.keras.models.Sequential()"></a>tf.keras.models.Sequential()</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">model = tf.keras.models.Sequential ([网络结构]) <span class="comment">#描述各层网络</span></span><br></pre></td></tr></table></figure>
<p>网络结构举例：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 拉直层</span></span><br><span class="line">tf.keras.layers.Flatten()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 全连接层</span></span><br><span class="line">tf.keras.layers.Dense(<span class="string">&quot;神经元个数&quot;</span>, activation = <span class="string">&quot;激活函数&quot;</span>, kernel_regularizer = <span class="string">&quot;哪种正则化&quot;</span>)</span><br><span class="line"><span class="comment"># activation（字符串给出）可选: relu、 softmax、 sigmoid、 tanh</span></span><br><span class="line"><span class="comment"># kernel_regularizer可选: tf.keras.regularizers.l1()、 tf.keras.regularizers.l2()</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 卷积层</span></span><br><span class="line">tf.keras.layers.Conv2D(filters = <span class="string">&quot;卷积核个数&quot;</span>, kernel_size = <span class="string">&quot;卷积核尺寸&quot;</span>,</span><br><span class="line">strides = <span class="string">&quot;卷积步长&quot;</span>, padding = <span class="string">&quot; valid&quot;</span> <span class="keyword">or</span> <span class="string">&quot;same&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># LSTM层</span></span><br><span class="line">tf.keras.layers.LSTM()</span><br><span class="line"><span class="comment"># 本章只使用拉直层和全连接层，卷积层和循环神经网络层将在之后的章节介绍</span></span><br></pre></td></tr></table></figure>
<h3 id="model-compile"><a href="#model-compile" class="headerlink" title="model.compile()"></a>model.compile()</h3><p>Compile 用于配置神经网络的训练方法，告知训练时使用的优化器、损失函数和准确率评测标准。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">model.<span class="built_in">compile</span>(optimizer = 优化器, loss = 损失函数, metrics = [“准确率”] )</span><br></pre></td></tr></table></figure>
<h4 id="optimizer"><a href="#optimizer" class="headerlink" title="optimizer"></a>optimizer</h4><p><code>optimizer</code> 可以是字符串形式给出的优化器名字，也可以是函数形式，使用函数形式可以设置学习率、动量和超参数。</p>
<p>可选项：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">‘sgd’ <span class="keyword">or</span> tf.keras.optimizers.SGD(lr=<span class="string">&#x27;学习率&#x27;</span>, momentum=<span class="string">&#x27;动量参数&#x27;</span>)</span><br><span class="line">‘adagrad’ <span class="keyword">or</span> tf.keras.optimizers.Adagrad(lr=<span class="string">&#x27;学习率&#x27;</span>)</span><br><span class="line">‘adadelta’ <span class="keyword">or</span> tf.keras.optimizers.Adadelta(lr=<span class="string">&#x27;学习率&#x27;</span>)</span><br><span class="line">‘adam’ <span class="keyword">or</span> tf.keras.optimizers.Adam(lr=<span class="string">&#x27;学习率&#x27;</span>, beta_1=<span class="number">0.9</span>, beta_2=<span class="number">0.999</span>)</span><br></pre></td></tr></table></figure>
<h4 id="loss"><a href="#loss" class="headerlink" title="loss"></a>loss</h4><p><code>Loss</code> 可以是字符串形式给出的损失函数的名字，也可以是函数形式。</p>
<p>可选项：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">‘mse’ <span class="keyword">or</span> tf.keras.losses.MeanSquaredError()</span><br><span class="line">‘sparse_categorical_crossentropy’ <span class="keyword">or</span> tf.keras.losses.SparseCategoricalCrossentropy(from_logits=<span class="literal">False</span>) <span class="comment"># 询问是否是原始输出，经不经过概率分布输出</span></span><br><span class="line"><span class="comment"># False : 神经网络预测结果输出前,经过概率分布</span></span><br><span class="line"><span class="comment"># True : 神经网络预测结果输出前,没有经过概率分布</span></span><br><span class="line"><span class="comment"># 比如十分类问题，概率是1/10，可能是概率参数设置问题</span></span><br></pre></td></tr></table></figure>
<p>损失函数常需要经过 <code>softmax</code> 等函数将输出转化为概率分布的形式。</p>
<p><code>from_logits</code> 则用来标注该损失函数是否需要转换为概率的形式， 取 False 时表示转化为概率分布，取 True 时表示没有转化为概率分布，直接输出。</p>
<h4 id="Metrics"><a href="#Metrics" class="headerlink" title="Metrics"></a>Metrics</h4><p><code>Metrics</code> 标注网络评测指标。</p>
<p>可选项：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&#x27;accuracy&#x27;</span> : y_和y都是数值, 如y_=[<span class="number">1</span>] y=[<span class="number">1</span>]</span><br><span class="line"><span class="string">&#x27;categorical_accuracy&#x27;</span> : y_和y都是独热码(概率分布), 如y_=[<span class="number">0</span>,<span class="number">1</span>,<span class="number">0</span>] y=[<span class="number">0.256</span>,<span class="number">0.695</span>,<span class="number">0.048</span>]</span><br><span class="line"><span class="string">&#x27;sparse_categorical_accuracy&#x27;</span> : y_是数值, y是独热码(概率分布), 如y_=[<span class="number">1</span>] y=[<span class="number">0.256</span>,<span class="number">0.695</span>,<span class="number">0.048</span>]</span><br></pre></td></tr></table></figure>
<h3 id="model-fit"><a href="#model-fit" class="headerlink" title="model.fit()"></a>model.fit()</h3><p>fit 函数用于执行训练过程</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">model.fit(</span><br><span class="line">    训练集的输入特征, </span><br><span class="line">    训练集的标签, </span><br><span class="line">    batch_size, <span class="comment"># 每次喂入神经网络的样本数</span></span><br><span class="line">    epochs, <span class="comment"># 迭代总次数</span></span><br><span class="line">    validation_data = (测试集的输入特征, 测试集的标签), <span class="comment"># 与validataion_split选其一</span></span><br><span class="line">    validataion_split = 从测试集划分多少比例给训练集, <span class="comment"># 与validation_data选其一</span></span><br><span class="line">    validation_freq = 测试的 epoch 间隔次数) <span class="comment"># 每多少次epoch迭代，使用测试集验证一次结果</span></span><br></pre></td></tr></table></figure>
<h3 id="model-summary"><a href="#model-summary" class="headerlink" title="model.summary()"></a>model.summary()</h3><p>summary 函数用于打印网络结构和参数统计</p>
<p>例如鸢尾花分类的神经网络，是四输入三输出的一层网络</p>
<img src="/2023/02/16/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%AE%9E%E8%B7%B5-Tensorflow%E7%AC%94%E8%AE%B0-MOOC-%E7%AC%AC%E4%B8%89%E8%AE%B2%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%85%AB%E8%82%A1/%E9%B8%A2%E5%B0%BE%E8%8A%B1%E5%88%86%E7%B1%BBsummary%E5%87%BD%E6%95%B0%E7%A4%BA%E4%BE%8B.png" class="" title="鸢尾花分类summary函数示例">
<p>上图是 model.summary()对鸢尾花分类网络的网络结构和参数统计，对于一个输入为 4 输出为 3 的全连接网络，共有 15 个参数。</p>
<h1 id="iris代码复现"><a href="#iris代码复现" class="headerlink" title="iris代码复现"></a>iris代码复现</h1><h2 id="用Sequential搭建网路"><a href="#用Sequential搭建网路" class="headerlink" title="用Sequential搭建网路"></a>用Sequential搭建网路</h2><p><code>p8_iris_sequential.py</code></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 1-import</span></span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> datasets</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="comment"># 2-train, test</span></span><br><span class="line">x_train = datasets.load_iris().data</span><br><span class="line">y_train = datasets.load_iris().target</span><br><span class="line"><span class="comment"># 其中测试集的输入特征 x_test 和标签 y_test 可以像 x_train 和 y_train 一样直接从数据集获取， 也可以如上述在 fit 中按比例从训练集中划分， 本例选择从训练集中划分，所以只需加载 x_train， y_train 即可。</span></span><br><span class="line"></span><br><span class="line">np.random.seed(<span class="number">116</span>)</span><br><span class="line">np.random.shuffle(x_train)</span><br><span class="line">np.random.seed(<span class="number">116</span>)</span><br><span class="line">np.random.shuffle(y_train)</span><br><span class="line">tf.random.set_seed(<span class="number">116</span>)</span><br><span class="line"><span class="comment"># 以上代码实现了数据集的乱序。</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 3-model = tf.keras.models.Sequential</span></span><br><span class="line">model = tf.keras.models.Sequential([tf.keras.layers.Dense(<span class="number">3</span>, activation=<span class="string">&#x27;softmax&#x27;</span>, kernel_regularizer=tf.keras.regularizers.l2())</span><br><span class="line">])</span><br><span class="line"><span class="comment"># 如上所示，本例使用了单层全连接网络，第一个参数表示神经元个数，第二个参数表示网络所使用的激活函数，第三个参数表示选用的正则化方法。</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 4-model.compile</span></span><br><span class="line">model.<span class="built_in">compile</span>(optimizer=tf.keras.optimizers.SGD(lr=<span class="number">0.1</span>), loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=<span class="literal">False</span>), metrics=[<span class="string">&#x27;sparse_categorical_accuracy&#x27;</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 5-model.fit</span></span><br><span class="line">model.fit(x_train, y_train, batch_size=<span class="number">32</span>, epochs=<span class="number">500</span>, validation_split=<span class="number">0.2</span>, validation_freq=<span class="number">20</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 6-model.summary</span></span><br><span class="line">model.summary()</span><br></pre></td></tr></table></figure>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line">Train on 120 samples, validate on 30 samples</span><br><span class="line">Epoch 1/500</span><br><span class="line"></span><br><span class="line"> 32/120 [=======&gt;......................] - ETA: 0s - loss: 3.8177 - sparse_categorical_accuracy: 0.3438</span><br><span class="line">120/120 [==============================] - 0s 2ms/sample - loss: 2.1962 - sparse_categorical_accuracy: 0.3500</span><br><span class="line">Epoch 2/500</span><br><span class="line"></span><br><span class="line">...</span><br><span class="line"></span><br><span class="line"> 32/120 [=======&gt;......................] - ETA: 0s - loss: 0.3353 - sparse_categorical_accuracy: 1.0000</span><br><span class="line">120/120 [==============================] - 0s 25us/sample - loss: 0.3535 - sparse_categorical_accuracy: 0.9500</span><br><span class="line">Epoch 150/500</span><br><span class="line"></span><br><span class="line">...</span><br><span class="line"></span><br><span class="line"> 32/120 [=======&gt;......................] - ETA: 0s - loss: 0.3871 - sparse_categorical_accuracy: 0.9688</span><br><span class="line">120/120 [==============================] - 0s 25us/sample - loss: 0.3718 - sparse_categorical_accuracy: 0.9417</span><br><span class="line">Epoch 300/500</span><br><span class="line"></span><br><span class="line">...</span><br><span class="line"></span><br><span class="line"> 32/120 [=======&gt;......................] - ETA: 0s - loss: 0.3613 - sparse_categorical_accuracy: 0.9375</span><br><span class="line">120/120 [==============================] - 0s 25us/sample - loss: 0.3658 - sparse_categorical_accuracy: 0.9583</span><br><span class="line">Epoch 450/500</span><br><span class="line"></span><br><span class="line">...</span><br><span class="line"></span><br><span class="line"> 32/120 [=======&gt;......................] - ETA: 0s - loss: 0.3630 - sparse_categorical_accuracy: 0.9688</span><br><span class="line">120/120 [==============================] - 0s 25us/sample - loss: 0.3486 - sparse_categorical_accuracy: 0.9583</span><br><span class="line">Epoch 500/500</span><br><span class="line"></span><br><span class="line"> 32/120 [=======&gt;......................] - ETA: 0s - loss: 0.3122 - sparse_categorical_accuracy: 0.9688</span><br><span class="line">120/120 [==============================] - 0s 63us/sample - loss: 0.3333 - sparse_categorical_accuracy: 0.9667 - val_loss: 0.4002 - val_sparse_categorical_accuracy: 1.0000</span><br><span class="line">Model: &quot;sequential&quot;</span><br><span class="line">_________________________________________________________________</span><br><span class="line">Layer (type)                 Output Shape              Param #   </span><br><span class="line">=================================================================</span><br><span class="line">dense (Dense)                multiple                  15        </span><br><span class="line">=================================================================</span><br><span class="line">Total params: 15</span><br><span class="line">Trainable params: 15</span><br><span class="line">Non-trainable params: 0</span><br><span class="line">_________________________________________________________________</span><br></pre></td></tr></table></figure>
<h2 id="用类Class搭建网络"><a href="#用类Class搭建网络" class="headerlink" title="用类Class搭建网络"></a>用类Class搭建网络</h2><p>使用 Sequential 可以快速搭建网络结构，即上层输入下层输出。但是如果网络包含跳连等其他复杂(非顺序)网络结构， Sequential 就无法表示了。 这就需要使用 class 来声明网络结构。</p>
<ul>
<li>1-import</li>
<li>2-train, test</li>
<li>3-class MyModel(Model) model=MyModel</li>
<li>4-model.compile</li>
<li>5-model.fit</li>
<li>6-model.summary</li>
</ul>
<p>可以使用class类封装一个神经网络结构</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">MyModel</span>(<span class="title class_ inherited__">Model</span>):</span><br><span class="line">	<span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>): <span class="comment"># 定义所需网络结构块</span></span><br><span class="line">		<span class="built_in">super</span>(MyModel, self).__init__()</span><br><span class="line">		//初始化网络结构</span><br><span class="line">		</span><br><span class="line">	<span class="keyword">def</span> <span class="title function_">call</span>(<span class="params">self, x</span>):	<span class="comment"># 写出向前传播</span></span><br><span class="line">		y = self.d1(x)</span><br><span class="line">		<span class="keyword">return</span> y</span><br><span class="line"></span><br><span class="line">model = MyModel()</span><br></pre></td></tr></table></figure>
<p>使用 <code>class</code> 类封装网络结构，如上所示是一个 <code>class</code> 模板。</p>
<p><code>MyModel</code> 表示声明的神经网络的名字，括号中的 <code>Model</code> 表示创建的类需要继承 <code>tensorflow</code> 库中的 <code>Model</code> 类。</p>
<p>类中需要定义两个函数，<code>__init__()</code> 函数为类的构造函数用于初始化类的参数， <code>spuer(MyModel,self).__init__()</code> 这行表示初始化父类的参数。 </p>
<p>之后便可初始化网络结构，搭建出神经网络所需的各种网络结构块。</p>
<p><code>call()</code>函数中调用<code>__init__()</code>函数中完成初始化的网络块，实现前向传播并返回推理值。使用 <code>class</code> 方式搭建鸢尾花网络结构的代码如下所示。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">IrisModel</span>(<span class="title class_ inherited__">Model</span>):</span><br><span class="line">	<span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">		<span class="built_in">super</span>(IrisModel, self).__init__()</span><br><span class="line">		self.d1 = Dense(<span class="number">3</span>, activation=<span class="string">&#x27;sigmoid&#x27;</span>, kernel_regularizer=tf.keras.regularizers.l2())</span><br><span class="line">	<span class="keyword">def</span> <span class="title function_">call</span>(<span class="params">self, x</span>):</span><br><span class="line">		y = self.d1(x)</span><br><span class="line">		<span class="keyword">return</span> y</span><br><span class="line">model = IrisModel <span class="comment"># 搭建好网络结构后只需要使用 Model=MyModel()构建类的对象，就可以使用该模型了。</span></span><br></pre></td></tr></table></figure>
<p><code>p11_iris_class.py</code></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 1-import</span></span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="comment">#################################</span></span><br><span class="line"><span class="keyword">from</span> tensorflow.keras.layers <span class="keyword">import</span> Dense</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras <span class="keyword">import</span> Model</span><br><span class="line"><span class="comment">#################################</span></span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> datasets</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="comment"># 2-train, test</span></span><br><span class="line">x_train = datasets.load_iris().data</span><br><span class="line">y_train = datasets.load_iris().target</span><br><span class="line"></span><br><span class="line">np.random.seed(<span class="number">116</span>)</span><br><span class="line">np.random.shuffle(x_train)</span><br><span class="line">np.random.seed(<span class="number">116</span>)</span><br><span class="line">np.random.shuffle(y_train)</span><br><span class="line">tf.random.set_seed(<span class="number">116</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 3-class MyModel</span></span><br><span class="line"><span class="comment">#################################</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">IrisModel</span>(<span class="title class_ inherited__">Model</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>(IrisModel, self).__init__()</span><br><span class="line">        self.d1 = Dense(<span class="number">3</span>, activation=<span class="string">&#x27;softmax&#x27;</span>, kernel_regularizer=tf.keras.regularizers.l2())</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">call</span>(<span class="params">self, x</span>):</span><br><span class="line">        y = self.d1(x)</span><br><span class="line">        <span class="keyword">return</span> y</span><br><span class="line"></span><br><span class="line">model = IrisModel()</span><br><span class="line"><span class="comment">#对比使用 Sequential()方法和 class 方法， 有两点区别：</span></span><br><span class="line"><span class="comment">#①import 中添加了 Model 模块和 Dense 层、 Flatten 层。</span></span><br><span class="line"><span class="comment">#②使用 class 声明网络结构， model = IrisModel()初始化模型对象。</span></span><br><span class="line"><span class="comment">#################################</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 4-model compile</span></span><br><span class="line">model.<span class="built_in">compile</span>(optimizer=tf.keras.optimizers.SGD(lr=<span class="number">0.1</span>), loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=<span class="literal">False</span>), metrics=[<span class="string">&#x27;sparse_categorical_accuracy&#x27;</span>])</span><br><span class="line"><span class="comment"># 如上所示，本例使用SGD优化器，并将学习率设置为0.1，选择SparseCategoricalCrossentrop 作为损失函数。 由于神经网络输出使用了softmax 激活函数，使得输出是概率分布，而不是原始输出， 所以需要将from_logits 参数设置为 False。 鸢尾花数据集给的标签是 0， 1， 2 这样的数值，而网络前向传播的输出为概率分布，所以 metrics 需要设置为sparse_categorical_accuracy。</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 5-model.fit</span></span><br><span class="line">model.fit(x_train, y_train, batch_size=<span class="number">32</span>, epochs=<span class="number">500</span>, validation_split=<span class="number">0.2</span>, validation_freq=<span class="number">20</span>)</span><br><span class="line"><span class="comment"># 在 fit 中执行训练过程, x_train,y_train 分别表示网络的输入特征和标签，batch_size 表示一次喂入神经网络的数据量, epochs 表示数据集的迭代次数validation_split 表示数据集中测试集的划分比例, validation_freq 表示每迭代 20 次在测试集上测试一次准确率</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 6-model.summary</span></span><br><span class="line">model.summary()</span><br></pre></td></tr></table></figure>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line">Train on 120 samples, validate on 30 samples</span><br><span class="line">Epoch 1/500</span><br><span class="line"></span><br><span class="line"> 32/120 [=======&gt;......................] - ETA: 0s - loss: 3.8177 - sparse_categorical_accuracy: 0.3438</span><br><span class="line">120/120 [==============================] - 0s 2ms/sample - loss: 2.1962 - sparse_categorical_accuracy: 0.3500</span><br><span class="line">Epoch 2/500</span><br><span class="line"></span><br><span class="line"> 32/120 [=======&gt;......................] - ETA: 0s - loss: 0.3353 - sparse_categorical_accuracy: 1.0000</span><br><span class="line">120/120 [==============================] - 0s 23us/sample - loss: 0.3535 - sparse_categorical_accuracy: 0.9500</span><br><span class="line">Epoch 150/500</span><br><span class="line"></span><br><span class="line"> 32/120 [=======&gt;......................] - ETA: 0s - loss: 0.3871 - sparse_categorical_accuracy: 0.9688</span><br><span class="line">120/120 [==============================] - 0s 25us/sample - loss: 0.3718 - sparse_categorical_accuracy: 0.9417</span><br><span class="line">Epoch 300/500</span><br><span class="line"></span><br><span class="line"> 32/120 [=======&gt;......................] - ETA: 0s - loss: 0.3613 - sparse_categorical_accuracy: 0.9375</span><br><span class="line">120/120 [==============================] - 0s 21us/sample - loss: 0.3658 - sparse_categorical_accuracy: 0.9583</span><br><span class="line">Epoch 450/500</span><br><span class="line"></span><br><span class="line"> 32/120 [=======&gt;......................] - ETA: 0s - loss: 0.3630 - sparse_categorical_accuracy: 0.9688</span><br><span class="line">120/120 [==============================] - 0s 25us/sample - loss: 0.3486 - sparse_categorical_accuracy: 0.9583</span><br><span class="line">Epoch 500/500</span><br><span class="line"></span><br><span class="line"> 32/120 [=======&gt;......................] - ETA: 0s - loss: 0.3122 - sparse_categorical_accuracy: 0.9688</span><br><span class="line">120/120 [==============================] - 0s 66us/sample - loss: 0.3333 - sparse_categorical_accuracy: 0.9667 - val_loss: 0.4002 - val_sparse_categorical_accuracy: 1.0000</span><br><span class="line">Model: &quot;iris_model&quot;</span><br><span class="line">_________________________________________________________________</span><br><span class="line">Layer (type)                 Output Shape              Param #   </span><br><span class="line">=================================================================</span><br><span class="line">dense (Dense)                multiple                  15        </span><br><span class="line">=================================================================</span><br><span class="line">Total params: 15</span><br><span class="line">Trainable params: 15</span><br><span class="line">Non-trainable params: 0</span><br><span class="line">_________________________________________________________________</span><br></pre></td></tr></table></figure>
<h1 id="MNIST数据集"><a href="#MNIST数据集" class="headerlink" title="MNIST数据集"></a>MNIST数据集</h1><ul>
<li>数据集介绍</li>
</ul>
<p>MNIST 数据集一共有 7 万张图片，是 28×28 像素的 0 到 9 手写数字数据集，其中 6 万张用于训练， 1 万张用于测试。每张图片包括 784（28×28）个像素点，使用全连接网络时可将 784 个像素点组成长度为 784 的一维数组，作为输入特征。数据集图片如下所示。</p>
<img src="/2023/02/16/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%AE%9E%E8%B7%B5-Tensorflow%E7%AC%94%E8%AE%B0-MOOC-%E7%AC%AC%E4%B8%89%E8%AE%B2%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%85%AB%E8%82%A1/MNIST%E6%95%B0%E6%8D%AE%E9%9B%86%E5%9B%BE%E7%89%87%E5%B1%95%E7%A4%BA.png" class="" title="MNIST数据集图片展示">
<ul>
<li>导入MNIST数据集</li>
</ul>
<p><code>keras</code> 函数库中提供了使用 <code>mnist</code> 数据集的接口，代码如下所示，可以使用<code>load_data()</code>直接从 <code>mnist</code> 中读取测试集和训练集</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">mnist = tf.keras.datasets.mnist</span><br><span class="line">(x_train, y_train), (x_test, y_test) = mnist.load_data()</span><br></pre></td></tr></table></figure>
<ul>
<li>输入全连接网络时需要先将数据拉直为一维数组，把 784 个像素点的灰度值作为输入特征输入神经网络。</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">tf.keras.layers.Flatten()</span><br><span class="line"><span class="comment"># [ 0 0 0 48 238 252 252 …… …… …… 253 186 12 0 0 0 0 0]</span></span><br></pre></td></tr></table></figure>
<ul>
<li>使用 <code>plt</code> 库中的两个函数可视化训练集中的图片。</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">plt.imshow(x_train[<span class="number">0</span>], cmap=<span class="string">&#x27;gray&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<img src="/2023/02/16/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%AE%9E%E8%B7%B5-Tensorflow%E7%AC%94%E8%AE%B0-MOOC-%E7%AC%AC%E4%B8%89%E8%AE%B2%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%85%AB%E8%82%A1/%E5%8F%AF%E8%A7%86%E5%8C%96%E8%AE%AD%E7%BB%83%E9%9B%86%E4%B8%AD%E7%9A%84%E5%9B%BE%E7%89%87.png" class="" title="可视化训练集中的图片">
<ul>
<li>使用 print 打印出训练集中第一个样本以二位数组的形式打印出来，如下所示。</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(<span class="string">&quot;x_train[0]:&quot;</span>, x_train[<span class="number">0</span>])</span><br></pre></td></tr></table></figure>
<img src="/2023/02/16/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%AE%9E%E8%B7%B5-Tensorflow%E7%AC%94%E8%AE%B0-MOOC-%E7%AC%AC%E4%B8%89%E8%AE%B2%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%85%AB%E8%82%A1/%E6%89%93%E5%8D%B0%E7%9A%84%E5%8F%AF%E8%A7%86%E5%8C%96%E5%9B%BE%E7%89%87.png" class="" title="打印的可视化图片">
<ul>
<li>打印出第一个样本的标签，为 5。</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(<span class="string">&quot;y_train[0]:&quot;</span>, y_train[<span class="number">0</span>])</span><br><span class="line"><span class="comment"># y_train[0]:5</span></span><br></pre></td></tr></table></figure>
<ul>
<li>打印出测试集样本的形状，共有 10000 个 28 行 28 列的三维数据。</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(<span class="string">&quot;x_test.shape:&quot;</span>, x_test.shape)</span><br><span class="line"><span class="comment"># x_test.shape:(10000, 28, 28)</span></span><br></pre></td></tr></table></figure>
<ul>
<li>完整代码</li>
</ul>
<p><code>p13_mnist_datasets.py</code></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line">mnist = tf.keras.datasets.mnist</span><br><span class="line">(x_train, y_train), (x_test, y_test) = mnist.load_data()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 可视化训练集输入特征的第一个元素</span></span><br><span class="line">plt.imshow(x_train[<span class="number">0</span>], cmap=<span class="string">&#x27;gray&#x27;</span>)  <span class="comment"># 绘制灰度图</span></span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 打印出训练集输入特征的第一个元素</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;x_train[0]:\n&quot;</span>, x_train[<span class="number">0</span>])</span><br><span class="line"><span class="comment"># 打印出训练集标签的第一个元素</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;y_train[0]:\n&quot;</span>, y_train[<span class="number">0</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 打印出整个训练集输入特征形状</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;x_train.shape:\n&quot;</span>, x_train.shape)</span><br><span class="line"><span class="comment"># 打印出整个训练集标签的形状</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;y_train.shape:\n&quot;</span>, y_train.shape)</span><br><span class="line"><span class="comment"># 打印出整个测试集输入特征的形状</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;x_test.shape:\n&quot;</span>, x_test.shape)</span><br><span class="line"><span class="comment"># 打印出整个测试集标签的形状</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;y_test.shape:\n&quot;</span>, y_test.shape)</span><br></pre></td></tr></table></figure>
<h1 id="训练MNIST数据集"><a href="#训练MNIST数据集" class="headerlink" title="训练MNIST数据集"></a>训练MNIST数据集</h1><h2 id="使用-Sequential-实现手写数字识别"><a href="#使用-Sequential-实现手写数字识别" class="headerlink" title="使用 Sequential 实现手写数字识别"></a>使用 Sequential 实现手写数字识别</h2><p><code>p14_mnist_sequential.py</code></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line">mnist = tf.keras.datasets.mnist</span><br><span class="line">(x_train, y_train), (x_test, y_test) = mnist.load_data()</span><br><span class="line"><span class="comment"># 输入特征归一化，使得原本0-255之间的灰度值变为0-1之间数值</span></span><br><span class="line"><span class="comment"># 输入特征的数值变小更适合神经网络吸收</span></span><br><span class="line">x_train, x_test = x_train / <span class="number">255.0</span>, x_test / <span class="number">255.0</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 搭建Sequential数组</span></span><br><span class="line"><span class="comment"># 先把输入特拉直为一维数组</span></span><br><span class="line"><span class="comment"># 第一层网络128个神经元</span></span><br><span class="line"><span class="comment"># 第二层网络10个神经元</span></span><br><span class="line">model = tf.keras.models.Sequential([</span><br><span class="line">    tf.keras.layers.Flatten(),</span><br><span class="line">    tf.keras.layers.Dense(<span class="number">128</span>, activation=<span class="string">&#x27;relu&#x27;</span>),</span><br><span class="line">    tf.keras.layers.Dense(<span class="number">10</span>, activation=<span class="string">&#x27;softmax&#x27;</span>)</span><br><span class="line">])</span><br><span class="line"></span><br><span class="line"><span class="comment"># compile配置训练方法</span></span><br><span class="line"><span class="comment"># 优化器选择adam</span></span><br><span class="line"><span class="comment"># 损失函数选择sparse_categorical_accuracy</span></span><br><span class="line"><span class="comment"># 输出满足概率分布，from_logits=False</span></span><br><span class="line">model.<span class="built_in">compile</span>(optimizer=<span class="string">&#x27;adam&#x27;</span>, loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=<span class="literal">False</span>), metrics=[<span class="string">&#x27;sparse_categorical_accuracy&#x27;</span>])</span><br><span class="line"></span><br><span class="line">model.fit(x_train, y_train, batch_size=<span class="number">32</span>, epochs=<span class="number">5</span>, validation_data=(x_test, y_test), validation_freq=<span class="number">1</span>)</span><br><span class="line">model.summary()</span><br></pre></td></tr></table></figure>
<p>是使用测试集测试的准确率</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">60000/60000 [==============================] - 3s 48us/sample - loss: 0.0455 - sparse_categorical_accuracy: 0.9852 - val_loss: 0.0700 - val_sparse_categorical_accuracy: 0.9789</span><br><span class="line">Model: &quot;sequential&quot;</span><br><span class="line">_________________________________________________________________</span><br><span class="line">Layer (type)                 Output Shape              Param #   </span><br><span class="line">=================================================================</span><br><span class="line">flatten (Flatten)            multiple                  0         </span><br><span class="line">_________________________________________________________________</span><br><span class="line">dense (Dense)                multiple                  100480    </span><br><span class="line">_________________________________________________________________</span><br><span class="line">dense_1 (Dense)              multiple                  1290      </span><br><span class="line">=================================================================</span><br><span class="line">Total params: 101,770</span><br><span class="line">Trainable params: 101,770</span><br><span class="line">Non-trainable params: 0</span><br><span class="line">_________________________________________________________________</span><br></pre></td></tr></table></figure>
<h2 id="使用-class-实现手写数字识别"><a href="#使用-class-实现手写数字识别" class="headerlink" title="使用 class 实现手写数字识别"></a>使用 class 实现手写数字识别</h2><p><code>p15_mnist_class.py</code></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras.layers <span class="keyword">import</span> Dense, Flatten</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras <span class="keyword">import</span> Model</span><br><span class="line"></span><br><span class="line">mnist = tf.keras.datasets.mnist</span><br><span class="line">(x_train, y_train), (x_test, y_test) = mnist.load_data()</span><br><span class="line">x_train, x_test = x_train / <span class="number">255.0</span>, x_test / <span class="number">255.0</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#####</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">MnistModel</span>(<span class="title class_ inherited__">Model</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>(MnistModel, self).__init__()</span><br><span class="line">        self.flatten = Flatten()</span><br><span class="line">        self.d1 = Dense(<span class="number">128</span>, activation=<span class="string">&#x27;relu&#x27;</span>)</span><br><span class="line">        self.d2 = Dense(<span class="number">10</span>, activation=<span class="string">&#x27;softmax&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">call</span>(<span class="params">self, x</span>):</span><br><span class="line">        x = self.flatten(x)</span><br><span class="line">        x = self.d1(x)</span><br><span class="line">        y = self.d2(x)</span><br><span class="line">        <span class="keyword">return</span> y</span><br><span class="line"><span class="comment">#####</span></span><br><span class="line"></span><br><span class="line">model = MnistModel()</span><br><span class="line"></span><br><span class="line">model.<span class="built_in">compile</span>(optimizer=<span class="string">&#x27;adam&#x27;</span>, loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=<span class="literal">False</span>), metrics=[<span class="string">&#x27;sparse_categorical_accuracy&#x27;</span>])</span><br><span class="line"></span><br><span class="line">model.fit(x_train, y_train, batch_size=<span class="number">32</span>, epochs=<span class="number">5</span>, validation_data=(x_test, y_test), validation_freq=<span class="number">1</span>)</span><br><span class="line">model.summary()</span><br></pre></td></tr></table></figure>
<p>训练时每个 step 给出的是训练集 accuracy 不具有参考价值，有实际评判价值的是 validation_freq 中设置的隔若干轮输出的测试集 accuracy。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">60000/60000 [==============================] - 3s 48us/sample - loss: 0.0440 - sparse_categorical_accuracy: 0.9869 - val_loss: 0.0836 - val_sparse_categorical_accuracy: 0.9741</span><br><span class="line">Model: &quot;mnist_model&quot;</span><br><span class="line">_________________________________________________________________</span><br><span class="line">Layer (type)                 Output Shape              Param #   </span><br><span class="line">=================================================================</span><br><span class="line">flatten (Flatten)            multiple                  0         </span><br><span class="line">_________________________________________________________________</span><br><span class="line">dense (Dense)                multiple                  100480    </span><br><span class="line">_________________________________________________________________</span><br><span class="line">dense_1 (Dense)              multiple                  1290      </span><br><span class="line">=================================================================</span><br><span class="line">Total params: 101,770</span><br><span class="line">Trainable params: 101,770</span><br><span class="line">Non-trainable params: 0</span><br><span class="line">_________________________________________________________________</span><br></pre></td></tr></table></figure>
<h1 id="Fashion数据集"><a href="#Fashion数据集" class="headerlink" title="Fashion数据集"></a>Fashion数据集</h1><p><code>Fashion_mnis</code>t 数据集具有 <code>mnist</code> 近乎所有的特征，包括 60000 张训练图片和 10000 张测试图片，图片被分为十类，每张图像为 28×28 的分辨率。</p>
<p>类别如下所示：</p>
<img src="/2023/02/16/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%AE%9E%E8%B7%B5-Tensorflow%E7%AC%94%E8%AE%B0-MOOC-%E7%AC%AC%E4%B8%89%E8%AE%B2%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%85%AB%E8%82%A1/Fashion%E6%95%B0%E6%8D%AE%E9%9B%86%E7%B1%BB%E5%88%AB.png" class="" title="Fashion数据集类别">
<p>图片示例如下：</p>
<img src="/2023/02/16/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%AE%9E%E8%B7%B5-Tensorflow%E7%AC%94%E8%AE%B0-MOOC-%E7%AC%AC%E4%B8%89%E8%AE%B2%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%85%AB%E8%82%A1/Fashion%E6%95%B0%E6%8D%AE%E9%9B%86%E7%A4%BA%E4%BE%8B.png" class="" title="Fashion数据集示例">
<p>由于 <code>Fashion_mnist</code> 数据集和 <code>mnist</code> 数据集具有相似的属性，所以对于 <code>mnist</code> 只需讲 <code>mnist</code> 数据集的加载换成 <code>Fashion_mnist</code> 就可以训练 <code>Fashion</code> 数据集了</p>
<ul>
<li>sequential构建</li>
</ul>
<p><code>p16_fashion_sequential.py</code></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line">fashion = tf.keras.datasets.fashion_mnist</span><br><span class="line">(x_train, y_train),(x_test, y_test) = fashion.load_data()</span><br><span class="line">x_train, x_test = x_train / <span class="number">255.0</span>, x_test / <span class="number">255.0</span></span><br><span class="line"></span><br><span class="line">model = tf.keras.models.Sequential([</span><br><span class="line">    tf.keras.layers.Flatten(),</span><br><span class="line">    tf.keras.layers.Dense(<span class="number">128</span>, activation=<span class="string">&#x27;relu&#x27;</span>),</span><br><span class="line">    tf.keras.layers.Dense(<span class="number">10</span>, activation=<span class="string">&#x27;softmax&#x27;</span>)</span><br><span class="line">])</span><br><span class="line"></span><br><span class="line">model.<span class="built_in">compile</span>(optimizer=<span class="string">&#x27;adam&#x27;</span>, loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=<span class="literal">False</span>), metrics=[<span class="string">&#x27;sparse_categorical_accuracy&#x27;</span>])</span><br><span class="line"></span><br><span class="line">model.fit(x_train, y_train, batch_size=<span class="number">32</span>, epochs=<span class="number">5</span>, validation_data=(x_test, y_test), validation_freq=<span class="number">1</span>)</span><br><span class="line">model.summary()</span><br></pre></td></tr></table></figure>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">60000/60000 [==============================] - 3s 48us/sample - loss: 0.2981 - sparse_categorical_accuracy: 0.8900 - val_loss: 0.3429 - val_sparse_categorical_accuracy: 0.8777</span><br><span class="line">Model: &quot;sequential&quot;</span><br><span class="line">_________________________________________________________________</span><br><span class="line">Layer (type)                 Output Shape              Param #   </span><br><span class="line">=================================================================</span><br><span class="line">flatten (Flatten)            multiple                  0         </span><br><span class="line">_________________________________________________________________</span><br><span class="line">dense (Dense)                multiple                  100480    </span><br><span class="line">_________________________________________________________________</span><br><span class="line">dense_1 (Dense)              multiple                  1290      </span><br><span class="line">=================================================================</span><br><span class="line">Total params: 101,770</span><br><span class="line">Trainable params: 101,770</span><br><span class="line">Non-trainable params: 0</span><br><span class="line">_________________________________________________________________</span><br></pre></td></tr></table></figure>
<ul>
<li>class构建</li>
</ul>
<p><code>p16_fashion_class.py</code></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras.layers <span class="keyword">import</span> Dense, Flatten</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras <span class="keyword">import</span> Model</span><br><span class="line"></span><br><span class="line">fashion = tf.keras.datasets.fashion_mnist</span><br><span class="line">(x_train, y_train),(x_test, y_test) = fashion.load_data()</span><br><span class="line">x_train, x_test = x_train / <span class="number">255.0</span>, x_test / <span class="number">255.0</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">MnistModel</span>(<span class="title class_ inherited__">Model</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>(MnistModel, self).__init__()</span><br><span class="line">        self.flatten = Flatten()</span><br><span class="line">        self.d1 = Dense(<span class="number">128</span>, activation=<span class="string">&#x27;relu&#x27;</span>)</span><br><span class="line">        self.d2 = Dense(<span class="number">10</span>, activation=<span class="string">&#x27;softmax&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">call</span>(<span class="params">self, x</span>):</span><br><span class="line">        x = self.flatten(x)</span><br><span class="line">        x = self.d1(x)</span><br><span class="line">        y = self.d2(x)</span><br><span class="line">        <span class="keyword">return</span> y</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">model = MnistModel()</span><br><span class="line"></span><br><span class="line">model.<span class="built_in">compile</span>(optimizer=<span class="string">&#x27;adam&#x27;</span>,</span><br><span class="line">              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=<span class="literal">False</span>),</span><br><span class="line">              metrics=[<span class="string">&#x27;sparse_categorical_accuracy&#x27;</span>])</span><br><span class="line"></span><br><span class="line">model.fit(x_train, y_train, batch_size=<span class="number">32</span>, epochs=<span class="number">5</span>, validation_data=(x_test, y_test), validation_freq=<span class="number">1</span>)</span><br><span class="line">model.summary()</span><br></pre></td></tr></table></figure>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">60000/60000 [==============================] - 3s 48us/sample - loss: 0.2965 - sparse_categorical_accuracy: 0.8910 - val_loss: 0.3379 - val_sparse_categorical_accuracy: 0.8780</span><br><span class="line">Model: &quot;mnist_model&quot;</span><br><span class="line">_________________________________________________________________</span><br><span class="line">Layer (type)                 Output Shape              Param #   </span><br><span class="line">=================================================================</span><br><span class="line">flatten (Flatten)            multiple                  0         </span><br><span class="line">_________________________________________________________________</span><br><span class="line">dense (Dense)                multiple                  100480    </span><br><span class="line">_________________________________________________________________</span><br><span class="line">dense_1 (Dense)              multiple                  1290      </span><br><span class="line">=================================================================</span><br><span class="line">Total params: 101,770</span><br><span class="line">Trainable params: 101,770</span><br><span class="line">Non-trainable params: 0</span><br><span class="line">_________________________________________________________________</span><br></pre></td></tr></table></figure></div></article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="mailto:undefined">HibisciDai</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="http://hibiscidai.com/2023/02/16/人工智能实践-Tensorflow笔记-MOOC-第三讲神经网络八股/">http://hibiscidai.com/2023/02/16/人工智能实践-Tensorflow笔记-MOOC-第三讲神经网络八股/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a target="_blank" rel="noopener" href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="http://hibiscidai.com">HibisciDai</a>！</span></div></div><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/">学习笔记</a><a class="post-meta__tags" href="/tags/Tensorflow/">Tensorflow</a><a class="post-meta__tags" href="/tags/TensorflowMOOC/">TensorflowMOOC</a></div><div class="social-share pull-right" data-disabled="linkedin,diandian"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/social-share.js@1.0.16/dist/css/share.min.css"><script src="https://cdn.jsdelivr.net/npm/social-share.js@1.0.16/dist/js/social-share.min.js"></script><nav id="pagination"><div class="prev-post pull-left"><a href="/2023/02/16/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%AE%9E%E8%B7%B5-Tensorflow%E7%AC%94%E8%AE%B0-MOOC-%E7%AC%AC%E4%B8%80%E8%AE%B2%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E8%AE%A1%E7%AE%97/"><i class="fa fa-chevron-left">  </i><span>人工智能实践-Tensorflow笔记-MOOC-第一讲神经网络计算</span></a></div><div class="next-post pull-right"><a href="/2023/02/16/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%AE%9E%E8%B7%B5-Tensorflow%E7%AC%94%E8%AE%B0-MOOC-%E7%AC%AC%E4%BA%94%E8%AE%B2%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"><span>人工智能实践-Tensorflow笔记-MOOC-第五讲卷积神经网络</span><i class="fa fa-chevron-right"></i></a></div></nav><div class="post-adv"><a target="_blank" rel="noopener" href="https://www.paofu.cloud/auth/register?code=j4I7">好用、实惠、稳定的梯子,点击这里<img src="https://pic.imgdb.cn/item/65572abac458853aefef30cd.png" width="1000" height="124" object-fit="cover" ></a></div><div id="lv-container" data-id="city" data-uid="MTAyMC8zNTQ2NC8xMjAwMA=="><script>(function(d, s) {
    var j, e = d.getElementsByTagName(s)[0];
    if (typeof LivereTower === 'function') { return; }
    j = d.createElement(s);
    j.src = 'https://cdn-city.livere.com/js/embed.dist.js';
    j.async = true;
    e.parentNode.insertBefore(j, e);
})(document, 'script');</script></div></div></div><footer class="footer-bg" style="background-image: url(/img/banner2.jpg)"><div class="layout" id="footer"><div class="copyright">&copy;2017 - 2025 By HibisciDai</div><div class="framework-info"><span>驱动 - </span><a target="_blank" rel="noopener" href="http://hexo.io"><span>Hexo</span></a><span class="footer-separator">|</span><span>主题 - </span><a target="_blank" rel="noopener" href="https://github.com/Molunerfinn/hexo-theme-melody"><span>Melody</span></a></div><div class="footer_custom_text">hitokoto</div><div class="busuanzi"><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><span id="busuanzi_container_page_pv"><i class="fa fa-file"></i><span id="busuanzi_value_page_pv"></span><span></span></span></div></div></footer><i class="fa fa-arrow-up" id="go-up" aria-hidden="true"></i><script src="/js/third-party/anime.min.js"></script><script src="/js/third-party/jquery.min.js"></script><script src="/js/third-party/jquery.fancybox.min.js"></script><script src="/js/third-party/velocity.min.js"></script><script src="/js/third-party/velocity.ui.min.js"></script><script src="/js/utils.js?version=1.9.0"></script><script src="/js/fancybox.js?version=1.9.0"></script><script src="/js/sidebar.js?version=1.9.0"></script><script src="/js/copy.js?version=1.9.0"></script><script src="/js/fireworks.js?version=1.9.0"></script><script src="/js/transition.js?version=1.9.0"></script><script src="/js/scroll.js?version=1.9.0"></script><script src="/js/head.js?version=1.9.0"></script><script type="text/x-mathjax-config">MathJax.Hub.Config({
  tex2jax: {
    inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
    processEscapes: true,
    skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
  },
  CommonHTML: {
    linebreaks: { automatic: true, width: "90% container" }
  },
  "HTML-CSS": { 
    linebreaks: { automatic: true, width: "90% container" }
  },
  "SVG": { 
    linebreaks: { automatic: true, width: "90% container" }
  }
});
</script><script type="text/x-mathjax-config">MathJax.Hub.Queue(function() {
  var all = MathJax.Hub.getAllJax(), i;
  for (i=0; i < all.length; i += 1) {
    all[i].SourceElement().parentNode.className += ' has-jax';
  }
});
</script><script src="https://cdn.bootcss.com/mathjax/2.7.2/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/katex@latest/dist/katex.min.css"><script src="https://cdn.jsdelivr.net/npm/katex-copytex@latest/dist/katex-copytex.min.js"></script><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/katex-copytex@latest/dist/katex-copytex.min.css"><script src="/js/katex.js"></script><script src="/js/search/local-search.js"></script><script id="ribbon" src="/js/third-party/canvas-ribbon.js" size="150" alpha="0.6" zIndex="-1" data-click="false"></script><script>if(/Android|webOS|iPhone|iPod|iPad|BlackBerry/i.test(navigator.userAgent)) {
  $('#nav').addClass('is-mobile')
  $('footer').addClass('is-mobile')
  $('#top-container').addClass('is-mobile')
}</script><div class="search-dialog" id="local-search"><div class="search-dialog__title" id="local-search-title">本地搜索</div><div id="local-input-panel"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章"></div></div></div><hr><div id="local-search-results"><div id="local-hits"></div><div id="local-stats"><div class="local-search-stats__hr" id="hr"><span>由</span> <a target="_blank" rel="noopener" href="https://github.com/wzpan/hexo-generator-search" style="color:#49B1F5;">hexo-generator-search</a>
 <span>提供支持</span></div></div></div><span class="search-close-button"><i class="fa fa-times"></i></span></div><div class="search-mask"></div></body></html>