<!DOCTYPE html><html lang="zh-Hans"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta name="description" content="实用Python程序设计MOOC-第十二章网络爬虫设计"><meta name="keywords" content="学习笔记,Python,PythonMOOC"><meta name="author" content="HibisciDai"><meta name="copyright" content="HibisciDai"><title>实用Python程序设计MOOC-第十二章网络爬虫设计 | HibisciDai</title><link rel="shortcut icon" href="/img/avatar.png"><link rel="stylesheet" href="/css/index.css?version=1.9.0"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/font-awesome@latest/css/font-awesome.min.css?version=1.9.0"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.7.2/css/all.css?version=1.9.0"><meta name="format-detection" content="telephone=no"><meta http-equiv="x-dns-prefetch-control" content="on"><link rel="dns-prefetch" href="https://cdn.jsdelivr.net"><link rel="manifest" href="/manifest.json"><link rel="manifest" href="/manifest.json"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><script src="https://v1.hitokoto.cn/?encode=js&amp;charset=utf-8&amp;select=.footer_custom_text" defer></script><script>var GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: {"path":"search.xml","languages":{"hits_empty":"找不到您查询的内容:${query}"}},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  hexoVersion: '6.1.0'
} </script><meta name="generator" content="Hexo 6.1.0"><link rel="alternate" href="/atom.xml" title="HibisciDai" type="application/atom+xml">
</head><body><canvas class="fireworks"></canvas><i class="fa fa-arrow-right" id="toggle-sidebar" aria-hidden="true"></i><div id="sidebar" data-display="true"><div class="toggle-sidebar-info text-center"><span data-toggle="切换文章详情">切换站点概览</span><hr></div><div class="sidebar-toc"><div class="sidebar-toc__title">目录</div><div class="sidebar-toc__progress"><span class="progress-notice">你已经读了</span><span class="progress-num">0</span><span class="progress-percentage">%</span><div class="sidebar-toc__progress-bar"></div></div><div class="sidebar-toc__content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%AE%9E%E7%94%A8Python%E7%A8%8B%E5%BA%8F%E8%AE%BE%E8%AE%A1MOOC-%E7%AC%AC%E5%8D%81%E4%BA%8C%E7%AB%A0%E7%BD%91%E7%BB%9C%E7%88%AC%E8%99%AB%E8%AE%BE%E8%AE%A1"><span class="toc-number">1.</span> <span class="toc-text">实用Python程序设计MOOC-第十二章网络爬虫设计</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E7%88%AC%E8%99%AB%E5%9F%BA%E6%9C%AC%E5%8E%9F%E7%90%86"><span class="toc-number">2.</span> <span class="toc-text">爬虫基本原理</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%88%AC%E8%99%AB%E7%9A%84%E7%94%A8%E9%80%94%E5%92%8C%E5%8E%9F%E7%90%86"><span class="toc-number">2.1.</span> <span class="toc-text">爬虫的用途和原理</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%9C%80%E5%9F%BA%E6%9C%AC%E7%9A%84%E7%88%AC%E8%99%AB%E5%86%99%E6%B3%95"><span class="toc-number">2.2.</span> <span class="toc-text">最基本的爬虫写法</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%A4%BA%E4%BE%8B%EF%BC%9A%E8%8E%B7%E5%8F%96%E7%99%BE%E5%BA%A6%E5%9B%BE%E7%89%87%E7%9A%84%E6%90%9C%E7%B4%A2%E7%BB%93%E6%9E%9C%E5%9B%BE%E7%89%87"><span class="toc-number">2.3.</span> <span class="toc-text">示例：获取百度图片的搜索结果图片</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E7%94%A8requests%E5%BA%93%E8%8E%B7%E5%8F%96%E7%BD%91%E9%A1%B5"><span class="toc-number">3.</span> <span class="toc-text">用requests库获取网页</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%94%A8requests-get%E8%8E%B7%E5%8F%96%E7%BD%91%E9%A1%B5"><span class="toc-number">3.1.</span> <span class="toc-text">用requests.get获取网页</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%94%A8requests-get%E8%8E%B7%E5%8F%96%E7%BD%91%E9%A1%B5%EF%BC%88%E7%BC%96%E7%A0%81%E8%AF%86%E5%88%AB%E5%8A%A0%E5%BC%BA%E7%89%88"><span class="toc-number">3.2.</span> <span class="toc-text">用requests.get获取网页（编码识别加强版)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%94%A8requests%E5%BA%93%E8%8E%B7%E5%8F%96%E7%BD%91%E9%A1%B5%E7%9A%84%E4%BC%98%E5%8A%BF%E5%92%8C%E5%B1%80%E9%99%90"><span class="toc-number">3.3.</span> <span class="toc-text">用requests库获取网页的优势和局限</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%BC%A5%E8%A1%A5requests%E4%B8%8D%E8%B6%B3%E7%9A%84%E5%85%B6%E5%AE%83%E8%8E%B7%E5%8F%96%E7%BD%91%E9%A1%B5%E7%9A%84%E5%8A%9E%E6%B3%95"><span class="toc-number">3.4.</span> <span class="toc-text">弥补requests不足的其它获取网页的办法</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E7%94%A8selenium%E5%BA%93%E8%8E%B7%E5%8F%96%E7%BD%91%E9%A1%B5"><span class="toc-number">4.</span> <span class="toc-text">用selenium库获取网页</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%94%A8selenium%E8%8E%B7%E5%8F%96%E7%BD%91%E9%A1%B5"><span class="toc-number">4.1.</span> <span class="toc-text">用selenium获取网页</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%94%A8pyppeteer%E5%BA%93%E8%8E%B7%E5%8F%96%E7%BD%91%E9%A1%B5"><span class="toc-number">4.2.</span> <span class="toc-text">用pyppeteer库获取网页</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%8E%AF%E5%A2%83%E5%AE%89%E8%A3%85"><span class="toc-number">4.2.1.</span> <span class="toc-text">环境安装</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%A2%84%E5%A4%87%E7%9F%A5%E8%AF%86%EF%BC%9A%E5%8D%8F%E7%A8%8B"><span class="toc-number">4.2.2.</span> <span class="toc-text">预备知识：协程</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%94%A8pyppeteer%E8%8E%B7%E5%8F%96%E7%BD%91%E9%A1%B5"><span class="toc-number">4.2.3.</span> <span class="toc-text">用pyppeteer获取网页</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%94%A8BeautifulSoup%E5%BA%93%E5%88%86%E6%9E%90%E7%BD%91%E9%A1%B5"><span class="toc-number">4.3.</span> <span class="toc-text">用BeautifulSoup库分析网页</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%88%86%E6%9E%90%E5%B9%B6%E6%8F%90%E5%8F%96%E7%BD%91%E9%A1%B5%E5%86%85%E5%AE%B9%E7%9A%84%E4%B8%89%E7%A7%8D%E6%96%B9%E5%BC%8F"><span class="toc-number">4.3.1.</span> <span class="toc-text">分析并提取网页内容的三种方式</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#html%E6%96%87%E6%A1%A3-%E7%BD%91%E9%A1%B5-%E4%B8%AD%E7%9A%84tag"><span class="toc-number">4.3.2.</span> <span class="toc-text">html文档(网页)中的tag</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#tag%E5%8F%AF%E4%BB%A5%E5%B5%8C%E5%A5%97"><span class="toc-number">4.3.3.</span> <span class="toc-text">tag可以嵌套</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%94%A8BeautifulSoup%E5%BA%93%E5%88%86%E6%9E%90html"><span class="toc-number">4.3.4.</span> <span class="toc-text">用BeautifulSoup库分析html</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%8A%8Ahtml%E6%96%87%E6%A1%A3%E8%BD%BD%E5%85%A5BeautifulSoup%E5%AF%B9%E8%B1%A1"><span class="toc-number">4.3.5.</span> <span class="toc-text">把html文档载入BeautifulSoup对象</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%AE%9E%E4%BE%8B%EF%BC%9A%E7%94%A8BeautifulSoup%E5%AF%B9%E8%B1%A1%E5%AF%BB%E6%89%BE%E6%83%B3%E8%A6%81%E7%9A%84tag"><span class="toc-number">4.3.6.</span> <span class="toc-text">实例：用BeautifulSoup对象寻找想要的tag</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%AE%9E%E4%BE%8B%EF%BC%9A%E7%88%AC%E5%8F%96%E6%AF%8F%E6%97%A5%E8%82%A1%E7%A5%A8%E4%BA%A4%E6%98%93%E4%BF%A1%E6%81%AF"><span class="toc-number">4.4.</span> <span class="toc-text">实例：爬取每日股票交易信息</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E9%9C%80%E8%A6%81%E7%99%BB%E5%BD%95%E7%9A%84%E7%88%AC%E8%99%AB"><span class="toc-number">4.5.</span> <span class="toc-text">需要登录的爬虫</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%88%AC%E5%8F%96Openjudge%E8%87%AA%E5%B7%B1%E6%8F%90%E4%BA%A4%E9%80%9A%E8%BF%87%E7%9A%84%E6%89%80%E6%9C%89%E7%A8%8B%E5%BA%8F%E6%BA%90%E7%A0%81"><span class="toc-number">4.5.1.</span> <span class="toc-text">爬取Openjudge自己提交通过的所有程序源码</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#pyppeteer-requests%E7%BC%96%E5%86%99%E5%BF%AB%E9%80%9F%E7%88%AC%E8%99%AB"><span class="toc-number">4.6.</span> <span class="toc-text">pyppeteer+requests编写快速爬虫</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%A2%84%E5%A4%87%E7%9F%A5%E8%AF%86%EF%BC%9A-cookie%E5%92%8Csession"><span class="toc-number">4.6.1.</span> <span class="toc-text">预备知识： cookie和session</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%B7%A5%E4%BD%9C%E5%8E%9F%E7%90%86"><span class="toc-number">4.6.2.</span> <span class="toc-text">工作原理</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E8%A1%A5%E5%85%85tips"><span class="toc-number">5.</span> <span class="toc-text">补充tips</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%BB%9D%E5%AF%B9%E7%BD%91%E5%9D%80%E5%92%8C%E7%9B%B8%E5%AF%B9%E7%BD%91%E5%9D%80"><span class="toc-number">5.1.</span> <span class="toc-text">绝对网址和相对网址</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%8F%8D%E5%8F%8D%E7%88%AC"><span class="toc-number">5.2.</span> <span class="toc-text">反反爬</span></a></li></ol></li></ol></div></div><div class="author-info hide"><div class="author-info__avatar text-center"><img src="/img/Avatar.png"></div><div class="author-info__name text-center">HibisciDai</div><div class="author-info__description text-center">HibisciDai'Blog</div><hr><div class="author-info-articles"><a class="author-info-articles__archives article-meta" href="/archives"><span class="pull-left">文章</span><span class="pull-right">224</span></a><a class="author-info-articles__tags article-meta" href="/tags"><span class="pull-left">标签</span><span class="pull-right">77</span></a><a class="author-info-articles__categories article-meta" href="/categories"><span class="pull-left">分类</span><span class="pull-right">30</span></a></div><hr><div class="author-info-links"><div class="author-info-links__title text-center">友情链接</div><a class="author-info-links__name text-center" target="_blank" rel="noopener" href="https://github.com/HibisciDai/hexo-theme-melody">HexoTheme-github</a><a class="author-info-links__name text-center" target="_blank" rel="noopener" href="https://molunerfinn.com/">molunerfinn</a></div></div></div><div id="content-outer"><div id="top-container" style="background-image: url(/img/banner2.jpg)"><div id="page-header"><span class="pull-left"> <a id="site-name" href="/">HibisciDai</a></span><i class="fa fa-bars toggle-menu pull-right" aria-hidden="true"></i><span class="pull-right menus">   <a class="site-page" href="/">主页</a><a class="site-page" href="/about">关于我</a><a class="site-page" href="/archives">归档</a><a class="site-page" href="/tags">标签</a><a class="site-page" href="/categories">分类</a><a class="site-page" href="/gallery">相册</a></span><span class="pull-right"><a class="site-page social-icon search"><i class="fa fa-search"></i><span> 搜索</span></a></span></div><div id="post-info"><div id="post-title">实用Python程序设计MOOC-第十二章网络爬虫设计</div><div id="post-meta"><time class="post-meta__date"><i class="fa fa-calendar" aria-hidden="true"></i> 2023-02-02</time><span class="post-meta__separator">|</span><i class="fa fa-inbox post-meta__icon" aria-hidden="true"></i><a class="post-meta__categories" href="/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/">学习笔记</a><div class="post-meta-wordcount"><span>字数总计: </span><span class="word-count">6.9k</span><span class="post-meta__separator">|</span><span>阅读时长: 30 分钟</span></div></div></div></div><div class="layout" id="content-inner"><article id="post"><div class="article-container" id="post-content"><img src="/2023/02/02/%E5%AE%9E%E7%94%A8Python%E7%A8%8B%E5%BA%8F%E8%AE%BE%E8%AE%A1MOOC-%E7%AC%AC%E5%8D%81%E4%BA%8C%E7%AB%A0%E7%BD%91%E7%BB%9C%E7%88%AC%E8%99%AB%E8%AE%BE%E8%AE%A1/%E5%AE%9E%E7%94%A8Python%E7%A8%8B%E5%BA%8F%E8%AE%BE%E8%AE%A1MOOC-%E7%AC%AC%E5%8D%81%E4%BA%8C%E7%AB%A0%E7%BD%91%E7%BB%9C%E7%88%AC%E8%99%AB%E8%AE%BE%E8%AE%A1.png" class="" title="实用Python程序设计MOOC-第十二章网络爬虫设计">
<p>实用Python程序设计MOOC-第十二章网络爬虫设计</p>
<span id="more"></span>
<p>[TOC]</p>
<h1 id="实用Python程序设计MOOC-第十二章网络爬虫设计"><a href="#实用Python程序设计MOOC-第十二章网络爬虫设计" class="headerlink" title="实用Python程序设计MOOC-第十二章网络爬虫设计"></a>实用Python程序设计MOOC-第十二章网络爬虫设计</h1><h1 id="爬虫基本原理"><a href="#爬虫基本原理" class="headerlink" title="爬虫基本原理"></a>爬虫基本原理</h1><h2 id="爬虫的用途和原理"><a href="#爬虫的用途和原理" class="headerlink" title="爬虫的用途和原理"></a>爬虫的用途和原理</h2><p>1) 在网络上搜集数据（比如搜索引擎）<br>2) 模拟浏览器快速操作（抢票，抢课，抢挂号…..)<br>3) 模拟浏览器操作，替代填表等重复操作</p>
<h2 id="最基本的爬虫写法"><a href="#最基本的爬虫写法" class="headerlink" title="最基本的爬虫写法"></a>最基本的爬虫写法</h2><p>数据获取型爬虫的本质就是自动获取网页并抽取其中的内容<br>1) 手工找出合适的url（网址） 。<br>2) 用浏览器手工查看url对应的网页，并查看网页源码，找出包含想要的内容（文件名，链接等）的字符串的模式。<br>3) 程序中获取url对应的网页。<br>4) 程序中用正则表达式或BeautifulSoup库抽取网页中想要的内容并保存。</p>
<h2 id="示例：获取百度图片的搜索结果图片"><a href="#示例：获取百度图片的搜索结果图片" class="headerlink" title="示例：获取百度图片的搜索结果图片"></a>示例：获取百度图片的搜索结果图片</h2><ol>
<li>/在百度图片敲关键字“desk”进行搜索</li>
<li><p>搜索后看浏览器地址栏的地址：<br><a target="_blank" rel="noopener" href="https://image.baidu.com/search/index?tn=baiduimage&amp;ipn=r&amp;ct=201326592&amp;cl=2&amp;lm=-1&amp;st=-1&amp;fm=index&amp;fr=&amp;hs=0&amp;xthttps=111111&amp;sf=1&amp;fmq=&amp;pv=&amp;ic=0&amp;nc=1&amp;z=&amp;se=1&amp;showtab=0&amp;fb=0&amp;width=&amp;height=&amp;face=0&amp;istype=2&amp;ie=utf-8&amp;word=desk&amp;oq=desk&amp;rsp=-1">搜索后看浏览器地址栏的地址</a></p>
</li>
<li><p>猜测只要在浏览器输入下面地址的word=内容，替换其中的单词，就能搜到图片：</p>
</li>
</ol>
<figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">https://image.baidu.com/search/index?tn=baiduimage&amp;ipn=r&amp;ct=201326592&amp;cl=2&amp;lm=-1&amp;st=-1&amp;fm=index&amp;fr=&amp;hs=0&amp;xthttps=111111&amp;sf=1&amp;fmq=&amp;pv=&amp;ic=0&amp;nc=1&amp;z=&amp;se=1&amp;showtab=0&amp;fb=0&amp;width=&amp;height=&amp;face=0&amp;istype=2&amp;ie=utf-8&amp;word=desk</span><br><span class="line"></span><br><span class="line">https://image.baidu.com/search/index?tn=baiduimage&amp;ipn=r&amp;ct=201326592&amp;cl=2&amp;lm=-1&amp;st=-1&amp;fm=index&amp;fr=&amp;hs=0&amp;xthttps=111111&amp;sf=1&amp;fmq=&amp;pv=&amp;ic=0&amp;nc=1&amp;z=&amp;se=1&amp;showtab=0&amp;fb=0&amp;width=&amp;height=&amp;face=0&amp;istype=2&amp;ie=utf-8&amp;word=猫</span><br></pre></td></tr></table></figure>
<p>浏览器输入后出现猫的搜索结果</p>
<ol>
<li><p>用浏览器访问刚才的url,并用浏览器查看源码(chrome)</p>
</li>
<li><p>在源码中查找</p>
</li>
</ol>
<p>复制出来的图片地址:<code>https://img1.baidu.com/it/u=716463119,473541077&amp;fm=26&amp;fmt=auto&amp;gp=0.jpg</code><br>为某张图片的网络地址，此链接是百度保存的缩略图的网址</p>
<p>查看网页源代码后搜索图片连接，找到源码：<br><code>716463119,473541077&amp;fm=26&amp;fmt=auto&amp;gp=0.jpg</code></p>
<p>发现图片链接在网页里都是这样的：<br><code>&#123;&quot;thumbURL&quot;:&quot;https://img1.baidu.com/it/u=716463119,473541077&amp;fm=26&amp;fmt=auto&amp;gp=0.sjpg&quot;, &quot;adType&quot;:&quot;0&quot;,&quot;midd</code></p>
<p>即thumbURL后跟的是图片连接。</p>
<p>可以用正则表达式提取图片链接</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> re</span><br><span class="line"><span class="keyword">import</span> requests <span class="comment">#request库用于获取网络资源 pip install requests</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">getHtml</span>(<span class="params">url</span>): <span class="comment">#获取网址为url的网页</span></span><br><span class="line"><span class="comment">#具体实现略，后面再讲述</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">getBaiduPictures</span>(<span class="params">word,n</span>):</span><br><span class="line"><span class="comment">#下载n个百度图片搜来的关于word的图片保存到本地</span></span><br><span class="line">	url=<span class="string">&quot;https://image.baidu.com/search/index?tn=baiduimage&amp;ipn=r&amp;ct=201326592&amp;cl=2&amp;lm=-1&amp;st=-1&amp;fm=index&amp;fr=&amp;hs=0&amp;xthttps=111111&amp;sf=1&amp;fmq=&amp;pv=&amp;ic=0&amp;nc=1&amp;z=&amp;se=1&amp;showtab=0&amp;fb=0&amp;width=&amp;height=&amp;face=0&amp;istype=2&amp;ie=utf-8&amp;word=&quot;</span></span><br><span class="line">	url += word</span><br><span class="line">	html = getHtml(url)</span><br><span class="line">	pt = <span class="string">&#x27;\&quot;thumbURL\&quot;:.*?\&quot;(.*?)\&quot;&#x27;</span> <span class="comment">#正则表达式，用于寻找图片网址</span></span><br><span class="line">	i = <span class="number">0</span></span><br><span class="line"><span class="comment">#&quot;thumbURL&quot;:&quot;https://img1.baidu.com/it/u=716463119,473541077&amp;fm=26&amp;fmt=auto&amp;gp=0.jpg&quot;,</span></span><br><span class="line">	<span class="keyword">for</span> x <span class="keyword">in</span> re.findall(pt, html): <span class="comment">#x就是图片url</span></span><br><span class="line">		<span class="built_in">print</span>(x)</span><br><span class="line">		x = x.lower()</span><br><span class="line">		<span class="keyword">try</span>:</span><br><span class="line">			r = requests.get(x, stream=<span class="literal">True</span>)<span class="comment">#获取x对应的网络资源</span></span><br><span class="line">			f = <span class="built_in">open</span>(<span class="string">&#x27;&#123;0&#125;&#123;1&#125;.jpg&#x27;</span>.<span class="built_in">format</span>(word,i), <span class="string">&quot;wb&quot;</span>)</span><br><span class="line">			<span class="comment">#&quot;wb&quot;表示二进制写方式打开文件</span></span><br><span class="line">			f.write(r.content) <span class="comment">#图片内容写入文件</span></span><br><span class="line">			f.close()</span><br><span class="line">			i = i + <span class="number">1</span></span><br><span class="line">		<span class="keyword">except</span> Exception <span class="keyword">as</span> e :</span><br><span class="line">			<span class="keyword">pass</span></span><br><span class="line">		<span class="keyword">if</span> i &gt;= n:</span><br><span class="line">			<span class="keyword">break</span></span><br><span class="line">getBaiduPictures(<span class="string">&quot;猫&quot;</span>, <span class="number">5</span>)</span><br><span class="line">getBaiduPictures(<span class="string">&quot;熊猫&quot;</span>, <span class="number">5</span>)</span><br></pre></td></tr></table></figure>
<h1 id="用requests库获取网页"><a href="#用requests库获取网页" class="headerlink" title="用requests库获取网页"></a>用requests库获取网页</h1><h2 id="用requests-get获取网页"><a href="#用requests-get获取网页" class="headerlink" title="用requests.get获取网页"></a>用requests.get获取网页</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">getHtml</span>(<span class="params">url</span>):  <span class="comment"># 获取网址url的网页</span></span><br><span class="line">    <span class="keyword">import</span> requests  <span class="comment"># request库用于获取网络资源,pip install request</span></span><br><span class="line">    fakeHeaders = &#123;<span class="string">&#x27;User-Agent&#x27;</span>:  <span class="comment"># 用于伪装浏览器发送请求</span></span><br><span class="line">                       <span class="string">&#x27;Mozilla/5.0 (Windows NT 10.0; Win64; x64) \</span></span><br><span class="line"><span class="string">                       AppleWebKit/537.36 (KHTML, like Gecko) \ &#x27;</span></span><br><span class="line">                       <span class="string">&#x27;Chrome/81.0.4044.138 Safari/537.36 Edg/81.0.416.77&#x27;</span>,</span><br><span class="line">                   <span class="string">&#x27;Accept&#x27;</span>: <span class="string">&#x27;text/html,application/xhtml+xml,*/*&#x27;</span>&#125;</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        r = requests.get(url, headers=fakeHeaders)</span><br><span class="line">        </span><br><span class="line">        r.encoding = r.apparent_encoding  <span class="comment"># 确保网页编码正确</span></span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> r.text  <span class="comment"># 返回值是个字符串，内含整个网页内容</span></span><br><span class="line">    <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">        <span class="built_in">print</span>(e)</span><br><span class="line">        <span class="keyword">return</span> <span class="string">&quot;&quot;</span></span><br><span class="line"><span class="comment"># 用法： html = getHtml(&quot;http://openjudge.cn&quot;)</span></span><br></pre></td></tr></table></figure>
<h2 id="用requests-get获取网页（编码识别加强版"><a href="#用requests-get获取网页（编码识别加强版" class="headerlink" title="用requests.get获取网页（编码识别加强版)"></a>用requests.get获取网页（编码识别加强版)</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">getHtml</span>(<span class="params">url</span>):</span><br><span class="line">    <span class="keyword">import</span> sys, requests</span><br><span class="line">    <span class="keyword">import</span> chardet  <span class="comment"># 编码处理库 pip install chardet</span></span><br><span class="line">    fakeHeaders = &#123;<span class="string">&#x27;User-Agent&#x27;</span>:</span><br><span class="line">                       <span class="string">&#x27;Mozilla/5.0 (Windows NT 10.0; Win64; x64) \</span></span><br><span class="line"><span class="string">                       AppleWebKit/537.36 (KHTML, like Gecko) \ &#x27;</span></span><br><span class="line">                       <span class="string">&#x27;Chrome/81.0.4044.138 Safari/537.36 Edg/81.0.416.77&#x27;</span>,</span><br><span class="line">                   <span class="string">&#x27;Accept&#x27;</span>: <span class="string">&#x27;text/html,application/xhtml+xml,*/*&#x27;</span>&#125;</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        r = requests.get(url, headers=fakeHeaders)</span><br><span class="line">        </span><br><span class="line">        ecd = chardet.detect(r.content)[<span class="string">&#x27;encoding&#x27;</span>]  <span class="comment"># ecd是个字符串</span></span><br><span class="line">        <span class="keyword">if</span> ecd.lower() != sys.getdefaultencoding().lower():</span><br><span class="line">            r.encoding = ecd  <span class="comment"># 修改r中文本的编码</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            r.encoding = r.apparent_encoding</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> r.textv</span><br><span class="line">    <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">        <span class="built_in">print</span>(e)</span><br><span class="line">        <span class="keyword">return</span> <span class="string">&quot;&quot;</span></span><br></pre></td></tr></table></figure>
<h2 id="用requests库获取网页的优势和局限"><a href="#用requests库获取网页的优势和局限" class="headerlink" title="用requests库获取网页的优势和局限"></a>用requests库获取网页的优势和局限</h2><ul>
<li>优势</li>
</ul>
<ul>
<li>相比其它方法， 速度快几倍</li>
<li>安装简单，分发容易</li>
</ul>
<ul>
<li>局限</li>
</ul>
<ul>
<li>容易被反爬虫手段屏蔽</li>
<li>不能获取包含javascript生成的动态网页<br>用上面的getHtml函数，不能得到百度图片搜索结果网页，得到的网页是空网页（被反爬了）</li>
</ul>
<h2 id="弥补requests不足的其它获取网页的办法"><a href="#弥补requests不足的其它获取网页的办法" class="headerlink" title="弥补requests不足的其它获取网页的办法"></a>弥补requests不足的其它获取网页的办法</h2><ul>
<li>使用selenium库 (慢，很容易被反爬，且已经被许多网站反爬，网上各种对付反爬的解决办法基本不管用，不推荐）</li>
<li>使用pyppeteer库（快，暂未被许多网站反爬，强烈推荐）</li>
</ul>
<h1 id="用selenium库获取网页"><a href="#用selenium库获取网页" class="headerlink" title="用selenium库获取网页"></a>用selenium库获取网页</h1><p><code>pip install selunium</code></p>
<p>需要chrome浏览器或firefox浏览器，此外还需要下载chrome驱动程序(chromedriver.exe)或firefox驱动程序(geckodriver.exe)</p>
<h2 id="用selenium获取网页"><a href="#用selenium获取网页" class="headerlink" title="用selenium获取网页"></a>用selenium获取网页</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">getHtml</span>(<span class="params">url</span>):  <span class="comment"># 暂时适用于百度图片搜索</span></span><br><span class="line">    <span class="keyword">from</span> selenium <span class="keyword">import</span> webdriver  <span class="comment"># 需要pip install selenium</span></span><br><span class="line">    <span class="keyword">from</span> selenium.webdriver.chrome.options <span class="keyword">import</span> Options</span><br><span class="line">    options = Options()  <span class="comment"># 浏览器选项</span></span><br><span class="line">    <span class="comment"># 等价于 options = webdriver.chrome.options.Options()</span></span><br><span class="line">    options.add_argument(<span class="string">&#x27;--headless&#x27;</span>)  <span class="comment"># 规定chrome浏览器隐身模式运行</span></span><br><span class="line">    options.add_argument(<span class="string">&#x27;--disable-gpu&#x27;</span>)  <span class="comment"># 禁止chrome使用gpu加速，能快点</span></span><br><span class="line">    driver = webdriver.Chrome(</span><br><span class="line">        executable_path=<span class="string">&#x27;c:/tmp/chromedriver.exe&#x27;</span>, options=options)</span><br><span class="line">    <span class="comment"># driver就是个chrome浏览器。需要下载安装chrome驱动器 chromedriver.exe</span></span><br><span class="line">    driver.get(url)  <span class="comment"># 浏览器装入网页</span></span><br><span class="line">    html = driver.page_source  <span class="comment"># 网页源代码</span></span><br><span class="line">    driver.close()  <span class="comment"># 关闭浏览器</span></span><br><span class="line">    driver.quit()  <span class="comment"># 退出</span></span><br><span class="line">    <span class="keyword">return</span> html  <span class="comment"># 返回字符串</span></span><br></pre></td></tr></table></figure>
<h2 id="用pyppeteer库获取网页"><a href="#用pyppeteer库获取网页" class="headerlink" title="用pyppeteer库获取网页"></a>用pyppeteer库获取网页</h2><ul>
<li><p>puppeteer是谷歌公司推出的可以控制Chrome浏览器的一套编程工具。一个日本工程师以此为基础推出了Python版本，叫pyppeteer。</p>
</li>
<li><p><a target="_blank" rel="noopener" href="https://pypi.org/project/pyppeteer/">pyppeteer的官网</a></p>
</li>
<li><p>启动一个浏览器Chromium，用浏览器装入网页。浏览器可以用无头模式（headless)，即隐藏模式启动，也可以显式启动。</p>
</li>
<li><p>从浏览器可以获取网页源代码，若网页有javascript程序，获取到的是javascript被浏览器执行后的网页源代码。</p>
</li>
<li><p>可以向浏览器发送命令，模拟用户在浏览器上键盘输入、鼠标点击等操作,让浏览器转到其它网页。</p>
</li>
<li><p>selenium原理及功能和pyppeteer一样。</p>
</li>
</ul>
<h3 id="环境安装"><a href="#环境安装" class="headerlink" title="环境安装"></a>环境安装</h3><p><code>pip install pyppeteer</code></p>
<ul>
<li>要求Python版本 &gt;= 3.6</li>
<li>必须下载并安装特殊版本的谷歌浏览器Chromium</li>
</ul>
<p>可以将Chromium压缩包随便解压在哪个文件夹，然后在程序指明其中chrome.exe的位置。<br>也可以将Chromium解压到pyppeteer的安装文件夹下面。这个文件夹通常类似：<br><code>C:\Users\username\AppData\Local\pyppeteer\pyppeteer\local-chromium\588429</code><br>把username要换成自己的windows用户名， 588429这里可能是别的数。<br>将Chromium压缩包里面的chrome-win32文件夹整个放在上面那个文件夹里面就行</p>
<h3 id="预备知识：协程"><a href="#预备知识：协程" class="headerlink" title="预备知识：协程"></a>预备知识：协程</h3><ul>
<li>协程就是前面加了’async’的函数(从Python 3.6开始有)</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">f</span>()</span><br><span class="line">	<span class="keyword">return</span> <span class="number">0</span></span><br></pre></td></tr></table></figure>
<ul>
<li>调用协程时，必须在函数名前面加’await’</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">await</span> f()</span><br></pre></td></tr></table></figure>
<ul>
<li><p>协程只能在协程里面调用，即await语句只能出现在协程里面。</p>
</li>
<li><p>协程是一种特殊的函数，多个协程可以并行。</p>
</li>
<li><p>pyppeteer中的所有函数都是协程，调用时前面都要加 await，且只能在协程中调用<br>初用协程，经常因为调用XXXX时忘了加await导致下面错误：</p>
</li>
</ul>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">RuntimeWarning: coroutine &#x27;XXXX&#x27; was never awaited</span><br></pre></td></tr></table></figure>
<h3 id="用pyppeteer获取网页"><a href="#用pyppeteer获取网页" class="headerlink" title="用pyppeteer获取网页"></a>用pyppeteer获取网页</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">getHtml</span>(<span class="params">url</span>):  <span class="comment"># 暂时适用于百度图片搜索</span></span><br><span class="line">    <span class="keyword">import</span> asyncio  <span class="comment"># Python 3.6之后自带的协程库</span></span><br><span class="line">    <span class="keyword">import</span> pyppeteer <span class="keyword">as</span> pyp</span><br><span class="line">    <span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">asGetHtml</span>(<span class="params">url</span>):  <span class="comment"># 获取url对应网页的源代码</span></span><br><span class="line">        browser = <span class="keyword">await</span> pyp.launch(headless=<span class="literal">False</span>)</span><br><span class="line">        <span class="comment"># 启动Chromium,browser即为Chromium浏览器，非隐藏启动</span></span><br><span class="line">        page = <span class="keyword">await</span> browser.newPage()  <span class="comment"># 在浏览器中打开一个新页面（标签）</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">await</span> page.setUserAgent(<span class="string">&#x27;Mozilla/5.0 (Windows NT 6.1; \</span></span><br><span class="line"><span class="string">Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) \</span></span><br><span class="line"><span class="string">Chrome/78.0.3904.70 Safari/537.36&#x27;</span>)  <span class="comment"># 反反爬措施</span></span><br><span class="line">        <span class="keyword">await</span> page.evaluateOnNewDocument(</span><br><span class="line">            <span class="string">&#x27;() =&gt;&#123; Object.defineProperties(navigator, \</span></span><br><span class="line"><span class="string">            &#123; webdriver:&#123; get: () =&gt; false &#125; &#125;) &#125;&#x27;</span>)  <span class="comment"># 反反爬措施</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">await</span> page.goto(url)  <span class="comment"># 装入url对应的网页</span></span><br><span class="line">        text = <span class="keyword">await</span> page.content()  <span class="comment"># page.coutent就是网页源代码字符串</span></span><br><span class="line">        <span class="keyword">await</span> browser.close()  <span class="comment"># 关闭浏览器</span></span><br><span class="line">        <span class="keyword">return</span> text</span><br><span class="line">		<span class="comment"># 速度大约比用requests.get慢5,6倍</span></span><br><span class="line"></span><br><span class="line">	m = asyncio.ensure_future(asGetHtml(url))  <span class="comment"># 协程外启动协程</span></span><br><span class="line">	asyncio.get_event_loop().run_until_complete(m)  <span class="comment"># 等待协程结束</span></span><br><span class="line">	<span class="keyword">return</span> m.result()  <span class="comment"># 返回的就是asGetHtml的返回值 text</span></span><br></pre></td></tr></table></figure>
<p>可以改进程序，只需要启动一次浏览器，生成一个page对象即可，以后获取不同网页都用相同page对象，所有事情完成后才关闭浏览器。</p>
<ul>
<li>launch的其它参数</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">browser = <span class="keyword">await</span> launch(headless=<span class="literal">False</span>, executablePath=<span class="string">&quot;c:/tmp/chrome-win32/chrome.exe&quot;</span>, userdataDir=<span class="string">&quot;c:/tmp&quot;</span>)</span><br></pre></td></tr></table></figure>
<p><code>excutablePath</code>: 如果Chromium没有安装在默认文件夹下面，则需要指定其位置。<br><code>userdataDir</code>: userdataDir指明用来存放浏览器工作期间存放临时文件的文件夹。不是必须，能够防止可能出现的莫名其妙的错误。</p>
<h2 id="用BeautifulSoup库分析网页"><a href="#用BeautifulSoup库分析网页" class="headerlink" title="用BeautifulSoup库分析网页"></a>用BeautifulSoup库分析网页</h2><h3 id="分析并提取网页内容的三种方式"><a href="#分析并提取网页内容的三种方式" class="headerlink" title="分析并提取网页内容的三种方式"></a>分析并提取网页内容的三种方式</h3><ol>
<li>正则表达式(速度最快，但适应变化略差)</li>
<li>BeautifulSoup库 (速度是正则表达式的约几分之一)</li>
<li>selenium或pyppeteer的中的浏览器对象的查找元素函数(速度是正则表达式的约百分之一，用在需要模拟在网页中进行输入，点击按钮等操作的时候)</li>
</ol>
<h3 id="html文档-网页-中的tag"><a href="#html文档-网页-中的tag" class="headerlink" title="html文档(网页)中的tag"></a>html文档(网页)中的tag</h3><p>tag格式通常为(少数没有正文和<code>&lt; /X &gt;</code>):</p>
<figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">X</span> <span class="attr">attr1</span>=<span class="string">&#x27;xxx&#x27;</span> <span class="attr">attr2</span>=<span class="string">&#x27;yyy&#x27;</span> <span class="attr">attr3</span>=<span class="string">&#x27;zzz&#x27;</span> …&gt;</span></span><br><span class="line">	nnnnnnnnnnnnnn</span><br><span class="line"><span class="tag">&lt;/<span class="name">X</span>&gt;</span></span><br></pre></td></tr></table></figure>
<ul>
<li>X : tag的名字(name)</li>
<li>attr1,attr2… : tag的属性（attr） =后面跟着属性的值</li>
<li>nnnnnnnnnnnnnn : tag的正文（text）</li>
</ul>
<p>例如:<br><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">a</span> <span class="attr">href</span>=<span class="string">&quot;www.sohu.com&quot;</span> <span class="attr">id</span>=<span class="string">&#x27;mylink&#x27;</span>&gt;</span>搜狐网<span class="tag">&lt;/<span class="name">a</span>&gt;</span></span><br></pre></td></tr></table></figure></p>
<ul>
<li>a ：tag的名字(name)</li>
<li>href, id ： tag的属性(attr)， =后面跟着属性的值</li>
<li>搜狐网 ： tag的正文(text)</li>
</ul>
<h3 id="tag可以嵌套"><a href="#tag可以嵌套" class="headerlink" title="tag可以嵌套"></a>tag可以嵌套</h3><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">div</span> <span class="attr">id</span>=<span class="string">&quot;siteHeader&quot;</span> <span class="attr">class</span>=<span class="string">&quot;wrapper&quot;</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">h1</span> <span class="attr">class</span>=<span class="string">&quot;logo&quot;</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">div</span> <span class="attr">id</span>=<span class="string">&quot;topsearch&quot;</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">ul</span> <span class="attr">id</span>=<span class="string">&quot;userMenu&quot;</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">li</span> &gt;</span><span class="tag">&lt;<span class="name">a</span> <span class="attr">href</span>=<span class="string">&quot;http://openjudge.cn/&quot;</span>&gt;</span>首页<span class="tag">&lt;/<span class="name">a</span>&gt;</span><span class="tag">&lt;/<span class="name">li</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br></pre></td></tr></table></figure>
<h3 id="用BeautifulSoup库分析html"><a href="#用BeautifulSoup库分析html" class="headerlink" title="用BeautifulSoup库分析html"></a>用BeautifulSoup库分析html</h3><ul>
<li>安装</li>
</ul>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install beautifulsoup4</span><br></pre></td></tr></table></figure>
<ul>
<li>导入</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> bs4</span><br></pre></td></tr></table></figure>
<ul>
<li>使用</li>
</ul>
<p>1) 将html文档装入一个BeautifulSoup对象X<br>2) 用X对象的<code>find</code>,<code>find_all</code>等函数去找想要的tag对象<br>3) 对找到的tag对象，还可以用其<code>find</code>,<code>find_all</code>函数去，找它内部包含（嵌套）的tag对象<br>4) tag对象的text就是该对象里的正文（text）， tag对象也可以看作是一个字典，里面包含各种属性(attr)及其值。</p>
<h3 id="把html文档载入BeautifulSoup对象"><a href="#把html文档载入BeautifulSoup对象" class="headerlink" title="把html文档载入BeautifulSoup对象"></a>把html文档载入BeautifulSoup对象</h3><ul>
<li>方法1，html文档来自字符串：</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">str</span> = <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">&lt;div id=&quot;siteHeader&quot; class=&quot;wrapper&quot;&gt;</span></span><br><span class="line"><span class="string">	&lt;h1 class=&quot;logo&quot;&gt;</span></span><br><span class="line"><span class="string">	&lt;div id=&quot;topsearch&quot;&gt;</span></span><br><span class="line"><span class="string">		&lt;ul id=&quot;userMenu&quot;&gt;</span></span><br><span class="line"><span class="string">		&lt;li &gt;&lt;a href=&quot;http://openjudge.cn/&quot;&gt;首页&lt;/a&gt;&lt;/li&gt;</span></span><br><span class="line"><span class="string">	&lt;/div&gt;</span></span><br><span class="line"><span class="string">&lt;/div&gt;</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="comment">#带href的 &lt;a&gt;都是链接，上面“首页”是链接文字 ,href后面http://openjudge.cn是链</span></span><br><span class="line">接地址</span><br><span class="line">soup = bs4.BeautifulSoup(<span class="built_in">str</span>, <span class="string">&quot;html.parser&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(soup.find(<span class="string">&quot;li&quot;</span>).text) <span class="comment">#&gt;&gt;首页</span></span><br></pre></td></tr></table></figure>
<ul>
<li>方法2，html文档来自于文件：</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">soup = bs4.BeautifulSoup(<span class="built_in">open</span>(<span class="string">&quot;c:\\tmp\\test.html&quot;</span>,<span class="string">&quot;r&quot;</span>,encoding=<span class="string">&quot;utf-8&quot;</span>), <span class="string">&quot;html.parser&quot;</span>)</span><br></pre></td></tr></table></figure>
<ul>
<li>方法3，html文档来自于给定网址：</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">getHtml</span>(<span class="params">url</span>):</span><br><span class="line"><span class="comment">#获得html文本</span></span><br><span class="line">	<span class="keyword">try</span>:</span><br><span class="line">		r = requests.get(url)</span><br><span class="line">		r.raise_for_status()</span><br><span class="line">		r.encoding = r.apparent_encoding</span><br><span class="line">		<span class="keyword">return</span> r.text</span><br><span class="line">	<span class="keyword">except</span>:</span><br><span class="line">		<span class="keyword">return</span> <span class="string">&quot;&quot;</span></span><br><span class="line">html = getHtml(<span class="string">&quot;https://cn.bing.com/dict/search?q=new&quot;</span>)</span><br><span class="line">soup = bs4.BeautifulSoup(html,<span class="string">&#x27;html.parser&#x27;</span>)</span><br></pre></td></tr></table></figure>
<h3 id="实例：用BeautifulSoup对象寻找想要的tag"><a href="#实例：用BeautifulSoup对象寻找想要的tag" class="headerlink" title="实例：用BeautifulSoup对象寻找想要的tag"></a>实例：用BeautifulSoup对象寻找想要的tag</h3><p><code>c:\tmp\test.html</code>:</p>
<figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&lt;!DOCTYPE <span class="keyword">HTML</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">html</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">body</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">div</span> <span class="attr">id</span>=<span class="string">&quot;synoid&quot;</span> <span class="attr">style</span>=<span class="string">&quot;display:block;&quot;</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">&quot;df_div2&quot;</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">&quot;de_title1&quot;</span>&gt;</span>adj.<span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">&quot;col_fl&quot;</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">a</span> <span class="attr">h</span>=<span class="string">&quot;ID=Dictionary,5237.1&quot;</span> <span class="attr">href</span>=<span class="string">&quot;https://cn.bing.com/dict/search?q=novel&quot;</span>&gt;</span></span><br><span class="line">				<span class="tag">&lt;<span class="name">span</span> <span class="attr">class</span>=<span class="string">&quot;p1-4&quot;</span>&gt;</span>novel<span class="tag">&lt;/<span class="name">span</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;/<span class="name">a</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">p</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">a</span> <span class="attr">h</span>=<span class="string">&quot;ID=Dictionary,5238.1&quot;</span> <span class="attr">href</span>=<span class="string">&quot;https://cn.bing.com/dict/search?q=newfangled&quot;</span>&gt;</span></span><br><span class="line">				<span class="tag">&lt;<span class="name">span</span> <span class="attr">class</span>=<span class="string">&quot;p1-4&quot;</span>&gt;</span>newfangled<span class="tag">&lt;/<span class="name">span</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;/<span class="name">a</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">a</span> <span class="attr">href</span>=<span class="string">&quot;http://www.baidu.com&quot;</span> <span class="attr">id</span>=<span class="string">&quot;searchlink1&quot;</span> <span class="attr">class</span>=<span class="string">&quot;sh1&quot;</span>&gt;</span>百度<span class="tag">&lt;/<span class="name">a</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">a</span> <span class="attr">href</span>=<span class="string">&quot;http://www.google.com&quot;</span> <span class="attr">id</span>=<span class="string">&quot;searchlink1&quot;</span> <span class="attr">class</span>=<span class="string">&quot;sh2&quot;</span>&gt;</span>谷歌<span class="tag">&lt;/<span class="name">a</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">body</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">html</span>&gt;</span></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> bs4</span><br><span class="line">soup = bs4.BeautifulSoup(<span class="built_in">open</span>(<span class="string">&quot;c:\\tmp\\test.html&quot;</span>, encoding = <span class="string">&quot;utf-8&quot;</span>),<span class="string">&quot;html.parser&quot;</span>)</span><br><span class="line"></span><br><span class="line">diva = soup.find(<span class="string">&quot;div&quot;</span>,attrs=&#123;<span class="string">&quot;id&quot;</span>:<span class="string">&quot;synoid&quot;</span>&#125;)</span><br><span class="line"><span class="comment">#寻找名为&quot;div&quot;,且具有值为&quot;synoid&quot;的属性&quot;id&quot;的tag</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> diva != <span class="literal">None</span>: <span class="comment">#如果找到</span></span><br><span class="line">	<span class="keyword">for</span> x <span class="keyword">in</span> diva.find_all(<span class="string">&quot;span&quot;</span>,attrs=&#123;<span class="string">&quot;class&quot;</span>:<span class="string">&quot;p1-4&quot;</span>&#125;):</span><br><span class="line">		<span class="built_in">print</span>(x.text) <span class="comment">#在diva内部继续找</span></span><br><span class="line">	<span class="keyword">for</span> x <span class="keyword">in</span> diva.find_all(<span class="string">&quot;a&quot;</span>,attrs=&#123;<span class="string">&quot;id&quot;</span>:<span class="string">&quot;searchlink1&quot;</span>&#125;):</span><br><span class="line">		<span class="built_in">print</span>(x.text)</span><br><span class="line">	x = diva.find(<span class="string">&quot;a&quot;</span>,attrs=&#123;<span class="string">&quot;id&quot;</span>:<span class="string">&quot;searchlink1&quot;</span>,<span class="string">&quot;class&quot;</span>:<span class="string">&quot;sh2&quot;</span>&#125;)</span><br><span class="line">	<span class="keyword">if</span> x != <span class="literal">None</span>:</span><br><span class="line">		<span class="built_in">print</span>(x.text)</span><br><span class="line">		<span class="built_in">print</span>(x[<span class="string">&quot;href&quot;</span>])</span><br><span class="line">		<span class="built_in">print</span>(x[<span class="string">&quot;id&quot;</span>])</span><br></pre></td></tr></table></figure>
<p>输出：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">novel</span><br><span class="line">newfangled</span><br><span class="line">百度</span><br><span class="line">谷歌</span><br><span class="line">谷歌</span><br><span class="line">http://www.google.com</span><br><span class="line">searchlink1</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#如果别处没有和 &lt;div id=&quot;synoid&quot; style=&quot;display:block;&quot;&gt; 内部的模式相似的东西，也可以不用先找这个 &quot;synoid&quot; tag</span></span><br><span class="line"><span class="keyword">import</span> bs4</span><br><span class="line">soup = bs4.BeautifulSoup(<span class="built_in">open</span>(<span class="string">&quot;c:\\tmp\\test.html&quot;</span>,encoding=<span class="string">&quot;utf-8&quot;</span>),<span class="string">&quot;html.parser&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> x <span class="keyword">in</span> soup.find_all(<span class="string">&quot;span&quot;</span>,attrs=&#123;<span class="string">&quot;class&quot;</span>:<span class="string">&quot;p1-4&quot;</span>&#125;):</span><br><span class="line">	<span class="built_in">print</span>(x.text)</span><br><span class="line">	</span><br><span class="line"><span class="keyword">for</span> x <span class="keyword">in</span> soup.find_all(<span class="string">&quot;a&quot;</span>,attrs=&#123;<span class="string">&quot;id&quot;</span>:<span class="string">&quot;searchlink1&quot;</span>&#125;):</span><br><span class="line">	<span class="built_in">print</span>(x.text)</span><br><span class="line"></span><br><span class="line">x = soup.find(<span class="string">&quot;a&quot;</span>,attrs=&#123;<span class="string">&quot;id&quot;</span>:<span class="string">&quot;searchlink1&quot;</span>,<span class="string">&quot;class&quot;</span>:<span class="string">&quot;sh2&quot;</span>&#125;)</span><br><span class="line"><span class="keyword">if</span> x != <span class="literal">None</span>:</span><br><span class="line">	<span class="built_in">print</span>(x.text)</span><br><span class="line">	<span class="built_in">print</span>(x[<span class="string">&quot;href&quot;</span>])</span><br><span class="line">	<span class="built_in">print</span>(x[<span class="string">&quot;id&quot;</span>])</span><br></pre></td></tr></table></figure>
<h2 id="实例：爬取每日股票交易信息"><a href="#实例：爬取每日股票交易信息" class="headerlink" title="实例：爬取每日股票交易信息"></a>实例：爬取每日股票交易信息</h2><p><a target="_blank" rel="noopener" href="https://www.banban.cn/gupiao/list_cyb.html">创业板股票交易代码大全</a><br><a target="_blank" rel="noopener" href="https://www.banban.cn/gupiao/list_sz.html">深圳股票交易代码大全</a><br><a target="_blank" rel="noopener" href="https://www.banban.cn/gupiao/list_sh.html">上证股票交易代码大全</a></p>
<p>查看源代码：</p>
<figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">li</span>&gt;</span><span class="tag">&lt;<span class="name">a</span> <span class="attr">href</span>=<span class="string">&quot;/gupiao/600151/&quot;</span>&gt;</span>航天机电(600151)<span class="tag">&lt;/<span class="name">a</span>&gt;</span><span class="tag">&lt;/<span class="name">li</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">li</span>&gt;</span><span class="tag">&lt;<span class="name">a</span> <span class="attr">href</span>=<span class="string">&quot;/gupiao/600156/&quot;</span>&gt;</span>华升股份(600156)<span class="tag">&lt;/<span class="name">a</span>&gt;</span><span class="tag">&lt;/<span class="name">li</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">li</span>&gt;</span><span class="tag">&lt;<span class="name">a</span> <span class="attr">href</span>=<span class="string">&quot;/gupiao/600160/&quot;</span>&gt;</span>巨化股份(600160)<span class="tag">&lt;/<span class="name">a</span>&gt;</span><span class="tag">&lt;/<span class="name">li</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">li</span>&gt;</span><span class="tag">&lt;<span class="name">a</span> <span class="attr">href</span>=<span class="string">&quot;/gupiao/600161/&quot;</span>&gt;</span>天坛生物(600161)<span class="tag">&lt;/<span class="name">a</span>&gt;</span><span class="tag">&lt;/<span class="name">li</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">li</span>&gt;</span><span class="tag">&lt;<span class="name">a</span> <span class="attr">href</span>=<span class="string">&quot;/gupiao/600162/&quot;</span>&gt;</span>香江控股(600162)<span class="tag">&lt;/<span class="name">a</span>&gt;</span><span class="tag">&lt;/<span class="name">li</span>&gt;</span></span><br></pre></td></tr></table></figure>
<p>东方财富网每日股票交易信息单只股票：</p>
<p>quote.eastmoney.com/sh600000.html 上证<br>quote.eastmoney.com/sz000017.html 深圳或创业板</p>
<p>该页面查看源代码，看不到 12.17, 12.51等交易数据。说明源代码里面包含javascript程序，<br>浏览器执行javascript程序以后，才能得到显示的页面。</p>
<p>因此python程序需要在取到网页后，还要执行里面的javascript程序，才能得到股票数据</p>
<p>用requests.get无法得到显示的网页。必须用selenium或者pyppeteer</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> re</span><br><span class="line"><span class="keyword">import</span> asyncio  <span class="comment"># Python 3.6之后自带的协程库</span></span><br><span class="line"><span class="keyword">import</span> pyppeteer <span class="keyword">as</span> pyp</span><br><span class="line"><span class="keyword">import</span> bs4</span><br><span class="line"></span><br><span class="line"><span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">antiAntiCrawler</span>(<span class="params">page</span>):  <span class="comment"># 为page添加反反爬虫手段</span></span><br><span class="line">    <span class="keyword">await</span> page.setUserAgent(<span class="string">&#x27;Mozilla/5.0 (Windows NT 6.1; \</span></span><br><span class="line"><span class="string">Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) \</span></span><br><span class="line"><span class="string">Chrome/78.0.3904.70 Safari/537.36&#x27;</span>)</span><br><span class="line">    <span class="keyword">await</span> page.evaluateOnNewDocument(</span><br><span class="line">        <span class="string">&#x27;() =&gt;&#123; Object.defineProperties(navigator, \</span></span><br><span class="line"><span class="string">        &#123; webdriver:&#123; get: () =&gt; false &#125; &#125;) &#125;&#x27;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 用正则表达式获取股票名称和代码</span></span><br><span class="line"><span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">getStockCodes</span>(<span class="params">page</span>):</span><br><span class="line"><span class="comment">#从&quot;https://www.banban.cn/gupiao/list_sh.html&quot;对应的page获取所有股票名称和代码</span></span><br><span class="line">	codes = []</span><br><span class="line">	<span class="comment"># 最终内容： [&quot;四川路桥(600039)&quot;,&quot;包钢股份(600010)&quot;......]</span></span><br><span class="line">	html = <span class="keyword">await</span> page.content()</span><br><span class="line">	pt = <span class="string">&#x27;&lt;a href=&quot;/gupiao/[^&quot;]*&quot;&gt;([^&lt;]*\(\d+\))&lt;/a&gt;&#x27;</span></span><br><span class="line">	<span class="comment"># 对应 &lt;li&gt;&lt;a href=&quot;/gupiao/600151/&quot;&gt;航天机电(600151)&lt;/a&gt;&lt;/li&gt;</span></span><br><span class="line">	<span class="keyword">for</span> x <span class="keyword">in</span> re.findall(pt, html):</span><br><span class="line">		codes.append(x)</span><br><span class="line">	<span class="keyword">return</span> codes</span><br><span class="line"><span class="comment"># 耗时： 0: 00:00.033943</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">getStockInfo</span>(<span class="params">url</span>):</span><br><span class="line">    browser = <span class="keyword">await</span> pyp.launch(headless=<span class="literal">False</span>)</span><br><span class="line">    <span class="comment"># 启动Chromium,browser即为Chromium浏览器，非隐藏启动</span></span><br><span class="line">    page = <span class="keyword">await</span> browser.newPage()  <span class="comment">#在浏览器中打开一个新页面（标签）</span></span><br><span class="line">    <span class="keyword">await</span> antiAntiCrawler(page)  <span class="comment">#新页面生成后一律调用此来反反爬</span></span><br><span class="line">    <span class="keyword">await</span> page.goto(url)  <span class="comment">#装入url对应的网页</span></span><br><span class="line">    codes = <span class="keyword">await</span> getStockCodes(page)</span><br><span class="line">    <span class="keyword">for</span> x <span class="keyword">in</span> codes[:<span class="number">3</span>]:  <span class="comment">#只取前三个股票信息</span></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;-----&quot;</span>, x)  <span class="comment">#x形如&quot;四川路桥(600039)&quot;</span></span><br><span class="line">        pos1, pos2 = x.index(<span class="string">&quot;(&quot;</span>), x.index(<span class="string">&quot;)&quot;</span>)</span><br><span class="line">        code = x[pos1 + <span class="number">1</span>:pos2]  <span class="comment"># 取股票代码,如600039</span></span><br><span class="line">        url = <span class="string">&quot;https://quote.eastmoney.com/sh&quot;</span> + code + <span class="string">&quot;.html&quot;</span></span><br><span class="line">        <span class="keyword">await</span> page.goto(url)</span><br><span class="line">        html = <span class="keyword">await</span> page.content()  <span class="comment"># 往下编程前可以先print(html)看一看</span></span><br><span class="line">        pt = <span class="string">&#x27;&lt;td&gt;([^&lt;]*)&lt;/td&gt;.*?&lt;td[^&gt;]*id=&quot;gt\d*?&quot;[^&gt;]*&gt;([^&lt;]*)&lt;/td&gt;&#x27;</span></span><br><span class="line">        <span class="keyword">for</span> x <span class="keyword">in</span> re.findall(pt, html, re.DOTALL):</span><br><span class="line">            <span class="built_in">print</span>(x[<span class="number">0</span>], x[<span class="number">1</span>])</span><br><span class="line">    <span class="keyword">await</span> browser.close()  <span class="comment"># 关闭浏览器</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">url = <span class="string">&quot;https://www.banban.cn/gupiao/list_sh.html&quot;</span></span><br><span class="line">loop = asyncio.get_event_loop()</span><br><span class="line">loop.run_until_complete(getStockInfo(url))</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">html = <span class="keyword">await</span> page.content()</span><br><span class="line"><span class="built_in">print</span>(html) <span class="comment">#打出的内容拷贝到记事本查看，找到以下内容：</span></span><br></pre></td></tr></table></figure>
<figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">tr</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">td</span>&gt;</span>今开： <span class="tag">&lt;/<span class="name">td</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">td</span> <span class="attr">id</span>=<span class="string">&quot;gt1&quot;</span> <span class="attr">class</span>=<span class="string">&quot;txtl&quot;</span> <span class="attr">data-bind</span>=<span class="string">&quot;46&quot;</span>&gt;</span>1.22<span class="tag">&lt;/<span class="name">td</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">td</span>&gt;</span>最高： <span class="tag">&lt;/<span class="name">td</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">td</span> <span class="attr">id</span>=<span class="string">&quot;gt2&quot;</span> <span class="attr">class</span>=<span class="string">&quot;txtl&quot;</span> <span class="attr">data-bind</span>=<span class="string">&quot;44&quot;</span>&gt;</span>1.22<span class="tag">&lt;/<span class="name">td</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">td</span>&gt;</span>涨停： <span class="tag">&lt;/<span class="name">td</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">td</span> <span class="attr">id</span>=<span class="string">&quot;gt3&quot;</span> <span class="attr">class</span>=<span class="string">&quot;txtl red&quot;</span> <span class="attr">data-bind</span>=<span class="string">&quot;51&quot;</span>&gt;</span>1.34<span class="tag">&lt;/<span class="name">td</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">td</span>&gt;</span>换手： <span class="tag">&lt;/<span class="name">td</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">td</span> <span class="attr">id</span>=<span class="string">&quot;gt4&quot;</span> <span class="attr">class</span>=<span class="string">&quot;txtl&quot;</span> <span class="attr">data-bind</span>=<span class="string">&quot;tr&quot;</span>&gt;</span>1%<span class="tag">&lt;/<span class="name">td</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">td</span>&gt;</span>成交量： <span class="tag">&lt;/<span class="name">td</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">td</span> <span class="attr">id</span>=<span class="string">&quot;gt5&quot;</span> <span class="attr">class</span>=<span class="string">&quot;txtl&quot;</span> <span class="attr">data-bind</span>=<span class="string">&quot;47&quot;</span>&gt;</span>316.4万手<span class="tag">&lt;/<span class="name">td</span>&gt;</span></span><br><span class="line">    .....................</span><br><span class="line">    <span class="tag">&lt;<span class="name">td</span> <span class="attr">id</span>=<span class="string">&quot;gt6&quot;</span> <span class="attr">class</span>=<span class="string">&quot;txtl&quot;</span> <span class="attr">data-bind</span>=<span class="string">&quot;pe&quot;</span>&gt;</span>245.41<span class="tag">&lt;/<span class="name">td</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">td</span>&gt;</span>总市值： <span class="tag">&lt;/<span class="name">td</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">td</span> <span class="attr">id</span>=<span class="string">&quot;gt7&quot;</span> <span class="attr">class</span>=<span class="string">&quot;txtl&quot;</span> <span class="attr">data-bind</span>=<span class="string">&quot;tmv&quot;</span>&gt;</span>547.0亿<span class="tag">&lt;/<span class="name">td</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">tr</span>&gt;</span></span><br></pre></td></tr></table></figure>
<p>正则表达式pt对应:<br><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">td</span>&gt;</span>今开： <span class="tag">&lt;/<span class="name">td</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">td</span> <span class="attr">id</span>=<span class="string">&quot;gt1&quot;</span> <span class="attr">class</span>=<span class="string">&quot;txtl&quot;</span> <span class="attr">data-bind</span>=<span class="string">&quot;46&quot;</span>&gt;</span>1.22<span class="tag">&lt;/<span class="name">td</span>&gt;</span></span><br></pre></td></tr></table></figure></p>
<p>输出结果：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">----- 包钢股份(600010)</span><br><span class="line">今开： 1.22</span><br><span class="line">最高： 1.22</span><br><span class="line">涨停： 1.34</span><br><span class="line">换手： 1%</span><br><span class="line">成交量： 316.4万手</span><br><span class="line">总市值： 547.0亿</span><br><span class="line">昨收： 1.22</span><br><span class="line">最低： 1.19</span><br><span class="line">跌停： 1.1</span><br><span class="line">量比： 1.04</span><br><span class="line">成交额： 3.81亿</span><br><span class="line">市净： 1.03</span><br><span class="line">流通市值： 380.1亿</span><br><span class="line">----- 四川路桥(600039)</span><br><span class="line">今开： 4.94</span><br><span class="line">最高： 4.95</span><br><span class="line">涨停： 5.43</span><br><span class="line">换手： 0.49%</span><br><span class="line">成交量： 17.64万手</span><br><span class="line">总市值： 232.8亿</span><br><span class="line">昨收： 4.94</span><br><span class="line">最低： 4.86</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#用BeautifulSoup获取股票名称和代码</span></span><br><span class="line"><span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">getStockCodes</span>(<span class="params">page</span>):</span><br><span class="line">    codes = []</span><br><span class="line">    html = <span class="keyword">await</span> page.content()</span><br><span class="line">    soup = bs4.BeautifulSoup(html, <span class="string">&quot;html.parser&quot;</span>)</span><br><span class="line">    <span class="keyword">for</span> x <span class="keyword">in</span> soup.find_all(<span class="string">&quot;li&quot;</span>):</span><br><span class="line">    <span class="comment">#对应 &lt;li&gt;&lt;a href=&quot;/gupiao/600151/&quot;&gt;航天机电(600151)&lt;/a&gt;&lt;/li&gt;</span></span><br><span class="line">    	a = x.find(<span class="string">&quot;a&quot;</span>)</span><br><span class="line">    	<span class="keyword">if</span>( <span class="string">&quot;(&quot;</span> <span class="keyword">in</span> a.text <span class="keyword">and</span> <span class="string">&quot;)&quot;</span> <span class="keyword">in</span> a.text):</span><br><span class="line">    		codes.append(a.text)</span><br><span class="line">    <span class="keyword">return</span> codes</span><br><span class="line">    <span class="comment">#耗时： 0: 00:00.193480</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#用浏览器自身的查找元素功能获取股票名称和代码</span></span><br><span class="line"><span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">getStockCodes</span>(<span class="params">page</span>):</span><br><span class="line">	codes = []</span><br><span class="line">	elements = <span class="keyword">await</span> page.querySelectorAll(<span class="string">&quot;li&quot;</span>) <span class="comment">#根据tag name找元素</span></span><br><span class="line">	<span class="comment">#对应 &lt;li&gt;&lt;a href=&quot;/gupiao/600151/&quot;&gt;航天机电(600151)&lt;/a&gt;&lt;/li&gt;</span></span><br><span class="line">	<span class="keyword">for</span> e <span class="keyword">in</span> elements:</span><br><span class="line">		a = <span class="keyword">await</span> e.querySelector(<span class="string">&quot;a&quot;</span>) <span class="comment">#根据tag name找元素</span></span><br><span class="line">		obj = <span class="keyword">await</span> a.getProperty(<span class="string">&quot;text&quot;</span>) <span class="comment">#还可以 a.getProperty(&quot;href&quot;)</span></span><br><span class="line">		<span class="comment">#上面这句不行就改成: obj = await a.getProperty(&quot;innerText&quot;)</span></span><br><span class="line">		text = <span class="keyword">await</span> obj.jsonValue() <span class="comment">#固定写法</span></span><br><span class="line">		<span class="keyword">if</span>( <span class="string">&quot;(&quot;</span> <span class="keyword">in</span> text <span class="keyword">and</span> <span class="string">&quot;)&quot;</span> <span class="keyword">in</span> text):</span><br><span class="line">			codes.append(text)</span><br><span class="line">	<span class="keyword">return</span> codes</span><br><span class="line">	<span class="comment">#耗时： 0:00:04.421178</span></span><br></pre></td></tr></table></figure>
<p>弹出菜单点“检查”，可以看到附近元素对应的源代码(查看源代码看不到)</p>
<h2 id="需要登录的爬虫"><a href="#需要登录的爬虫" class="headerlink" title="需要登录的爬虫"></a>需要登录的爬虫</h2><ul>
<li><p>许多网站需要登录后才能访问其内容</p>
<p>  京东、淘宝需要登录才能访问交易记录<br>  openjudge.cn 需要登录才能看提交过的源代码</p>
</li>
<li><p>登录操作，无法用一个url表示出来</p>
</li>
<li><p>解决办法之一：用浏览器模拟登录过程，输入用户名密码、点登录按钮。或者程序启动浏览器，等待手工登录后，程序再继续爬虫操作(对有验证码的情况)</p>
</li>
</ul>
<h3 id="爬取Openjudge自己提交通过的所有程序源码"><a href="#爬取Openjudge自己提交通过的所有程序源码" class="headerlink" title="爬取Openjudge自己提交通过的所有程序源码"></a>爬取Openjudge自己提交通过的所有程序源码</h3><ul>
<li>程序命令浏览器模拟登录过程，即输入用户名密码、点登录按钮</li>
<li>或：程序启动浏览器，等待手工登录后，程序再继续爬虫操作(对有验证码的情况，或者懒得写代码的情况)</li>
<li>更高级做法：不用浏览器，经数据包分析后，用requests库进行数据传输进行登录</li>
</ul>
<p>鼠标右键点击右上角的“个人首页”，在弹出的菜单上选“检查” :</p>
<p>点击 “个人首页”， 进入：</p>
<figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">a</span> <span class="attr">href</span>=<span class="string">&quot;http://cxsjsxmooc.openjudge.cn/2020t1fallall2/solution/25212869/&quot;</span> <span class="attr">class</span>=<span class="string">&quot;result-right&quot;</span>&gt;</span>Accepted<span class="tag">&lt;/<span class="name">a</span>&gt;</span></span><br></pre></td></tr></table></figure>
<p>点击某个题的“Accepted”链接，进入:</p>
<figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">pre</span> <span class="attr">class</span>=<span class="string">&quot;sh_python&quot;</span>&gt;</span></span><br><span class="line">n = int(input())</span><br><span class="line">lst = []</span><br><span class="line">for i in range(n):</span><br><span class="line">	s = input().split()</span><br><span class="line">	lst.append((s[0], int(s[1])))</span><br><span class="line">lst.sort(key= lambda x : (-x[1], x[0]))</span><br><span class="line">for x in lst:</span><br><span class="line">	print(x[0], x[1])<span class="tag">&lt;/<span class="name">pre</span>&gt;</span></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> asyncio</span><br><span class="line"><span class="keyword">import</span> pyppeteer <span class="keyword">as</span> pyp</span><br><span class="line"></span><br><span class="line"><span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">antiAntiCrawler</span>(<span class="params">page</span>):</span><br><span class="line">    <span class="comment"># 为page添加反反爬虫手段</span></span><br><span class="line">    <span class="keyword">await</span> page.setUserAgent(<span class="string">&#x27;Mozilla/5.0 (Windows NT 6.1; Win64; x64) \ &#x27;</span> <span class="string">&#x27;AppleWebKit/537.36 (KHTML, like Gecko) &#x27;</span> <span class="string">&#x27;Chrome/78.0.3904.70 Safari/537.36&#x27;</span>)</span><br><span class="line">    <span class="keyword">await</span> page.evaluateOnNewDocument(</span><br><span class="line">        <span class="string">&#x27;() =&gt;&#123; Object.defineProperties(navigator,&#x27;</span></span><br><span class="line">        <span class="string">&#x27;&#123; webdriver:&#123; get: () =&gt; false &#125; &#125;) &#125;&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">getOjSourceCode</span>(<span class="params">loginUrl</span>):</span><br><span class="line">    width, height = <span class="number">1400</span>, <span class="number">800</span>  <span class="comment">#网页宽高</span></span><br><span class="line">    browser = <span class="keyword">await</span> pyp.launch(headless=<span class="literal">False</span>,</span><br><span class="line">                               userdataDir=<span class="string">&quot;c:/tmp&quot;</span>,</span><br><span class="line">                               args=[<span class="string">f&#x27;--window-size=<span class="subst">&#123;width&#125;</span>,<span class="subst">&#123;height&#125;</span>&#x27;</span>])</span><br><span class="line">    page = <span class="keyword">await</span> browser.newPage()</span><br><span class="line">    <span class="keyword">await</span> antiAntiCrawler(page)</span><br><span class="line">    <span class="keyword">await</span> page.setViewport(&#123;<span class="string">&#x27;width&#x27;</span>: width, <span class="string">&#x27;height&#x27;</span>: height&#125;)</span><br><span class="line">    <span class="keyword">await</span> page.goto(loginUrl)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 若手动登录，则以下若干行可以去掉</span></span><br><span class="line">    element = <span class="keyword">await</span> page.querySelector(<span class="string">&quot;#email&quot;</span>)  <span class="comment"># 找到账户输入框</span></span><br><span class="line">    <span class="keyword">await</span> element.<span class="built_in">type</span>(<span class="string">&quot;XXXXX@qq.com&quot;</span>)  <span class="comment"># 输入邮箱</span></span><br><span class="line">    element = <span class="keyword">await</span> page.querySelector(<span class="string">&quot;#password&quot;</span>)  <span class="comment"># 找到密码输入框</span></span><br><span class="line">    <span class="keyword">await</span> element.<span class="built_in">type</span>(<span class="string">&quot;XXXXXXXXX&quot;</span>)  <span class="comment"># 输入密码</span></span><br><span class="line">    element = <span class="keyword">await</span> page.querySelector(<span class="string">&quot;#main &gt; form &gt; div.user-login &gt;    p:nth-child(2) &gt; button&quot;</span>) <span class="comment">#找到登录按钮</span></span><br><span class="line">    <span class="keyword">await</span> element.click()  <span class="comment"># 点击登录按钮</span></span><br><span class="line">    <span class="comment"># 若手动登录，则以上若干行可以去掉。time.sleep(10)或等待某个元素出现</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">await</span> page.waitForSelector(<span class="string">&quot;#main&gt;h2&quot;</span>, timeout=<span class="number">30000</span>)  <span class="comment"># 等待“正在进行的比赛....&quot;标题出现</span></span><br><span class="line"></span><br><span class="line">    element = <span class="keyword">await</span> page.querySelector(<span class="string">&quot;#userMenu&gt;li:nth-child(2)&gt;a&quot;</span>)</span><br><span class="line">    <span class="comment"># 找&quot;个人首页”链接</span></span><br><span class="line">    <span class="keyword">await</span> element.click()  <span class="comment"># 点击个人首页链接</span></span><br><span class="line">    <span class="keyword">await</span> page.waitForNavigation()  <span class="comment"># 等新网页装入完毕</span></span><br><span class="line"></span><br><span class="line">    elements = <span class="keyword">await</span> page.querySelectorAll(<span class="string">&quot;.result-right&quot;</span>)</span><br><span class="line">    <span class="comment"># 找所有&quot;Accepted&quot;链接, 其有属性 class=&quot;result-right&quot;</span></span><br><span class="line">    page2 = <span class="keyword">await</span> browser.newPage()  <span class="comment"># 新开一个页面 (标签)</span></span><br><span class="line">    <span class="keyword">await</span> antiAntiCrawler(page2)	<span class="comment">#添加反反爬</span></span><br><span class="line">    <span class="keyword">for</span> element <span class="keyword">in</span> elements[:<span class="number">2</span>]:  <span class="comment"># 只打印前两个程序</span></span><br><span class="line">        obj = <span class="keyword">await</span> element.getProperty(<span class="string">&quot;href&quot;</span>)  <span class="comment"># 获取href属性</span></span><br><span class="line">    	url = <span class="keyword">await</span> obj.jsonValue()</span><br><span class="line">   		<span class="keyword">await</span> page2.goto(url)  <span class="comment"># 在新页面(标签)中装入新网页</span></span><br><span class="line">    	element = <span class="keyword">await</span> page2.querySelector(<span class="string">&quot;pre&quot;</span>)  <span class="comment"># 查找pre tag</span></span><br><span class="line">    	obj = <span class="keyword">await</span> element.getProperty(<span class="string">&quot;innerText&quot;</span>)  <span class="comment"># 取源代码</span></span><br><span class="line">    	text = <span class="keyword">await</span> obj.jsonValue()</span><br><span class="line">    	<span class="built_in">print</span>(text)</span><br><span class="line">    	<span class="built_in">print</span>(<span class="string">&quot;-------------------------&quot;</span>)</span><br><span class="line">    <span class="keyword">await</span> browser.close()</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">main</span>():</span><br><span class="line">    url = <span class="string">&quot;http://openjudge.cn/auth/login/&quot;</span></span><br><span class="line">    syncio.get_event_loop().run_until_complete(getOjSourceCode(url))</span><br><span class="line"></span><br><span class="line">main()</span><br></pre></td></tr></table></figure>
<h2 id="pyppeteer-requests编写快速爬虫"><a href="#pyppeteer-requests编写快速爬虫" class="headerlink" title="pyppeteer+requests编写快速爬虫"></a>pyppeteer+requests编写快速爬虫</h2><ul>
<li>requests要对付登录比较麻烦（要用到抓包等技巧）</li>
<li>pyppeteer没有requests快(因为要浏览器渲染网页)</li>
<li>对于需要登录，且登录后的网页都不是javascript生成的动态网页的情况，可以使用pyppeteer登录后，再用requests做剩下的事情。</li>
</ul>
<p>网址: <a target="_blank" rel="noopener" href="http://openjudge.cn/user/2312/">http://openjudge.cn/user/2312/</a></p>
<p>不登录，访问同样网址，提示没有登录<br>同样的访问请求，服务器怎么知道浏览器是否登录过？</p>
<h3 id="预备知识：-cookie和session"><a href="#预备知识：-cookie和session" class="headerlink" title="预备知识： cookie和session"></a>预备知识： cookie和session</h3><ul>
<li><p>登录成功后，服务器向浏览器发送一些身份标识数据，称为cookie，浏览器以后每次向服务器发送请求，都带上cookie，服务器就能知道请求来自前面那个登录的浏览器了。</p>
</li>
<li><p>服务器在内存为浏览器维护一个session，每个浏览器对应不同的session，里面存放着该浏览器的状态（比如一系列的填表等步骤已经进行到什么程度），不同的session有不同的session id，浏览器发送请求的时候，如果带上session id,服务器也能知道是哪个浏览器在请求。</p>
</li>
<li><p>在客户计算机上由cookie可以生成标识同一个浏览器的session。</p>
</li>
</ul>
<h3 id="工作原理"><a href="#工作原理" class="headerlink" title="工作原理"></a>工作原理</h3><ul>
<li>pyppeteer的浏览器的页面有cookies()函数可以获得cookie</li>
<li>requests.Session()可以生成一个空session</li>
<li>session的cookies.update(cookies)函数可以根据cookies生成相应session</li>
<li>session的get(url)函数，可以向服务器发送带session的请求</li>
<li>获得cookie，生成相应session以后，爬取网页都用session的get函数进行(前提：网页不是javascript生成的。如果是，依然用pyppeteer的浏览器爬取）</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> asyncio</span><br><span class="line"><span class="keyword">import</span> pyppeteer <span class="keyword">as</span> pyp</span><br><span class="line"><span class="keyword">import</span> bs4</span><br><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">sessionGetHtml</span>(<span class="params">session, url</span>):  <span class="comment"># 发送带session的网页请求</span></span><br><span class="line">    fakeHeaders = &#123;</span><br><span class="line">        <span class="string">&#x27;User-Agent&#x27;</span>: <span class="string">&#x27;Mozilla/5.0 (Windows NT 10.0; Win64; x64) \</span></span><br><span class="line"><span class="string">    AppleWebKit/537.36 (KHTML, like Gecko) \</span></span><br><span class="line"><span class="string">    Chrome/81.0.4044.138 Safari/537.36 Edg/81.0.416.77&#x27;</span></span><br><span class="line">    &#125;  <span class="comment"># 伪装浏览器用的请求头</span></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        result = session.get(url, headers=fakeHeaders)</span><br><span class="line">        result.encoding = result.apparent_encoding</span><br><span class="line">        <span class="keyword">return</span> result.text</span><br><span class="line">    <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">        <span class="built_in">print</span>(e)</span><br><span class="line">        <span class="keyword">return</span> <span class="string">&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">makeSession</span>(<span class="params">page</span>):</span><br><span class="line">    <span class="comment"># 返回一个session,将其内部cookies修改成pypeteer浏览器页面对象中的cookies</span></span><br><span class="line">    cookies = <span class="keyword">await</span> page.cookies() <span class="comment">#cookies是一个列表,每个元素都是一个字典</span></span><br><span class="line">    cookies1 = &#123;&#125;</span><br><span class="line">    <span class="keyword">for</span> cookie <span class="keyword">in</span> cookies: <span class="comment"># requests中的cookies只要&quot;name&quot;属性</span></span><br><span class="line">    	cookies1[cookie[<span class="string">&#x27;name&#x27;</span>]] = cookie[<span class="string">&#x27;value&#x27;</span>]</span><br><span class="line">    session = requests.Session()</span><br><span class="line">    session.cookies.update(cookies1)</span><br><span class="line">    <span class="keyword">return</span> session</span><br><span class="line"></span><br><span class="line"><span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">antiAntiCrawler</span>(<span class="params">page</span>):</span><br><span class="line">    <span class="comment">#为page添加反反爬虫手段</span></span><br><span class="line">    <span class="keyword">await</span> page.setUserAgent(<span class="string">&#x27;Mozilla/5.0 (Windows NT 6.1; Win64; x64) \ &#x27;</span></span><br><span class="line">    <span class="string">&#x27;AppleWebKit/537.36 (KHTML, like Gecko) &#x27;</span></span><br><span class="line">    <span class="string">&#x27;Chrome/78.0.3904.70 Safari/537.36&#x27;</span>)</span><br><span class="line">    <span class="keyword">await</span> page.evaluateOnNewDocument(</span><br><span class="line">    <span class="string">&#x27;() =&gt;&#123; Object.defineProperties(navigator,&#x27;</span></span><br><span class="line">    <span class="string">&#x27;&#123; webdriver:&#123; get: () =&gt; false &#125; &#125;) &#125;&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">getOjSourceCode</span>(<span class="params">loginUrl</span>):</span><br><span class="line">    width, height = <span class="number">1400</span>, <span class="number">800</span> <span class="comment">#网页宽高</span></span><br><span class="line">    browser = <span class="keyword">await</span> pyp.launch(headless=<span class="literal">False</span>,</span><br><span class="line">    userdataDir = <span class="string">&quot;c:/tmp&quot;</span>,</span><br><span class="line">    args=[<span class="string">f&#x27;--window-size=<span class="subst">&#123;width&#125;</span>,<span class="subst">&#123;height&#125;</span>&#x27;</span>])</span><br><span class="line">    page = <span class="keyword">await</span> browser.newPage()</span><br><span class="line">    <span class="keyword">await</span> antiAntiCrawler(page)</span><br><span class="line">    <span class="keyword">await</span> page.setViewport(&#123;<span class="string">&#x27;width&#x27;</span>: width, <span class="string">&#x27;height&#x27;</span>: height&#125;)</span><br><span class="line">    <span class="keyword">await</span> page.goto(loginUrl)</span><br><span class="line">    <span class="keyword">await</span> page.waitForSelector(<span class="string">&quot;#main&gt;h2&quot;</span>,</span><br><span class="line">    timeout=<span class="number">30000</span>) <span class="comment">#等待手动登录后，“正在进行的比赛....&quot;标题出现</span></span><br><span class="line">    element = <span class="keyword">await</span> page.querySelector(<span class="string">&quot;#userMenu&gt;li:nth-child(2)&gt;a&quot;</span>)</span><br><span class="line">    <span class="comment">#找&quot;个人首页”链接</span></span><br><span class="line">    <span class="keyword">await</span> element.click() <span class="comment">#点击个人首页链接</span></span><br><span class="line">    <span class="keyword">await</span> page.waitForNavigation() <span class="comment">#等新网页装入完毕</span></span><br><span class="line">    </span><br><span class="line">    elements = <span class="keyword">await</span> page.querySelectorAll(<span class="string">&quot;.result-right&quot;</span>)</span><br><span class="line">    <span class="comment">#找所有&quot;Accepted&quot;链接, 其有属性 class=&quot;result-right&quot;</span></span><br><span class="line">    session = <span class="keyword">await</span> makeSession(page)</span><br><span class="line">    <span class="keyword">for</span> element <span class="keyword">in</span> elements[:<span class="number">2</span>]:</span><br><span class="line">    	obj = <span class="keyword">await</span> element.getProperty(<span class="string">&quot;href&quot;</span>)</span><br><span class="line">        url = <span class="keyword">await</span> obj.jsonValue()</span><br><span class="line">        html = sessionGetHtml(session, url)</span><br><span class="line">        soup = bs4.BeautifulSoup(html, <span class="string">&quot;html.parser&quot;</span>)</span><br><span class="line">        element = soup.find(<span class="string">&quot;pre&quot;</span>)</span><br><span class="line">        <span class="built_in">print</span>(element.text)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;-------------------------&quot;</span>)</span><br><span class="line">    <span class="keyword">await</span> browser.close()</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">main</span>():</span><br><span class="line">    url = <span class="string">&quot;http://openjudge.cn/auth/login/&quot;</span></span><br><span class="line">    asyncio.get_event_loop().run_until_complete(getOjSourceCode(url))</span><br><span class="line">main()</span><br></pre></td></tr></table></figure>
<h1 id="补充tips"><a href="#补充tips" class="headerlink" title="补充tips"></a>补充tips</h1><h2 id="绝对网址和相对网址"><a href="#绝对网址和相对网址" class="headerlink" title="绝对网址和相对网址"></a>绝对网址和相对网址</h2><ul>
<li><p>绝对网址以http:// 或 https:// 开头 ,相对网址无这两种开头<br>如果当前网页网址是：<br><code>http://www.pku.edu.cn/education/index.htm</code><br>而该网页中有一个链接，其中网址是相对的，形如：<br><code>&lt;a href=&quot;dict/word.htm&quot;&gt;词典单词&lt;/a&gt;</code><br>则该链接的真实网址（绝对网址）是：<br><code>http://www.pku.edu.cn/education/dict/word.htm</code></p>
</li>
<li><p>使用requests库时，获得当前网页网址: </p>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">r = requests.get(<span class="string">&quot;http://openjudge.cn&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(r.url) <span class="comment">#&gt;&gt;http://openjudge.cn</span></span><br><span class="line"><span class="comment">#或：</span></span><br><span class="line">session = requests.session()</span><br><span class="line">r = session.get(<span class="string">&quot;http://openjudge.cn&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(r.url)</span><br></pre></td></tr></table></figure>
<ul>
<li>使用pyppeteer库时，获得当前网页网址:</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">browser = <span class="keyword">await</span> pyp.launch(headless=<span class="literal">False</span>)</span><br><span class="line">page = <span class="keyword">await</span> browser.newPage()</span><br><span class="line"><span class="keyword">await</span> page.goto(<span class="string">&quot;http://openjudge.cn&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(page.url) <span class="comment">#&gt;&gt;http://openjudge.cn</span></span><br></pre></td></tr></table></figure>
<h2 id="反反爬"><a href="#反反爬" class="headerlink" title="反反爬"></a>反反爬</h2><ul>
<li>连续的两个操作之间，加入适当延时，模拟人的动作，以免因动作太快被识破</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> time</span><br><span class="line">time.sleep(<span class="number">2</span>) <span class="comment">#暂停2秒，啥也不做</span></span><br></pre></td></tr></table></figure>
<p>也可以用<code>time.sleep(...)</code>来等待一段时间，确保网页加载完成</p>
</div></article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="mailto:undefined">HibisciDai</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="http://hibiscidai.com/2023/02/02/实用Python程序设计MOOC-第十二章网络爬虫设计/">http://hibiscidai.com/2023/02/02/实用Python程序设计MOOC-第十二章网络爬虫设计/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a target="_blank" rel="noopener" href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="http://hibiscidai.com">HibisciDai</a>！</span></div></div><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/">学习笔记</a><a class="post-meta__tags" href="/tags/Python/">Python</a><a class="post-meta__tags" href="/tags/PythonMOOC/">PythonMOOC</a></div><div class="social-share pull-right" data-disabled="linkedin,diandian"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/social-share.js@1.0.16/dist/css/share.min.css"><script src="https://cdn.jsdelivr.net/npm/social-share.js@1.0.16/dist/js/social-share.min.js"></script><nav id="pagination"><div class="prev-post pull-left"><a href="/2023/02/03/%E5%AE%9E%E7%94%A8Python%E7%A8%8B%E5%BA%8F%E8%AE%BE%E8%AE%A1MOOC-%E7%AC%AC%E5%8D%81%E4%B8%89%E7%AB%A0%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1%E7%A8%8B%E5%BA%8F%E8%AE%BE%E8%AE%A1/"><i class="fa fa-chevron-left">  </i><span>实用Python程序设计MOOC-第十三章面向对象程序设计</span></a></div><div class="next-post pull-right"><a href="/2023/02/01/%E5%AE%9E%E7%94%A8Python%E7%A8%8B%E5%BA%8F%E8%AE%BE%E8%AE%A1MOOC-%E7%AC%AC%E5%8D%81%E4%B8%80%E7%AB%A0%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E5%92%8C%E5%B1%95%E7%A4%BA/"><span>实用Python程序设计MOOC-第十一章数据分析和展示</span><i class="fa fa-chevron-right"></i></a></div></nav><div class="post-adv"><a target="_blank" rel="noopener" href="https://xn--mesr8b36x.agency/#/register?code=R5RS1JHy">好用、实惠、稳定的梯子,点击这里<img src="https://pic.imgdb.cn/item/65572abac458853aefef30cd.png" width="1000" height="124" object-fit="cover" ></a></div><div id="lv-container" data-id="city" data-uid="MTAyMC8zNTQ2NC8xMjAwMA=="><script>(function(d, s) {
    var j, e = d.getElementsByTagName(s)[0];
    if (typeof LivereTower === 'function') { return; }
    j = d.createElement(s);
    j.src = 'https://cdn-city.livere.com/js/embed.dist.js';
    j.async = true;
    e.parentNode.insertBefore(j, e);
})(document, 'script');</script></div></div></div><footer class="footer-bg" style="background-image: url(/img/banner2.jpg)"><div class="layout" id="footer"><div class="copyright">&copy;2017 - 2024 By HibisciDai</div><div class="framework-info"><span>驱动 - </span><a target="_blank" rel="noopener" href="http://hexo.io"><span>Hexo</span></a><span class="footer-separator">|</span><span>主题 - </span><a target="_blank" rel="noopener" href="https://github.com/Molunerfinn/hexo-theme-melody"><span>Melody</span></a></div><div class="footer_custom_text">hitokoto</div><div class="busuanzi"><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><span id="busuanzi_container_page_pv"><i class="fa fa-file"></i><span id="busuanzi_value_page_pv"></span><span></span></span></div></div></footer><i class="fa fa-arrow-up" id="go-up" aria-hidden="true"></i><script src="/js/third-party/anime.min.js"></script><script src="/js/third-party/jquery.min.js"></script><script src="/js/third-party/jquery.fancybox.min.js"></script><script src="/js/third-party/velocity.min.js"></script><script src="/js/third-party/velocity.ui.min.js"></script><script src="/js/utils.js?version=1.9.0"></script><script src="/js/fancybox.js?version=1.9.0"></script><script src="/js/sidebar.js?version=1.9.0"></script><script src="/js/copy.js?version=1.9.0"></script><script src="/js/fireworks.js?version=1.9.0"></script><script src="/js/transition.js?version=1.9.0"></script><script src="/js/scroll.js?version=1.9.0"></script><script src="/js/head.js?version=1.9.0"></script><script type="text/x-mathjax-config">MathJax.Hub.Config({
  tex2jax: {
    inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
    processEscapes: true,
    skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
  },
  CommonHTML: {
    linebreaks: { automatic: true, width: "90% container" }
  },
  "HTML-CSS": { 
    linebreaks: { automatic: true, width: "90% container" }
  },
  "SVG": { 
    linebreaks: { automatic: true, width: "90% container" }
  }
});
</script><script type="text/x-mathjax-config">MathJax.Hub.Queue(function() {
  var all = MathJax.Hub.getAllJax(), i;
  for (i=0; i < all.length; i += 1) {
    all[i].SourceElement().parentNode.className += ' has-jax';
  }
});
</script><script src="https://cdn.bootcss.com/mathjax/2.7.2/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/katex@latest/dist/katex.min.css"><script src="https://cdn.jsdelivr.net/npm/katex-copytex@latest/dist/katex-copytex.min.js"></script><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/katex-copytex@latest/dist/katex-copytex.min.css"><script src="/js/katex.js"></script><script src="/js/search/local-search.js"></script><script id="ribbon" src="/js/third-party/canvas-ribbon.js" size="150" alpha="0.6" zIndex="-1" data-click="false"></script><script>if(/Android|webOS|iPhone|iPod|iPad|BlackBerry/i.test(navigator.userAgent)) {
  $('#nav').addClass('is-mobile')
  $('footer').addClass('is-mobile')
  $('#top-container').addClass('is-mobile')
}</script><div class="search-dialog" id="local-search"><div class="search-dialog__title" id="local-search-title">本地搜索</div><div id="local-input-panel"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章"></div></div></div><hr><div id="local-search-results"><div id="local-hits"></div><div id="local-stats"><div class="local-search-stats__hr" id="hr"><span>由</span> <a target="_blank" rel="noopener" href="https://github.com/wzpan/hexo-generator-search" style="color:#49B1F5;">hexo-generator-search</a>
 <span>提供支持</span></div></div></div><span class="search-close-button"><i class="fa fa-times"></i></span></div><div class="search-mask"></div></body></html>