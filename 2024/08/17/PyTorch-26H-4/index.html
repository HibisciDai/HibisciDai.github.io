<!DOCTYPE html><html lang="zh-Hans"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta name="description" content="PyTorch-26H-4"><meta name="keywords" content="学习笔记,PyTorch"><meta name="author" content="HibisciDai"><meta name="copyright" content="HibisciDai"><title>PyTorch-26H-4 | HibisciDai</title><link rel="shortcut icon" href="/img/avatar.png"><link rel="stylesheet" href="/css/index.css?version=1.9.0"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/font-awesome@latest/css/font-awesome.min.css?version=1.9.0"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.7.2/css/all.css?version=1.9.0"><meta name="format-detection" content="telephone=no"><meta http-equiv="x-dns-prefetch-control" content="on"><link rel="dns-prefetch" href="https://cdn.jsdelivr.net"><link rel="manifest" href="/manifest.json"><link rel="manifest" href="/manifest.json"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><script src="https://v1.hitokoto.cn/?encode=js&amp;charset=utf-8&amp;select=.footer_custom_text" defer></script><script>var GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: {"path":"search.xml","languages":{"hits_empty":"找不到您查询的内容:${query}"}},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  hexoVersion: '6.1.0'
} </script><meta name="generator" content="Hexo 6.1.0"><link rel="alternate" href="/atom.xml" title="HibisciDai" type="application/atom+xml">
</head><body><canvas class="fireworks"></canvas><i class="fa fa-arrow-right" id="toggle-sidebar" aria-hidden="true"></i><div id="sidebar" data-display="true"><div class="toggle-sidebar-info text-center"><span data-toggle="切换文章详情">切换站点概览</span><hr></div><div class="sidebar-toc"><div class="sidebar-toc__title">目录</div><div class="sidebar-toc__progress"><span class="progress-notice">你已经读了</span><span class="progress-num">0</span><span class="progress-percentage">%</span><div class="sidebar-toc__progress-bar"></div></div><div class="sidebar-toc__content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#PyTorch-26H-4"><span class="toc-number">1.</span> <span class="toc-text">PyTorch-26H-4</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Where-does-computer-vision-get-used"><span class="toc-number">2.</span> <span class="toc-text">Where does computer vision get used?</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#input-and-output-shape"><span class="toc-number">2.1.</span> <span class="toc-text">input and output shape</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#What-is-a-convolutional-neural-network-CNN"><span class="toc-number">3.</span> <span class="toc-text">What is a convolutional neural network(CNN)</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#What-we%E2%80%99re-going-to-cover"><span class="toc-number">4.</span> <span class="toc-text">What we’re going to cover</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#0-Computer-vision-libraries-in-PyTorch"><span class="toc-number">5.</span> <span class="toc-text">0. Computer vision libraries in PyTorch</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#1-Getting-a-dataset-%E8%8E%B7%E5%8F%96%E6%95%B0%E6%8D%AE%E9%9B%86"><span class="toc-number">6.</span> <span class="toc-text">1. Getting a dataset 获取数据集</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#1-1-Input-and-output-shapes-of-a-computer-vision-model-%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89%E6%A8%A1%E5%9E%8B%E7%9A%84%E8%BE%93%E5%85%A5%E5%92%8C%E8%BE%93%E5%87%BA%E5%BD%A2%E7%8A%B6"><span class="toc-number">6.1.</span> <span class="toc-text">1.1 Input and output shapes of a computer vision model 计算机视觉模型的输入和输出形状</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#1-2-Visualizing-our-data"><span class="toc-number">6.2.</span> <span class="toc-text">1.2 Visualizing our data</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#2-Prepare-DataLoader"><span class="toc-number">7.</span> <span class="toc-text">2. Prepare DataLoader</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#3-Model-0-Build-a-baseline-model-%E6%A8%A1%E5%9E%8B-0%EF%BC%9A%E5%BB%BA%E7%AB%8B%E5%9F%BA%E7%BA%BF%E6%A8%A1%E5%9E%8B"><span class="toc-number">8.</span> <span class="toc-text">3. Model 0: Build a baseline model 模型 0：建立基线模型</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#3-1-Setup-loss-optimizer-and-evaluation-metrics-%E8%AE%BE%E7%BD%AE%E6%8D%9F%E5%A4%B1%E3%80%81%E4%BC%98%E5%8C%96%E5%99%A8%E5%92%8C%E8%AF%84%E4%BC%B0%E6%8C%87%E6%A0%87"><span class="toc-number">8.1.</span> <span class="toc-text">3.1 Setup loss, optimizer and evaluation metrics 设置损失、优化器和评估指标</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3-2-Creating-a-function-to-time-our-experiments-%E5%88%9B%E5%BB%BA%E4%B8%80%E4%B8%AA%E5%87%BD%E6%95%B0%E6%9D%A5%E8%AE%A1%E6%97%B6%E6%88%91%E4%BB%AC%E7%9A%84%E5%AE%9E%E9%AA%8C"><span class="toc-number">8.2.</span> <span class="toc-text">3.2 Creating a function to time our experiments 创建一个函数来计时我们的实验</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3-3-Creating-a-training-loop-and-training-a-model-on-batches-of-data-%E5%88%9B%E5%BB%BA%E8%AE%AD%E7%BB%83%E5%BE%AA%E7%8E%AF%E5%B9%B6%E5%9C%A8%E6%89%B9%E9%87%8F%E6%95%B0%E6%8D%AE%E4%B8%8A%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B"><span class="toc-number">8.3.</span> <span class="toc-text">3.3 Creating a training loop and training a model on batches of data 创建训练循环并在批量数据上训练模型</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#4-Make-predictions-and-get-Model-0-results-%E8%BF%9B%E8%A1%8C%E9%A2%84%E6%B5%8B%E5%B9%B6%E8%8E%B7%E5%8F%96%E6%A8%A1%E5%9E%8B-0-%E7%BB%93%E6%9E%9C"><span class="toc-number">9.</span> <span class="toc-text">4. Make predictions and get Model 0 results 进行预测并获取模型 0 结果</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#5-Setup-device-agnostic-code-for-using-a-GPU-if-there-is-one-%E8%AE%BE%E7%BD%AE%E8%AE%BE%E5%A4%87%E6%97%A0%E5%85%B3%E4%BB%A3%E7%A0%81%EF%BC%88%E5%A6%82%E6%9E%9C%E6%9C%89-GPU-%E5%88%99%E4%BD%BF%E7%94%A8-GPU%EF%BC%89"><span class="toc-number">10.</span> <span class="toc-text">5. Setup device agnostic-code (for using a GPU if there is one)设置设备无关代码（如果有 GPU 则使用 GPU）</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#6-Model-1-Building-a-better-model-with-non-linearity-%E6%9E%84%E5%BB%BA%E6%9B%B4%E5%A5%BD%E7%9A%84%E9%9D%9E%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B"><span class="toc-number">11.</span> <span class="toc-text">6. Model 1: Building a better model with non-linearity 构建更好的非线性模型</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#6-1-Setup-loss-optimizer-and-evaluation-metrics-%E8%AE%BE%E7%BD%AE%E6%8D%9F%E5%A4%B1%E3%80%81%E4%BC%98%E5%8C%96%E5%99%A8%E5%92%8C%E8%AF%84%E4%BC%B0%E6%8C%87%E6%A0%87"><span class="toc-number">11.1.</span> <span class="toc-text">6.1 Setup loss, optimizer and evaluation metrics 设置损失、优化器和评估指标</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#6-2-Functionizing-training-and-evaluation-testing-loops-%E5%8A%9F%E8%83%BD%E5%8C%96%E8%AE%AD%E7%BB%83%E5%92%8C%E6%B5%8B%E8%AF%95%E5%BE%AA%E7%8E%AF"><span class="toc-number">11.2.</span> <span class="toc-text">6.2 Functionizing training and evaluation&#x2F;testing loops 功能化训练和测试循环</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#7-Model-2-Building-a-Convolutional-Neural-Network-CNN-%E6%A8%A1%E5%9E%8B2%EF%BC%9A%E5%BB%BA%E7%AB%8B%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%EF%BC%88CNN%EF%BC%89"><span class="toc-number">12.</span> <span class="toc-text">7. Model 2: Building a Convolutional Neural Network (CNN)模型2：建立卷积神经网络（CNN）</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#What-model-should-I-use-%E6%88%91%E5%BA%94%E8%AF%A5%E4%BD%BF%E7%94%A8%E4%BB%80%E4%B9%88%E6%A8%A1%E5%9E%8B%EF%BC%9F"><span class="toc-number">12.1.</span> <span class="toc-text">What model should I use?我应该使用什么模型？</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#7-1-Stepping-throughnn-Conv2d"><span class="toc-number">12.2.</span> <span class="toc-text">7.1 Stepping throughnn.Conv2d()</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#7-2-Stepping-through-nn-MaxPool2d"><span class="toc-number">12.3.</span> <span class="toc-text">7.2 Stepping through nn.MaxPool2d()</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#7-3-Setup-a-loss-function-and-optimizer-for-model-2"><span class="toc-number">12.4.</span> <span class="toc-text">7.3 Setup a loss function and optimizer for model_2</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#7-4-Training-and-testing-model-2-using-our-training-and-test-functions"><span class="toc-number">12.5.</span> <span class="toc-text">7.4 Training and testing model_2 using our training and test functions</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#8-Compare-model-results-and-training-time-%E6%AF%94%E8%BE%83%E6%A8%A1%E5%9E%8B%E7%BB%93%E6%9E%9C%E5%92%8C%E8%AE%AD%E7%BB%83%E6%97%B6%E9%97%B4"><span class="toc-number">13.</span> <span class="toc-text">8. Compare model results and training time 比较模型结果和训练时间</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#Performance-speed-tradeoff"><span class="toc-number">13.1.</span> <span class="toc-text">Performance-speed tradeoff</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#9-Make-and-evaluate-random-predictions-with-best-model-%E4%BD%BF%E7%94%A8%E6%9C%80%E4%BD%B3%E6%A8%A1%E5%9E%8B%E8%BF%9B%E8%A1%8C%E9%9A%8F%E6%9C%BA%E9%A2%84%E6%B5%8B%E5%B9%B6%E8%AF%84%E4%BC%B0"><span class="toc-number">14.</span> <span class="toc-text">9. Make and evaluate random predictions with best model 使用最佳模型进行随机预测并评估</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#10-Making-a-confusion-matrix-for-further-prediction-evaluation-%E5%88%B6%E4%BD%9C%E6%B7%B7%E6%B7%86%E7%9F%A9%E9%98%B5%E4%BB%A5%E8%BF%9B%E8%A1%8C%E8%BF%9B%E4%B8%80%E6%AD%A5%E7%9A%84%E9%A2%84%E6%B5%8B%E8%AF%84%E4%BC%B0"><span class="toc-number">15.</span> <span class="toc-text">10. Making a confusion matrix for further prediction evaluation 制作混淆矩阵以进行进一步的预测评估</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E9%A6%96%E5%85%88%E7%94%A8%E8%AE%AD%E7%BB%83%E5%A5%BD%E7%9A%84%E6%A8%A1%E5%9E%8B%E8%BF%9B%E8%A1%8C%E9%A2%84%E6%B5%8B%E3%80%82"><span class="toc-number">15.1.</span> <span class="toc-text">首先用训练好的模型进行预测。</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%88%B6%E4%BD%9C%E6%B7%B7%E6%B7%86%E7%9F%A9%E9%98%B5"><span class="toc-number">15.2.</span> <span class="toc-text">制作混淆矩阵</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%BB%98%E5%88%B6%E6%B7%B7%E6%B7%86%E7%9F%A9%E9%98%B5"><span class="toc-number">15.3.</span> <span class="toc-text">绘制混淆矩阵</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#11-Save-and-load-best-performing-model"><span class="toc-number">16.</span> <span class="toc-text">11. Save and load best performing model</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Exercises"><span class="toc-number">17.</span> <span class="toc-text">Exercises</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Extra-curriculum"><span class="toc-number">18.</span> <span class="toc-text">Extra-curriculum</span></a></li></ol></div></div><div class="author-info hide"><div class="author-info__avatar text-center"><img src="/img/Avatar.png"></div><div class="author-info__name text-center">HibisciDai</div><div class="author-info__description text-center">HibisciDai'Blog</div><hr><div class="author-info-articles"><a class="author-info-articles__archives article-meta" href="/archives"><span class="pull-left">文章</span><span class="pull-right">244</span></a><a class="author-info-articles__tags article-meta" href="/tags"><span class="pull-left">标签</span><span class="pull-right">88</span></a><a class="author-info-articles__categories article-meta" href="/categories"><span class="pull-left">分类</span><span class="pull-right">33</span></a></div><hr><div class="author-info-links"><div class="author-info-links__title text-center">友情链接</div><a class="author-info-links__name text-center" target="_blank" rel="noopener" href="https://github.com/HibisciDai/hexo-theme-melody">HexoTheme-github</a><a class="author-info-links__name text-center" target="_blank" rel="noopener" href="https://molunerfinn.com/">molunerfinn</a></div></div></div><div id="content-outer"><div id="top-container" style="background-image: url(/img/banner2.jpg)"><div id="page-header"><span class="pull-left"> <a id="site-name" href="/">HibisciDai</a></span><i class="fa fa-bars toggle-menu pull-right" aria-hidden="true"></i><span class="pull-right menus">   <a class="site-page" href="/">主页</a><a class="site-page" href="/about">关于我</a><a class="site-page" href="/archives">归档</a><a class="site-page" href="/tags">标签</a><a class="site-page" href="/categories">分类</a><a class="site-page" href="/gallery">相册</a></span><span class="pull-right"><a class="site-page social-icon search"><i class="fa fa-search"></i><span> 搜索</span></a></span></div><div id="post-info"><div id="post-title">PyTorch-26H-4</div><div id="post-meta"><time class="post-meta__date"><i class="fa fa-calendar" aria-hidden="true"></i> 2024-08-17</time><span class="post-meta__separator">|</span><i class="fa fa-inbox post-meta__icon" aria-hidden="true"></i><a class="post-meta__categories" href="/categories/PyTorch/">PyTorch</a><div class="post-meta-wordcount"><span>字数总计: </span><span class="word-count">14k</span><span class="post-meta__separator">|</span><span>阅读时长: 60 分钟</span></div></div></div></div><div class="layout" id="content-inner"><article id="post"><div class="article-container" id="post-content"><img src="/2024/08/17/PyTorch-26H-4/PyTorch-26H-4.png" class="" title="PyTorch-26H-4">
<p>PyTorch-26H-4</p>
<span id="more"></span>
<h1 id="PyTorch-26H-4"><a href="#PyTorch-26H-4" class="headerlink" title="PyTorch-26H-4"></a>PyTorch-26H-4</h1><p>主页：<a target="_blank" rel="noopener" href="https://www.freecodecamp.org/news/learn-pytorch-for-deep-learning-in-day/">https://www.freecodecamp.org/news/learn-pytorch-for-deep-learning-in-day/</a></p>
<p>youtub：<a target="_blank" rel="noopener" href="https://youtu.be/V_xro1bcAuA">https://youtu.be/V_xro1bcAuA</a></p>
<p>github：<a target="_blank" rel="noopener" href="https://github.com/mrdbourke/pytorch-deep-learning">https://github.com/mrdbourke/pytorch-deep-learning</a></p>
<p>Learn PyTorch for Deep Learning: Zero to Mastery book：<a target="_blank" rel="noopener" href="https://www.learnpytorch.io/">https://www.learnpytorch.io/</a></p>
<p>PyTorch documentation：<a target="_blank" rel="noopener" href="https://pytorch.org/docs/stable/index.html">https://pytorch.org/docs/stable/index.html</a></p>
<p>计算机视觉<a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Computer_vision">Computer vision</a>是教计算机看东西的艺术。</p>
<p>例如，它可能涉及建立一个模型来对照片是猫还是狗进行分类（二元分类<a target="_blank" rel="noopener" href="https://developers.google.com/machine-learning/glossary#binary-classification">binary classification</a>）。</p>
<p>或者照片是猫、狗还是鸡（多类分类<a target="_blank" rel="noopener" href="https://developers.google.com/machine-learning/glossary#multi-class-classification">multi-class classification</a>）。</p>
<p>或者识别汽车在视频帧中出现的位置（物体检测<a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Object_detection">object detection</a>）。</p>
<p>或者弄清楚图像中不同物体可以分离的位置（全景分割<a target="_blank" rel="noopener" href="https://arxiv.org/abs/1801.00868">panoptic segmentation</a>）。</p>
<p><a target="_blank" rel="noopener" href="https://machinelearning.apple.com/">machinelearning_apple</a></p>
<img src="/2024/08/17/PyTorch-26H-4/PyTorch-26H-4-1.png" class="" title="PyTorch-26H-4-1">
<h1 id="Where-does-computer-vision-get-used"><a href="#Where-does-computer-vision-get-used" class="headerlink" title="Where does computer vision get used?"></a>Where does computer vision get used?</h1><p>如果您使用智能手机，那么您已 经使用了计算机视觉。</p>
<p>相机和照片应用程序使用计算机视觉来增强<a target="_blank" rel="noopener" href="https://machinelearning.apple.com/research/panoptic-segmentation">computer vision to enhance</a>和分类图像。</p>
<p>现代汽车使用计算机视觉<a target="_blank" rel="noopener" href="https://youtu.be/j0z4FweCy4M?t=2989">computer vision</a>来避开其他车辆并保持在车道线内。</p>
<img src="/2024/08/17/PyTorch-26H-4/PyTorch-26H-4-1_2.png" class="" title="PyTorch-26H-4-1_2">
<p>制造商使用计算机视觉来识别各种产品的缺陷。</p>
<p>安全摄像机使用计算机视觉来检测潜在的入侵者。</p>
<p>本质上，任何能够用视觉描述的事物都可能成为潜在的计算机视觉问题。</p>
<h2 id="input-and-output-shape"><a href="#input-and-output-shape" class="headerlink" title="input and output shape"></a>input and output shape</h2><img src="/2024/08/17/PyTorch-26H-4/PyTorch-26H-4-1_3.png" class="" title="PyTorch-26H-4-1_3">
<img src="/2024/08/17/PyTorch-26H-4/PyTorch-26H-4-1_4.png" class="" title="PyTorch-26H-4-1_4">
<img src="/2024/08/17/PyTorch-26H-4/PyTorch-26H-4-1_5.png" class="" title="PyTorch-26H-4-1_5">
<h1 id="What-is-a-convolutional-neural-network-CNN"><a href="#What-is-a-convolutional-neural-network-CNN" class="headerlink" title="What is a convolutional neural network(CNN)"></a>What is a convolutional neural network(CNN)</h1><img src="/2024/08/17/PyTorch-26H-4/PyTorch-26H-4-1_6.png" class="" title="PyTorch-26H-4-1_6">
<p><a target="_blank" rel="noopener" href="https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html">torch.nn.Conv2d</a></p>
<h1 id="What-we’re-going-to-cover"><a href="#What-we’re-going-to-cover" class="headerlink" title="What we’re going to cover"></a>What we’re going to cover</h1><ul>
<li>Getting a vision dataset to work with using <code>torchvision.datasets</code></li>
<li>使用 <code>torchvision.datasets</code> 获取视觉数据集</li>
<li>Architecture of a convolutional neural network (CNN) with PyTorch</li>
<li>使用 PyTorch 构建卷积神经网络 (CNN) 架构</li>
<li>An end-to-end multi-class image classification problem</li>
<li>端到端多类图像分类问题</li>
<li>Steps in modelling with CNNs in PyTorch</li>
<li>使用 PyTorch 中的 CNN 建模的步骤</li>
<li>Creating a CNN model with PyTorch</li>
<li>使用 PyTorch 创建 CNN 模型</li>
<li>Picking a loss and optimizer</li>
<li>选择损失和优化器</li>
<li>Training a PyTorch computer vision model</li>
<li>训练 PyTorch 计算机视觉模型</li>
<li>Evaluating a model</li>
<li>评估模型</li>
</ul>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center">话题</th>
<th style="text-align:center">内容</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">0. PyTorch 中的计算机视觉库</td>
<td style="text-align:center">PyTorch 有许多内置的有用的计算机视觉库</td>
</tr>
<tr>
<td style="text-align:center">1. 加载数据</td>
<td style="text-align:center">为了练习计算机视觉，我们将从FashionMNIST](<a target="_blank" rel="noopener" href="https://github.com/zalandoresearch/fashion-mnist)中的一些不同服装的图像开始。">https://github.com/zalandoresearch/fashion-mnist)中的一些不同服装的图像开始。</a></td>
</tr>
<tr>
<td style="text-align:center">2.准备数据</td>
<td style="text-align:center">我们有一些图像，让我们用 <a target="_blank" rel="noopener" href="https://pytorch.org/docs/stable/data.html">PyTorch <code>DataLoader</code></a>加载它们，以便我们可以在训练循环中使用它们。</td>
</tr>
<tr>
<td style="text-align:center">3. 模型 0：建立基线模型</td>
<td style="text-align:center">在这里我们将创建一个多类分类模型来学习数据中的模式，我们还将选择一个损失函数 <strong>loss function</strong>、优化器 <strong>optimizer</strong>并建立一个训练循环<strong>training loop</strong>.。</td>
</tr>
<tr>
<td style="text-align:center">4. 做出预测并评估模型 0</td>
<td style="text-align:center">让我们用基线模型做出一些预测并对其进行评估。</td>
</tr>
<tr>
<td style="text-align:center">5. 为未来型号设置与设备无关的代码</td>
<td style="text-align:center">编写与设备无关的代码是最佳做法，因此让我们进行设置。</td>
</tr>
<tr>
<td style="text-align:center">6. 模型 1：添加非线性</td>
<td style="text-align:center">实验是机器学习的重要组成部分，让我们尝试通过添加非线性层来改进我们的基线模型。</td>
</tr>
<tr>
<td style="text-align:center">7.模型2：卷积神经网络（CNN）</td>
<td style="text-align:center">是时候具体了解计算机视觉并介绍强大的卷积神经网络架构了。</td>
</tr>
<tr>
<td style="text-align:center">8. 比较我们的模型</td>
<td style="text-align:center">我们建立了三个不同的模型，让我们对它们进行比较。</td>
</tr>
<tr>
<td style="text-align:center">9.评估我们的最佳模型</td>
<td style="text-align:center">让我们对随机图像做出一些预测并评估我们最好的模型。</td>
</tr>
<tr>
<td style="text-align:center">10. 制作混淆矩阵</td>
<td style="text-align:center">混淆矩阵是评估分类模型的好方法，让我们看看如何创建一个混淆矩阵。</td>
</tr>
<tr>
<td style="text-align:center">11.保存并加载性能最佳的模型</td>
<td style="text-align:center">因为我们可能需要稍后使用我们的模型，所以我们保存它并确保它能正确加载。</td>
</tr>
</tbody>
</table>
</div>
<h1 id="0-Computer-vision-libraries-in-PyTorch"><a href="#0-Computer-vision-libraries-in-PyTorch" class="headerlink" title="0. Computer vision libraries in PyTorch"></a>0. Computer vision libraries in PyTorch</h1><p>PyTorch 计算机视觉库</p>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center">PyTorch模块</th>
<th style="text-align:center">作用</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center"><a target="_blank" rel="noopener" href="https://pytorch.org/vision/stable/index.html"><code>torchvision</code></a></td>
<td style="text-align:center">包含常用于计算机视觉问题的数据集、模型架构和图像转换。</td>
</tr>
<tr>
<td style="text-align:center"><a target="_blank" rel="noopener" href="https://pytorch.org/vision/stable/datasets.html"><code>torchvision.datasets</code></a></td>
<td style="text-align:center">许多示例计算机视觉数据集，用于解决图像分类、对象检测、图像字幕、视频分类等一系列问题。它还包含<a target="_blank" rel="noopener" href="https://pytorch.org/vision/stable/datasets.html#base-classes-for-custom-datasets">一系列用于制作自定义数据集的基类</a>。</td>
</tr>
<tr>
<td style="text-align:center"><a target="_blank" rel="noopener" href="https://pytorch.org/vision/stable/models.html"><code>torchvision.models</code></a></td>
<td style="text-align:center">该模块包含在 PyTorch 中实现的性能良好且常用的计算机视觉模型架构。</td>
</tr>
<tr>
<td style="text-align:center"><a target="_blank" rel="noopener" href="https://pytorch.org/vision/stable/transforms.html"><code>torchvision.transforms</code></a></td>
<td style="text-align:center">通常，图像需要在用于模型之前进行转换（转换为数字/处理/增强），常见的图像转换可以在这里找到。</td>
</tr>
<tr>
<td style="text-align:center"><a target="_blank" rel="noopener" href="https://pytorch.org/docs/stable/data.html#torch.utils.data.Dataset"><code>torch.utils.data.Dataset</code></a></td>
<td style="text-align:center">PyTorch 的基础数据集类。</td>
</tr>
<tr>
<td style="text-align:center"><a target="_blank" rel="noopener" href="https://pytorch.org/docs/stable/data.html#module-torch.utils.data"><code>torch.utils.data.DataLoader</code></a></td>
<td style="text-align:center">在数据集上创建一个 Python 可迭代对象（使用 创建<code>torch.utils.data.Dataset</code>）。</td>
</tr>
</tbody>
</table>
</div>
<p><code>torch.utils.data.Dataset</code>和类<code>torch.utils.data.DataLoader</code>不仅适用于 PyTorch 中的计算机视觉，它们还能够处理许多不同类型的数据。</p>
<p><a target="_blank" rel="noopener" href="https://pytorch.org/vision/stable/transforms.html">torchvison文档</a></p>
<p>导入相关依赖项：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Import PyTorch</span></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"></span><br><span class="line"><span class="comment"># Import torchvision </span></span><br><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> datasets</span><br><span class="line"><span class="keyword">from</span> torchvision.transforms <span class="keyword">import</span> ToTensor</span><br><span class="line"></span><br><span class="line"><span class="comment"># Import matplotlib for visualization</span></span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="comment"># Check versions</span></span><br><span class="line"><span class="comment"># Note: your PyTorch version shouldn&#x27;t be lower than 1.10.0 and torchvision version shouldn&#x27;t be lower than 0.11</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;PyTorch version: <span class="subst">&#123;torch.__version__&#125;</span>\ntorchvision version: <span class="subst">&#123;torchvision.__version__&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">PyTorch version: 2.4.1</span><br><span class="line">torchvision version: 0.19.1</span><br></pre></td></tr></table></figure>
<h1 id="1-Getting-a-dataset-获取数据集"><a href="#1-Getting-a-dataset-获取数据集" class="headerlink" title="1. Getting a dataset 获取数据集"></a>1. Getting a dataset 获取数据集</h1><p>从 FashionMNIST 开始。</p>
<p>MNIST，Modified National Institute of Standards and Technology，修改后的国家标准与技术研究院</p>
<p><a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/MNIST_database">original MNIST dataset</a>原始 MNIST 数据集包含数千个手写数字示例（从 0 到 9），用于构建计算机视觉模型来识别邮政服务的数字。</p>
<p><a target="_blank" rel="noopener" href="https://github.com/zalandoresearch/fashion-mnist">FashionMNIST</a>Zalando Research 制作的FashionMNIST是一个类似的设置。</p>
<p>包含 10 种不同服装的灰度图像。</p>
<img src="/2024/08/17/PyTorch-26H-4/PyTorch-26H-4-2.png" class="" title="PyTorch-26H-4-2">
<p><code>torchvision.datasets</code>包含大量示例数据集，可用于练习编写计算机视觉代码。<code>FashionMNIST</code> 就是其中一个数据集。由于它有 10 个不同的图像类别（不同类型的服装），因此它是一个多类别分类问题。</p>
<p>稍后，我们将构建一个计算机视觉神经网络来识别这些图像中不同风格的服装。</p>
<p>PyTorch 中存储了大量常见的计算机视觉数据集<code>torchvision.datasets</code>。</p>
<p>为了下载它，我们提供以下参数：</p>
<ul>
<li><code>root: str</code>，将数据下载到哪个文件夹？</li>
<li><code>train: Bool</code>，要训练还是测试分割？</li>
<li><code>download: Bool</code>，是否应该下载数据？</li>
<li><code>transform: torchvision.transforms</code>，想对数据进行哪些转换？</li>
<li><code>target_transform</code>， 如果您愿意，可以转换目标（标签）。</li>
</ul>
<p>许多其他数据集torchvision都有这些参数选项。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Setup training data</span></span><br><span class="line">train_data = datasets.FashionMNIST(</span><br><span class="line">    root=<span class="string">&quot;data&quot;</span>, <span class="comment"># where to download data to?</span></span><br><span class="line">    train=<span class="literal">True</span>, <span class="comment"># get training data</span></span><br><span class="line">    download=<span class="literal">True</span>, <span class="comment"># download data if it doesn&#x27;t exist on disk</span></span><br><span class="line">    transform=ToTensor(), <span class="comment"># images come as PIL format, we want to turn into Torch tensors</span></span><br><span class="line">    target_transform=<span class="literal">None</span> <span class="comment"># you can transform labels as well</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Setup testing data</span></span><br><span class="line">test_data = datasets.FashionMNIST(</span><br><span class="line">    root=<span class="string">&quot;data&quot;</span>,</span><br><span class="line">    train=<span class="literal">False</span>, <span class="comment"># get test data</span></span><br><span class="line">    download=<span class="literal">True</span>,</span><br><span class="line">    transform=ToTensor()</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz</span><br><span class="line">Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to data/FashionMNIST/raw/train-images-idx3-ubyte.gz</span><br><span class="line"><span class="meta prompt_">100%</span><span class="language-bash">|██████████| 26.4M/26.4M [00:01&lt;00:00, 14.2MB/s]</span></span><br><span class="line">Extracting data/FashionMNIST/raw/train-images-idx3-ubyte.gz to data/FashionMNIST/raw</span><br><span class="line"></span><br><span class="line">Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz</span><br><span class="line">Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to data/FashionMNIST/raw/train-labels-idx1-ubyte.gz</span><br><span class="line"><span class="meta prompt_">100%</span><span class="language-bash">|██████████| 29.5k/29.5k [00:00&lt;00:00, 232kB/s]</span></span><br><span class="line">Extracting data/FashionMNIST/raw/train-labels-idx1-ubyte.gz to data/FashionMNIST/raw</span><br><span class="line"></span><br><span class="line">Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz</span><br><span class="line">Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz</span><br><span class="line"><span class="meta prompt_">100%</span><span class="language-bash">|██████████| 4.42M/4.42M [00:01&lt;00:00, 4.32MB/s]</span></span><br><span class="line">Extracting data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to data/FashionMNIST/raw</span><br><span class="line"></span><br><span class="line">Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz</span><br><span class="line">Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz</span><br><span class="line"><span class="meta prompt_">100%</span><span class="language-bash">|██████████| 5.15k/5.15k [00:00&lt;00:00, 15.8MB/s]Extracting data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to data/FashionMNIST/raw</span></span><br></pre></td></tr></table></figure>
<p>国内下载有问题，使用google colab上传代码下载后加载到本地。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">len</span>(train_data),<span class="built_in">len</span>(test_data)</span><br></pre></td></tr></table></figure>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">(60000, 10000)</span><br></pre></td></tr></table></figure>
<img src="/2024/08/17/PyTorch-26H-4/PyTorch-26H-4-3.png" class="" title="PyTorch-26H-4-3">
<p>查看第一个训练样本：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">image, label = train_data[<span class="number">0</span>]</span><br><span class="line">image, label</span><br></pre></td></tr></table></figure>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">(tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,...</span><br><span class="line">, 9)</span><br></pre></td></tr></table></figure>
<h2 id="1-1-Input-and-output-shapes-of-a-computer-vision-model-计算机视觉模型的输入和输出形状"><a href="#1-1-Input-and-output-shapes-of-a-computer-vision-model-计算机视觉模型的输入和输出形状" class="headerlink" title="1.1 Input and output shapes of a computer vision model 计算机视觉模型的输入和输出形状"></a>1.1 Input and output shapes of a computer vision model 计算机视觉模型的输入和输出形状</h2><p>得到了一个很大的值张量（图像），它可以得出目标的单一值（标签）。</p>
<ul>
<li>看图像形状</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">image.shape</span><br></pre></td></tr></table></figure>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.Size([1, 28, 28])</span><br></pre></td></tr></table></figure>
<p>图像张量的形状<code>[1, 28, 28]</code>具体如下：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[color_channels=1, height=28, width=28]</span><br></pre></td></tr></table></figure>
<p>有<code>color_channels=1</code>意味着图像是灰度的。</p>
<img src="/2024/08/17/PyTorch-26H-4/PyTorch-26H-4-4.png" class="" title="PyTorch-26H-4-4">
<p>不同的问题会有不同的输入和输出形状。<br>但前提是不变的：将数据编码为数字，建立模型来寻找这些数字中的模式，将这些模式转换成有意义的东西。</p>
<p>如果<code>color_channels=3</code>，图像的像素值为红、绿和蓝（这也称为RGB 颜色模型）。</p>
<p>我们当前张量的顺序通常被称为<code>CHW</code>（颜色通道、高度、宽度）。</p>
<p><strong>关于图像通道，channel last</strong></p>
<blockquote>
<p>关于图像应该表示为<code>CHW</code>（颜色通道优先）还是<code>HWC</code>（颜色通道最后）存在争议。<br>注意：还将看到<code>NCHW</code>和<code>NHWC</code>格式，其中<code>N</code>代表图像数量。例如，如果有<code>batch_size=32</code>，则张量形状可能是<code>[32, 1, 28, 28]</code>。我们稍后会介绍批量大小。<br>PyTorch 通常接受<code>NCHW</code>（通道优先）作为许多运算符的默认设置。<br>不过，PyTorch 也解释说<code>NHWC</code>（通道最后）表现更好，被认为是最佳实践<a target="_blank" rel="noopener" href="https://pytorch.org/blog/tensor-memory-format-matters/#pytorch-best-practice">considered best practice</a>.。<br>由于我们的数据集和模型相对较小，这不会产生太大的影响。<br>但是当处理更大的图像数据集并使用卷积神经网络时请记住这一点（我们稍后会看到这些）。</p>
</blockquote>
<ul>
<li>检查数据的更多形状</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># How many samples are there? </span></span><br><span class="line"><span class="built_in">len</span>(train_data.data), <span class="built_in">len</span>(train_data.targets), <span class="built_in">len</span>(test_data.data), <span class="built_in">len</span>(test_data.targets)</span><br></pre></td></tr></table></figure>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">(60000, 60000, 10000, 10000)</span><br></pre></td></tr></table></figure>
<p>我们有 60,000 个训练样本和 10,000 个测试样本。</p>
<ul>
<li>检查数据类别</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># See classes</span></span><br><span class="line">class_names = train_data.classes</span><br><span class="line">class_names</span><br></pre></td></tr></table></figure>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">[&#x27;T-shirt/top&#x27;,</span><br><span class="line"> &#x27;Trouser&#x27;,</span><br><span class="line"> &#x27;Pullover&#x27;,</span><br><span class="line"> &#x27;Dress&#x27;,</span><br><span class="line"> &#x27;Coat&#x27;,</span><br><span class="line"> &#x27;Sandal&#x27;,</span><br><span class="line"> &#x27;Shirt&#x27;,</span><br><span class="line"> &#x27;Sneaker&#x27;,</span><br><span class="line"> &#x27;Bag&#x27;,</span><br><span class="line"> &#x27;Ankle boot&#x27;]</span><br></pre></td></tr></table></figure>
<p>10个类别的衣服，意味着多分类模型。</p>
<h2 id="1-2-Visualizing-our-data"><a href="#1-2-Visualizing-our-data" class="headerlink" title="1.2 Visualizing our data"></a>1.2 Visualizing our data</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">image, label = train_data[<span class="number">0</span>]</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Image shape: <span class="subst">&#123;image.shape&#125;</span>&quot;</span>)</span><br><span class="line">plt.imshow(image.squeeze()) <span class="comment"># image shape is [1, 28, 28] (colour channels, height, width)</span></span><br><span class="line">plt.title(label);</span><br></pre></td></tr></table></figure>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Image shape: torch.Size([1, 28, 28])</span><br></pre></td></tr></table></figure>
<img src="/2024/08/17/PyTorch-26H-4/PyTorch-26H-4-5.png" class="" title="PyTorch-26H-4-5">
<p>我们可以使用<code>plt.imshow()</code>的<code>cmap</code>参数将图像转换为灰度。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">plt.imshow(image.squeeze(), cmap=<span class="string">&quot;gray&quot;</span>)</span><br><span class="line">plt.title(class_names[label]);</span><br></pre></td></tr></table></figure>
<img src="/2024/08/17/PyTorch-26H-4/PyTorch-26H-4-6.png" class="" title="PyTorch-26H-4-6">
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Plot more images</span></span><br><span class="line">torch.manual_seed(<span class="number">42</span>)</span><br><span class="line">fig = plt.figure(figsize=(<span class="number">9</span>, <span class="number">9</span>))</span><br><span class="line">rows, cols = <span class="number">4</span>, <span class="number">4</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, rows * cols + <span class="number">1</span>):</span><br><span class="line">    random_idx = torch.randint(<span class="number">0</span>, <span class="built_in">len</span>(train_data), size=[<span class="number">1</span>]).item()</span><br><span class="line">    img, label = train_data[random_idx]</span><br><span class="line">    fig.add_subplot(rows, cols, i)</span><br><span class="line">    plt.imshow(img.squeeze(), cmap=<span class="string">&quot;gray&quot;</span>)</span><br><span class="line">    plt.title(class_names[label])</span><br><span class="line">    plt.axis(<span class="literal">False</span>);</span><br></pre></td></tr></table></figure>
<img src="/2024/08/17/PyTorch-26H-4/PyTorch-26H-4-7.png" class="" title="PyTorch-26H-4-7">
<h1 id="2-Prepare-DataLoader"><a href="#2-Prepare-DataLoader" class="headerlink" title="2. Prepare DataLoader"></a>2. Prepare DataLoader</h1><p>已经准备好数据集了，下一步是用<code>torch.utils.data.DataLoader</code>或准备。</p>
<p>它有助于将数据加载到模型中，用于训练和推理。</p>
<p>它将较大的数据转换 <code>Dataset</code> 成由较小块组成的 Python 可迭代数据。<br>这些较小的块称为批次或小批次，可以通过参数设置 <code>batch_size</code>。</p>
<p>在理想世界中，您可以一次对所有数据进行前向传递和后向传递。<br>但是一旦你开始使用非常大的数据集，除非你拥有无限的计算能力，否则将它们分成几批会更容易。</p>
<p>对于小批量（数据的一小部分），梯度下降在每个时期执行得更频繁（每个小批量一次，而不是每个时期一次）。合适的批次大小是多少？<a target="_blank" rel="noopener" href="https://twitter.com/ylecun/status/989610208497360896?s=20&amp;t=N96J_jotN--PYuJk2WcjMw">32 是一个好的起点</a><br>但由于这是一个您可以设置的值（超参数），您可以尝试各种不同的值，尽管通常最常使用 2 的幂（例如 32、64、128、256、512）。</p>
<img src="/2024/08/17/PyTorch-26H-4/PyTorch-26H-4-8.png" class="" title="PyTorch-26H-4-8">
<p>对 FashionMNIST 进行批处理，批处理大小为 32，并开启随机排序功能。其他数据集也会发生类似的批处理过程，但会根据批处理大小而有所不同。</p>
<p><a target="_blank" rel="noopener" href="https://pytorch.org/docs/stable/data.html">torch.utils.data</a></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> DataLoader</span><br><span class="line"></span><br><span class="line"><span class="comment"># Setup the batch size hyperparameter</span></span><br><span class="line">BATCH_SIZE = <span class="number">32</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Turn datasets into iterables (batches)</span></span><br><span class="line">train_dataloader = DataLoader(train_data, <span class="comment"># dataset to turn into iterable</span></span><br><span class="line">    batch_size=BATCH_SIZE, <span class="comment"># how many samples per batch? </span></span><br><span class="line">    shuffle=<span class="literal">True</span> <span class="comment"># shuffle data every epoch?</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">test_dataloader = DataLoader(test_data,</span><br><span class="line">    batch_size=BATCH_SIZE,</span><br><span class="line">    shuffle=<span class="literal">False</span> <span class="comment"># don&#x27;t necessarily have to shuffle the testing data</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Let&#x27;s check out what we&#x27;ve created</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Dataloaders: <span class="subst">&#123;train_dataloader, test_dataloader&#125;</span>&quot;</span>) </span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Length of train datalo ader: <span class="subst">&#123;<span class="built_in">len</span>(train_dataloader)&#125;</span> batches of <span class="subst">&#123;BATCH_SIZE&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Length of test dataloader: <span class="subst">&#123;<span class="built_in">len</span>(test_dataloader)&#125;</span> batches of <span class="subst">&#123;BATCH_SIZE&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Dataloaders: (&lt;torch.utils.data.dataloader.DataLoader object at 0x00000248133AACA0&gt;, &lt;torch.utils.data.dataloader.DataLoader object at 0x0000024813313580&gt;)</span><br><span class="line">Length of train dataloader: 1875 batches of 32</span><br><span class="line">Length of test dataloader: 313 batches of 32</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Check out what&#x27;s inside the training dataloader</span></span><br><span class="line">train_features_batch, train_labels_batch = <span class="built_in">next</span>(<span class="built_in">iter</span>(train_dataloader))</span><br><span class="line">train_features_batch.shape, train_labels_batch.shape</span><br></pre></td></tr></table></figure>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">(torch.Size([32, 1, 28, 28]), torch.Size([32]))</span><br></pre></td></tr></table></figure>
<p>我们通过检查单个样本可以看到数据保持不变。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Show a sample</span></span><br><span class="line">torch.manual_seed(<span class="number">42</span>)</span><br><span class="line">random_idx = torch.randint(<span class="number">0</span>, <span class="built_in">len</span>(train_features_batch), size=[<span class="number">1</span>]).item()</span><br><span class="line">img, label = train_features_batch[random_idx], train_labels_batch[random_idx]</span><br><span class="line">plt.imshow(img.squeeze(), cmap=<span class="string">&quot;gray&quot;</span>)</span><br><span class="line">plt.title(class_names[label])</span><br><span class="line">plt.axis(<span class="string">&quot;Off&quot;</span>);</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Image size: <span class="subst">&#123;img.shape&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Label: <span class="subst">&#123;label&#125;</span>, label size: <span class="subst">&#123;label.shape&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Image size: torch.Size([1, 28, 28])</span><br><span class="line">Label: 6, label size: torch.Size([])</span><br></pre></td></tr></table></figure>
<img src="/2024/08/17/PyTorch-26H-4/PyTorch-26H-4-9.png" class="" title="PyTorch-26H-4-9">
<h1 id="3-Model-0-Build-a-baseline-model-模型-0：建立基线模型"><a href="#3-Model-0-Build-a-baseline-model-模型-0：建立基线模型" class="headerlink" title="3. Model 0: Build a baseline model 模型 0：建立基线模型"></a>3. Model 0: Build a baseline model 模型 0：建立基线模型</h1><p>通过子类化来构建<code>基线模型</code> <code>nn.Module</code>了。</p>
<p><code>基线模型</code>是你所能想象到的最简单的模型之一。</p>
<p>您使用基线作为起点，并尝试使用后续更复杂的模型对其进行改进。</p>
<p>基线模型将由两层组成<code>nn.Linear()</code>。</p>
<p>因为我们正在处理图像数据，所以我们将使用不同的层来开始。</p>
<p>这就是<code>nn.Flatten()</code>层。</p>
<p><code>nn.Flatten()</code>将张量的维度压缩为单个向量。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Create a flatten layer</span></span><br><span class="line">flatten_model = nn.Flatten() <span class="comment"># all nn modules function as a model (can do a forward pass)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Get a single sample</span></span><br><span class="line">x = train_features_batch[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># Flatten the sample</span></span><br><span class="line">output = flatten_model(x) <span class="comment"># perform forward pass</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Print out what happened</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Shape before flattening: <span class="subst">&#123;x.shape&#125;</span> -&gt; [color_channels, height, width]&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Shape after flattening: <span class="subst">&#123;output.shape&#125;</span> -&gt; [color_channels, height*width]&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Try uncommenting below and see what happens</span></span><br><span class="line"><span class="comment">#print(x)</span></span><br><span class="line"><span class="comment">#print(output)</span></span><br></pre></td></tr></table></figure>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Shape before flattening: torch.Size([1, 28, 28]) -&gt; [color_channels, height, width]</span><br><span class="line">Shape after flattening: torch.Size([1, 784]) -&gt; [color_channels, height*width]</span><br></pre></td></tr></table></figure>
<p><code>nn.Flatten()</code>将形状从<code>[color_channels, height, width]</code>变为<code>[color_channels, height*width]</code></p>
<p>已经将像素数据从高度和宽度维度转换为一个长特征向量。<br>并且<code>nn.Linear()</code>层喜欢将其输入视为特征向量的形式。<br>让我们使用它<code>nn.Flatten()</code>作为第一层来创建我们的第一个模型。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"><span class="keyword">class</span> <span class="title class_">FashionMNISTModelV0</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, input_shape: <span class="built_in">int</span>, hidden_units: <span class="built_in">int</span>, output_shape: <span class="built_in">int</span></span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.layer_stack = nn.Sequential(</span><br><span class="line">            nn.Flatten(), <span class="comment"># neural networks like their inputs in vector form</span></span><br><span class="line">            nn.Linear(in_features=input_shape, out_features=hidden_units), <span class="comment"># in_features = number of features in a data sample (784 pixels)</span></span><br><span class="line">            nn.Linear(in_features=hidden_units, out_features=output_shape)</span><br><span class="line">        )</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        <span class="keyword">return</span> self.layer_stack(x)</span><br></pre></td></tr></table></figure>
<p>实例化模型，设置以下参数：</p>
<ul>
<li><code>input_shape=784</code>，这是模型中所拥有的特征数，在我们的例子中，目标图像中每个像素都有一个特征（28 像素高 x 28 像素宽 = 784 个特征）。</li>
<li><code>hidden_units=10</code>，隐藏层中的单元/神经元的数量，这个数字可以是任何你想要的，但为了保持模型较小，我们将从开始10。</li>
<li><code>output_shape=len(class_names)</code>，因为我们正在处理多类分类问题，所以我们需要数据集中每个类一个输出神经元。</li>
</ul>
<p>创建模型的一个实例并将其发送到 CPU（我们将很快在 CPU 上运行一个小测试，model_0对比在 GPU 上运行的类似模型）。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">torch.manual_seed(<span class="number">42</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Need to setup model with input parameters</span></span><br><span class="line">model_0 = FashionMNISTModelV0(input_shape=<span class="number">784</span>, <span class="comment"># one for every pixel (28x28)</span></span><br><span class="line">    hidden_units=<span class="number">10</span>, <span class="comment"># how many units in the hidden layer</span></span><br><span class="line">    output_shape=<span class="built_in">len</span>(class_names) <span class="comment"># one for every class</span></span><br><span class="line">)</span><br><span class="line">model_0.to(<span class="string">&quot;cpu&quot;</span>) <span class="comment"># keep model on CPU to begin with </span></span><br></pre></td></tr></table></figure>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">FashionMNISTModelV0(</span><br><span class="line">  (layer_stack): Sequential(</span><br><span class="line">    (0): Flatten(start_dim=1, end_dim=-1)</span><br><span class="line">    (1): Linear(in_features=784, out_features=10, bias=True)</span><br><span class="line">    (2): Linear(in_features=10, out_features=10, bias=True)</span><br><span class="line">  )</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<h2 id="3-1-Setup-loss-optimizer-and-evaluation-metrics-设置损失、优化器和评估指标"><a href="#3-1-Setup-loss-optimizer-and-evaluation-metrics-设置损失、优化器和评估指标" class="headerlink" title="3.1 Setup loss, optimizer and evaluation metrics 设置损失、优化器和评估指标"></a>3.1 Setup loss, optimizer and evaluation metrics 设置损失、优化器和评估指标</h2><p><code>损失函数</code>：由于我们处理的是多类数据，因此我们的损失函数将是 <code>nn.crossEntropyLoss( )</code><br><code>优化器</code>：我们的优化器 <code>torch.optim.sGD()</code>(随机梯度下降)<br><code>评估指标</code>：由于我们正在处理分类问题，因此我们使用准确率作为评估指标</p>
<p>因为我们正在研究分类问题，所以我们引入<code>helper_functions.py</code> 脚本，然后引入<code>accuracy_fn()</code> 我们在笔记本 02中定义的脚本。</p>
<p><strong>您可以从</strong><a target="_blank" rel="noopener" href="https://torchmetrics.readthedocs.io/en/latest/">TorchMetrics 包</a>中导入各种评估指标，而不是导入和使用我们自己的准确性函数或评估指标。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">from</span> pathlib <span class="keyword">import</span> Path </span><br><span class="line"></span><br><span class="line"><span class="comment"># Download helper functions from Learn PyTorch repo (if not already downloaded)</span></span><br><span class="line"><span class="keyword">if</span> Path(<span class="string">&quot;helper_functions.py&quot;</span>).is_file():</span><br><span class="line">  <span class="built_in">print</span>(<span class="string">&quot;helper_functions.py already exists, skipping download&quot;</span>)</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">  <span class="built_in">print</span>(<span class="string">&quot;Downloading helper_functions.py&quot;</span>)</span><br><span class="line">  <span class="comment"># Note: you need the &quot;raw&quot; GitHub URL for this to work</span></span><br><span class="line">  request = requests.get(<span class="string">&quot;https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/helper_functions.py&quot;</span>)</span><br><span class="line">  <span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&quot;helper_functions.py&quot;</span>, <span class="string">&quot;wb&quot;</span>) <span class="keyword">as</span> f:</span><br><span class="line">    f.write(request.content)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Import accuracy metric</span></span><br><span class="line"><span class="comment"># 导入准确度指标</span></span><br><span class="line"><span class="keyword">from</span> helper_functions <span class="keyword">import</span> accuracy_fn <span class="comment"># Note: could also use torchmetrics.Accuracy(task = &#x27;multiclass&#x27;, num_classes=len(class_names)).to(device)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Setup loss function and optimizer</span></span><br><span class="line"><span class="comment"># 设置损失函数和优化器</span></span><br><span class="line">loss_fn = nn.CrossEntropyLoss() <span class="comment"># this is also called &quot;criterion&quot;/&quot;cost function&quot; in some places</span></span><br><span class="line"><span class="comment"># 在某些地方这也被称为“标准”/“成本函数”</span></span><br><span class="line">optimizer = torch.optim.SGD(params=model_0.parameters(), lr=<span class="number">0.1</span>)</span><br></pre></td></tr></table></figure>
<h2 id="3-2-Creating-a-function-to-time-our-experiments-创建一个函数来计时我们的实验"><a href="#3-2-Creating-a-function-to-time-our-experiments-创建一个函数来计时我们的实验" class="headerlink" title="3.2 Creating a function to time our experiments 创建一个函数来计时我们的实验"></a>3.2 Creating a function to time our experiments 创建一个函数来计时我们的实验</h2><p>机器学习非常具有实验性。<br>您经常想要跟踪的两个主要内容是：</p>
<ol>
<li>模型的性能（损失和准确度值等）</li>
<li>运行速度</li>
</ol>
<p>制作一个计时函数来测量我们的模型在 CPU 上训练所需的时间与使用 GPU 所需的时间。</p>
<p>我们将在 CPU 上训练这个模型，然后在 GPU 上训练下一个模型，看看会发生什么。</p>
<p>我们的计时函数将从Python <a target="_blank" rel="noopener" href="https://docs.python.org/3/library/timeit.html">timeit</a> 模块导入<a target="_blank" rel="noopener" href="https://docs.python.org/3/library/timeit.html#timeit.default_timer">timeit.default_timer()</a> 函数。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> timeit <span class="keyword">import</span> default_timer <span class="keyword">as</span> timer </span><br><span class="line"><span class="keyword">def</span> <span class="title function_">print_train_time</span>(<span class="params">start: <span class="built_in">float</span>, end: <span class="built_in">float</span>, device: torch.device = <span class="literal">None</span></span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Prints difference between start and end time.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        start (float): Start time of computation (preferred in timeit format). </span></span><br><span class="line"><span class="string">        end (float): End time of computation.</span></span><br><span class="line"><span class="string">        device ([type], optional): Device that compute is running on. Defaults to None.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">        float: time between start and end in seconds (higher is longer).</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    total_time = end - start</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;Train time on <span class="subst">&#123;device&#125;</span>: <span class="subst">&#123;total_time:<span class="number">.3</span>f&#125;</span> seconds&quot;</span>)</span><br><span class="line">    <span class="keyword">return</span> total_time</span><br></pre></td></tr></table></figure>
<h2 id="3-3-Creating-a-training-loop-and-training-a-model-on-batches-of-data-创建训练循环并在批量数据上训练模型"><a href="#3-3-Creating-a-training-loop-and-training-a-model-on-batches-of-data-创建训练循环并在批量数据上训练模型" class="headerlink" title="3.3 Creating a training loop and training a model on batches of data 创建训练循环并在批量数据上训练模型"></a>3.3 Creating a training loop and training a model on batches of data 创建训练循环并在批量数据上训练模型</h2><p>已经准备的东西：一个计时器、一个损失函数、一个优化器、一个模型。</p>
<p>创建一个训练循环和一个测试循环来训练和评估我们的模型。</p>
<p>我们将使用与以前的笔记本相同的步骤，但由于我们的数据现在是批量形式，我们将添加另一个循环来循环遍历我们的数据批次。</p>
<p>我们的数据批次包含在我们的<code>DataLoaders</code> 中，<code>train_dataloader</code>分别<code>test_dataloader</code>用于训练和测试数据分割。</p>
<p>一个批次是 <code>X</code>（特征）和 <code>y</code>（标签）的 <code>BATCH_SIZE</code> 个样本，因为我们使用 <code>BATCH_SIZE=32</code>，所以我们的批次有 32 个图像和目标样本。</p>
<p>由于我们正在对批量数据进行计算，因此我们的损失和评估指标将按批次计算，而不是按整个数据集计算。</p>
<p>这意味着我们必须将损失和准确度值除以每个数据集各自的数据加载器中的批次数。</p>
<p>让我们逐步进行：</p>
<p>1、循环历经各个时期。<br>2、循环训练批次，执行训练步骤，计算每个批次的 train loss 训练损失。<br>3、循环测试批次，执行测试步骤，计算每个批次的 test loss 测试损失。<br>4、打印出正在发生的事情。<br>5、计时全部内容（为了好玩）。</p>
<p><a target="_blank" rel="noopener" href="https://github.com/tqdm/tqdm">tqdm</a> ：开源的进度条，colab内置了tqdm，不需要导入。只需要将tqdm装入迭代器就可以使用。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Import tqdm for progress bar</span></span><br><span class="line"><span class="keyword">from</span> tqdm.auto <span class="keyword">import</span> tqdm</span><br><span class="line"></span><br><span class="line"><span class="comment"># Set the seed and start the timer</span></span><br><span class="line">torch.manual_seed(<span class="number">42</span>)</span><br><span class="line">train_time_start_on_cpu = timer()</span><br><span class="line"></span><br><span class="line"><span class="comment"># Set the number of epochs (we&#x27;ll keep this small for faster training times)</span></span><br><span class="line">epochs = <span class="number">3</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Create training and testing loop</span></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> tqdm(<span class="built_in">range</span>(epochs)):</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;Epoch: <span class="subst">&#123;epoch&#125;</span>\n-------&quot;</span>)</span><br><span class="line">    <span class="comment">### Training</span></span><br><span class="line">    train_loss = <span class="number">0</span></span><br><span class="line">    <span class="comment"># Add a loop to loop through training batches</span></span><br><span class="line">    <span class="keyword">for</span> batch, (X, y) <span class="keyword">in</span> <span class="built_in">enumerate</span>(train_dataloader):</span><br><span class="line">        model_0.train() </span><br><span class="line">        <span class="comment"># 1. Forward pass</span></span><br><span class="line">        y_pred = model_0(X)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 2. Calculate loss (per batch)</span></span><br><span class="line">        loss = loss_fn(y_pred, y)</span><br><span class="line">        train_loss += loss <span class="comment"># accumulatively add up the loss per epoch </span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 3. Optimizer zero grad</span></span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 4. Loss backward</span></span><br><span class="line">        loss.backward()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 5. Optimizer step</span></span><br><span class="line">        optimizer.step()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Print out how many samples have been seen</span></span><br><span class="line">        <span class="keyword">if</span> batch % <span class="number">400</span> == <span class="number">0</span>:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&quot;Looked at <span class="subst">&#123;batch * <span class="built_in">len</span>(X)&#125;</span>/<span class="subst">&#123;<span class="built_in">len</span>(train_dataloader.dataset)&#125;</span> samples&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Divide total train loss by length of train dataloader (average loss per batch per epoch)</span></span><br><span class="line">    train_loss /= <span class="built_in">len</span>(train_dataloader)</span><br><span class="line">    </span><br><span class="line">    <span class="comment">### Testing</span></span><br><span class="line">    <span class="comment"># Setup variables for accumulatively adding up loss and accuracy </span></span><br><span class="line">    test_loss, test_acc = <span class="number">0</span>, <span class="number">0</span> </span><br><span class="line">    model_0.<span class="built_in">eval</span>()</span><br><span class="line">    <span class="keyword">with</span> torch.inference_mode():</span><br><span class="line">        <span class="keyword">for</span> X, y <span class="keyword">in</span> test_dataloader:</span><br><span class="line">            <span class="comment"># 1. Forward pass</span></span><br><span class="line">            test_pred = model_0(X)</span><br><span class="line">           </span><br><span class="line">            <span class="comment"># 2. Calculate loss (accumulatively)</span></span><br><span class="line">            test_loss += loss_fn(test_pred, y) <span class="comment"># accumulatively add up the loss per epoch</span></span><br><span class="line"></span><br><span class="line">            <span class="comment"># 3. Calculate accuracy (preds need to be same as y_true)</span></span><br><span class="line">            test_acc += accuracy_fn(y_true=y, y_pred=test_pred.argmax(dim=<span class="number">1</span>))</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Calculations on test metrics need to happen inside torch.inference_mode()</span></span><br><span class="line">        <span class="comment"># Divide total test loss by length of test dataloader (per batch)</span></span><br><span class="line">        test_loss /= <span class="built_in">len</span>(test_dataloader)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Divide total accuracy by length of test dataloader (per batch)</span></span><br><span class="line">        test_acc /= <span class="built_in">len</span>(test_dataloader)</span><br><span class="line"></span><br><span class="line">    <span class="comment">## Print out what&#x27;s happening</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;\nTrain loss: <span class="subst">&#123;train_loss:<span class="number">.5</span>f&#125;</span> | Test loss: <span class="subst">&#123;test_loss:<span class="number">.5</span>f&#125;</span>, Test acc: <span class="subst">&#123;test_acc:<span class="number">.2</span>f&#125;</span>%\n&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Calculate training time      </span></span><br><span class="line">train_time_end_on_cpu = timer()</span><br><span class="line">total_train_time_model_0 = print_train_time(start=train_time_start_on_cpu, </span><br><span class="line">                                           end=train_time_end_on_cpu,</span><br><span class="line">                                           device=<span class="built_in">str</span>(<span class="built_in">next</span>(model_0.parameters()).device))</span><br></pre></td></tr></table></figure>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">Epoch: 0</span><br><span class="line">-------</span><br><span class="line">Looked at 0/60000 samples</span><br><span class="line">Looked at 12800/60000 samples</span><br><span class="line">Looked at 25600/60000 samples</span><br><span class="line">Looked at 38400/60000 samples</span><br><span class="line">Looked at 51200/60000 samples</span><br><span class="line"></span><br><span class="line">Train loss: 0.59039 | Test loss: 0.50954, Test acc: 82.04%</span><br><span class="line"></span><br><span class="line">Epoch: 1</span><br><span class="line">-------</span><br><span class="line">Looked at 0/60000 samples</span><br><span class="line">Looked at 12800/60000 samples</span><br><span class="line">Looked at 25600/60000 samples</span><br><span class="line">Looked at 38400/60000 samples</span><br><span class="line">Looked at 51200/60000 samples</span><br><span class="line"></span><br><span class="line">Train loss: 0.47633 | Test loss: 0.47989, Test acc: 83.20%</span><br><span class="line"></span><br><span class="line">Epoch: 2</span><br><span class="line">-------</span><br><span class="line">Looked at 0/60000 samples</span><br><span class="line">Looked at 12800/60000 samples</span><br><span class="line">Looked at 25600/60000 samples</span><br><span class="line">Looked at 38400/60000 samples</span><br><span class="line">Looked at 51200/60000 samples</span><br><span class="line"></span><br><span class="line">Train loss: 0.45503 | Test loss: 0.47664, Test acc: 83.43%</span><br><span class="line"></span><br><span class="line">Train time on cpu: 44.767 seconds</span><br></pre></td></tr></table></figure>
<h1 id="4-Make-predictions-and-get-Model-0-results-进行预测并获取模型-0-结果"><a href="#4-Make-predictions-and-get-Model-0-results-进行预测并获取模型-0-结果" class="headerlink" title="4. Make predictions and get Model 0 results 进行预测并获取模型 0 结果"></a>4. Make predictions and get Model 0 results 进行预测并获取模型 0 结果</h1><p>创建一个函数，它包含一个训练好的模型、一个DataLoader、一个损失函数和一个准确度函数。</p>
<p>该函数将使用模型对数据进行预测DataLoader，然后我们可以使用损失函数和准确度函数评估这些预测。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line">torch.manual_seed(<span class="number">42</span>)</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">eval_model</span>(<span class="params">model: torch.nn.Module, </span></span><br><span class="line"><span class="params">               data_loader: torch.utils.data.DataLoader, </span></span><br><span class="line"><span class="params">               loss_fn: torch.nn.Module, </span></span><br><span class="line"><span class="params">               accuracy_fn</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Returns a dictionary containing the results of model predicting on data_loader.返回包含 data_loader 模型预测结果的字典。</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        model (torch.nn.Module): A PyTorch model capable of making predictions on data_loader.能够对 data_loader 进行预测的 PyTorch 模型。</span></span><br><span class="line"><span class="string">        data_loader (torch.utils.data.DataLoader): The target dataset to predict on.要进行预测的目标数据集。</span></span><br><span class="line"><span class="string">        loss_fn (torch.nn.Module): The loss function of model.模型的损失函数。</span></span><br><span class="line"><span class="string">        accuracy_fn: An accuracy function to compare the models predictions to the truth labels.用于将模型预测与真实标签进行比较的准确度函数。</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">        (dict): Results of model making predictions on data_loader.模型对 data_loader 进行预测的结果。</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    loss, acc = <span class="number">0</span>, <span class="number">0</span></span><br><span class="line">    model.<span class="built_in">eval</span>()</span><br><span class="line">    <span class="keyword">with</span> torch.inference_mode():</span><br><span class="line">        <span class="keyword">for</span> X, y <span class="keyword">in</span> tqdm(data_loader):</span><br><span class="line">            <span class="comment"># Make predictions with the model</span></span><br><span class="line">            y_pred = model(X)</span><br><span class="line">            </span><br><span class="line">            <span class="comment"># Accumulate the loss and accuracy values per batch</span></span><br><span class="line">            loss += loss_fn(y_pred, y)</span><br><span class="line">            acc += accuracy_fn(y_true=y, </span><br><span class="line">                                y_pred=y_pred.argmax(dim=<span class="number">1</span>)) <span class="comment"># For accuracy, need the prediction labels (logits -&gt; pred_prob -&gt; pred_labels)</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Scale loss and acc to find the average loss/acc per batch放损失和 acc 以找到每批的平均损失/ acc</span></span><br><span class="line">        loss /= <span class="built_in">len</span>(data_loader)</span><br><span class="line">        acc /= <span class="built_in">len</span>(data_loader)</span><br><span class="line">        </span><br><span class="line">    <span class="keyword">return</span> &#123;<span class="string">&quot;model_name&quot;</span>: model.__class__.__name__, <span class="comment"># only works when model was created with a class</span></span><br><span class="line">            <span class="string">&quot;model_loss&quot;</span>: loss.item(),</span><br><span class="line">            <span class="string">&quot;model_acc&quot;</span>: acc&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># Calculate model 0 results on test dataset</span></span><br><span class="line">model_0_results = eval_model(model=model_0, data_loader=test_dataloader,</span><br><span class="line">    loss_fn=loss_fn, accuracy_fn=accuracy_fn</span><br><span class="line">)</span><br><span class="line">model_0_results</span><br></pre></td></tr></table></figure>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&#123;&#x27;model_name&#x27;: &#x27;FashionMNISTModelV0&#x27;,</span><br><span class="line"> &#x27;model_loss&#x27;: 0.47663888335227966,</span><br><span class="line"> &#x27;model_acc&#x27;: 83.42651757188499&#125;</span><br></pre></td></tr></table></figure>
<p>可以使用这个词典将基线模型结果与其他模型进行比较。</p>
<p>模型训练时间取决于所用的硬件。通常，处理器越多意味着训练速度越快，较小数据集上的较小模型通常比大型模型和大型数据集训练速度更快。</p>
<h1 id="5-Setup-device-agnostic-code-for-using-a-GPU-if-there-is-one-设置设备无关代码（如果有-GPU-则使用-GPU）"><a href="#5-Setup-device-agnostic-code-for-using-a-GPU-if-there-is-one-设置设备无关代码（如果有-GPU-则使用-GPU）" class="headerlink" title="5. Setup device agnostic-code (for using a GPU if there is one)设置设备无关代码（如果有 GPU 则使用 GPU）"></a>5. Setup device agnostic-code (for using a GPU if there is one)设置设备无关代码（如果有 GPU 则使用 GPU）</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Setup device agnostic code</span></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line">device = <span class="string">&quot;cuda&quot;</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&quot;cpu&quot;</span></span><br><span class="line">device</span><br></pre></td></tr></table></figure>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cuda</span><br></pre></td></tr></table></figure>
<h1 id="6-Model-1-Building-a-better-model-with-non-linearity-构建更好的非线性模型"><a href="#6-Model-1-Building-a-better-model-with-non-linearity-构建更好的非线性模型" class="headerlink" title="6. Model 1: Building a better model with non-linearity 构建更好的非线性模型"></a>6. Model 1: Building a better model with non-linearity 构建更好的非线性模型</h1><p>我们将通过重新创建与之前类似的模型来实现此目的，但这次我们将在每个线性层之间放置非线性函数（<code>nn.ReLU()</code>）。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Create a model with non-linear and linear layers</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">FashionMNISTModelV1</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, input_shape: <span class="built_in">int</span>, hidden_units: <span class="built_in">int</span>, output_shape: <span class="built_in">int</span></span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.layer_stack = nn.Sequential(</span><br><span class="line">            nn.Flatten(), <span class="comment"># flatten inputs into single vector</span></span><br><span class="line">            nn.Linear(in_features=input_shape, out_features=hidden_units),</span><br><span class="line">            nn.ReLU(),</span><br><span class="line">            nn.Linear(in_features=hidden_units, out_features=output_shape),</span><br><span class="line">            nn.ReLU()</span><br><span class="line">        )</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x: torch.Tensor</span>):</span><br><span class="line">        <span class="keyword">return</span> self.layer_stack(x)</span><br></pre></td></tr></table></figure>
<p>用之前使用的相同设置来实例化它。我们需要<code>input_shape=784</code>（等于我们的图像数据的特征数量）、<code>hidden_units=10</code>（从小处开始并与我们的基线模型相同）和<code>output_shape=len(class_names)</code>（每个类一个输出单元）。</p>
<blockquote>
<p>除了添加非线性层之外，我们保持模型的大多数设置不变。这是运行一系列机器学习实验的标准做法，更改一件事并查看会发生什么，然后重复、重复、重复。</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">torch.manual_seed(<span class="number">42</span>)</span><br><span class="line">model_1 = FashionMNISTModelV1(input_shape=<span class="number">784</span>, <span class="comment"># number of input features</span></span><br><span class="line">    hidden_units=<span class="number">10</span>,</span><br><span class="line">    output_shape=<span class="built_in">len</span>(class_names) <span class="comment"># number of output classes desired</span></span><br><span class="line">).to(device) <span class="comment"># send model to GPU if it&#x27;s available</span></span><br><span class="line"><span class="built_in">next</span>(model_1.parameters()).device <span class="comment"># check model device</span></span><br></pre></td></tr></table></figure>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">device(type=&#x27;cuda&#x27;, index=0)</span><br></pre></td></tr></table></figure>
<h2 id="6-1-Setup-loss-optimizer-and-evaluation-metrics-设置损失、优化器和评估指标"><a href="#6-1-Setup-loss-optimizer-and-evaluation-metrics-设置损失、优化器和评估指标" class="headerlink" title="6.1 Setup loss, optimizer and evaluation metrics 设置损失、优化器和评估指标"></a>6.1 Setup loss, optimizer and evaluation metrics 设置损失、优化器和评估指标</h2><p>像往常一样，我们将设置一个损失函数、一个优化器和一个评估指标（我们可以做多个评估指标，但目前我们将坚持准确性）</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> helper_functions <span class="keyword">import</span> accuracy_fn</span><br><span class="line">loss_fn = nn.CrossEntropyLoss()</span><br><span class="line">optimizer = torch.optim.SGD(params=model_1.parameters(), </span><br><span class="line">                            lr=<span class="number">0.1</span>)</span><br></pre></td></tr></table></figure>
<h2 id="6-2-Functionizing-training-and-evaluation-testing-loops-功能化训练和测试循环"><a href="#6-2-Functionizing-training-and-evaluation-testing-loops-功能化训练和测试循环" class="headerlink" title="6.2 Functionizing training and evaluation/testing loops 功能化训练和测试循环"></a>6.2 Functionizing training and evaluation/testing loops 功能化训练和测试循环</h2><p>training loop - train_step()<br>testing loop - test_step()</p>
<p>到目前为止，我们一直在反复编写训练和测试循环。</p>
<p>让我们再次编写它们，但这次我们将把它们放在函数中，以便可以反复调用它们。</p>
<p>而且因为我们现在使用的是与设备无关的代码，所以我们一定要在特征 (X) 和目标 (y) 张量上调用 .to(device)。</p>
<p>对于训练循环，我们将创建一个名为 <code>train_step()</code> 的函数，它接受一个模型、一个 DataLoader、一个损失函数和一个优化器。</p>
<p>测试循环将类似，但它将被称为 <code>test_step()</code>，它将接受一个模型、一个 DataLoader、一个损失函数和一个评估函数。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">train_step</span>(<span class="params">model: torch.nn.Module,</span></span><br><span class="line"><span class="params">               data_loader: torch.utils.data.DataLoader,</span></span><br><span class="line"><span class="params">               loss_fn: torch.nn.Module,</span></span><br><span class="line"><span class="params">               optimizer: torch.optim.Optimizer,</span></span><br><span class="line"><span class="params">               accuracy_fn,</span></span><br><span class="line"><span class="params">               device: torch.device = device</span>):</span><br><span class="line">    train_loss, train_acc = <span class="number">0</span>, <span class="number">0</span></span><br><span class="line">    model.to(device)</span><br><span class="line">    <span class="keyword">for</span> batch, (X, y) <span class="keyword">in</span> <span class="built_in">enumerate</span>(data_loader):</span><br><span class="line">        <span class="comment"># Send data to GPU</span></span><br><span class="line">        X, y = X.to(device), y.to(device)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 1. Forward pass</span></span><br><span class="line">        y_pred = model(X)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 2. Calculate loss</span></span><br><span class="line">        loss = loss_fn(y_pred, y)</span><br><span class="line">        train_loss += loss</span><br><span class="line">        train_acc += accuracy_fn(y_true=y,</span><br><span class="line">                                 y_pred=y_pred.argmax(dim=<span class="number">1</span>)) <span class="comment"># Go from logits -&gt; pred labels</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 3. Optimizer zero grad</span></span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 4. Loss backward</span></span><br><span class="line">        loss.backward()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 5. Optimizer step</span></span><br><span class="line">        optimizer.step()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Calculate loss and accuracy per epoch and print out what&#x27;s happening</span></span><br><span class="line">    train_loss /= <span class="built_in">len</span>(data_loader)</span><br><span class="line">    train_acc /= <span class="built_in">len</span>(data_loader)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;Train loss: <span class="subst">&#123;train_loss:<span class="number">.5</span>f&#125;</span> | Train accuracy: <span class="subst">&#123;train_acc:<span class="number">.2</span>f&#125;</span>%&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">test_step</span>(<span class="params">data_loader: torch.utils.data.DataLoader,</span></span><br><span class="line"><span class="params">              model: torch.nn.Module,</span></span><br><span class="line"><span class="params">              loss_fn: torch.nn.Module,</span></span><br><span class="line"><span class="params">              accuracy_fn,</span></span><br><span class="line"><span class="params">              device: torch.device = device</span>):</span><br><span class="line">    test_loss, test_acc = <span class="number">0</span>, <span class="number">0</span></span><br><span class="line">    model.to(device)</span><br><span class="line">    model.<span class="built_in">eval</span>() <span class="comment"># put model in eval mode</span></span><br><span class="line">    <span class="comment"># Turn on inference context manager</span></span><br><span class="line">    <span class="keyword">with</span> torch.inference_mode(): </span><br><span class="line">        <span class="keyword">for</span> X, y <span class="keyword">in</span> data_loader:</span><br><span class="line">            <span class="comment"># Send data to GPU</span></span><br><span class="line">            X, y = X.to(device), y.to(device)</span><br><span class="line">            </span><br><span class="line">            <span class="comment"># 1. Forward pass</span></span><br><span class="line">            test_pred = model(X)</span><br><span class="line">            </span><br><span class="line">            <span class="comment"># 2. Calculate loss and accuracy</span></span><br><span class="line">            test_loss += loss_fn(test_pred, y)</span><br><span class="line">            test_acc += accuracy_fn(y_true=y,</span><br><span class="line">                y_pred=test_pred.argmax(dim=<span class="number">1</span>) <span class="comment"># Go from logits -&gt; pred labels</span></span><br><span class="line">            )</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Adjust metrics and print out</span></span><br><span class="line">        test_loss /= <span class="built_in">len</span>(data_loader)</span><br><span class="line">        test_acc /= <span class="built_in">len</span>(data_loader)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;Test loss: <span class="subst">&#123;test_loss:<span class="number">.5</span>f&#125;</span> | Test accuracy: <span class="subst">&#123;test_acc:<span class="number">.2</span>f&#125;</span>%\n&quot;</span>)</span><br></pre></td></tr></table></figure>
<blockquote>
<p>可以自定义执行测试步骤的频率。有时人们每 5 个 epoch 或 10 个 epoch 执行一次，或者在我们的情况下，每个 epoch 执行一次。</p>
</blockquote>
<p>计时一下，看看代码在 GPU 上运行需要多长时间。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">torch.manual_seed(<span class="number">42</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Measure time</span></span><br><span class="line"><span class="keyword">from</span> timeit <span class="keyword">import</span> default_timer <span class="keyword">as</span> timer</span><br><span class="line">train_time_start_on_gpu = timer()</span><br><span class="line"></span><br><span class="line">epochs = <span class="number">3</span></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> tqdm(<span class="built_in">range</span>(epochs)):</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;Epoch: <span class="subst">&#123;epoch&#125;</span>\n---------&quot;</span>)</span><br><span class="line">    train_step(data_loader=train_dataloader, </span><br><span class="line">        model=model_1, </span><br><span class="line">        loss_fn=loss_fn,</span><br><span class="line">        optimizer=optimizer,</span><br><span class="line">        accuracy_fn=accuracy_fn</span><br><span class="line">    )</span><br><span class="line">    test_step(data_loader=test_dataloader,</span><br><span class="line">        model=model_1,</span><br><span class="line">        loss_fn=loss_fn,</span><br><span class="line">        accuracy_fn=accuracy_fn</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">train_time_end_on_gpu = timer()</span><br><span class="line">total_train_time_model_1 = print_train_time(start=train_time_start_on_gpu,</span><br><span class="line">                                            end=train_time_end_on_gpu,</span><br><span class="line">                                            device=device)</span><br></pre></td></tr></table></figure>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">Epoch: 0</span><br><span class="line">---------</span><br><span class="line">Train loss: 1.09199 | Train accuracy: 61.34%</span><br><span class="line">Test loss: 0.95636 | Test accuracy: 65.00%</span><br><span class="line"></span><br><span class="line">Epoch: 1</span><br><span class="line">---------</span><br><span class="line">Train loss: 0.78101 | Train accuracy: 71.93%</span><br><span class="line">Test loss: 0.72227 | Test accuracy: 73.91%</span><br><span class="line"></span><br><span class="line">Epoch: 2</span><br><span class="line">---------</span><br><span class="line">Train loss: 0.67027 | Train accuracy: 75.94%</span><br><span class="line">Test loss: 0.68500 | Test accuracy: 75.02%</span><br><span class="line"></span><br><span class="line">Train time on cuda: 41.929 seconds</span><br></pre></td></tr></table></figure>
<blockquote>
<p>CUDA 与 CPU 上的训练时间在很大程度上取决于您使用的 CPU/GPU 的质量。<br>问：“我使用了 GPU，但我的模型训练速度并没有更快，这可能是为什么？”<br>答：一个原因可能是因为数据集和模型都太小（就像我们正在处理的数据集和模型一样），使用 GPU 的好处被实际将数据传输到那里所需的时间所抵消。将数据从 CPU 内存（默认）复制到 GPU 内存之间存在一个小瓶颈。因此，对于较小的模型和数据集，CPU 实际上可能是计算的最佳位置。<br>但对于更大的数据集和模型，GPU 提供的计算速度通常远远超过获取数据的成本。不过，这很大程度上取决于使用的硬件。通过练习，你会习惯训练模型的最佳位置。</p>
</blockquote>
<p>让<code>model_1</code>使用<code>eval_model()</code>函数来评估训练并看看它进展如何。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">torch.manual_seed(<span class="number">42</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Note: This will error due to `eval_model()` not using device agnostic code </span></span><br><span class="line">model_1_results = eval_model(model=model_1, </span><br><span class="line">    data_loader=test_dataloader,</span><br><span class="line">    loss_fn=loss_fn, </span><br><span class="line">    accuracy_fn=accuracy_fn) </span><br><span class="line">model_1_results </span><br></pre></td></tr></table></figure>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument mat1 in method wrapper_CUDA_addmm)</span><br></pre></td></tr></table></figure>
<p>这是因为已经设置了数据和模型来使用与设备无关的代码，但没有设置评估函数。<br>如何通过将目标<code>device</code>参数传递给<code>eval_model()</code>函数来解决这个问题？</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Move values to device</span></span><br><span class="line">torch.manual_seed(<span class="number">42</span>)</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">eval_model</span>(<span class="params">model: torch.nn.Module, </span></span><br><span class="line"><span class="params">               data_loader: torch.utils.data.DataLoader, </span></span><br><span class="line"><span class="params">               loss_fn: torch.nn.Module, </span></span><br><span class="line"><span class="params">               accuracy_fn, </span></span><br><span class="line"><span class="params">               device: torch.device = device</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Evaluates a given model on a given dataset.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        model (torch.nn.Module): A PyTorch model capable of making predictions on data_loader.</span></span><br><span class="line"><span class="string">        data_loader (torch.utils.data.DataLoader): The target dataset to predict on.</span></span><br><span class="line"><span class="string">        loss_fn (torch.nn.Module): The loss function of model.</span></span><br><span class="line"><span class="string">        accuracy_fn: An accuracy function to compare the models predictions to the truth labels.</span></span><br><span class="line"><span class="string">        device (str, optional): Target device to compute on. Defaults to device.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">        (dict): Results of model making predictions on data_loader.</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    loss, acc = <span class="number">0</span>, <span class="number">0</span></span><br><span class="line">    model.<span class="built_in">eval</span>()</span><br><span class="line">    <span class="keyword">with</span> torch.inference_mode():</span><br><span class="line">        <span class="keyword">for</span> X, y <span class="keyword">in</span> data_loader:</span><br><span class="line">            <span class="comment"># Send data to the target device</span></span><br><span class="line">            X, y = X.to(device), y.to(device)</span><br><span class="line">            y_pred = model(X)</span><br><span class="line">            loss += loss_fn(y_pred, y)</span><br><span class="line">            acc += accuracy_fn(y_true=y, y_pred=y_pred.argmax(dim=<span class="number">1</span>))</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Scale loss and acc</span></span><br><span class="line">        loss /= <span class="built_in">len</span>(data_loader)</span><br><span class="line">        acc /= <span class="built_in">len</span>(data_loader)</span><br><span class="line">    <span class="keyword">return</span> &#123;<span class="string">&quot;model_name&quot;</span>: model.__class__.__name__, <span class="comment"># only works when model was created with a class</span></span><br><span class="line">            <span class="string">&quot;model_loss&quot;</span>: loss.item(),</span><br><span class="line">            <span class="string">&quot;model_acc&quot;</span>: acc&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># Calculate model 1 results with device-agnostic code </span></span><br><span class="line">model_1_results = eval_model(model=model_1, data_loader=test_dataloader,</span><br><span class="line">    loss_fn=loss_fn, accuracy_fn=accuracy_fn,</span><br><span class="line">    device=device</span><br><span class="line">)</span><br><span class="line">model_1_results</span><br></pre></td></tr></table></figure>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&#123;&#x27;model_name&#x27;: &#x27;FashionMNISTModelV1&#x27;,</span><br><span class="line"> &#x27;model_loss&#x27;: 0.6850008964538574,</span><br><span class="line"> &#x27;model_acc&#x27;: 75.01996805111821&#125;</span><br></pre></td></tr></table></figure>
<p>在这种情况下，在模型中添加非线性似乎使得它的性能比基线更差。<br>这是机器学习中需要注意的一点，有时你认为应该起作用的东西却不起作用。<br>然后，你原本认为可能行不通的事情却真的发生了。<br>它既是科学，又是艺术。</p>
<p>从表面上看，我们的模型似乎对训练数据<strong>过度拟合</strong>。<br>过度拟合意味着我们的模型很好地学习了训练数据，但是这些模式不能推广到测试数据。</p>
<p><strong>解决过度拟合的两种主要方法包括：<br>1、使用较小或不同的模型（某些模型比其他模型更适合某些类型的数据）。<br>2、使用更大的数据集（数据越多，模型学习可概括模式的机会就越大）。</strong></p>
<h1 id="7-Model-2-Building-a-Convolutional-Neural-Network-CNN-模型2：建立卷积神经网络（CNN）"><a href="#7-Model-2-Building-a-Convolutional-Neural-Network-CNN-模型2：建立卷积神经网络（CNN）" class="headerlink" title="7. Model 2: Building a Convolutional Neural Network (CNN)模型2：建立卷积神经网络（CNN）"></a>7. Model 2: Building a Convolutional Neural Network (CNN)模型2：建立卷积神经网络（CNN）</h1><p>现在是时候创建一个<a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Convolutional_neural_network">卷积神经网络</a>（CNN 或 ConvNet）了</p>
<p>由于我们处理的是视觉数据，让我们看看使用 CNN 模型是否可以改进我们的基线。</p>
<p>我们将要使用的 CNN 模型是来自<a target="_blank" rel="noopener" href="https://poloclub.github.io/cnn-explainer/">CNN Explainer</a>网站的 TinyVGG。</p>
<p>它遵循卷积神经网络的典型结构：</p>
<p><code>Input layer -&gt; [Convolutional layer -&gt; activation layer -&gt; pooling layer] -&gt; Output layer</code></p>
<p>根据需要，其中的内容<code>[Convolutional layer -&gt; activation layer -&gt; pooling layer]</code>可以放大和重复多次。</p>
<h2 id="What-model-should-I-use-我应该使用什么模型？"><a href="#What-model-should-I-use-我应该使用什么模型？" class="headerlink" title="What model should I use?我应该使用什么模型？"></a>What model should I use?我应该使用什么模型？</h2><div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center">问题类型</th>
<th style="text-align:center">使用的模型（一般）</th>
<th style="text-align:center">代码示例</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">结构化数据（Excel 电子表格、行和列数据）</td>
<td style="text-align:center">Gradient boosted models梯度增强模型、Random Forests随机森林、XGBoost</td>
<td style="text-align:center"><a target="_blank" rel="noopener" href="https://scikit-learn.org/stable/modules/classes.html#module-sklearn.ensemble"><code>sklearn.ensemble</code></a>, <a target="_blank" rel="noopener" href="https://xgboost.readthedocs.io/en/stable/">XGBoost library</a></td>
</tr>
<tr>
<td style="text-align:center">非结构化数据（图像、音频、语言）</td>
<td style="text-align:center">Convolutional Neural卷积神经网络、Transformer</td>
<td style="text-align:center"><a target="_blank" rel="noopener" href="https://pytorch.org/vision/stable/models.html"><code>torchvision.models</code></a>, <a target="_blank" rel="noopener" href="https://huggingface.co/docs/transformers/index">HuggingFace Transformers</a></td>
</tr>
</tbody>
</table>
</div>
<p><a target="_blank" rel="noopener" href="https://poloclub.github.io/cnn-explainer/">关于模型的讨论已经足够了，现在让我们构建一个 CNN 来复制CNN Explainer 网站</a>上的模型。</p>
<p>为此，我们将利用<a target="_blank" rel="noopener" href="https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html"><code>nn.Conv2d()</code></a>和<a target="_blank" rel="noopener" href="https://pytorch.org/docs/stable/generated/torch.nn.MaxPool2d.html"><code>nn.MaxPool2d()</code></a>层<code>torch.nn</code>。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Create a convolutional neural network </span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">FashionMNISTModelV2</span>(nn.Module):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Model architecture copying TinyVGG from: </span></span><br><span class="line"><span class="string">    https://poloclub.github.io/cnn-explainer/</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, input_shape: <span class="built_in">int</span>, hidden_units: <span class="built_in">int</span>, output_shape: <span class="built_in">int</span></span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.block_1 = nn.Sequential(</span><br><span class="line">            nn.Conv2d(in_channels=input_shape, </span><br><span class="line">                      out_channels=hidden_units, </span><br><span class="line">                      kernel_size=<span class="number">3</span>, <span class="comment"># how big is the square that&#x27;s going over the image?</span></span><br><span class="line">                      stride=<span class="number">1</span>, <span class="comment"># default</span></span><br><span class="line">                      padding=<span class="number">1</span>),<span class="comment"># options = &quot;valid&quot; (no padding) or &quot;same&quot; (output has same shape as input) or int for specific number </span></span><br><span class="line">            nn.ReLU(),</span><br><span class="line">            nn.Conv2d(in_channels=hidden_units, </span><br><span class="line">                      out_channels=hidden_units,</span><br><span class="line">                      kernel_size=<span class="number">3</span>,</span><br><span class="line">                      stride=<span class="number">1</span>,</span><br><span class="line">                      padding=<span class="number">1</span>),</span><br><span class="line">            nn.ReLU(),</span><br><span class="line">            nn.MaxPool2d(kernel_size=<span class="number">2</span>,</span><br><span class="line">                         stride=<span class="number">2</span>) <span class="comment"># default stride value is same as kernel_size</span></span><br><span class="line">        )</span><br><span class="line">        self.block_2 = nn.Sequential(</span><br><span class="line">            nn.Conv2d(hidden_units, hidden_units, <span class="number">3</span>, padding=<span class="number">1</span>),</span><br><span class="line">            nn.ReLU(),</span><br><span class="line">            nn.Conv2d(hidden_units, hidden_units, <span class="number">3</span>, padding=<span class="number">1</span>),</span><br><span class="line">            nn.ReLU(),</span><br><span class="line">            nn.MaxPool2d(<span class="number">2</span>)</span><br><span class="line">        )</span><br><span class="line">        self.classifier = nn.Sequential(</span><br><span class="line">            nn.Flatten(),</span><br><span class="line">            <span class="comment"># Where did this in_features shape come from? </span></span><br><span class="line">            <span class="comment"># It&#x27;s because each layer of our network compresses and changes the shape of our input data.</span></span><br><span class="line">            nn.Linear(in_features=hidden_units*<span class="number">7</span>*<span class="number">7</span>, </span><br><span class="line">                      out_features=output_shape)</span><br><span class="line">        )</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x: torch.Tensor</span>):</span><br><span class="line">        x = self.block_1(x)</span><br><span class="line">        <span class="comment"># print(x.shape)</span></span><br><span class="line">        x = self.block_2(x)</span><br><span class="line">        <span class="comment"># print(x.shape)</span></span><br><span class="line">        x = self.classifier(x)</span><br><span class="line">        <span class="comment"># print(x.shape)</span></span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line">torch.manual_seed(<span class="number">42</span>)</span><br><span class="line">model_2 = FashionMNISTModelV2(input_shape=<span class="number">1</span>, </span><br><span class="line">    hidden_units=<span class="number">10</span>, </span><br><span class="line">    output_shape=<span class="built_in">len</span>(class_names)).to(device)</span><br><span class="line">model_2</span><br></pre></td></tr></table></figure>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">FashionMNISTModelV2(</span><br><span class="line">  (block_1): Sequential(</span><br><span class="line">    (0): Conv2d(1, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))</span><br><span class="line">    (1): ReLU()</span><br><span class="line">    (2): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))</span><br><span class="line">    (3): ReLU()</span><br><span class="line">    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)</span><br><span class="line">  )</span><br><span class="line">  (block_2): Sequential(</span><br><span class="line">    (0): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))</span><br><span class="line">    (1): ReLU()</span><br><span class="line">    (2): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))</span><br><span class="line">    (3): ReLU()</span><br><span class="line">    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)</span><br><span class="line">  )</span><br><span class="line">  (classifier): Sequential(</span><br><span class="line">    (0): Flatten(start_dim=1, end_dim=-1)</span><br><span class="line">    (1): Linear(in_features=490, out_features=10, bias=True)</span><br><span class="line">  )</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<h2 id="7-1-Stepping-throughnn-Conv2d"><a href="#7-1-Stepping-throughnn-Conv2d" class="headerlink" title="7.1 Stepping throughnn.Conv2d()"></a>7.1 Stepping through<code>nn.Conv2d()</code></h2><p>我们可以开始使用上面的模型，看看会发生什么，但让我们首先逐步了解我们添加的两个新层：</p>
<ul>
<li><a target="_blank" rel="noopener" href="https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html"><code>nn.Conv2d()</code></a>，也称为卷积层。</li>
<li><a target="_blank" rel="noopener" href="https://pytorch.org/docs/stable/generated/torch.nn.MaxPool2d.html"><code>nn.MaxPool2d()</code></a>，也称为最大池化层。</li>
</ul>
<blockquote>
<p>问题：nn.Conv2d()中的“2d”代表什么？<br>2d 表示二维数据。例如，我们的图像有两个维度：高度和宽度。是的，有颜色通道维度，但每个颜色通道维度也有两个维度：高度和宽度。<br>对于其他维度数据（例如文本的 1D 或 3D 对象的 3D），还有nn.Conv1d()和nn.Conv3d()。</p>
</blockquote>
<p>为了测试这些层，让我们创建一些玩具数据，就像 CNN Explainer 上使用的数据一样。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">torch.manual_seed(<span class="number">42</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Create sample batch of random numbers with same size as image batch</span></span><br><span class="line">images = torch.randn(size=(<span class="number">32</span>, <span class="number">3</span>, <span class="number">64</span>, <span class="number">64</span>)) <span class="comment"># [batch_size, color_channels, height, width]</span></span><br><span class="line">test_image = images[<span class="number">0</span>] <span class="comment"># get a single image for testing</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Image batch shape: <span class="subst">&#123;images.shape&#125;</span> -&gt; [batch_size, color_channels, height, width]&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Single image shape: <span class="subst">&#123;test_image.shape&#125;</span> -&gt; [color_channels, height, width]&quot;</span>) </span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Single image pixel values:\n<span class="subst">&#123;test_image&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">Image batch shape: torch.Size([32, 3, 64, 64]) -&gt; [batch_size, color_channels, height, width]</span><br><span class="line">Single image shape: torch.Size([3, 64, 64]) -&gt; [color_channels, height, width]</span><br><span class="line">Single image pixel values:</span><br><span class="line">tensor([[[ 1.9269,  1.4873,  0.9007,  ...,  1.8446, -1.1845,  1.3835],...)</span><br></pre></td></tr></table></figure>
<p>让我们创建一个<code>nn.Conv2d()</code>具有各种参数的示例：</p>
<ul>
<li><code>in_channels(int)</code>， 输入图像中的通道数。</li>
<li><code>out_channels(int)</code>，卷积产生的通道数。</li>
<li><code>kernel_size(int or tuple)</code>，卷积核/过滤器的大小。</li>
<li><code>stride(int or tuple, optional)</code>，卷积核每次采取的步长。默认值：1。</li>
<li><code>padding(int, tuple, str)</code>，在输入的四边添加填充。默认值：0。</li>
</ul>
<img src="/2024/08/17/PyTorch-26H-4/PyTorch-26H-4-10.gif" class="" title="PyTorch-26H-4-10">
<p>更改某<code>nn.Conv2d()</code>一层的超参数时发生的情况的示例。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">torch.manual_seed(<span class="number">42</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Create a convolutional layer with same dimensions as TinyVGG </span></span><br><span class="line"><span class="comment"># (try changing any of the parameters and see what happens)</span></span><br><span class="line">conv_layer = nn.Conv2d(in_channels=<span class="number">3</span>,</span><br><span class="line">                       out_channels=<span class="number">10</span>,</span><br><span class="line">                       kernel_size=<span class="number">3</span>,</span><br><span class="line">                       stride=<span class="number">1</span>,</span><br><span class="line">                       padding=<span class="number">0</span>) <span class="comment"># also try using &quot;valid&quot; or &quot;same&quot; here </span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Pass the data through the convolutional layer</span></span><br><span class="line">conv_layer(test_image) <span class="comment"># Note: If running PyTorch &lt;1.11.0, this will error because of shape issues (nn.Conv.2d() expects a 4d tensor as input) </span></span><br></pre></td></tr></table></figure>
<p>如果尝试传入单张图像，我们会收到形状不匹配错误：</p>
<blockquote>
<p>RuntimeError: Expected 4-dimensional input for 4-dimensional weight [10, 3, 3, 3], but got 3-dimensional input of size [3, 64, 64] instead</p>
</blockquote>
<p>这是因为我们的<code>nn.Conv2d()</code>层需要一个大小为 <code>(N, C, H, W)</code> 或 <code>[batch_size, color_channels, height, width]</code> 的4 维张量作为输入。</p>
<p>目前我们的单幅图像 <code>test_image</code> 只有 <code>[color_channels, height, width]</code> 或 <code>[3, 64, 64]</code> 的形状。</p>
<p>我们可以使用 <code>test_image.unsqueeze(dim=0)</code> 为单个图像修复此问题，为 <code>N</code> 添加额外的维度。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Add extra dimension to test image</span></span><br><span class="line">test_image.unsqueeze(dim=<span class="number">0</span>).shape</span><br></pre></td></tr></table></figure>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.Size([1, 3, 64, 64])</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Pass test image with extra dimension through conv_layer</span></span><br><span class="line">conv_layer(test_image.unsqueeze(dim=<span class="number">0</span>)).shape</span><br></pre></td></tr></table></figure>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.Size([1, 10, 62, 62])</span><br></pre></td></tr></table></figure>
<p>嗯，注意我们的形状发生了什么变化（与<a target="_blank" rel="noopener" href="https://poloclub.github.io/cnn-explainer/">CNN Explainer</a>上 TinyVGG 的第一层形状相同），我们得到了不同的通道大小以及不同的像素大小。</p>
<p>如果我们改变 <code>conv_layer</code> 的值会怎样？</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">torch.manual_seed(<span class="number">42</span>)</span><br><span class="line"><span class="comment"># Create a new conv_layer with different values (try setting these to whatever you like)</span></span><br><span class="line">conv_layer_2 = nn.Conv2d(in_channels=<span class="number">3</span>, <span class="comment"># same number of color channels as our input image</span></span><br><span class="line">                         out_channels=<span class="number">10</span>,</span><br><span class="line">                         kernel_size=(<span class="number">5</span>, <span class="number">5</span>), <span class="comment"># kernel is usually a square so a tuple also works</span></span><br><span class="line">                         stride=<span class="number">2</span>,</span><br><span class="line">                         padding=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Pass single image through new conv_layer_2 (this calls nn.Conv2d()&#x27;s forward() method on the input)</span></span><br><span class="line">conv_layer_2(test_image.unsqueeze(dim=<span class="number">0</span>)).shape</span><br></pre></td></tr></table></figure>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.Size([1, 10, 30, 30])</span><br></pre></td></tr></table></figure>
<p>哇，我们的形状又发生了变化。</p>
<p>现在我们的图像是形状<code>[1, 10, 30, 30]</code>（如果使用不同的值，它会有所不同）或<code>[batch_size=1, color_channels=10, height=30, width=30]</code>。</p>
<p>这里发生了什么事？</p>
<p>在幕后，我们<code>nn.Conv2d()</code>正在压缩图像中存储的信息。</p>
<p>它通过根据其内部参数对输入（我们的测试图像）执行操作来实现这一点。</p>
<p>其目标与我们一直在构建的所有其他神经网络类似。</p>
<p>数据输入后，各层会在优化器的帮助下尝试更新其内部参数（模式）以降低损失函数。</p>
<p>唯一的区别在于不同层如何计算它们的参数更新，或者用 PyTorch 术语来说，层方法中存在的操作<code>forward()</code>。</p>
<p>如果我们检查一下，<code>conv_layer_2.state_dict()</code>我们会发现与我们之前看到的类似的权重和偏差设置。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Check out the conv_layer_2 internal parameters</span></span><br><span class="line"><span class="built_in">print</span>(conv_layer_2.state_dict())</span><br></pre></td></tr></table></figure>
<p>权重和偏差张量的一堆随机数。</p>
<p><code>nn.Conv2d()</code>它们的形状由我们在设置时传递的输入来操纵。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Get shapes of weight and bias tensors within conv_layer_2</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;conv_layer_2 weight shape: \n<span class="subst">&#123;conv_layer_2.weight.shape&#125;</span> -&gt; [out_channels=10, in_channels=3, kernel_size=5, kernel_size=5]&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;\nconv_layer_2 bias shape: \n<span class="subst">&#123;conv_layer_2.bias.shape&#125;</span> -&gt; [out_channels=10]&quot;</span>)</span><br></pre></td></tr></table></figure>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">conv_layer_2 weight shape: </span><br><span class="line">torch.Size([10, 3, 5, 5]) -&gt; [out_channels=10, in_channels=3, kernel_size=5, kernel_size=5]</span><br><span class="line"></span><br><span class="line">conv_layer_2 bias shape: </span><br><span class="line">torch.Size([10]) -&gt; [out_channels=10]</span><br></pre></td></tr></table></figure>
<blockquote>
<p>问题：我们应该如何设置图层的参数nn.Conv2d()？<br>这是个好主意。但与机器学习中的许多其他事物类似，这些值并不是一成不变的（回想一下，因为这些值是我们可以自己设置的，所以它们被称为“超参数”）。<br>找出答案的最佳方法是尝试不同的值并观察它们如何影响模型的性能。<br>或者更好的是，找到一个与您的问题类似的工作示例（就像我们对 TinyVGG 所做的那样）并复制它。</p>
</blockquote>
<p>但前提保持不变：从随机数开始并更新它们以更好地表示数据。</p>
<h2 id="7-2-Stepping-through-nn-MaxPool2d"><a href="#7-2-Stepping-through-nn-MaxPool2d" class="headerlink" title="7.2 Stepping through nn.MaxPool2d()"></a>7.2 Stepping through <code>nn.MaxPool2d()</code></h2><p>让我们检查一下当我们移动<code>nn.MaxPool2d()</code>数据时会发生什么。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Print out original image shape without and with unsqueezed dimension</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Test image original shape: <span class="subst">&#123;test_image.shape&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Test image with unsqueezed dimension: <span class="subst">&#123;test_image.unsqueeze(dim=<span class="number">0</span>).shape&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Create a sample nn.MaxPoo2d() layer</span></span><br><span class="line">max_pool_layer = nn.MaxPool2d(kernel_size=<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Pass data through just the conv_layer</span></span><br><span class="line">test_image_through_conv = conv_layer(test_image.unsqueeze(dim=<span class="number">0</span>))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Shape after going through conv_layer(): <span class="subst">&#123;test_image_through_conv.shape&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Pass data through the max pool layer</span></span><br><span class="line">test_image_through_conv_and_max_pool = max_pool_layer(test_image_through_conv)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Shape after going through conv_layer() and max_pool_layer(): <span class="subst">&#123;test_image_through_conv_and_max_pool.shape&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">Test image original shape: torch.Size([3, 64, 64])</span><br><span class="line">Test image with unsqueezed dimension: torch.Size([1, 3, 64, 64])</span><br><span class="line">Shape after going through conv_layer(): torch.Size([1, 10, 62, 62])</span><br><span class="line">Shape after going through conv_layer() and max_pool_layer(): torch.Size([1, 10, 31, 31])</span><br></pre></td></tr></table></figure>
<p>注意层内和层外发生的形状的变化<code>nn.MaxPool2d()</code>。</p>
<p><code>kernel_size</code>层的将<code>nn.MaxPool2d()</code>影响输出形状的大小。</p>
<p>在我们的例子中，形状从一幅<code>62x62</code>图像分成另<code>31x31</code>一幅图像。</p>
<p>让我们用较小的张量看一下这个工作。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">torch.manual_seed(<span class="number">42</span>)</span><br><span class="line"><span class="comment"># Create a random tensor with a similar number of dimensions to our images</span></span><br><span class="line">random_tensor = torch.randn(size=(<span class="number">1</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Random tensor:\n<span class="subst">&#123;random_tensor&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Random tensor shape: <span class="subst">&#123;random_tensor.shape&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Create a max pool layer</span></span><br><span class="line">max_pool_layer = nn.MaxPool2d(kernel_size=<span class="number">2</span>) <span class="comment"># see what happens when you change the kernel_size value </span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Pass the random tensor through the max pool layer</span></span><br><span class="line">max_pool_tensor = max_pool_layer(random_tensor)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;\nMax pool tensor:\n<span class="subst">&#123;max_pool_tensor&#125;</span> &lt;- this is the maximum value from random_tensor&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Max pool tensor shape: <span class="subst">&#123;max_pool_tensor.shape&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">Random tensor:</span><br><span class="line">tensor([[[[0.3367, 0.1288],</span><br><span class="line">          [0.2345, 0.2303]]]])</span><br><span class="line">Random tensor shape: torch.Size([1, 1, 2, 2])</span><br><span class="line"></span><br><span class="line">Max pool tensor:</span><br><span class="line">tensor([[[[0.3367]]]]) &lt;- this is the maximum value from random_tensor</span><br><span class="line">Max pool tensor shape: torch.Size([1, 1, 1, 1])</span><br></pre></td></tr></table></figure>
<p>注意 <code>random_tensor</code> 和 <code>max_pool_tensor</code> 之间的最后两个维度，它们从 <code>[2, 2]</code> 变为 <code>[1, 1]</code>。<br>本质上，它们减半了。<br>对于 <code>nn.MaxPool2d()</code>，<code>kernel_size</code> 的不同值，变化会有所不同。<br>还要注意，<code>max_pool_tensor</code> 中剩余的值是 <code>random_tensor</code> 中的最大值。</p>
<p>这里发生了什么事？<br>这是神经网络难题的另一个重要部分。<br>本质上，<strong>神经网络中的每一层都试图将数据从高维空间压缩到低维空间。</strong><br>换句话说，获取大量数字（原始数据）并从这些数字中学习模式，这些模式具有预测性，同时其规模也比原始值小。</p>
<p>从人工智能的角度来看，你可以将神经网络的整个目标视为压缩信息。</p>
<img src="/2024/08/17/PyTorch-26H-4/PyTorch-26H-4-11.png" class="" title="PyTorch-26H-4-11">
<p>这意味着，从神经网络的角度来看，智能就是压缩。</p>
<p>这是使用<code>nn.MaxPool2d()</code>层的想法：从张量的一部分中取最大值，而忽略其余部分。</p>
<p>本质上，降低张量的维数，同时仍然保留（希望）很大一部分信息。</p>
<p>对于层来说也是同样的情况nn.Conv2d()。</p>
<p>除了不只是取最大值之外，还对数据执行卷积运算（请参阅<a target="_blank" rel="noopener" href="https://poloclub.github.io/cnn-explainer/">CNN 解释器网页</a><code>nn.Conv2d()</code>上的实际操作）。</p>
<blockquote>
<p><strong>练习：</strong>您认为该<a target="_blank" rel="noopener" href="https://pytorch.org/docs/stable/generated/torch.nn.AvgPool2d.html"><code>nn.AvgPool2d()</code></a>层的作用是什么？尝试像上面一样创建一个随机张量并将其传递出去。检查输入和输出形状以及输入和输出值。<br><strong>课外活动：</strong>查找“最常见的卷积神经网络”，你找到了哪些架构？库中包含其中的任何架构吗<a target="_blank" rel="noopener" href="https://pytorch.org/vision/stable/models.html"><code>torchvision.models</code></a>？你认为你可以用它们做什么？</p>
</blockquote>
<h2 id="7-3-Setup-a-loss-function-and-optimizer-for-model-2"><a href="#7-3-Setup-a-loss-function-and-optimizer-for-model-2" class="headerlink" title="7.3 Setup a loss function and optimizer for model_2"></a>7.3 Setup a loss function and optimizer for <code>model_2</code></h2><p>我们将像以前一样使用这些函数，<code>nn.CrossEntropyLoss()</code> 作为损失函数（因为我们处理的是多类分类数据）。</p>
<p>并使用 <code>torch.optim.SGD()</code> 作为优化器，以 0.1 的学习率优化 <code>model_2.parameters()</code>。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Setup loss and optimizer</span></span><br><span class="line">loss_fn = nn.CrossEntropyLoss()</span><br><span class="line">optimizer = torch.optim.SGD(params=model_2.parameters(), </span><br><span class="line">                             lr=<span class="number">0.1</span>)</span><br></pre></td></tr></table></figure>
<h2 id="7-4-Training-and-testing-model-2-using-our-training-and-test-functions"><a href="#7-4-Training-and-testing-model-2-using-our-training-and-test-functions" class="headerlink" title="7.4 Training and testing model_2 using our training and test functions"></a>7.4 Training and testing <code>model_2</code> using our training and test functions</h2><p>损失和优化器已准备好！训练和测试的时间。<br>我们将使用之前创建的<code>train_step()</code>和<code>test_step()</code>函数。<br>我们还将测量时间以将其与我们的其他模型进行比较。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">torch.manual_seed(<span class="number">42</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Measure time</span></span><br><span class="line"><span class="keyword">from</span> timeit <span class="keyword">import</span> default_timer <span class="keyword">as</span> timer</span><br><span class="line">train_time_start_model_2 = timer()</span><br><span class="line"></span><br><span class="line"><span class="comment"># Train and test model </span></span><br><span class="line">epochs = <span class="number">3</span></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> tqdm(<span class="built_in">range</span>(epochs)):</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;Epoch: <span class="subst">&#123;epoch&#125;</span>\n---------&quot;</span>)</span><br><span class="line">    train_step(data_loader=train_dataloader, </span><br><span class="line">        model=model_2, </span><br><span class="line">        loss_fn=loss_fn,</span><br><span class="line">        optimizer=optimizer,</span><br><span class="line">        accuracy_fn=accuracy_fn,</span><br><span class="line">        device=device</span><br><span class="line">    )</span><br><span class="line">    test_step(data_loader=test_dataloader,</span><br><span class="line">        model=model_2,</span><br><span class="line">        loss_fn=loss_fn,</span><br><span class="line">        accuracy_fn=accuracy_fn,</span><br><span class="line">        device=device</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">train_time_end_model_2 = timer()</span><br><span class="line">total_train_time_model_2 = print_train_time(start=train_time_start_model_2,</span><br><span class="line">                                           end=train_time_end_model_2,</span><br><span class="line">                                           device=device)</span><br></pre></td></tr></table></figure>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">Epoch: 0</span><br><span class="line">---------</span><br><span class="line">Train loss: 0.59664 | Train accuracy: 78.43%</span><br><span class="line">Test loss: 0.38824 | Test accuracy: 86.24%</span><br><span class="line"></span><br><span class="line">Epoch: 1</span><br><span class="line">---------</span><br><span class="line">Train loss: 0.35712 | Train accuracy: 87.12%</span><br><span class="line">Test loss: 0.34803 | Test accuracy: 87.15%</span><br><span class="line"></span><br><span class="line">Epoch: 2</span><br><span class="line">---------</span><br><span class="line">Train loss: 0.31907 | Train accuracy: 88.50%</span><br><span class="line">Test loss: 0.32589 | Test accuracy: 88.37%</span><br><span class="line"></span><br><span class="line">Train time on cuda: 51.457 seconds</span><br></pre></td></tr></table></figure>
<p>看起来卷积层和最大池化层有助于提高性能。</p>
<p>让我们<code>model_2</code>用我们的函数评估的结果<code>eval_model()</code>。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Get model_2 results </span></span><br><span class="line">model_2_results = eval_model(</span><br><span class="line">    model=model_2,</span><br><span class="line">    data_loader=test_dataloader,</span><br><span class="line">    loss_fn=loss_fn,</span><br><span class="line">    accuracy_fn=accuracy_fn</span><br><span class="line">)</span><br><span class="line">model_2_results</span><br></pre></td></tr></table></figure>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&#123;&#x27;model_name&#x27;: &#x27;FashionMNISTModelV2&#x27;,</span><br><span class="line"> &#x27;model_loss&#x27;: 0.3258868157863617,</span><br><span class="line"> &#x27;model_acc&#x27;: 88.36861022364218&#125;</span><br></pre></td></tr></table></figure>
<h1 id="8-Compare-model-results-and-training-time-比较模型结果和训练时间"><a href="#8-Compare-model-results-and-training-time-比较模型结果和训练时间" class="headerlink" title="8. Compare model results and training time 比较模型结果和训练时间"></a>8. Compare model results and training time 比较模型结果和训练时间</h1><p>我们训练了三种不同的模型。</p>
<ul>
<li><code>model_0</code>，我们的基线模型有两层<code>nn.Linear()</code>。</li>
<li><code>model_1</code>，与我们的基线模型设置相同，只是层与层<code>nn.ReLU()</code>之间有层<code>nn.Linear()</code>。</li>
<li><code>model_2</code>，我们的第一个 CNN 模型模仿了 CNN Explainer 网站上的 TinyVGG 架构。</li>
</ul>
<p>这是机器学习的常规做法。</p>
<p>建立多个模型并进行多次训练实验，以查看哪个表现最佳。</p>
<p>让我们将模型结果字典合并到 DataFrame 中并找出答案。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line">compare_results = pd.DataFrame([model_0_results, model_1_results, model_2_results])</span><br><span class="line">compare_results</span><br></pre></td></tr></table></figure>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center">model_name</th>
<th style="text-align:center">model_loss</th>
<th style="text-align:center">model_acc</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">FashionMNISTModelV0</td>
<td style="text-align:center">0.476639</td>
<td style="text-align:center">83.426518</td>
</tr>
<tr>
<td style="text-align:center">FashionMNISTModelV1</td>
<td style="text-align:center">0.685001</td>
<td style="text-align:center">75.019968</td>
</tr>
<tr>
<td style="text-align:center">FashionMNISTModelV2</td>
<td style="text-align:center">0.325887</td>
<td style="text-align:center">88.368610</td>
</tr>
</tbody>
</table>
</div>
<p>添加训练时间值。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Add training times to results comparison</span></span><br><span class="line">compare_results[<span class="string">&quot;training_time&quot;</span>] = [total_train_time_model_0,</span><br><span class="line">                                    total_train_time_model_1,</span><br><span class="line">                                    total_train_time_model_2]</span><br><span class="line">compare_results</span><br></pre></td></tr></table></figure>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center">model_name</th>
<th style="text-align:center">model_loss</th>
<th style="text-align:center">model_acc</th>
<th style="text-align:center">training_time</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">FashionMNISTModelV0</td>
<td style="text-align:center">0.476639</td>
<td style="text-align:center">83.426518</td>
<td style="text-align:center">463.021015</td>
</tr>
<tr>
<td style="text-align:center">FashionMNISTModelV1</td>
<td style="text-align:center">0.685001</td>
<td style="text-align:center">75.019968</td>
<td style="text-align:center">45.538106</td>
</tr>
<tr>
<td style="text-align:center">FashionMNISTModelV2</td>
<td style="text-align:center">0.325887</td>
<td style="text-align:center">88.368610</td>
<td style="text-align:center">52.672458</td>
</tr>
</tbody>
</table>
</div>
<p>看起来我们的 <code>CNN（FashionMNISTModelV2）</code>模型表现最佳（损失最低、准确度最高），但训练时间最长。</p>
<p>并且我们的<code>基线模型 ( FashionMNISTModelV0)</code> 的表现优于<code>model_1( FashionMNISTModelV1)</code>。</p>
<h2 id="Performance-speed-tradeoff"><a href="#Performance-speed-tradeoff" class="headerlink" title="Performance-speed tradeoff"></a>Performance-speed tradeoff</h2><p>在机器学习中需要注意的是性能和速度的权衡。</p>
<p>一般来说，更大、更复杂的模型会获得更好的性能（就像我们所做的那样model_2）。</p>
<p>然而，这种性能的提升往往是以牺牲训练速度和推理速度为代价的。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Visualize our model results</span></span><br><span class="line">compare_results.set_index(<span class="string">&quot;model_name&quot;</span>)[<span class="string">&quot;model_acc&quot;</span>].plot(kind=<span class="string">&quot;barh&quot;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&quot;accuracy (%)&quot;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&quot;model&quot;</span>);</span><br></pre></td></tr></table></figure>
<img src="/2024/08/17/PyTorch-26H-4/PyTorch-26H-4-12.png" class="" title="PyTorch-26H-4-12">
<h1 id="9-Make-and-evaluate-random-predictions-with-best-model-使用最佳模型进行随机预测并评估"><a href="#9-Make-and-evaluate-random-predictions-with-best-model-使用最佳模型进行随机预测并评估" class="headerlink" title="9. Make and evaluate random predictions with best model 使用最佳模型进行随机预测并评估"></a>9. Make and evaluate random predictions with best model 使用最佳模型进行随机预测并评估</h1><p>将我们的模型相互比较了，让我们进一步评估我们表现最好的模型<code>model_2</code>。</p>
<p>为此，让我们创建一个函数<code>make_predictions()</code>，我们可以在其中传递模型和一些数据以供其预测。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">make_predictions</span>(<span class="params">model: torch.nn.Module, data: <span class="built_in">list</span>, device: torch.device = device</span>):</span><br><span class="line">    pred_probs = []</span><br><span class="line">    model.<span class="built_in">eval</span>()</span><br><span class="line">    <span class="keyword">with</span> torch.inference_mode():</span><br><span class="line">        <span class="keyword">for</span> sample <span class="keyword">in</span> data:</span><br><span class="line">            <span class="comment"># Prepare sample</span></span><br><span class="line">            sample = torch.unsqueeze(sample, dim=<span class="number">0</span>).to(device) <span class="comment"># Add an extra dimension and send sample to device</span></span><br><span class="line"></span><br><span class="line">            <span class="comment"># Forward pass (model outputs raw logit)</span></span><br><span class="line">            pred_logit = model(sample)</span><br><span class="line"></span><br><span class="line">            <span class="comment"># Get prediction probability (logit -&gt; prediction probability)</span></span><br><span class="line">            pred_prob = torch.softmax(pred_logit.squeeze(), dim=<span class="number">0</span>) <span class="comment"># note: perform softmax on the &quot;logits&quot; dimension, not &quot;batch&quot; dimension (in this case we have a batch size of 1, so can perform on dim=0)</span></span><br><span class="line"></span><br><span class="line">            <span class="comment"># Get pred_prob off GPU for further calculations</span></span><br><span class="line">            pred_probs.append(pred_prob.cpu())</span><br><span class="line">            </span><br><span class="line">    <span class="comment"># Stack the pred_probs to turn list into a tensor</span></span><br><span class="line">    <span class="keyword">return</span> torch.stack(pred_probs)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> random</span><br><span class="line">random.seed(<span class="number">42</span>)</span><br><span class="line">test_samples = []</span><br><span class="line">test_labels = []</span><br><span class="line"><span class="keyword">for</span> sample, label <span class="keyword">in</span> random.sample(<span class="built_in">list</span>(test_data), k=<span class="number">9</span>):</span><br><span class="line">    test_samples.append(sample)</span><br><span class="line">    test_labels.append(label)</span><br><span class="line"></span><br><span class="line"><span class="comment"># View the first test sample shape and label</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Test sample image shape: <span class="subst">&#123;test_samples[<span class="number">0</span>].shape&#125;</span>\nTest sample label: <span class="subst">&#123;test_labels[<span class="number">0</span>]&#125;</span> (<span class="subst">&#123;class_names[test_labels[<span class="number">0</span>]]&#125;</span>)&quot;</span>)</span><br></pre></td></tr></table></figure>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Test sample image shape: torch.Size([1, 28, 28])</span><br><span class="line">Test sample label: 5 (Sandal)</span><br></pre></td></tr></table></figure>
<p>现在我们可以使用 <code>make_predictions()</code> 函数来预测 <code>test_samples</code>。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Make predictions on test samples with model 2</span></span><br><span class="line">pred_probs= make_predictions(model=model_2, </span><br><span class="line">                             data=test_samples)</span><br><span class="line"></span><br><span class="line"><span class="comment"># View first two prediction probabilities list</span></span><br><span class="line">pred_probs[:<span class="number">2</span>]</span><br></pre></td></tr></table></figure>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">tensor([[7.7393e-08, 6.9452e-08, 7.9230e-09, 7.5061e-08, 1.0008e-08, 9.9992e-01,</span><br><span class="line">         1.6065e-06, 6.7758e-07, 6.3521e-06, 7.4828e-05],</span><br><span class="line">        [2.0884e-02, 8.1752e-01, 6.5737e-04, 6.4430e-02, 6.4946e-02, 4.4571e-04,</span><br><span class="line">         2.9005e-02, 2.8220e-04, 7.9620e-04, 1.0312e-03]])</span><br></pre></td></tr></table></figure>
<p>现在，我们可以通过获取 <code>torch.softmax()</code> 激活函数输出的 <code>torch.argmax()</code> 从预测概率转到预测标签。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Turn the prediction probabilities into prediction labels by taking the argmax()</span></span><br><span class="line">pred_classes = pred_probs.argmax(dim=<span class="number">1</span>)</span><br><span class="line">pred_classes</span><br></pre></td></tr></table></figure>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tensor([5, 1, 7, 4, 3, 0, 4, 7, 1])</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Are our predictions in the same form as our test labels? </span></span><br><span class="line">test_labels, pred_classes</span><br></pre></td></tr></table></figure>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">([5, 1, 7, 4, 3, 0, 4, 7, 1], tensor([5, 1, 7, 4, 3, 0, 4, 7, 1]))</span><br></pre></td></tr></table></figure>
<p>现在，我们预测的类别与测试标签的格式相同，我们可以进行比较了。<br>由于我们处理的是图像数据，因此让我们坚持数据探索者的座右铭。<br>“可视化，可视化，可视化！”</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Plot predictions</span></span><br><span class="line">plt.figure(figsize=(<span class="number">9</span>, <span class="number">9</span>))</span><br><span class="line">nrows = <span class="number">3</span></span><br><span class="line">ncols = <span class="number">3</span></span><br><span class="line"><span class="keyword">for</span> i, sample <span class="keyword">in</span> <span class="built_in">enumerate</span>(test_samples):</span><br><span class="line">  <span class="comment"># Create a subplot</span></span><br><span class="line">  plt.subplot(nrows, ncols, i+<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">  <span class="comment"># Plot the target image</span></span><br><span class="line">  plt.imshow(sample.squeeze(), cmap=<span class="string">&quot;gray&quot;</span>)</span><br><span class="line"></span><br><span class="line">  <span class="comment"># Find the prediction label (in text form, e.g. &quot;Sandal&quot;)</span></span><br><span class="line">  pred_label = class_names[pred_classes[i]]</span><br><span class="line"></span><br><span class="line">  <span class="comment"># Get the truth label (in text form, e.g. &quot;T-shirt&quot;)</span></span><br><span class="line">  truth_label = class_names[test_labels[i]] </span><br><span class="line"></span><br><span class="line">  <span class="comment"># Create the title text of the plot</span></span><br><span class="line">  title_text = <span class="string">f&quot;Pred: <span class="subst">&#123;pred_label&#125;</span> | Truth: <span class="subst">&#123;truth_label&#125;</span>&quot;</span></span><br><span class="line">  </span><br><span class="line">  <span class="comment"># Check for equality and change title colour accordingly</span></span><br><span class="line">  <span class="keyword">if</span> pred_label == truth_label:</span><br><span class="line">      plt.title(title_text, fontsize=<span class="number">10</span>, c=<span class="string">&quot;g&quot;</span>) <span class="comment"># green text if correct</span></span><br><span class="line">  <span class="keyword">else</span>:</span><br><span class="line">      plt.title(title_text, fontsize=<span class="number">10</span>, c=<span class="string">&quot;r&quot;</span>) <span class="comment"># red text if wrong</span></span><br><span class="line">  plt.axis(<span class="literal">False</span>);</span><br></pre></td></tr></table></figure>
<img src="/2024/08/17/PyTorch-26H-4/PyTorch-26H-4-13.png" class="" title="PyTorch-26H-4-13">
<h1 id="10-Making-a-confusion-matrix-for-further-prediction-evaluation-制作混淆矩阵以进行进一步的预测评估"><a href="#10-Making-a-confusion-matrix-for-further-prediction-evaluation-制作混淆矩阵以进行进一步的预测评估" class="headerlink" title="10. Making a confusion matrix for further prediction evaluation 制作混淆矩阵以进行进一步的预测评估"></a>10. Making a confusion matrix for further prediction evaluation 制作混淆矩阵以进行进一步的预测评估</h1><p>对于分类问题，我们可以使用许多<a target="_blank" rel="noopener" href="https://www.learnpytorch.io/02_pytorch_classification/#9-more-classification-evaluation-metrics">不同的评估指标。</a></p>
<p>最直观的一种是<a target="_blank" rel="noopener" href="https://www.dataschool.io/simple-guide-to-confusion-matrix-terminology/">混淆矩阵</a>。</p>
<p>混淆矩阵可以显示分类模型在预测和真实标签之间混淆的地方。</p>
<p>为了制作混淆矩阵，我们将经历三个步骤：<br>1、使用我们训练的模型进行预测<code>model_2</code>（混淆矩阵将预测与真实标签进行比较）。<br>2、使用制作混淆矩阵<code>torchmetrics.ConfusionMatrix</code>。<br>3、使用绘制混淆矩阵<code>mlxtend.plotting.plot_confusion_matrix()</code>。</p>
<h2 id="首先用训练好的模型进行预测。"><a href="#首先用训练好的模型进行预测。" class="headerlink" title="首先用训练好的模型进行预测。"></a>首先用训练好的模型进行预测。</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Import tqdm for progress bar</span></span><br><span class="line"><span class="keyword">from</span> tqdm.auto <span class="keyword">import</span> tqdm</span><br><span class="line"></span><br><span class="line"><span class="comment"># 1. Make predictions with trained model</span></span><br><span class="line">y_preds = []</span><br><span class="line">model_2.<span class="built_in">eval</span>()</span><br><span class="line"><span class="keyword">with</span> torch.inference_mode():</span><br><span class="line">  <span class="keyword">for</span> X, y <span class="keyword">in</span> tqdm(test_dataloader, desc=<span class="string">&quot;Making predictions&quot;</span>):</span><br><span class="line">    <span class="comment"># Send data and targets to target device</span></span><br><span class="line">    X, y = X.to(device), y.to(device)</span><br><span class="line">    <span class="comment"># Do the forward pass</span></span><br><span class="line">    y_logit = model_2(X)</span><br><span class="line">    <span class="comment"># Turn predictions from logits -&gt; prediction probabilities -&gt; predictions labels</span></span><br><span class="line">    y_pred = torch.softmax(y_logit, dim=<span class="number">1</span>).argmax(dim=<span class="number">1</span>) <span class="comment"># note: perform softmax on the &quot;logits&quot; dimension, not &quot;batch&quot; dimension (in this case we have a batch size of 32, so can perform on dim=1)</span></span><br><span class="line">    <span class="comment"># Put predictions on CPU for evaluation</span></span><br><span class="line">    y_preds.append(y_pred.cpu())</span><br><span class="line"><span class="comment"># Concatenate list of predictions into a tensor</span></span><br><span class="line">y_pred_tensor = torch.cat(y_preds)</span><br></pre></td></tr></table></figure>
<h2 id="制作混淆矩阵"><a href="#制作混淆矩阵" class="headerlink" title="制作混淆矩阵"></a>制作混淆矩阵</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># See if torchmetrics exists, if not, install it</span></span><br><span class="line"><span class="keyword">try</span>:</span><br><span class="line">    <span class="keyword">import</span> torchmetrics, mlxtend</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;mlxtend version: <span class="subst">&#123;mlxtend.__version__&#125;</span>&quot;</span>)</span><br><span class="line">    <span class="keyword">assert</span> <span class="built_in">int</span>(mlxtend.__version__.split(<span class="string">&quot;.&quot;</span>)[<span class="number">1</span>]) &gt;= <span class="number">19</span>, <span class="string">&quot;mlxtend verison should be 0.19.0 or higher&quot;</span></span><br><span class="line"><span class="keyword">except</span>:</span><br><span class="line">    !pip install -q torchmetrics -U mlxtend <span class="comment"># &lt;- Note: If you&#x27;re using Google Colab, this may require restarting the runtime</span></span><br><span class="line">    <span class="keyword">import</span> torchmetrics, mlxtend</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;mlxtend version: <span class="subst">&#123;mlxtend.__version__&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Import mlxtend upgraded version</span></span><br><span class="line"><span class="keyword">import</span> mlxtend </span><br><span class="line"><span class="built_in">print</span>(mlxtend.__version__)</span><br><span class="line"><span class="keyword">assert</span> <span class="built_in">int</span>(mlxtend.__version__.split(<span class="string">&quot;.&quot;</span>)[<span class="number">1</span>]) &gt;= <span class="number">19</span> <span class="comment"># should be version 0.19.0 or higher</span></span><br></pre></td></tr></table></figure>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">0.23.1</span><br></pre></td></tr></table></figure>
<p><code>torchmetrics</code> 和 <code>mlxtend</code>安装完毕，让我们制作一个混淆矩阵！</p>
<p>首先，我们将创建一个<code>torchmetrics.ConfusionMatrix</code>实例，通过设置来告诉它我们要处理多少个类<code>num_classes=len(class_names)</code>。</p>
<p>然后，我们将通过向我们的实例传递模型的预测（<code>preds=y_pred_tensor</code>）和目标（<code>target=test_data.targets</code>）来创建一个混淆矩阵（张量格式）。</p>
<p><code>plot_confusion_matrix()</code>最后，我们可以使用中的函数绘制混淆矩阵<code>mlxtend.plotting</code>。</p>
<h2 id="绘制混淆矩阵"><a href="#绘制混淆矩阵" class="headerlink" title="绘制混淆矩阵"></a>绘制混淆矩阵</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> torchmetrics <span class="keyword">import</span> ConfusionMatrix</span><br><span class="line"><span class="keyword">from</span> mlxtend.plotting <span class="keyword">import</span> plot_confusion_matrix</span><br><span class="line"></span><br><span class="line"><span class="comment"># 2. Setup confusion matrix instance and compare predictions to targets</span></span><br><span class="line">confmat = ConfusionMatrix(num_classes=<span class="built_in">len</span>(class_names), task=<span class="string">&#x27;multiclass&#x27;</span>)</span><br><span class="line">confmat_tensor = confmat(preds=y_pred_tensor,</span><br><span class="line">                         target=test_data.targets)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 3. Plot the confusion matrix</span></span><br><span class="line">fig, ax = plot_confusion_matrix(</span><br><span class="line">    conf_mat=confmat_tensor.numpy(), <span class="comment"># matplotlib likes working with NumPy </span></span><br><span class="line">    class_names=class_names, <span class="comment"># turn the row and column labels into class names</span></span><br><span class="line">    figsize=(<span class="number">10</span>, <span class="number">7</span>)</span><br><span class="line">);</span><br></pre></td></tr></table></figure>
<img src="/2024/08/17/PyTorch-26H-4/PyTorch-26H-4-14.png" class="" title="PyTorch-26H-4-14">
<p>哇哦！看起来不是很棒吗？</p>
<p>我们可以看到我们的模型表现相当好，因为大多数深色方块都位于从左上到右下的对角线上（理想模型只有在这些方块中有值，其他地方都为 0）。</p>
<p>该模型对相似的类别最为“困惑”，例如，对于实际标记为“衬衫”的图像，预测其为“套头衫”。</p>
<p>对于实际标记为“T 恤/上衣”的类别，预测其为“衬衫”，方法也是一样。</p>
<p>这种信息通常比单一的准确度指标更有帮助，因为它可以告诉我们模型哪里出了问题。</p>
<p>它也暗示了为什么模型可能会出现某些错误。</p>
<p>可以理解的是，对于标有“T 恤/上衣”的图像，模型有时会预测“衬衫”。</p>
<p>我们可以利用此类信息进一步检查我们的模型和数据，看看如何改进。</p>
<h1 id="11-Save-and-load-best-performing-model"><a href="#11-Save-and-load-best-performing-model" class="headerlink" title="11. Save and load best performing model"></a>11. Save and load best performing model</h1><p>使用以下组合来保存和加载 PyTorch 模型：</p>
<p><code>torch.save</code>- 用于保存整个 PyTorch 模型或模型的函数state_dict()。<br><code>torch.load</code>- 用于加载已保存的 PyTorch 对象的函数。<br><code>torch.nn.Module.load_state_dict()</code>- 将保存的<code>state_dict()</code>内容加载到现有模型实例中的功能。</p>
<p>保存 <code>model_2</code> 的 <code>state_dict()</code> 然后重新加载并评估它，以确保 保存 和 加载 正确进行。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pathlib <span class="keyword">import</span> Path</span><br><span class="line"></span><br><span class="line"><span class="comment"># Create models directory (if it doesn&#x27;t already exist), see: https://docs.python.org/3/library/pathlib.html#pathlib.Path.mkdir</span></span><br><span class="line">MODEL_PATH = Path(<span class="string">&quot;models&quot;</span>)</span><br><span class="line">MODEL_PATH.mkdir(parents=<span class="literal">True</span>, <span class="comment"># create parent directories if needed</span></span><br><span class="line">                 exist_ok=<span class="literal">True</span> <span class="comment"># if models directory already exists, don&#x27;t error</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Create model save path</span></span><br><span class="line">MODEL_NAME = <span class="string">&quot;03_pytorch_computer_vision_model_2.pth&quot;</span></span><br><span class="line">MODEL_SAVE_PATH = MODEL_PATH / MODEL_NAME</span><br><span class="line"></span><br><span class="line"><span class="comment"># Save the model state dict</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Saving model to: <span class="subst">&#123;MODEL_SAVE_PATH&#125;</span>&quot;</span>)</span><br><span class="line">torch.save(obj=model_2.state_dict(), <span class="comment"># only saving the state_dict() only saves the learned parameters</span></span><br><span class="line">           f=MODEL_SAVE_PATH)</span><br></pre></td></tr></table></figure>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Saving model to: models/03_pytorch_computer_vision_model_2.pth</span><br></pre></td></tr></table></figure>
<p>现在我们已经有一个保存的模型，我们可以使用和的<code>state_dict()</code>组合将其重新加载。<code>load_state_dict()torch.load()</code></p>
<p>由于我们正在使用<code>load_state_dict()</code>，我们需要创建一个<code>FashionMNISTModelV2()</code>具有与我们保存的模型相同的输入参数的新实例<code>state_dict()</code>。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Create a new instance of FashionMNISTModelV2 (the same class as our saved state_dict())</span></span><br><span class="line"><span class="comment"># Note: loading model will error if the shapes here aren&#x27;t the same as the saved version</span></span><br><span class="line">loaded_model_2 = FashionMNISTModelV2(input_shape=<span class="number">1</span>, </span><br><span class="line">                                    hidden_units=<span class="number">10</span>, <span class="comment"># try changing this to 128 and seeing what happens </span></span><br><span class="line">                                    output_shape=<span class="number">10</span>) </span><br><span class="line"></span><br><span class="line"><span class="comment"># Load in the saved state_dict()</span></span><br><span class="line">loaded_model_2.load_state_dict(torch.load(f=MODEL_SAVE_PATH))</span><br><span class="line"></span><br><span class="line"><span class="comment"># Send model to GPU</span></span><br><span class="line">loaded_model_2 = loaded_model_2.to(device)</span><br></pre></td></tr></table></figure>
<p>现在我们已经有一个加载的模型，我们可以对其进行评估，eval_model()以确保其参数与model_2保存之前的工作方式类似。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Evaluate loaded model</span></span><br><span class="line">torch.manual_seed(<span class="number">42</span>)</span><br><span class="line"></span><br><span class="line">loaded_model_2_results = eval_model(</span><br><span class="line">    model=loaded_model_2,</span><br><span class="line">    data_loader=test_dataloader,</span><br><span class="line">    loss_fn=loss_fn, </span><br><span class="line">    accuracy_fn=accuracy_fn</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">loaded_model_2_results</span><br></pre></td></tr></table></figure>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&#123;&#x27;model_name&#x27;: &#x27;FashionMNISTModelV2&#x27;,</span><br><span class="line"> &#x27;model_loss&#x27;: 0.3258868157863617,</span><br><span class="line"> &#x27;model_acc&#x27;: 88.36861022364218&#125;</span><br></pre></td></tr></table></figure>
<p>这些结果看起来是否相同<code>model_2_results</code>？</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">model_2_results</span><br></pre></td></tr></table></figure>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&#123;&#x27;model_name&#x27;: &#x27;FashionMNISTModelV2&#x27;,</span><br><span class="line"> &#x27;model_loss&#x27;: 0.3258868157863617,</span><br><span class="line"> &#x27;model_acc&#x27;: 88.36861022364218&#125;</span><br></pre></td></tr></table></figure>
<p>我们可以使用 <code>torch.isclose()</code> 来确定两个张量是否彼此接近，并通过参数 <code>atol</code>（绝对容差）和 <code>rtol</code>（相对容差）传入接近度的容差级别。</p>
<p>如果我们的模型的结果接近，则 <code>torch.isclose()</code> 的输出应该为 true。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Check to see if results are close to each other (if they are very far away, there may be an error)</span></span><br><span class="line">torch.isclose(torch.tensor(model_2_results[<span class="string">&quot;model_loss&quot;</span>]), </span><br><span class="line">              torch.tensor(loaded_model_2_results[<span class="string">&quot;model_loss&quot;</span>]),</span><br><span class="line">              atol=<span class="number">1e-08</span>, <span class="comment"># absolute tolerance</span></span><br><span class="line">              rtol=<span class="number">0.0001</span>) <span class="comment"># relative tolerance</span></span><br></pre></td></tr></table></figure>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tensor(True)</span><br></pre></td></tr></table></figure>
<h1 id="Exercises"><a href="#Exercises" class="headerlink" title="Exercises"></a>Exercises</h1><p>所有练习都集中于练习以上部分中的代码。</p>
<p>您应该能够通过参考每个部分或按照链接的资源来完成它们。</p>
<p>所有练习都应使用与<a target="_blank" rel="noopener" href="https://pytorch.org/docs/stable/notes/cuda.html#device-agnostic-code">设备无关的代码</a>来完成。</p>
<p><strong>资源：</strong></p>
<ul>
<li><a target="_blank" rel="noopener" href="https://github.com/mrdbourke/pytorch-deep-learning/blob/main/extras/exercises/03_pytorch_computer_vision_exercises.ipynb">03 练习模板笔记本</a></li>
<li><a target="_blank" rel="noopener" href="https://github.com/mrdbourke/pytorch-deep-learning/blob/main/extras/solutions/03_pytorch_computer_vision_exercise_solutions.ipynb">03 示例解决方案笔记本</a>（在查看<em>之前先</em>尝试练习）</li>
</ul>
<ol>
<li><p>目前计算机视觉在工业领域中的应用有哪三个？</p>
</li>
<li><p>搜索“机器学习中的过度拟合是什么”，然后写下你发现的内容。</p>
</li>
<li><p>搜索“机器学习中防止过度拟合的方法”，写下你发现的 3 件事，并写下每件事的一句话。<strong>注意：</strong>有很多这样的方法，所以不要太担心所有方法，只需选择 3 个并从中开始。</p>
</li>
<li><p>花 20 分钟阅读和点击<a target="_blank" rel="noopener" href="https://poloclub.github.io/cnn-explainer/"> CNN Explainer 网站</a></p>
<ul>
<li>使用“上传”按钮上传您自己的示例图像，并查看当您的图像通过 CNN 时其每一层发生的情况。</li>
</ul>
</li>
<li><p>加载<a target="_blank" rel="noopener" href="https://pytorch.org/vision/stable/generated/torchvision.datasets.MNIST.html#torchvision.datasets.MNIST"><code>torchvision.datasets.MNIST()</code></a>训练和测试数据集。</p>
</li>
<li><p>可视化 MNIST 训练数据集的至少 5 个不同样本。</p>
</li>
<li><p>将 MNIST 训练和测试数据集转换为数据加载器<code>torch.utils.data.DataLoader</code>，设置<code>batch_size=32</code>。</p>
</li>
<li><p>重新创建在此笔记本中使用的模型（来自<a target="_blank" rel="noopener" href="https://poloclub.github.io/cnn-explainer/">CNN Explainer 网站</a><code>model_2</code>的相同模型，也称为 TinyVGG），能够适合 MNIST 数据集。</p>
</li>
<li><p>在 CPU 和 GPU 上训练你在练习 8 中构建的模型，并查看每个模型需要多长时间。</p>
</li>
<li><p>使用训练好的模型进行预测，并将其中至少 5 个预测与目标标签进行比较。</p>
</li>
<li><p>绘制混淆矩阵，将模型的预测与真实标签进行比较。</p>
</li>
<li><p>创建一个形状的随机张量<code>[1, 3, 64, 64]</code>，并将其传递到具有各种超参数设置的层（这些可以是您选择的任何设置），如果参数上升和下降，<code>nn.Conv2d()</code>您会注意到什么？<code>kernel_size</code></p>
</li>
<li><p>model_2使用与本笔记本训练的模型类似的模型对测试<code>torchvision.datasets.FashionMNIST</code> 数据集进行预测。</p>
<ul>
<li>然后绘制一些模型错误的预测以及图像的标签应该是什么。</li>
<li>在将这些预测可视化之后，您认为这更多的是建模错误还是数据错误？</li>
<li>例如，模型是否可以做得更好，或者数据的标签是否太接近（例如，“衬衫”标签太接近“T 恤/上衣”）？</li>
</ul>
</li>
</ol>
<h1 id="Extra-curriculum"><a href="#Extra-curriculum" class="headerlink" title="Extra-curriculum"></a>Extra-curriculum</h1><ul>
<li><strong>观看：</strong> <a target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=iaSUYvmCekI&amp;list=PLtBw6njQRU-rwp5__7C0oIVt26ZgjG9NI&amp;index=3">麻省理工学院的深度计算机视觉简介</a>讲座。这将让你对卷积神经网络有一个很好的直观认识。</li>
<li>花 10 分钟点击<a target="_blank" rel="noopener" href="https://pytorch.org/vision/stable/index.html">PyTorch 视觉库</a>的不同选项，有哪些不同的模块可用？</li>
<li>查找“最常见的卷积神经网络”，你找到了哪些架构？这些架构中是否有任何一个包含在<a target="_blank" rel="noopener" href="https://pytorch.org/vision/stable/models.html"><code>torchvision.models</code></a>库中？你认为你可以用它们做什么？</li>
<li>要了解大量预训练的 PyTorch 计算机视觉模型以及 PyTorch 计算机视觉功能的许多不同扩展，请查看Ross Wightman 的<a target="_blank" rel="noopener" href="https://github.com/rwightman/pytorch-image-models/">PyTorch 图像模型库<code>timm</code></a>（Torch 图像模型）。</li>
</ul>
</div></article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="mailto:undefined">HibisciDai</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="http://hibiscidai.com/2024/08/17/PyTorch-26H-4/">http://hibiscidai.com/2024/08/17/PyTorch-26H-4/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a target="_blank" rel="noopener" href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="http://hibiscidai.com">HibisciDai</a>！</span></div></div><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/">学习笔记</a><a class="post-meta__tags" href="/tags/PyTorch/">PyTorch</a></div><div class="social-share pull-right" data-disabled="linkedin,diandian"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/social-share.js@1.0.16/dist/css/share.min.css"><script src="https://cdn.jsdelivr.net/npm/social-share.js@1.0.16/dist/js/social-share.min.js"></script><nav id="pagination"><div class="prev-post pull-left"><a href="/2024/08/18/PyTorch-26H-5/"><i class="fa fa-chevron-left">  </i><span>PyTorch-26H-5</span></a></div><div class="next-post pull-right"><a href="/2024/08/16/PyTorch-26H-3/"><span>PyTorch-26H-3</span><i class="fa fa-chevron-right"></i></a></div></nav><div class="post-adv"><a target="_blank" rel="noopener" href="https://www.paofu.cloud/auth/register?code=j4I7">好用、实惠、稳定的梯子,点击这里<img src="https://pic.imgdb.cn/item/65572abac458853aefef30cd.png" width="1000" height="124" object-fit="cover" ></a></div><div id="lv-container" data-id="city" data-uid="MTAyMC8zNTQ2NC8xMjAwMA=="><script>(function(d, s) {
    var j, e = d.getElementsByTagName(s)[0];
    if (typeof LivereTower === 'function') { return; }
    j = d.createElement(s);
    j.src = 'https://cdn-city.livere.com/js/embed.dist.js';
    j.async = true;
    e.parentNode.insertBefore(j, e);
})(document, 'script');</script></div></div></div><footer class="footer-bg" style="background-image: url(/img/banner2.jpg)"><div class="layout" id="footer"><div class="copyright">&copy;2017 - 2025 By HibisciDai</div><div class="framework-info"><span>驱动 - </span><a target="_blank" rel="noopener" href="http://hexo.io"><span>Hexo</span></a><span class="footer-separator">|</span><span>主题 - </span><a target="_blank" rel="noopener" href="https://github.com/Molunerfinn/hexo-theme-melody"><span>Melody</span></a></div><div class="footer_custom_text">hitokoto</div><div class="busuanzi"><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><span id="busuanzi_container_page_pv"><i class="fa fa-file"></i><span id="busuanzi_value_page_pv"></span><span></span></span></div></div></footer><i class="fa fa-arrow-up" id="go-up" aria-hidden="true"></i><script src="/js/third-party/anime.min.js"></script><script src="/js/third-party/jquery.min.js"></script><script src="/js/third-party/jquery.fancybox.min.js"></script><script src="/js/third-party/velocity.min.js"></script><script src="/js/third-party/velocity.ui.min.js"></script><script src="/js/utils.js?version=1.9.0"></script><script src="/js/fancybox.js?version=1.9.0"></script><script src="/js/sidebar.js?version=1.9.0"></script><script src="/js/copy.js?version=1.9.0"></script><script src="/js/fireworks.js?version=1.9.0"></script><script src="/js/transition.js?version=1.9.0"></script><script src="/js/scroll.js?version=1.9.0"></script><script src="/js/head.js?version=1.9.0"></script><script type="text/x-mathjax-config">MathJax.Hub.Config({
  tex2jax: {
    inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
    processEscapes: true,
    skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
  },
  CommonHTML: {
    linebreaks: { automatic: true, width: "90% container" }
  },
  "HTML-CSS": { 
    linebreaks: { automatic: true, width: "90% container" }
  },
  "SVG": { 
    linebreaks: { automatic: true, width: "90% container" }
  }
});
</script><script type="text/x-mathjax-config">MathJax.Hub.Queue(function() {
  var all = MathJax.Hub.getAllJax(), i;
  for (i=0; i < all.length; i += 1) {
    all[i].SourceElement().parentNode.className += ' has-jax';
  }
});
</script><script src="https://cdn.bootcss.com/mathjax/2.7.2/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/katex@latest/dist/katex.min.css"><script src="https://cdn.jsdelivr.net/npm/katex-copytex@latest/dist/katex-copytex.min.js"></script><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/katex-copytex@latest/dist/katex-copytex.min.css"><script src="/js/katex.js"></script><script src="/js/search/local-search.js"></script><script id="ribbon" src="/js/third-party/canvas-ribbon.js" size="150" alpha="0.6" zIndex="-1" data-click="false"></script><script>if(/Android|webOS|iPhone|iPod|iPad|BlackBerry/i.test(navigator.userAgent)) {
  $('#nav').addClass('is-mobile')
  $('footer').addClass('is-mobile')
  $('#top-container').addClass('is-mobile')
}</script><div class="search-dialog" id="local-search"><div class="search-dialog__title" id="local-search-title">本地搜索</div><div id="local-input-panel"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章"></div></div></div><hr><div id="local-search-results"><div id="local-hits"></div><div id="local-stats"><div class="local-search-stats__hr" id="hr"><span>由</span> <a target="_blank" rel="noopener" href="https://github.com/wzpan/hexo-generator-search" style="color:#49B1F5;">hexo-generator-search</a>
 <span>提供支持</span></div></div></div><span class="search-close-button"><i class="fa fa-times"></i></span></div><div class="search-mask"></div></body></html>