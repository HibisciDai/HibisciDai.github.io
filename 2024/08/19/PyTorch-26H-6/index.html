<!DOCTYPE html><html lang="zh-Hans"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta name="description" content="PyTorch-26H-6"><meta name="keywords" content="学习笔记,PyTorch"><meta name="author" content="HibisciDai"><meta name="copyright" content="HibisciDai"><title>PyTorch-26H-6 | HibisciDai</title><link rel="shortcut icon" href="/img/avatar.png"><link rel="stylesheet" href="/css/index.css?version=1.9.0"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/font-awesome@latest/css/font-awesome.min.css?version=1.9.0"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.7.2/css/all.css?version=1.9.0"><meta name="format-detection" content="telephone=no"><meta http-equiv="x-dns-prefetch-control" content="on"><link rel="dns-prefetch" href="https://cdn.jsdelivr.net"><link rel="manifest" href="/manifest.json"><link rel="manifest" href="/manifest.json"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><script src="https://v1.hitokoto.cn/?encode=js&amp;charset=utf-8&amp;select=.footer_custom_text" defer></script><script>var GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: {"path":"search.xml","languages":{"hits_empty":"找不到您查询的内容:${query}"}},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  hexoVersion: '6.1.0'
} </script><meta name="generator" content="Hexo 6.1.0"><link rel="alternate" href="/atom.xml" title="HibisciDai" type="application/atom+xml">
</head><body><canvas class="fireworks"></canvas><i class="fa fa-arrow-right" id="toggle-sidebar" aria-hidden="true"></i><div id="sidebar" data-display="true"><div class="toggle-sidebar-info text-center"><span data-toggle="切换文章详情">切换站点概览</span><hr></div><div class="sidebar-toc"><div class="sidebar-toc__title">目录</div><div class="sidebar-toc__progress"><span class="progress-notice">你已经读了</span><span class="progress-num">0</span><span class="progress-percentage">%</span><div class="sidebar-toc__progress-bar"></div></div><div class="sidebar-toc__content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#PyTorch-26H-6"><span class="toc-number">1.</span> <span class="toc-text">PyTorch-26H-6</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#What-is-going-modular-%E4%BB%80%E4%B9%88%E6%98%AF%E6%A8%A1%E5%9D%97%E5%8C%96"><span class="toc-number">2.</span> <span class="toc-text">What is going modular? 什么是模块化?</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Why-would-you-want-to-go-modular-%E4%B8%BA%E4%BD%95%E8%A6%81%E9%87%87%E7%94%A8%E6%A8%A1%E5%9D%97%E5%8C%96%EF%BC%9F"><span class="toc-number">3.</span> <span class="toc-text">Why would you want to go modular? 为何要采用模块化？</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#Pros-and-cons-of-notebooks-vs-Python-scripts-%E7%AC%94%E8%AE%B0%E6%9C%AC%E4%B8%8E-Python-%E8%84%9A%E6%9C%AC%E7%9A%84%E4%BC%98%E7%BC%BA%E7%82%B9"><span class="toc-number">3.1.</span> <span class="toc-text">Pros and cons of notebooks vs Python scripts 笔记本与 Python 脚本的优缺点</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#My-workflow-%E5%B7%A5%E4%BD%9C%E6%B5%81%E7%A8%8B"><span class="toc-number">3.2.</span> <span class="toc-text">My workflow 工作流程</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#PyTorch-in-the-wild-PyTorch-%E7%9A%84%E5%BA%94%E7%94%A8"><span class="toc-number">3.3.</span> <span class="toc-text">PyTorch in the wild PyTorch 的应用</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#What-we%E2%80%99re-going-to-cover"><span class="toc-number">4.</span> <span class="toc-text">What we’re going to cover</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#Why-two-parts"><span class="toc-number">4.1.</span> <span class="toc-text">Why two parts?</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#What-we%E2%80%99re-working-towards"><span class="toc-number">4.2.</span> <span class="toc-text">What we’re working towards</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Things-to-note"><span class="toc-number">4.3.</span> <span class="toc-text">Things to note</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#0-Cell-mode-vs-script-mode-%E5%8D%95%E5%85%83%E6%A0%BC%E6%A8%A1%E5%BC%8F%E4%B8%8E%E8%84%9A%E6%9C%AC%E6%A8%A1%E5%BC%8F"><span class="toc-number">5.</span> <span class="toc-text">0. Cell mode vs. script mode 单元格模式与脚本模式</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#1-Get-data-%E8%8E%B7%E5%8F%96%E6%95%B0%E6%8D%AE"><span class="toc-number">6.</span> <span class="toc-text">1. Get data 获取数据</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#2-Create-Datasets-and-DataLoaders-data-setup-py-%E5%88%9B%E5%BB%BA%E6%95%B0%E6%8D%AE%E9%9B%86%E5%92%8C%E6%95%B0%E6%8D%AE%E5%8A%A0%E8%BD%BD%E5%99%A8%EF%BC%88data-setup-py%EF%BC%89"><span class="toc-number">7.</span> <span class="toc-text">2. Create Datasets and DataLoaders (data_setup.py) 创建数据集和数据加载器（data_setup.py）</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#3-Making-a-model-model-builder-py-%E5%88%B6%E4%BD%9C%E6%A8%A1%E5%9E%8B%EF%BC%88model-builder-py%EF%BC%89"><span class="toc-number">8.</span> <span class="toc-text">3. Making a model (model_builder.py)制作模型（model_builder.py）</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#4-Creating-train-step-and-test-step-functions-and-train-to-combine-them-%E5%88%9B%E5%BB%BAtrain-step-%E5%92%8Ctest-step-%E5%87%BD%E6%95%B0%E5%B9%B6%E5%B0%86train-%E5%AE%83%E4%BB%AC%E7%BB%84%E5%90%88%E8%B5%B7%E6%9D%A5"><span class="toc-number">9.</span> <span class="toc-text">4. Creating train_step() and test_step() functions and train() to combine them 创建train_step()和test_step()函数并将train()它们组合起来</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#5-Creating-a-function-to-save-the-model-utils-py-%E5%88%9B%E5%BB%BA%E4%B8%80%E4%B8%AA%E5%87%BD%E6%95%B0%E6%9D%A5%E4%BF%9D%E5%AD%98%E6%A8%A1%E5%9E%8B%EF%BC%88utils-py%EF%BC%89"><span class="toc-number">10.</span> <span class="toc-text">5. Creating a function to save the model (utils.py) 创建一个函数来保存模型（utils.py）</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#6-Train-evaluate-and-save-the-model-train-py-%E8%AE%AD%E7%BB%83%E3%80%81%E8%AF%84%E4%BC%B0%E5%B9%B6%E4%BF%9D%E5%AD%98%E6%A8%A1%E5%9E%8B%EF%BC%88train-py%EF%BC%89"><span class="toc-number">11.</span> <span class="toc-text">6. Train, evaluate and save the model (train.py)训练、评估并保存模型（train.py）</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Exercises"><span class="toc-number">12.</span> <span class="toc-text">Exercises</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Extra-curriculum"><span class="toc-number">13.</span> <span class="toc-text">Extra-curriculum</span></a></li></ol></div></div><div class="author-info hide"><div class="author-info__avatar text-center"><img src="/img/Avatar.png"></div><div class="author-info__name text-center">HibisciDai</div><div class="author-info__description text-center">HibisciDai'Blog</div><hr><div class="author-info-articles"><a class="author-info-articles__archives article-meta" href="/archives"><span class="pull-left">文章</span><span class="pull-right">244</span></a><a class="author-info-articles__tags article-meta" href="/tags"><span class="pull-left">标签</span><span class="pull-right">88</span></a><a class="author-info-articles__categories article-meta" href="/categories"><span class="pull-left">分类</span><span class="pull-right">33</span></a></div><hr><div class="author-info-links"><div class="author-info-links__title text-center">友情链接</div><a class="author-info-links__name text-center" target="_blank" rel="noopener" href="https://github.com/HibisciDai/hexo-theme-melody">HexoTheme-github</a><a class="author-info-links__name text-center" target="_blank" rel="noopener" href="https://molunerfinn.com/">molunerfinn</a></div></div></div><div id="content-outer"><div id="top-container" style="background-image: url(/img/banner2.jpg)"><div id="page-header"><span class="pull-left"> <a id="site-name" href="/">HibisciDai</a></span><i class="fa fa-bars toggle-menu pull-right" aria-hidden="true"></i><span class="pull-right menus">   <a class="site-page" href="/">主页</a><a class="site-page" href="/about">关于我</a><a class="site-page" href="/archives">归档</a><a class="site-page" href="/tags">标签</a><a class="site-page" href="/categories">分类</a><a class="site-page" href="/gallery">相册</a></span><span class="pull-right"><a class="site-page social-icon search"><i class="fa fa-search"></i><span> 搜索</span></a></span></div><div id="post-info"><div id="post-title">PyTorch-26H-6</div><div id="post-meta"><time class="post-meta__date"><i class="fa fa-calendar" aria-hidden="true"></i> 2024-08-19</time><span class="post-meta__separator">|</span><i class="fa fa-inbox post-meta__icon" aria-hidden="true"></i><a class="post-meta__categories" href="/categories/PyTorch/">PyTorch</a><div class="post-meta-wordcount"><span>字数总计: </span><span class="word-count">5.5k</span><span class="post-meta__separator">|</span><span>阅读时长: 24 分钟</span></div></div></div></div><div class="layout" id="content-inner"><article id="post"><div class="article-container" id="post-content"><img src="/2024/08/19/PyTorch-26H-6/PyTorch-26H-6.png" class="" title="PyTorch-26H-6">
<p>PyTorch-26H-6</p>
<span id="more"></span>
<h1 id="PyTorch-26H-6"><a href="#PyTorch-26H-6" class="headerlink" title="PyTorch-26H-6"></a>PyTorch-26H-6</h1><p>主页：<a target="_blank" rel="noopener" href="https://www.freecodecamp.org/news/learn-pytorch-for-deep-learning-in-day/">https://www.freecodecamp.org/news/learn-pytorch-for-deep-learning-in-day/</a></p>
<p>youtub：<a target="_blank" rel="noopener" href="https://youtu.be/V_xro1bcAuA">https://youtu.be/V_xro1bcAuA</a></p>
<p>github：<a target="_blank" rel="noopener" href="https://github.com/mrdbourke/pytorch-deep-learning">https://github.com/mrdbourke/pytorch-deep-learning</a></p>
<p>Learn PyTorch for Deep Learning: Zero to Mastery book：<a target="_blank" rel="noopener" href="https://www.learnpytorch.io/">https://www.learnpytorch.io/</a></p>
<p>PyTorch documentation：<a target="_blank" rel="noopener" href="https://pytorch.org/docs/stable/index.html">https://pytorch.org/docs/stable/index.html</a></p>
<p>本节回答以下问题：“如何将我的笔记本代码转换为 Python 脚本？”</p>
<p>为此，我们将把 上一节 自定义数据集 的笔记本中最有用的代码单元转换为一系列 Python 脚本，并保存到名为的目录中<code>going_modular</code>。</p>
<h1 id="What-is-going-modular-什么是模块化"><a href="#What-is-going-modular-什么是模块化" class="headerlink" title="What is going modular? 什么是模块化?"></a>What is going modular? 什么是模块化?</h1><p>模块化涉及将笔记本代码（来自 Jupyter Notebook 或 Google Colab 笔记本）转换为一系列提供类似功能的不同 Python 脚本。</p>
<p>例如，我们可以将笔记本代码从一系列单元格转换为以下 Python 文件：</p>
<ul>
<li><code>data_setup.py</code>： 如果需要，可以准备并下载数据的文件。</li>
<li><code>engine.py</code>：包含各种训练功能的文件。</li>
<li><code>model_builder.py</code>或者<code>model.py</code>：一个用于创建 PyTorch 模型的文件。</li>
<li><code>train.py</code>：一个利用所有其他文件并训练目标 PyTorch 模型的文件。</li>
<li><code>utils.py</code>：专用于实用功能的文件。</li>
</ul>
<blockquote>
<p>注意：上述文件的命名和布局取决于您的用例和代码要求。Python 脚本与单个笔记本单元一样通用，这意味着您可以为几乎任何类型的功能创建一个脚本。</p>
</blockquote>
<h1 id="Why-would-you-want-to-go-modular-为何要采用模块化？"><a href="#Why-would-you-want-to-go-modular-为何要采用模块化？" class="headerlink" title="Why would you want to go modular? 为何要采用模块化？"></a>Why would you want to go modular? 为何要采用模块化？</h1><p>笔记本非常适合快速迭代探索和运行实验。</p>
<p>然而，对于更大规模的项目，您可能会发现 Python 脚本更具可重复性且更易于运行。</p>
<p>尽管这是一个有争议的话题，但像<a target="_blank" rel="noopener" href="https://netflixtechblog.com/notebook-innovation-591ee3221233">Netflix 这样的公司已经展示了他们如何使用笔记本编写生产代码</a>。</p>
<p>生产代码是运行以向某人或某物提供服务的代码。</p>
<p>例如，如果有一个在线运行的应用程序，其他人可以访问和使用，则运行该应用程序的代码被视为生产代码。</p>
<p>像 fast.ai <a target="_blank" rel="noopener" href="https://github.com/fastai/nbdev"><code>nb-dev</code></a>（笔记本开发的缩写）这样的库，能够使用 Jupyter Notebooks 编写整个 Python 库（包括文档）。</p>
<h2 id="Pros-and-cons-of-notebooks-vs-Python-scripts-笔记本与-Python-脚本的优缺点"><a href="#Pros-and-cons-of-notebooks-vs-Python-scripts-笔记本与-Python-脚本的优缺点" class="headerlink" title="Pros and cons of notebooks vs Python scripts 笔记本与 Python 脚本的优缺点"></a>Pros and cons of notebooks vs Python scripts 笔记本与 Python 脚本的优缺点</h2><div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center"></th>
<th style="text-align:center">优点</th>
<th style="text-align:center">缺点</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">Notebooks</td>
<td style="text-align:center">易于实验/入门</td>
<td style="text-align:center">版本控制可能很困难</td>
</tr>
<tr>
<td style="text-align:center"></td>
<td style="text-align:center">易于分享（例如 Google Colab 笔记本的链接）</td>
<td style="text-align:center">难以仅使用特定部件</td>
</tr>
<tr>
<td style="text-align:center"></td>
<td style="text-align:center">非常直观</td>
<td style="text-align:center">文本和图形可能会妨碍代码</td>
</tr>
<tr>
<td style="text-align:center">Python 脚本</td>
<td style="text-align:center">可以将代码打包在一起（节省在不同的笔记本中重写类似代码的麻烦）</td>
<td style="text-align:center">实验并不直观（通常必须运行整个脚本而不是一个单元格）</td>
</tr>
<tr>
<td style="text-align:center"></td>
<td style="text-align:center">可以使用 git 进行版本控制</td>
<td style="text-align:center"></td>
</tr>
<tr>
<td style="text-align:center"></td>
<td style="text-align:center">许多开源项目使用脚本</td>
<td style="text-align:center"></td>
</tr>
<tr>
<td style="text-align:center"></td>
<td style="text-align:center">较大的项目可以在云供应商上运行（对笔记本的支持不太多）</td>
</tr>
</tbody>
</table>
</div>
<h2 id="My-workflow-工作流程"><a href="#My-workflow-工作流程" class="headerlink" title="My workflow 工作流程"></a>My workflow 工作流程</h2><p>通常在 Jupyter/Google Colab 笔记本中启动机器学习项目，以便快速进行实验和可视化。</p>
<p>然后，当我完成一些工作时，我会将最有用的代码片段移到 Python 脚本中。</p>
<img src="/2024/08/19/PyTorch-26H-6/PyTorch-26H-6-1.png" class="" title="PyTorch-26H-6-1">
<p>编写机器学习代码有许多可能的工作流程。有些人喜欢从脚本开始，而其他人（比如我）则喜欢从笔记本开始，然后再转到脚本。</p>
<h2 id="PyTorch-in-the-wild-PyTorch-的应用"><a href="#PyTorch-in-the-wild-PyTorch-的应用" class="headerlink" title="PyTorch in the wild PyTorch 的应用"></a>PyTorch in the wild PyTorch 的应用</h2><p>有许多基于 PyTorch 的 ML 项目的代码存储库都有关于如何以 Python 脚本的形式运行 PyTorch 代码的说明。</p>
<p>例如，可能会被指示在终端/命令行中运行如下代码来训练模型：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python train.py --model MODEL_NAME --batch_size BATCH_SIZE --lr LEARNING_RATE --num_epochs NUM_EPOCHS</span><br></pre></td></tr></table></figure>
<img src="/2024/08/19/PyTorch-26H-6/PyTorch-26H-6-2.png" class="" title="PyTorch-26H-6-2">
<p><code>train.py</code>在命令行上运行具有各种超参数设置的 PyTorch脚本。</p>
<p>在这种情况下，<code>train.py</code>目标 Python 脚本可能包含训练 PyTorch 模型的函数。</p>
<p>并且<code>--model</code>、<code>--batch_size</code>、<code>--lr</code>和<code>--num_epochs</code>被称为参数标志。</p>
<p>您可以将它们设置为您喜欢的任何值，如果它们兼容<code>train.py</code>，它们就会起作用，如果不兼容，它们就会出错。</p>
<p>例如，假设我们想要使用笔记本 04 训练我们的 TinyVGG 模型 10 个时期，批量大小为 32，学习率为 0.001：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python train.py --model tinyvgg --batch_size 32 --lr 0.001 --num_epochs 10</span><br></pre></td></tr></table></figure>
<p><code>train.py</code>您可以根据需要在脚本中设置任意数量的这些参数标志。</p>
<p>用于训练最先进的计算机视觉模型的 PyTorch 博客文章采用了这种风格。</p>
<h1 id="What-we’re-going-to-cover"><a href="#What-we’re-going-to-cover" class="headerlink" title="What we’re going to cover"></a>What we’re going to cover</h1><p>本节的主要概念是：将有用的笔记本代码单元转换为可重复使用的 Python 文件。</p>
<p>这样做可以节省我们一遍又一遍编写相同代码的时间。</p>
<p>此部分有两个笔记本：</p>
<ul>
<li>走向模块化：第 1 部分（单元模式） ——此笔记本作为传统的 Jupyter Notebook/Google Colab 笔记本运行，是笔记本 04的浓缩版。</li>
<li>走向模块化：第 2 部分（脚本模式） ——这个笔记本与第 1 部分相同，但增加了将每个主要部分转换为 Python 脚本的功能，例如<code>data_setup.py</code>和<code>train.py</code>。</li>
</ul>
<p>本文档中的文本重点介绍代码单元 05. 走向模块化：第 2 部分（脚本模式），即<code>%%writefile ...</code>位于顶部的代码单元。</p>
<h2 id="Why-two-parts"><a href="#Why-two-parts" class="headerlink" title="Why two parts?"></a>Why two parts?</h2><p>因为有时学习某事物的最好方法是观察它与其他事物的不同之处。</p>
<p>如果你并排运行每个笔记本，你会看到它们的不同之处，这就是关键的学习内容所在。</p>
<img src="/2024/08/19/PyTorch-26H-6/PyTorch-26H-6-3.png" class="" title="PyTorch-26H-6-3">
<h2 id="What-we’re-working-towards"><a href="#What-we’re-working-towards" class="headerlink" title="What we’re working towards"></a>What we’re working towards</h2><ul>
<li>使用命令行中的一行代码即可训练我们在笔记本 04（Food Vision Mini）中构建的模型：python train.py。</li>
<li>可重用 Python 脚本的目录结构，例如：</li>
</ul>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">going_modular/</span><br><span class="line">├── going_modular/</span><br><span class="line">│   ├── data_setup.py</span><br><span class="line">│   ├── engine.py</span><br><span class="line">│   ├── model_builder.py</span><br><span class="line">│   ├── train.py</span><br><span class="line">│   └── utils.py</span><br><span class="line">├── models/</span><br><span class="line">│   ├── 05_going_modular_cell_mode_tinyvgg_model.pth</span><br><span class="line">│   └── 05_going_modular_script_mode_tinyvgg_model.pth</span><br><span class="line">└── data/</span><br><span class="line">    └── pizza_steak_sushi/</span><br><span class="line">        ├── train/</span><br><span class="line">        │   ├── pizza/</span><br><span class="line">        │   │   ├── image01.jpeg</span><br><span class="line">        │   │   └── ...</span><br><span class="line">        │   ├── steak/</span><br><span class="line">        │   └── sushi/</span><br><span class="line">        └── test/</span><br><span class="line">            ├── pizza/</span><br><span class="line">            ├── steak/</span><br><span class="line">            └── sushi/</span><br></pre></td></tr></table></figure>
<h2 id="Things-to-note"><a href="#Things-to-note" class="headerlink" title="Things to note"></a>Things to note</h2><ul>
<li><strong>文档字符串</strong>- 编写可重复且易于理解的代码非常重要。考虑到这一点，我们将放入脚本中的每个函数/类都是根据 Google 的<a target="_blank" rel="noopener" href="https://google.github.io/styleguide/pyguide.html#383-functions-and-methods">Python 文档字符串样式</a>创建的。</li>
<li><strong>在脚本顶部导入</strong>——由于我们要创建的所有 Python 脚本都可以被视为一个小程序，因此所有脚本都需要在脚本开始时导入它们的输入模块，例如：</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Import modules required for train.py</span></span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> data_setup, engine, model_builder, utils</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> transforms</span><br></pre></td></tr></table></figure>
<h1 id="0-Cell-mode-vs-script-mode-单元格模式与脚本模式"><a href="#0-Cell-mode-vs-script-mode-单元格模式与脚本模式" class="headerlink" title="0. Cell mode vs. script mode 单元格模式与脚本模式"></a>0. Cell mode vs. script mode 单元格模式与脚本模式</h1><p>单元格模式笔记本，例如<a target="_blank" rel="noopener" href="https://github.com/mrdbourke/pytorch-deep-learning/blob/main/going_modular/05_pytorch_going_modular_cell_mode.ipynb">05. 走向模块化第 1 部分（单元格模式）</a>是一个正常运行的笔记本，笔记本中的每个单元格都是代码或 markdown。</p>
<p>脚本模式笔记本（例如<a target="_blank" rel="noopener" href="https://github.com/mrdbourke/pytorch-deep-learning/blob/main/going_modular/05_pytorch_going_modular_script_mode.ipynb">05. Going Modular Part 2（脚本模式））</a>与单元格模式笔记本非常相似，但是，许多代码单元格可以转换为 Python 脚本。</p>
<blockquote>
<p>注意：您不需要通过笔记本创建 Python 脚本，您可以直接通过 IDE（集成开发环境）创建它们，例如VS Code。将脚本模式笔记本作为本节的一部分只是为了演示从笔记本到 Python 脚本的一种方法。</p>
</blockquote>
<h1 id="1-Get-data-获取数据"><a href="#1-Get-data-获取数据" class="headerlink" title="1. Get data 获取数据"></a>1. Get data 获取数据</h1><p><a target="_blank" rel="noopener" href="https://www.learnpytorch.io/04_pytorch_custom_datasets/#1-get-data">获取 05 个笔记本中每个笔记本的数据的方式与获取04 个笔记本</a>中的数据的方式相同。</p>
<p>通过 Python 的模块调用 GitHub<code>requests</code>下载<code>.zip</code>文件并解压。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">import</span> zipfile</span><br><span class="line"><span class="keyword">from</span> pathlib <span class="keyword">import</span> Path</span><br><span class="line"></span><br><span class="line"><span class="comment"># Setup path to data folder</span></span><br><span class="line">data_path = Path(<span class="string">&quot;data/&quot;</span>)</span><br><span class="line">image_path = data_path / <span class="string">&quot;pizza_steak_sushi&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># If the image folder doesn&#x27;t exist, download it and prepare it... </span></span><br><span class="line"><span class="keyword">if</span> image_path.is_dir():</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;<span class="subst">&#123;image_path&#125;</span> directory exists.&quot;</span>)</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;Did not find <span class="subst">&#123;image_path&#125;</span> directory, creating one...&quot;</span>)</span><br><span class="line">    image_path.mkdir(parents=<span class="literal">True</span>, exist_ok=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Download pizza, steak, sushi data</span></span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(data_path / <span class="string">&quot;pizza_steak_sushi.zip&quot;</span>, <span class="string">&quot;wb&quot;</span>) <span class="keyword">as</span> f:</span><br><span class="line">    request = requests.get(<span class="string">&quot;https://github.com/mrdbourke/pytorch-deep-learning/raw/main/data/pizza_steak_sushi.zip&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Downloading pizza, steak, sushi data...&quot;</span>)</span><br><span class="line">    f.write(request.content)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Unzip pizza, steak, sushi data</span></span><br><span class="line"><span class="keyword">with</span> zipfile.ZipFile(data_path / <span class="string">&quot;pizza_steak_sushi.zip&quot;</span>, <span class="string">&quot;r&quot;</span>) <span class="keyword">as</span> zip_ref:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Unzipping pizza, steak, sushi data...&quot;</span>) </span><br><span class="line">    zip_ref.extractall(image_path)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Remove zip file</span></span><br><span class="line">os.remove(data_path / <span class="string">&quot;pizza_steak_sushi.zip&quot;</span>)</span><br></pre></td></tr></table></figure>
<p>这样就会产生一个名为 <code>data</code> 的文件，其中包含另一个名为的目录，<code>pizza_steak_sushi</code>其中包含标准图像分类格式的披萨、牛排和寿司图像。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">data/</span><br><span class="line">└── pizza_steak_sushi/</span><br><span class="line">    ├── train/</span><br><span class="line">    │   ├── pizza/</span><br><span class="line">    │   │   ├── train_image01.jpeg</span><br><span class="line">    │   │   ├── test_image02.jpeg</span><br><span class="line">    │   │   └── ...</span><br><span class="line">    │   ├── steak/</span><br><span class="line">    │   │   └── ...</span><br><span class="line">    │   └── sushi/</span><br><span class="line">    │       └── ...</span><br><span class="line">    └── test/</span><br><span class="line">        ├── pizza/</span><br><span class="line">        │   ├── test_image01.jpeg</span><br><span class="line">        │   └── test_image02.jpeg</span><br><span class="line">        ├── steak/</span><br><span class="line">        └── sushi/</span><br></pre></td></tr></table></figure>
<h1 id="2-Create-Datasets-and-DataLoaders-data-setup-py-创建数据集和数据加载器（data-setup-py）"><a href="#2-Create-Datasets-and-DataLoaders-data-setup-py-创建数据集和数据加载器（data-setup-py）" class="headerlink" title="2. Create Datasets and DataLoaders (data_setup.py) 创建数据集和数据加载器（data_setup.py）"></a>2. Create Datasets and DataLoaders (data_setup.py) 创建数据集和数据加载器（data_setup.py）</h1><p>一旦我们获得了数据，我们就可以将其转换为 <code>PyTorchDataset</code> 的和 <code>DataLoader</code>（一个用于训练数据，一个用于测试数据）。</p>
<p>我们将有用 <code>Dataset</code> 和 <code>DataLoader</code> 创建的代码转换为一个名为的函数<code>create_dataloaders()</code>。</p>
<p>我们使用以下行将其写入文件<code>%%writefile going_modular/data_setup.py</code>。</p>
<p><code>data_setup.py</code></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br></pre></td><td class="code"><pre><span class="line">%%writefile going_modular/data_setup.py</span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">Contains functionality for creating PyTorch DataLoaders for </span></span><br><span class="line"><span class="string">image classification data.</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> datasets, transforms</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> DataLoader</span><br><span class="line"></span><br><span class="line">NUM_WORKERS = os.cpu_count()</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">create_dataloaders</span>(<span class="params"></span></span><br><span class="line"><span class="params">    train_dir: <span class="built_in">str</span>, </span></span><br><span class="line"><span class="params">    test_dir: <span class="built_in">str</span>, </span></span><br><span class="line"><span class="params">    transform: transforms.Compose, </span></span><br><span class="line"><span class="params">    batch_size: <span class="built_in">int</span>, </span></span><br><span class="line"><span class="params">    num_workers: <span class="built_in">int</span>=NUM_WORKERS</span></span><br><span class="line"><span class="params"></span>):</span><br><span class="line">  <span class="string">&quot;&quot;&quot;Creates training and testing DataLoaders.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">  Takes in a training directory and testing directory path and turns</span></span><br><span class="line"><span class="string">  them into PyTorch Datasets and then into PyTorch DataLoaders.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">  Args:</span></span><br><span class="line"><span class="string">    train_dir: Path to training directory.</span></span><br><span class="line"><span class="string">    test_dir: Path to testing directory.</span></span><br><span class="line"><span class="string">    transform: torchvision transforms to perform on training and testing data.</span></span><br><span class="line"><span class="string">    batch_size: Number of samples per batch in each of the DataLoaders.</span></span><br><span class="line"><span class="string">    num_workers: An integer for number of workers per DataLoader.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">  Returns:</span></span><br><span class="line"><span class="string">    A tuple of (train_dataloader, test_dataloader, class_names).</span></span><br><span class="line"><span class="string">    Where class_names is a list of the target classes.</span></span><br><span class="line"><span class="string">    Example usage:</span></span><br><span class="line"><span class="string">      train_dataloader, test_dataloader, class_names = \</span></span><br><span class="line"><span class="string">        = create_dataloaders(train_dir=path/to/train_dir,</span></span><br><span class="line"><span class="string">                             test_dir=path/to/test_dir,</span></span><br><span class="line"><span class="string">                             transform=some_transform,</span></span><br><span class="line"><span class="string">                             batch_size=32,</span></span><br><span class="line"><span class="string">                             num_workers=4)</span></span><br><span class="line"><span class="string">  &quot;&quot;&quot;</span></span><br><span class="line">  <span class="comment"># Use ImageFolder to create dataset(s)</span></span><br><span class="line">  train_data = datasets.ImageFolder(train_dir, transform=transform)</span><br><span class="line">  test_data = datasets.ImageFolder(test_dir, transform=transform)</span><br><span class="line"></span><br><span class="line">  <span class="comment"># Get class names</span></span><br><span class="line">  class_names = train_data.classes</span><br><span class="line"></span><br><span class="line">  <span class="comment"># Turn images into data loaders</span></span><br><span class="line">  train_dataloader = DataLoader(</span><br><span class="line">      train_data,</span><br><span class="line">      batch_size=batch_size,</span><br><span class="line">      shuffle=<span class="literal">True</span>,</span><br><span class="line">      num_workers=num_workers,</span><br><span class="line">      pin_memory=<span class="literal">True</span>,</span><br><span class="line">  )</span><br><span class="line">  test_dataloader = DataLoader(</span><br><span class="line">      test_data,</span><br><span class="line">      batch_size=batch_size,</span><br><span class="line">      shuffle=<span class="literal">False</span>, <span class="comment"># don&#x27;t need to shuffle test data</span></span><br><span class="line">      num_workers=num_workers,</span><br><span class="line">      pin_memory=<span class="literal">True</span>,</span><br><span class="line">  )</span><br><span class="line"></span><br><span class="line">  <span class="keyword">return</span> train_dataloader, test_dataloader, class_names</span><br></pre></td></tr></table></figure>
<p>如果我们想要制作 <code>DataLoader</code>，我们现在可以使用其中的函数，<code>data_setup.py</code>如下所示：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Import data_setup.py</span></span><br><span class="line"><span class="keyword">from</span> going_modular <span class="keyword">import</span> data_setup</span><br><span class="line"></span><br><span class="line"><span class="comment"># Create train/test dataloader and get class names as a list</span></span><br><span class="line">train_dataloader, test_dataloader, class_names = data_setup.create_dataloaders(...)</span><br></pre></td></tr></table></figure>
<h1 id="3-Making-a-model-model-builder-py-制作模型（model-builder-py）"><a href="#3-Making-a-model-model-builder-py-制作模型（model-builder-py）" class="headerlink" title="3. Making a model (model_builder.py)制作模型（model_builder.py）"></a>3. Making a model (model_builder.py)制作模型（model_builder.py）</h1><p>在过去的几本笔记本（笔记本 03 和笔记本 04）中，我们已经构建了 TinyVGG 模型几次。</p>
<p>因此将模型放入其文件中以便我们可以反复重复使用它是很有意义的。</p>
<p>我们将<code>TinyVGG()</code>模型类放入脚本中，如下所示<code>%%writefile going_modular/model_builder.py</code>：</p>
<p><code>model_builder.py</code></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br></pre></td><td class="code"><pre><span class="line">%%writefile going_modular/model_builder.py</span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">Contains PyTorch model code to instantiate a TinyVGG model.</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn </span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">TinyVGG</span>(nn.Module):</span><br><span class="line">  <span class="string">&quot;&quot;&quot;Creates the TinyVGG architecture.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">  Replicates the TinyVGG architecture from the CNN explainer website in PyTorch.</span></span><br><span class="line"><span class="string">  See the original architecture here: https://poloclub.github.io/cnn-explainer/</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">  Args:</span></span><br><span class="line"><span class="string">    input_shape: An integer indicating number of input channels.</span></span><br><span class="line"><span class="string">    hidden_units: An integer indicating number of hidden units between layers.</span></span><br><span class="line"><span class="string">    output_shape: An integer indicating number of output units.</span></span><br><span class="line"><span class="string">  &quot;&quot;&quot;</span></span><br><span class="line">  <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, input_shape: <span class="built_in">int</span>, hidden_units: <span class="built_in">int</span>, output_shape: <span class="built_in">int</span></span>) -&gt; <span class="literal">None</span>:</span><br><span class="line">      <span class="built_in">super</span>().__init__()</span><br><span class="line">      self.conv_block_1 = nn.Sequential(</span><br><span class="line">          nn.Conv2d(in_channels=input_shape, </span><br><span class="line">                    out_channels=hidden_units, </span><br><span class="line">                    kernel_size=<span class="number">3</span>, </span><br><span class="line">                    stride=<span class="number">1</span>, </span><br><span class="line">                    padding=<span class="number">0</span>),  </span><br><span class="line">          nn.ReLU(),</span><br><span class="line">          nn.Conv2d(in_channels=hidden_units, </span><br><span class="line">                    out_channels=hidden_units,</span><br><span class="line">                    kernel_size=<span class="number">3</span>,</span><br><span class="line">                    stride=<span class="number">1</span>,</span><br><span class="line">                    padding=<span class="number">0</span>),</span><br><span class="line">          nn.ReLU(),</span><br><span class="line">          nn.MaxPool2d(kernel_size=<span class="number">2</span>,</span><br><span class="line">                        stride=<span class="number">2</span>)</span><br><span class="line">      )</span><br><span class="line">      self.conv_block_2 = nn.Sequential(</span><br><span class="line">          nn.Conv2d(hidden_units, hidden_units, kernel_size=<span class="number">3</span>, padding=<span class="number">0</span>),</span><br><span class="line">          nn.ReLU(),</span><br><span class="line">          nn.Conv2d(hidden_units, hidden_units, kernel_size=<span class="number">3</span>, padding=<span class="number">0</span>),</span><br><span class="line">          nn.ReLU(),</span><br><span class="line">          nn.MaxPool2d(<span class="number">2</span>)</span><br><span class="line">      )</span><br><span class="line">      self.classifier = nn.Sequential(</span><br><span class="line">          nn.Flatten(),</span><br><span class="line">          <span class="comment"># Where did this in_features shape come from? </span></span><br><span class="line">          <span class="comment"># It&#x27;s because each layer of our network compresses and changes the shape of our inputs data.</span></span><br><span class="line">          nn.Linear(in_features=hidden_units*<span class="number">13</span>*<span class="number">13</span>,</span><br><span class="line">                    out_features=output_shape)</span><br><span class="line">      )</span><br><span class="line"></span><br><span class="line">  <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x: torch.Tensor</span>):</span><br><span class="line">      x = self.conv_block_1(x)</span><br><span class="line">      x = self.conv_block_2(x)</span><br><span class="line">      x = self.classifier(x)</span><br><span class="line">      <span class="keyword">return</span> x</span><br><span class="line">      <span class="comment"># return self.classifier(self.conv_block_2(self.conv_block_1(x))) # &lt;- leverage the benefits of operator fusion</span></span><br></pre></td></tr></table></figure>
<p>现在，我们不用每次都从头开始编写 TinyVGG 模型，而是可以使用以下方法导入它：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="comment"># Import model_builder.py</span></span><br><span class="line"><span class="keyword">from</span> going_modular <span class="keyword">import</span> model_builder</span><br><span class="line">device = <span class="string">&quot;cuda&quot;</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&quot;cpu&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Instantiate an instance of the model from the &quot;model_builder.py&quot; script</span></span><br><span class="line">torch.manual_seed(<span class="number">42</span>)</span><br><span class="line">model = model_builder.TinyVGG(input_shape=<span class="number">3</span>,</span><br><span class="line">                              hidden_units=<span class="number">10</span>, </span><br><span class="line">                              output_shape=<span class="built_in">len</span>(class_names)).to(device)</span><br></pre></td></tr></table></figure>
<h1 id="4-Creating-train-step-and-test-step-functions-and-train-to-combine-them-创建train-step-和test-step-函数并将train-它们组合起来"><a href="#4-Creating-train-step-and-test-step-functions-and-train-to-combine-them-创建train-step-和test-step-函数并将train-它们组合起来" class="headerlink" title="4. Creating train_step() and test_step() functions and train() to combine them 创建train_step()和test_step()函数并将train()它们组合起来"></a>4. Creating train_step() and test_step() functions and train() to combine them 创建train_step()和test_step()函数并将train()它们组合起来</h1><p><a target="_blank" rel="noopener" href="https://www.learnpytorch.io/04_pytorch_custom_datasets/#75-create-train-test-loop-functions">我们在笔记本 04</a>中写了几个训练函数：</p>
<ul>
<li><code>train_step()</code> - 接受一个模型、一个 <code>DataLoader</code>、一个损失函数和一个优化器，并在 <code>DataLoader</code> 上训练模型。</li>
<li><code>test_step()</code> - 接受一个模型、一个 <code>DataLoader</code> 和一个损失函数，并在 <code>DataLoader</code> 上评估模型。</li>
<li><code>train()</code> - 在给定的周期数内同时执行 1. 和 2.，并返回结果字典。</li>
</ul>
<p>由于这些将成为我们模型训练的引擎，我们可以将它们全部放入一个 Python 脚本中，<code>engine.py</code>并使用以下行进行调用<code>%%writefile going_modular/engine.py</code>：</p>
<p><code>engine.py</code><br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br></pre></td><td class="code"><pre><span class="line">%%writefile going_modular/engine.py</span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">Contains functions for training and testing a PyTorch model.</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> tqdm.auto <span class="keyword">import</span> tqdm</span><br><span class="line"><span class="keyword">from</span> typing <span class="keyword">import</span> <span class="type">Dict</span>, <span class="type">List</span>, <span class="type">Tuple</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">train_step</span>(<span class="params">model: torch.nn.Module, </span></span><br><span class="line"><span class="params">               dataloader: torch.utils.data.DataLoader, </span></span><br><span class="line"><span class="params">               loss_fn: torch.nn.Module, </span></span><br><span class="line"><span class="params">               optimizer: torch.optim.Optimizer,</span></span><br><span class="line"><span class="params">               device: torch.device</span>) -&gt; <span class="type">Tuple</span>[<span class="built_in">float</span>, <span class="built_in">float</span>]:</span><br><span class="line">  <span class="string">&quot;&quot;&quot;Trains a PyTorch model for a single epoch.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">  Turns a target PyTorch model to training mode and then</span></span><br><span class="line"><span class="string">  runs through all of the required training steps (forward</span></span><br><span class="line"><span class="string">  pass, loss calculation, optimizer step).</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">  Args:</span></span><br><span class="line"><span class="string">    model: A PyTorch model to be trained.</span></span><br><span class="line"><span class="string">    dataloader: A DataLoader instance for the model to be trained on.</span></span><br><span class="line"><span class="string">    loss_fn: A PyTorch loss function to minimize.</span></span><br><span class="line"><span class="string">    optimizer: A PyTorch optimizer to help minimize the loss function.</span></span><br><span class="line"><span class="string">    device: A target device to compute on (e.g. &quot;cuda&quot; or &quot;cpu&quot;).</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">  Returns:</span></span><br><span class="line"><span class="string">    A tuple of training loss and training accuracy metrics.</span></span><br><span class="line"><span class="string">    In the form (train_loss, train_accuracy). For example:</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    (0.1112, 0.8743)</span></span><br><span class="line"><span class="string">  &quot;&quot;&quot;</span></span><br><span class="line">  <span class="comment"># Put model in train mode</span></span><br><span class="line">  model.train()</span><br><span class="line"></span><br><span class="line">  <span class="comment"># Setup train loss and train accuracy values</span></span><br><span class="line">  train_loss, train_acc = <span class="number">0</span>, <span class="number">0</span></span><br><span class="line"></span><br><span class="line">  <span class="comment"># Loop through data loader data batches</span></span><br><span class="line">  <span class="keyword">for</span> batch, (X, y) <span class="keyword">in</span> <span class="built_in">enumerate</span>(dataloader):</span><br><span class="line">      <span class="comment"># Send data to target device</span></span><br><span class="line">      X, y = X.to(device), y.to(device)</span><br><span class="line"></span><br><span class="line">      <span class="comment"># 1. Forward pass</span></span><br><span class="line">      y_pred = model(X)</span><br><span class="line"></span><br><span class="line">      <span class="comment"># 2. Calculate  and accumulate loss</span></span><br><span class="line">      loss = loss_fn(y_pred, y)</span><br><span class="line">      train_loss += loss.item() </span><br><span class="line"></span><br><span class="line">      <span class="comment"># 3. Optimizer zero grad</span></span><br><span class="line">      optimizer.zero_grad()</span><br><span class="line"></span><br><span class="line">      <span class="comment"># 4. Loss backward</span></span><br><span class="line">      loss.backward()</span><br><span class="line"></span><br><span class="line">      <span class="comment"># 5. Optimizer step</span></span><br><span class="line">      optimizer.step()</span><br><span class="line"></span><br><span class="line">      <span class="comment"># Calculate and accumulate accuracy metric across all batches</span></span><br><span class="line">      y_pred_class = torch.argmax(torch.softmax(y_pred, dim=<span class="number">1</span>), dim=<span class="number">1</span>)</span><br><span class="line">      train_acc += (y_pred_class == y).<span class="built_in">sum</span>().item()/<span class="built_in">len</span>(y_pred)</span><br><span class="line"></span><br><span class="line">  <span class="comment"># Adjust metrics to get average loss and accuracy per batch </span></span><br><span class="line">  train_loss = train_loss / <span class="built_in">len</span>(dataloader)</span><br><span class="line">  train_acc = train_acc / <span class="built_in">len</span>(dataloader)</span><br><span class="line">  <span class="keyword">return</span> train_loss, train_acc</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">test_step</span>(<span class="params">model: torch.nn.Module, </span></span><br><span class="line"><span class="params">              dataloader: torch.utils.data.DataLoader, </span></span><br><span class="line"><span class="params">              loss_fn: torch.nn.Module,</span></span><br><span class="line"><span class="params">              device: torch.device</span>) -&gt; <span class="type">Tuple</span>[<span class="built_in">float</span>, <span class="built_in">float</span>]:</span><br><span class="line">  <span class="string">&quot;&quot;&quot;Tests a PyTorch model for a single epoch.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">  Turns a target PyTorch model to &quot;eval&quot; mode and then performs</span></span><br><span class="line"><span class="string">  a forward pass on a testing dataset.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">  Args:</span></span><br><span class="line"><span class="string">    model: A PyTorch model to be tested.</span></span><br><span class="line"><span class="string">    dataloader: A DataLoader instance for the model to be tested on.</span></span><br><span class="line"><span class="string">    loss_fn: A PyTorch loss function to calculate loss on the test data.</span></span><br><span class="line"><span class="string">    device: A target device to compute on (e.g. &quot;cuda&quot; or &quot;cpu&quot;).</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">  Returns:</span></span><br><span class="line"><span class="string">    A tuple of testing loss and testing accuracy metrics.</span></span><br><span class="line"><span class="string">    In the form (test_loss, test_accuracy). For example:</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    (0.0223, 0.8985)</span></span><br><span class="line"><span class="string">  &quot;&quot;&quot;</span></span><br><span class="line">  <span class="comment"># Put model in eval mode</span></span><br><span class="line">  model.<span class="built_in">eval</span>() </span><br><span class="line"></span><br><span class="line">  <span class="comment"># Setup test loss and test accuracy values</span></span><br><span class="line">  test_loss, test_acc = <span class="number">0</span>, <span class="number">0</span></span><br><span class="line"></span><br><span class="line">  <span class="comment"># Turn on inference context manager</span></span><br><span class="line">  <span class="keyword">with</span> torch.inference_mode():</span><br><span class="line">      <span class="comment"># Loop through DataLoader batches</span></span><br><span class="line">      <span class="keyword">for</span> batch, (X, y) <span class="keyword">in</span> <span class="built_in">enumerate</span>(dataloader):</span><br><span class="line">          <span class="comment"># Send data to target device</span></span><br><span class="line">          X, y = X.to(device), y.to(device)</span><br><span class="line"></span><br><span class="line">          <span class="comment"># 1. Forward pass</span></span><br><span class="line">          test_pred_logits = model(X)</span><br><span class="line"></span><br><span class="line">          <span class="comment"># 2. Calculate and accumulate loss</span></span><br><span class="line">          loss = loss_fn(test_pred_logits, y)</span><br><span class="line">          test_loss += loss.item()</span><br><span class="line"></span><br><span class="line">          <span class="comment"># Calculate and accumulate accuracy</span></span><br><span class="line">          test_pred_labels = test_pred_logits.argmax(dim=<span class="number">1</span>)</span><br><span class="line">          test_acc += ((test_pred_labels == y).<span class="built_in">sum</span>().item()/<span class="built_in">len</span>(test_pred_labels))</span><br><span class="line"></span><br><span class="line">  <span class="comment"># Adjust metrics to get average loss and accuracy per batch </span></span><br><span class="line">  test_loss = test_loss / <span class="built_in">len</span>(dataloader)</span><br><span class="line">  test_acc = test_acc / <span class="built_in">len</span>(dataloader)</span><br><span class="line">  <span class="keyword">return</span> test_loss, test_acc</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">train</span>(<span class="params">model: torch.nn.Module, </span></span><br><span class="line"><span class="params">          train_dataloader: torch.utils.data.DataLoader, </span></span><br><span class="line"><span class="params">          test_dataloader: torch.utils.data.DataLoader, </span></span><br><span class="line"><span class="params">          optimizer: torch.optim.Optimizer,</span></span><br><span class="line"><span class="params">          loss_fn: torch.nn.Module,</span></span><br><span class="line"><span class="params">          epochs: <span class="built_in">int</span>,</span></span><br><span class="line"><span class="params">          device: torch.device</span>) -&gt; <span class="type">Dict</span>[<span class="built_in">str</span>, <span class="type">List</span>]:</span><br><span class="line">  <span class="string">&quot;&quot;&quot;Trains and tests a PyTorch model.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">  Passes a target PyTorch models through train_step() and test_step()</span></span><br><span class="line"><span class="string">  functions for a number of epochs, training and testing the model</span></span><br><span class="line"><span class="string">  in the same epoch loop.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">  Calculates, prints and stores evaluation metrics throughout.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">  Args:</span></span><br><span class="line"><span class="string">    model: A PyTorch model to be trained and tested.</span></span><br><span class="line"><span class="string">    train_dataloader: A DataLoader instance for the model to be trained on.</span></span><br><span class="line"><span class="string">    test_dataloader: A DataLoader instance for the model to be tested on.</span></span><br><span class="line"><span class="string">    optimizer: A PyTorch optimizer to help minimize the loss function.</span></span><br><span class="line"><span class="string">    loss_fn: A PyTorch loss function to calculate loss on both datasets.</span></span><br><span class="line"><span class="string">    epochs: An integer indicating how many epochs to train for.</span></span><br><span class="line"><span class="string">    device: A target device to compute on (e.g. &quot;cuda&quot; or &quot;cpu&quot;).</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">  Returns:</span></span><br><span class="line"><span class="string">    A dictionary of training and testing loss as well as training and</span></span><br><span class="line"><span class="string">    testing accuracy metrics. Each metric has a value in a list for </span></span><br><span class="line"><span class="string">    each epoch.</span></span><br><span class="line"><span class="string">    In the form: &#123;train_loss: [...],</span></span><br><span class="line"><span class="string">                  train_acc: [...],</span></span><br><span class="line"><span class="string">                  test_loss: [...],</span></span><br><span class="line"><span class="string">                  test_acc: [...]&#125; </span></span><br><span class="line"><span class="string">    For example if training for epochs=2: </span></span><br><span class="line"><span class="string">                 &#123;train_loss: [2.0616, 1.0537],</span></span><br><span class="line"><span class="string">                  train_acc: [0.3945, 0.3945],</span></span><br><span class="line"><span class="string">                  test_loss: [1.2641, 1.5706],</span></span><br><span class="line"><span class="string">                  test_acc: [0.3400, 0.2973]&#125; </span></span><br><span class="line"><span class="string">  &quot;&quot;&quot;</span></span><br><span class="line">  <span class="comment"># Create empty results dictionary</span></span><br><span class="line">  results = &#123;<span class="string">&quot;train_loss&quot;</span>: [],</span><br><span class="line">      <span class="string">&quot;train_acc&quot;</span>: [],</span><br><span class="line">      <span class="string">&quot;test_loss&quot;</span>: [],</span><br><span class="line">      <span class="string">&quot;test_acc&quot;</span>: []</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment"># Loop through training and testing steps for a number of epochs</span></span><br><span class="line">  <span class="keyword">for</span> epoch <span class="keyword">in</span> tqdm(<span class="built_in">range</span>(epochs)):</span><br><span class="line">      train_loss, train_acc = train_step(model=model,</span><br><span class="line">                                          dataloader=train_dataloader,</span><br><span class="line">                                          loss_fn=loss_fn,</span><br><span class="line">                                          optimizer=optimizer,</span><br><span class="line">                                          device=device)</span><br><span class="line">      test_loss, test_acc = test_step(model=model,</span><br><span class="line">          dataloader=test_dataloader,</span><br><span class="line">          loss_fn=loss_fn,</span><br><span class="line">          device=device)</span><br><span class="line"></span><br><span class="line">      <span class="comment"># Print out what&#x27;s happening</span></span><br><span class="line">      <span class="built_in">print</span>(</span><br><span class="line">          <span class="string">f&quot;Epoch: <span class="subst">&#123;epoch+<span class="number">1</span>&#125;</span> | &quot;</span></span><br><span class="line">          <span class="string">f&quot;train_loss: <span class="subst">&#123;train_loss:<span class="number">.4</span>f&#125;</span> | &quot;</span></span><br><span class="line">          <span class="string">f&quot;train_acc: <span class="subst">&#123;train_acc:<span class="number">.4</span>f&#125;</span> | &quot;</span></span><br><span class="line">          <span class="string">f&quot;test_loss: <span class="subst">&#123;test_loss:<span class="number">.4</span>f&#125;</span> | &quot;</span></span><br><span class="line">          <span class="string">f&quot;test_acc: <span class="subst">&#123;test_acc:<span class="number">.4</span>f&#125;</span>&quot;</span></span><br><span class="line">      )</span><br><span class="line"></span><br><span class="line">      <span class="comment"># Update results dictionary</span></span><br><span class="line">      results[<span class="string">&quot;train_loss&quot;</span>].append(train_loss)</span><br><span class="line">      results[<span class="string">&quot;train_acc&quot;</span>].append(train_acc)</span><br><span class="line">      results[<span class="string">&quot;test_loss&quot;</span>].append(test_loss)</span><br><span class="line">      results[<span class="string">&quot;test_acc&quot;</span>].append(test_acc)</span><br><span class="line"></span><br><span class="line">  <span class="comment"># Return the filled results at the end of the epochs</span></span><br><span class="line">  <span class="keyword">return</span> results</span><br></pre></td></tr></table></figure></p>
<p>可以通过以下方式从中导入函数：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Import engine.py</span></span><br><span class="line"><span class="keyword">from</span> going_modular <span class="keyword">import</span> engine</span><br><span class="line"></span><br><span class="line"><span class="comment"># Use train() by calling it from engine.py</span></span><br><span class="line">engine.train(...)</span><br></pre></td></tr></table></figure>
<h1 id="5-Creating-a-function-to-save-the-model-utils-py-创建一个函数来保存模型（utils-py）"><a href="#5-Creating-a-function-to-save-the-model-utils-py-创建一个函数来保存模型（utils-py）" class="headerlink" title="5. Creating a function to save the model (utils.py) 创建一个函数来保存模型（utils.py）"></a>5. Creating a function to save the model (utils.py) 创建一个函数来保存模型（utils.py）</h1><p>通常您会希望在训练期间或训练后保存模型。</p>
<p>由于我们已经在之前的笔记本中编写了几次保存模型的代码，因此将其转换为函数并将其保存到文件中是有意义的。</p>
<p>将辅助函数存储在名为 (utilities 的缩写) 的文件中是一种常见的做法<code>utils.py</code>。</p>
<p>我们将函数保存到名为以下行的<code>save_model()</code>文件中：<code>utils.py%%writefile going_modular/utils.py</code></p>
<p><code>utils.py</code><br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line">%%writefile going_modular/utils.py</span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">Contains various utility functions for PyTorch model training and saving.</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> pathlib <span class="keyword">import</span> Path</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">save_model</span>(<span class="params">model: torch.nn.Module,</span></span><br><span class="line"><span class="params">               target_dir: <span class="built_in">str</span>,</span></span><br><span class="line"><span class="params">               model_name: <span class="built_in">str</span></span>):</span><br><span class="line">  <span class="string">&quot;&quot;&quot;Saves a PyTorch model to a target directory.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">  Args:</span></span><br><span class="line"><span class="string">    model: A target PyTorch model to save.</span></span><br><span class="line"><span class="string">    target_dir: A directory for saving the model to.</span></span><br><span class="line"><span class="string">    model_name: A filename for the saved model. Should include</span></span><br><span class="line"><span class="string">      either &quot;.pth&quot; or &quot;.pt&quot; as the file extension.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">  Example usage:</span></span><br><span class="line"><span class="string">    save_model(model=model_0,</span></span><br><span class="line"><span class="string">               target_dir=&quot;models&quot;,</span></span><br><span class="line"><span class="string">               model_name=&quot;05_going_modular_tingvgg_model.pth&quot;)</span></span><br><span class="line"><span class="string">  &quot;&quot;&quot;</span></span><br><span class="line">  <span class="comment"># Create target directory</span></span><br><span class="line">  target_dir_path = Path(target_dir)</span><br><span class="line">  target_dir_path.mkdir(parents=<span class="literal">True</span>,</span><br><span class="line">                        exist_ok=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">  <span class="comment"># Create model save path</span></span><br><span class="line">  <span class="keyword">assert</span> model_name.endswith(<span class="string">&quot;.pth&quot;</span>) <span class="keyword">or</span> model_name.endswith(<span class="string">&quot;.pt&quot;</span>), <span class="string">&quot;model_name should end with &#x27;.pt&#x27; or &#x27;.pth&#x27;&quot;</span></span><br><span class="line">  model_save_path = target_dir_path / model_name</span><br><span class="line"></span><br><span class="line">  <span class="comment"># Save the model state_dict()</span></span><br><span class="line">  <span class="built_in">print</span>(<span class="string">f&quot;[INFO] Saving model to: <span class="subst">&#123;model_save_path&#125;</span>&quot;</span>)</span><br><span class="line">  torch.save(obj=model.state_dict(),</span><br><span class="line">             f=model_save_path)</span><br></pre></td></tr></table></figure></p>
<p>现在，如果我们想使用我们的<code>save_model()</code>函数，而不必重新编写它，我们可以导入它并通过以下方式使用它：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Import utils.py</span></span><br><span class="line"><span class="keyword">from</span> going_modular <span class="keyword">import</span> utils</span><br><span class="line"></span><br><span class="line"><span class="comment"># Save a model to file</span></span><br><span class="line">save_model(model=...</span><br><span class="line">           target_dir=...,</span><br><span class="line">           model_name=...)</span><br></pre></td></tr></table></figure>
<h1 id="6-Train-evaluate-and-save-the-model-train-py-训练、评估并保存模型（train-py）"><a href="#6-Train-evaluate-and-save-the-model-train-py-训练、评估并保存模型（train-py）" class="headerlink" title="6. Train, evaluate and save the model (train.py)训练、评估并保存模型（train.py）"></a>6. Train, evaluate and save the model (train.py)训练、评估并保存模型（train.py）</h1><p>如前所述，您经常会遇到将所有功能组合在一个<code>train.py</code>文件中的 <code>PyTorch</code> 存储库。</p>
<p>该文件本质上是在说“使用任何可用的数据来训练模型”。</p>
<p>在我们的 <code>train.py</code> 文件中，我们将结合我们创建的其他 Python 脚本的所有功能并使用它来训练模型。</p>
<p>这样，我们就可以使用命令行中的一行代码来训练 PyTorch 模型：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python train.py</span><br></pre></td></tr></table></figure>
<p>要创建 <code>train.py</code>，我们将执行以下步骤：</p>
<ul>
<li>导入各种依赖项，即 <code>torch</code>、<code>os</code>、<code>torchvision.transforms</code> 和来自 <code>going_modular</code> 目录、<code>data_setup</code>、<code>engine</code>、<code>model_builder</code>、<code>utils</code> 的所有脚本。</li>
<li>注意：由于 <code>train.py</code> 将位于 <code>going_modular</code> 目录中，我们可以通过 <code>import ...</code> 而不是 <code>from going_modular import ....</code> 来导入其他模块。</li>
<li>设置各种超参数，例如批处理大小、时期数、学习率和隐藏单元数（这些可以在将来通过 Python 的 <code>argparse</code> 设置）。</li>
<li>设置训练和测试目录。</li>
<li>设置与设备无关的代码。</li>
<li>创建必要的数据转换。</li>
<li>使用 <code>data_setup.py</code> 创建 <code>DataLoaders</code>。</li>
<li>使用 <code>model_builder.py</code> 创建模型。</li>
<li>设置损失函数和优化器。</li>
<li>使用 <code>engine.py</code> 训练模型。</li>
<li>使用 <code>utils.py</code> 保存模型。</li>
</ul>
<p>我们可以使用以下行从笔记本单元创建文件<code>%%writefile going_modular/train.py</code>：</p>
<p><code>train.py</code><br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br></pre></td><td class="code"><pre><span class="line">%%writefile going_modular/train.py</span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">Trains a PyTorch image classification model using device-agnostic code.</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> data_setup, engine, model_builder, utils</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> transforms</span><br><span class="line"></span><br><span class="line"><span class="comment"># Setup hyperparameters</span></span><br><span class="line">NUM_EPOCHS = <span class="number">5</span></span><br><span class="line">BATCH_SIZE = <span class="number">32</span></span><br><span class="line">HIDDEN_UNITS = <span class="number">10</span></span><br><span class="line">LEARNING_RATE = <span class="number">0.001</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Setup directories</span></span><br><span class="line">train_dir = <span class="string">&quot;data/pizza_steak_sushi/train&quot;</span></span><br><span class="line">test_dir = <span class="string">&quot;data/pizza_steak_sushi/test&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Setup target device</span></span><br><span class="line">device = <span class="string">&quot;cuda&quot;</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&quot;cpu&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Create transforms</span></span><br><span class="line">data_transform = transforms.Compose([</span><br><span class="line">  transforms.Resize((<span class="number">64</span>, <span class="number">64</span>)),</span><br><span class="line">  transforms.ToTensor()</span><br><span class="line">])</span><br><span class="line"></span><br><span class="line"><span class="comment"># Create DataLoaders with help from data_setup.py</span></span><br><span class="line">train_dataloader, test_dataloader, class_names = data_setup.create_dataloaders(</span><br><span class="line">    train_dir=train_dir,</span><br><span class="line">    test_dir=test_dir,</span><br><span class="line">    transform=data_transform,</span><br><span class="line">    batch_size=BATCH_SIZE</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Create model with help from model_builder.py</span></span><br><span class="line">model = model_builder.TinyVGG(</span><br><span class="line">    input_shape=<span class="number">3</span>,</span><br><span class="line">    hidden_units=HIDDEN_UNITS,</span><br><span class="line">    output_shape=<span class="built_in">len</span>(class_names)</span><br><span class="line">).to(device)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Set loss and optimizer</span></span><br><span class="line">loss_fn = torch.nn.CrossEntropyLoss()</span><br><span class="line">optimizer = torch.optim.Adam(model.parameters(),</span><br><span class="line">                             lr=LEARNING_RATE)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Start training with help from engine.py</span></span><br><span class="line">engine.train(model=model,</span><br><span class="line">             train_dataloader=train_dataloader,</span><br><span class="line">             test_dataloader=test_dataloader,</span><br><span class="line">             loss_fn=loss_fn,</span><br><span class="line">             optimizer=optimizer,</span><br><span class="line">             epochs=NUM_EPOCHS,</span><br><span class="line">             device=device)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Save the model with help from utils.py</span></span><br><span class="line">utils.save_model(model=model,</span><br><span class="line">                 target_dir=<span class="string">&quot;models&quot;</span>,</span><br><span class="line">                 model_name=<span class="string">&quot;05_going_modular_script_mode_tinyvgg_model.pth&quot;</span>)</span><br></pre></td></tr></table></figure></p>
<p>现在我们可以通过在命令行上运行以下行来训练 PyTorch 模型：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python train.py</span><br></pre></td></tr></table></figure>
<p>这样做将利用我们创建的所有其他代码脚本。</p>
<p>如果我们愿意，我们可以调整我们的train.py文件以使用 Pythonargparse模块的参数标志输入，这将允许我们提供不同的超参数设置，如前所述：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python train.py --model MODEL_NAME --batch_size BATCH_SIZE --lr LEARNING_RATE --num_epochs NUM_EPOCHS</span><br></pre></td></tr></table></figure>
<h1 id="Exercises"><a href="#Exercises" class="headerlink" title="Exercises"></a>Exercises</h1><p><strong>资源：</strong></p>
<ul>
<li><a target="_blank" rel="noopener" href="https://github.com/mrdbourke/pytorch-deep-learning/blob/main/extras/exercises/05_pytorch_going_modular_exercise_template.ipynb">05 年练习模板笔记本</a></li>
<li>05 示例解决方案笔记本<ul>
<li><a target="_blank" rel="noopener" href="https://youtu.be/ijgFhMK3pp4">YouTube 上 05 解决方案笔记本</a>的实时编码演示</li>
</ul>
</li>
</ul>
<p><strong>练习：</strong></p>
<ol>
<li><p>将获取数据的代码（来自上面的 1.获取数据部分）转换为 Python 脚本，例如<code>get_data.py</code></p>
<ul>
<li>当您运行脚本时，<code>python get_data.py</code>它应该检查数据是否已经存在，如果存在则跳过下载。</li>
<li>如果数据下载成功，您应该能够<code>pizza_steak_sushi</code>从<code>data</code>目录访问图像。</li>
</ul>
</li>
<li><p>使用<br>Python 的<code>argparse</code>模块能够发送<code>train.py</code>训练程序的自定义超参数值。</p>
<ul>
<li>添加使用不同方法的参数：<ul>
<li>训练/测试目录</li>
<li>学习率</li>
<li>批次大小</li>
<li>训练的周期数</li>
<li>TinyVGG 模型中的隐藏单元数量</li>
</ul>
</li>
<li>保持上述每个参数的默认值不变（如笔记本 05 中所示）。</li>
<li>例如，您应该能够运行类似于以下代码行的程序来训练一个学习率为 0.003、批量大小为 64 的 TinyVGG 模型，为期 20 个时期：<code>python train.py --learning_rate 0.003 --batch_size 64 --num_epochs 20</code>。</li>
<li><strong>注意：</strong>由于<code>train.py</code>利用了我们在 05 节中创建的其他脚本，例如、<code>model_builder.py</code>和<code>utils.py</code>，<code>engine.py</code>因此您必须确保它们也可供使用。您可以在<a target="_blank" rel="noopener" href="https://github.com/mrdbourke/pytorch-deep-learning/tree/main/going_modular/going_modular"><code>going_modular</code>课程 GitHub 上的文件夹</a>中找到这些脚本。</li>
</ul>
</li>
<li><p><code>predict.py</code>创建一个脚本来对给定已保存模型的文件路径的目标图像进行预测（例如）。</p>
<ul>
<li>例如，您应该能够运行命令<code>python predict.py some_image.jpeg</code>并让训练有素的 PyTorch 模型对图像进行预测并返回其预测。</li>
<li>要查看示例预测代码，请查看<a target="_blank" rel="noopener" href="https://www.learnpytorch.io/04_pytorch_custom_datasets/#113-putting-custom-image-prediction-together-building-a-function">笔记本 04 中的自定义图像预测部分</a>。</li>
<li>您可能还需要编写代码来加载经过训练的模型。</li>
</ul>
</li>
</ol>
<h1 id="Extra-curriculum"><a href="#Extra-curriculum" class="headerlink" title="Extra-curriculum"></a>Extra-curriculum</h1><ul>
<li>要了解有关构建 Python 项目的更多信息，请查看 Real Python 的<a target="_blank" rel="noopener" href="https://realpython.com/python-application-layouts/">Python 应用程序布局</a>指南。</li>
<li>有关 PyTorch 代码样式的想法，请查看<a target="_blank" rel="noopener" href="https://github.com/IgorSusmelj/pytorch-styleguide#recommended-code-structure-for-training-your-model">Igor Susmelj 的 PyTorch 样式指南</a>（本章中的大部分样式均基于本指南 + 各种类似的 PyTorch 存储库）。</li>
<li><code>train.py</code>有关PyTorch 团队编写的用于训练最先进的图像分类模型的示例脚本和各种其他 PyTorch 脚本，请查看<a target="_blank" rel="noopener" href="https://github.com/pytorch/vision/tree/main/references/classification"><code>classification</code>GitHub 上的存储库</a>。</li>
</ul>
</div></article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="mailto:undefined">HibisciDai</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="http://hibiscidai.com/2024/08/19/PyTorch-26H-6/">http://hibiscidai.com/2024/08/19/PyTorch-26H-6/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a target="_blank" rel="noopener" href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="http://hibiscidai.com">HibisciDai</a>！</span></div></div><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/">学习笔记</a><a class="post-meta__tags" href="/tags/PyTorch/">PyTorch</a></div><div class="social-share pull-right" data-disabled="linkedin,diandian"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/social-share.js@1.0.16/dist/css/share.min.css"><script src="https://cdn.jsdelivr.net/npm/social-share.js@1.0.16/dist/js/social-share.min.js"></script><nav id="pagination"><div class="prev-post pull-left"><a href="/2024/08/20/PyTorch-26H-7/"><i class="fa fa-chevron-left">  </i><span>PyTorch-26H-7</span></a></div><div class="next-post pull-right"><a href="/2024/08/18/PyTorch-26H-5/"><span>PyTorch-26H-5</span><i class="fa fa-chevron-right"></i></a></div></nav><div class="post-adv"><a target="_blank" rel="noopener" href="https://www.paofu.cloud/auth/register?code=j4I7">好用、实惠、稳定的梯子,点击这里<img src="https://pic.imgdb.cn/item/65572abac458853aefef30cd.png" width="1000" height="124" object-fit="cover" ></a></div><div id="lv-container" data-id="city" data-uid="MTAyMC8zNTQ2NC8xMjAwMA=="><script>(function(d, s) {
    var j, e = d.getElementsByTagName(s)[0];
    if (typeof LivereTower === 'function') { return; }
    j = d.createElement(s);
    j.src = 'https://cdn-city.livere.com/js/embed.dist.js';
    j.async = true;
    e.parentNode.insertBefore(j, e);
})(document, 'script');</script></div></div></div><footer class="footer-bg" style="background-image: url(/img/banner2.jpg)"><div class="layout" id="footer"><div class="copyright">&copy;2017 - 2025 By HibisciDai</div><div class="framework-info"><span>驱动 - </span><a target="_blank" rel="noopener" href="http://hexo.io"><span>Hexo</span></a><span class="footer-separator">|</span><span>主题 - </span><a target="_blank" rel="noopener" href="https://github.com/Molunerfinn/hexo-theme-melody"><span>Melody</span></a></div><div class="footer_custom_text">hitokoto</div><div class="busuanzi"><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><span id="busuanzi_container_page_pv"><i class="fa fa-file"></i><span id="busuanzi_value_page_pv"></span><span></span></span></div></div></footer><i class="fa fa-arrow-up" id="go-up" aria-hidden="true"></i><script src="/js/third-party/anime.min.js"></script><script src="/js/third-party/jquery.min.js"></script><script src="/js/third-party/jquery.fancybox.min.js"></script><script src="/js/third-party/velocity.min.js"></script><script src="/js/third-party/velocity.ui.min.js"></script><script src="/js/utils.js?version=1.9.0"></script><script src="/js/fancybox.js?version=1.9.0"></script><script src="/js/sidebar.js?version=1.9.0"></script><script src="/js/copy.js?version=1.9.0"></script><script src="/js/fireworks.js?version=1.9.0"></script><script src="/js/transition.js?version=1.9.0"></script><script src="/js/scroll.js?version=1.9.0"></script><script src="/js/head.js?version=1.9.0"></script><script type="text/x-mathjax-config">MathJax.Hub.Config({
  tex2jax: {
    inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
    processEscapes: true,
    skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
  },
  CommonHTML: {
    linebreaks: { automatic: true, width: "90% container" }
  },
  "HTML-CSS": { 
    linebreaks: { automatic: true, width: "90% container" }
  },
  "SVG": { 
    linebreaks: { automatic: true, width: "90% container" }
  }
});
</script><script type="text/x-mathjax-config">MathJax.Hub.Queue(function() {
  var all = MathJax.Hub.getAllJax(), i;
  for (i=0; i < all.length; i += 1) {
    all[i].SourceElement().parentNode.className += ' has-jax';
  }
});
</script><script src="https://cdn.bootcss.com/mathjax/2.7.2/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/katex@latest/dist/katex.min.css"><script src="https://cdn.jsdelivr.net/npm/katex-copytex@latest/dist/katex-copytex.min.js"></script><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/katex-copytex@latest/dist/katex-copytex.min.css"><script src="/js/katex.js"></script><script src="/js/search/local-search.js"></script><script id="ribbon" src="/js/third-party/canvas-ribbon.js" size="150" alpha="0.6" zIndex="-1" data-click="false"></script><script>if(/Android|webOS|iPhone|iPod|iPad|BlackBerry/i.test(navigator.userAgent)) {
  $('#nav').addClass('is-mobile')
  $('footer').addClass('is-mobile')
  $('#top-container').addClass('is-mobile')
}</script><div class="search-dialog" id="local-search"><div class="search-dialog__title" id="local-search-title">本地搜索</div><div id="local-input-panel"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章"></div></div></div><hr><div id="local-search-results"><div id="local-hits"></div><div id="local-stats"><div class="local-search-stats__hr" id="hr"><span>由</span> <a target="_blank" rel="noopener" href="https://github.com/wzpan/hexo-generator-search" style="color:#49B1F5;">hexo-generator-search</a>
 <span>提供支持</span></div></div></div><span class="search-close-button"><i class="fa fa-times"></i></span></div><div class="search-mask"></div></body></html>