<!DOCTYPE html><html lang="zh-Hans"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta name="description" content="Hadoop-MapReduce详解-2"><meta name="keywords" content="学习笔记,Hadoop,大数据"><meta name="author" content="HibisciDai"><meta name="copyright" content="HibisciDai"><title>Hadoop-MapReduce详解-2 | HibisciDai</title><link rel="shortcut icon" href="/img/avatar.png"><link rel="stylesheet" href="/css/index.css?version=1.9.0"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/font-awesome@latest/css/font-awesome.min.css?version=1.9.0"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.7.2/css/all.css?version=1.9.0"><meta name="format-detection" content="telephone=no"><meta http-equiv="x-dns-prefetch-control" content="on"><link rel="dns-prefetch" href="https://cdn.jsdelivr.net"><link rel="manifest" href="/manifest.json"><link rel="manifest" href="/manifest.json"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><script src="https://v1.hitokoto.cn/?encode=js&amp;charset=utf-8&amp;select=.footer_custom_text" defer></script><script>var GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: {"path":"search.xml","languages":{"hits_empty":"找不到您查询的内容:${query}"}},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  hexoVersion: '6.1.0'
} </script><meta name="generator" content="Hexo 6.1.0"><link rel="alternate" href="/atom.xml" title="HibisciDai" type="application/atom+xml">
</head><body><canvas class="fireworks"></canvas><i class="fa fa-arrow-right" id="toggle-sidebar" aria-hidden="true"></i><div id="sidebar" data-display="true"><div class="toggle-sidebar-info text-center"><span data-toggle="切换文章详情">切换站点概览</span><hr></div><div class="sidebar-toc"><div class="sidebar-toc__title">目录</div><div class="sidebar-toc__progress"><span class="progress-notice">你已经读了</span><span class="progress-num">0</span><span class="progress-percentage">%</span><div class="sidebar-toc__progress-bar"></div></div><div class="sidebar-toc__content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#Hadoop-MapReduce%E8%AF%A6%E8%A7%A3-2"><span class="toc-number">1.</span> <span class="toc-text">Hadoop-MapReduce详解-2</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E7%AC%AC3%E7%AB%A0-MapReduce%E6%A1%86%E6%9E%B6%E5%8E%9F%E7%90%86"><span class="toc-number">2.</span> <span class="toc-text">第3章 MapReduce框架原理</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#InputFormat%E6%95%B0%E6%8D%AE%E8%BE%93%E5%85%A5"><span class="toc-number">2.1.</span> <span class="toc-text">InputFormat数据输入</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%88%87%E7%89%87%E4%B8%8EMapTask%E5%B9%B6%E8%A1%8C%E5%BA%A6%E5%86%B3%E5%AE%9A%E6%9C%BA%E5%88%B6"><span class="toc-number">2.1.1.</span> <span class="toc-text">切片与MapTask并行度决定机制</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Job%E6%8F%90%E4%BA%A4%E6%B5%81%E7%A8%8B%E6%BA%90%E7%A0%81%E5%92%8C%E5%88%87%E7%89%87%E6%BA%90%E7%A0%81%E8%AF%A6%E8%A7%A3"><span class="toc-number">2.1.2.</span> <span class="toc-text">Job提交流程源码和切片源码详解</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#FileInputFormat%E5%88%87%E7%89%87%E6%9C%BA%E5%88%B6"><span class="toc-number">2.1.3.</span> <span class="toc-text">FileInputFormat切片机制</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%88%87%E7%89%87%E6%9C%BA%E5%88%B6"><span class="toc-number">2.1.3.1.</span> <span class="toc-text">切片机制</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%A1%88%E4%BE%8B%E5%88%86%E6%9E%90"><span class="toc-number">2.1.3.2.</span> <span class="toc-text">案例分析</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#CombineTextInputFormat%E5%88%87%E7%89%87%E6%9C%BA%E5%88%B6"><span class="toc-number">2.1.4.</span> <span class="toc-text">CombineTextInputFormat切片机制</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#CombineTextInputFormat%E6%A1%88%E4%BE%8B%E5%AE%9E%E6%93%8D"><span class="toc-number">2.1.5.</span> <span class="toc-text">CombineTextInputFormat案例实操</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E9%9C%80%E6%B1%82"><span class="toc-number">2.1.5.1.</span> <span class="toc-text">需求</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%AE%9E%E7%8E%B0%E8%BF%87%E7%A8%8B"><span class="toc-number">2.1.5.2.</span> <span class="toc-text">实现过程</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#FileInputFormat%E5%AE%9E%E7%8E%B0%E7%B1%BB"><span class="toc-number">2.1.6.</span> <span class="toc-text">FileInputFormat实现类</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#TextInputFormat"><span class="toc-number">2.1.6.1.</span> <span class="toc-text">TextInputFormat</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#KeyValueTextInputFormat"><span class="toc-number">2.1.6.2.</span> <span class="toc-text">KeyValueTextInputFormat</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#KyeValueTextInputFormat%E4%BD%BF%E7%94%A8%E6%A1%88%E4%BE%8B"><span class="toc-number">2.1.7.</span> <span class="toc-text">KyeValueTextInputFormat使用案例</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E9%9C%80%E6%B1%82-1"><span class="toc-number">2.1.7.1.</span> <span class="toc-text">需求</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E9%9C%80%E6%B1%82%E5%88%86%E6%9E%90"><span class="toc-number">2.1.7.2.</span> <span class="toc-text">需求分析</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#NLineInputFormat"><span class="toc-number">2.1.7.3.</span> <span class="toc-text">NLineInputFormat</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#NLineInputFormat%E4%BD%BF%E7%94%A8%E6%A1%88%E4%BE%8B"><span class="toc-number">2.1.8.</span> <span class="toc-text">NLineInputFormat使用案例</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E9%9C%80%E6%B1%82-2"><span class="toc-number">2.1.8.1.</span> <span class="toc-text">需求</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E9%9C%80%E6%B1%82%E5%88%86%E6%9E%90-1"><span class="toc-number">2.1.8.2.</span> <span class="toc-text">需求分析</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%87%AA%E5%AE%9A%E4%B9%89InputFormat"><span class="toc-number">2.1.9.</span> <span class="toc-text">自定义InputFormat</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%87%AA%E5%AE%9A%E4%B9%89InputFormat%E6%A1%88%E4%BE%8B%E5%AE%9E%E6%93%8D"><span class="toc-number">2.1.10.</span> <span class="toc-text">自定义InputFormat案例实操</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E9%9C%80%E6%B1%82-3"><span class="toc-number">2.1.10.1.</span> <span class="toc-text">需求</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E9%9C%80%E6%B1%82%E5%88%86%E6%9E%90-2"><span class="toc-number">2.1.10.2.</span> <span class="toc-text">需求分析</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E7%A8%8B%E5%BA%8F%E5%AE%9E%E7%8E%B0"><span class="toc-number">2.1.10.3.</span> <span class="toc-text">程序实现</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#MapReduce%E5%B7%A5%E4%BD%9C%E6%B5%81%E7%A8%8B"><span class="toc-number">2.2.</span> <span class="toc-text">MapReduce工作流程</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%B5%81%E7%A8%8B%E8%AF%A6%E8%A7%A3"><span class="toc-number">2.2.1.</span> <span class="toc-text">流程详解</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%B3%A8%E6%84%8F"><span class="toc-number">2.2.2.</span> <span class="toc-text">注意</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90%E6%B5%81%E7%A8%8B"><span class="toc-number">2.2.3.</span> <span class="toc-text">源码解析流程</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Shuffle%E6%9C%BA%E5%88%B6"><span class="toc-number">2.3.</span> <span class="toc-text">Shuffle机制</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Shuffle%E6%9C%BA%E5%88%B6-1"><span class="toc-number">2.3.1.</span> <span class="toc-text">Shuffle机制</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Partition%E5%88%86%E5%8C%BA"><span class="toc-number">2.3.2.</span> <span class="toc-text">Partition分区</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Partition%E5%88%86%E5%8C%BA%E6%A1%88%E4%BE%8B%E5%AE%9E%E6%93%8D"><span class="toc-number">2.3.3.</span> <span class="toc-text">Partition分区案例实操</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E9%9C%80%E6%B1%82%E5%88%86%E6%9E%90-3"><span class="toc-number">2.3.3.1.</span> <span class="toc-text">需求分析</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#WritableComparable%E6%8E%92%E5%BA%8F"><span class="toc-number">2.3.4.</span> <span class="toc-text">WritableComparable排序</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%8E%92%E5%BA%8F%E6%A6%82%E8%BF%B0"><span class="toc-number">2.3.4.1.</span> <span class="toc-text">排序概述</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%8E%92%E5%BA%8F%E5%88%86%E7%B1%BB"><span class="toc-number">2.3.4.2.</span> <span class="toc-text">排序分类</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E8%87%AA%E5%AE%9A%E4%B9%89%E6%8E%92%E5%BA%8FWritableComparable"><span class="toc-number">2.3.4.3.</span> <span class="toc-text">自定义排序WritableComparable</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#WritableComparable%E6%8E%92%E5%BA%8F%E6%A1%88%E4%BE%8B%E5%AE%9E%E6%93%8D%EF%BC%88%E5%85%A8%E6%8E%92%E5%BA%8F%EF%BC%89"><span class="toc-number">2.3.5.</span> <span class="toc-text">WritableComparable排序案例实操（全排序）</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E9%9C%80%E6%B1%82%E5%88%86%E6%9E%90-4"><span class="toc-number">2.3.5.1.</span> <span class="toc-text">需求分析</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0"><span class="toc-number">2.3.5.2.</span> <span class="toc-text">代码实现</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#WritableComparable%E6%8E%92%E5%BA%8F%E6%A1%88%E4%BE%8B%E5%AE%9E%E6%93%8D%EF%BC%88%E5%8C%BA%E5%86%85%E6%8E%92%E5%BA%8F%EF%BC%89"><span class="toc-number">2.3.6.</span> <span class="toc-text">WritableComparable排序案例实操（区内排序）</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E9%9C%80%E6%B1%82%E5%88%86%E6%9E%90-5"><span class="toc-number">2.3.6.1.</span> <span class="toc-text">需求分析</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%A1%88%E4%BE%8B%E5%AE%9E%E6%93%8D"><span class="toc-number">2.3.6.2.</span> <span class="toc-text">案例实操</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Combiner%E5%90%88%E5%B9%B6"><span class="toc-number">2.3.7.</span> <span class="toc-text">Combiner合并</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E9%9C%80%E6%B1%82-4"><span class="toc-number">2.3.7.1.</span> <span class="toc-text">需求</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Combiner%E5%90%88%E5%B9%B6%E6%A1%88%E4%BE%8B%E5%AE%9E%E6%93%8D"><span class="toc-number">2.3.8.</span> <span class="toc-text">Combiner合并案例实操</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E9%9C%80%E6%B1%82%E5%88%86%E6%9E%90-6"><span class="toc-number">2.3.8.1.</span> <span class="toc-text">需求分析</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%A1%88%E4%BE%8B%E5%AE%9E%E6%93%8D-%E6%96%B9%E6%A1%88%E4%B8%80"><span class="toc-number">2.3.8.2.</span> <span class="toc-text">案例实操-方案一</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%A1%88%E4%BE%8B%E5%AE%9E%E6%93%8D-%E6%96%B9%E6%A1%88%E4%BA%8C"><span class="toc-number">2.3.8.3.</span> <span class="toc-text">案例实操-方案二</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#GroupingComparator%E5%88%86%E7%BB%84%EF%BC%88%E8%BE%85%E5%8A%A9%E6%8E%92%E5%BA%8F%EF%BC%89"><span class="toc-number">2.3.9.</span> <span class="toc-text">GroupingComparator分组（辅助排序）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#GroupingComparator%E5%88%86%E7%BB%84%E6%A1%88%E4%BE%8B%E5%AE%9E%E6%93%8D"><span class="toc-number">2.3.10.</span> <span class="toc-text">GroupingComparator分组案例实操</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E9%9C%80%E6%B1%82%E5%88%86%E6%9E%90-7"><span class="toc-number">2.3.10.1.</span> <span class="toc-text">需求分析</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0-1"><span class="toc-number">2.3.10.2.</span> <span class="toc-text">代码实现</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#MapTask%E5%B7%A5%E4%BD%9C%E6%9C%BA%E5%88%B6"><span class="toc-number">2.4.</span> <span class="toc-text">MapTask工作机制</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#ReduceTask%E5%B7%A5%E4%BD%9C%E6%9C%BA%E5%88%B6"><span class="toc-number">2.5.</span> <span class="toc-text">ReduceTask工作机制</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#ReduceTask%E5%B7%A5%E4%BD%9C%E6%9C%BA%E5%88%B6-1"><span class="toc-number">2.5.1.</span> <span class="toc-text">ReduceTask工作机制</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%AE%BE%E7%BD%AEReduceTask%E5%B9%B6%E8%A1%8C%E5%BA%A6%EF%BC%88%E4%B8%AA%E6%95%B0%EF%BC%89"><span class="toc-number">2.5.2.</span> <span class="toc-text">设置ReduceTask并行度（个数）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%AE%9E%E9%AA%8C%EF%BC%9A%E6%B5%8B%E8%AF%95ReduceTask%E5%A4%9A%E5%B0%91%E5%90%88%E9%80%82"><span class="toc-number">2.5.3.</span> <span class="toc-text">实验：测试ReduceTask多少合适</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%B3%A8%E6%84%8F%E4%BA%8B%E9%A1%B9"><span class="toc-number">2.5.4.</span> <span class="toc-text">注意事项</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#OutputFormat%E6%95%B0%E6%8D%AE%E8%BE%93%E5%87%BA"><span class="toc-number">2.6.</span> <span class="toc-text">OutputFormat数据输出</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#OutputFormat%E6%8E%A5%E5%8F%A3%E5%AE%9E%E7%8E%B0%E7%B1%BB"><span class="toc-number">2.6.1.</span> <span class="toc-text">OutputFormat接口实现类</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%87%AA%E5%AE%9A%E4%B9%89OutputFromat"><span class="toc-number">2.6.2.</span> <span class="toc-text">自定义OutputFromat</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%BD%BF%E7%94%A8%E5%9C%BA%E6%99%AF"><span class="toc-number">2.6.2.1.</span> <span class="toc-text">使用场景</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E8%87%AA%E5%AE%9A%E4%B9%89OutputFormat%E6%AD%A5%E9%AA%A4"><span class="toc-number">2.6.2.2.</span> <span class="toc-text">自定义OutputFormat步骤</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%87%AA%E5%AE%9A%E4%B9%89OutputFormat%E6%A1%88%E4%BE%8B%E5%AE%9E%E6%93%8D"><span class="toc-number">2.6.3.</span> <span class="toc-text">自定义OutputFormat案例实操</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E9%9C%80%E6%B1%82%E5%88%86%E6%9E%90-8"><span class="toc-number">2.6.3.1.</span> <span class="toc-text">需求分析</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E9%9C%80%E6%B1%82-5"><span class="toc-number">2.6.3.1.1.</span> <span class="toc-text">需求</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E8%BE%93%E5%85%A5%E6%95%B0%E6%8D%AE"><span class="toc-number">2.6.3.1.2.</span> <span class="toc-text">输入数据</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E6%9C%9F%E6%9C%9B%E8%BE%93%E5%87%BA%E6%95%B0%E6%8D%AE"><span class="toc-number">2.6.3.1.3.</span> <span class="toc-text">期望输出数据</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E8%87%AA%E5%AE%9A%E4%B9%89%E4%B8%80%E4%B8%AAOutputFormat%E7%B1%BB"><span class="toc-number">2.6.3.1.4.</span> <span class="toc-text">自定义一个OutputFormat类</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E9%A9%B1%E5%8A%A8%E7%B1%BBDriver"><span class="toc-number">2.6.3.1.5.</span> <span class="toc-text">驱动类Driver</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%A1%88%E4%BE%8B%E5%AE%9E%E6%93%8D-1"><span class="toc-number">2.6.3.2.</span> <span class="toc-text">案例实操</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Join%E5%A4%9A%E7%A7%8D%E5%BA%94%E7%94%A8"><span class="toc-number">2.7.</span> <span class="toc-text">Join多种应用</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Reduce-Join"><span class="toc-number">2.7.1.</span> <span class="toc-text">Reduce Join</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Reduce-Join%E6%A1%88%E4%BE%8B%E5%AE%9E%E6%93%8D"><span class="toc-number">2.7.2.</span> <span class="toc-text">Reduce Join案例实操</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E9%9C%80%E6%B1%82%E5%88%86%E6%9E%90-9"><span class="toc-number">2.7.2.1.</span> <span class="toc-text">需求分析</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E9%9C%80%E6%B1%82-6"><span class="toc-number">2.7.2.1.1.</span> <span class="toc-text">需求</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E8%BE%93%E5%85%A5%E6%95%B0%E6%8D%AE-1"><span class="toc-number">2.7.2.1.2.</span> <span class="toc-text">输入数据</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E8%BE%93%E5%87%BA%E6%95%B0%E6%8D%AE"><span class="toc-number">2.7.2.1.3.</span> <span class="toc-text">输出数据</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#MapTask"><span class="toc-number">2.7.2.1.4.</span> <span class="toc-text">MapTask</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#ReduceTask"><span class="toc-number">2.7.2.1.5.</span> <span class="toc-text">ReduceTask</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0-2"><span class="toc-number">2.7.2.2.</span> <span class="toc-text">代码实现</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Map-Join"><span class="toc-number">2.7.3.</span> <span class="toc-text">Map Join</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%BD%BF%E7%94%A8%E5%9C%BA%E6%99%AF-1"><span class="toc-number">2.7.3.1.</span> <span class="toc-text">使用场景</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%BC%98%E7%82%B9"><span class="toc-number">2.7.3.2.</span> <span class="toc-text">优点</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%85%B7%E4%BD%93%E5%8A%9E%E6%B3%95%EF%BC%9A%E9%87%87%E7%94%A8DistributedCache"><span class="toc-number">2.7.3.3.</span> <span class="toc-text">具体办法：采用DistributedCache</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E9%9C%80%E6%B1%82%E5%88%86%E6%9E%90-10"><span class="toc-number">2.7.3.4.</span> <span class="toc-text">需求分析</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E9%9C%80%E6%B1%82-7"><span class="toc-number">2.7.3.4.1.</span> <span class="toc-text">需求</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0-3"><span class="toc-number">2.7.3.5.</span> <span class="toc-text">代码实现</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%AE%A1%E6%95%B0%E5%99%A8%E5%BA%94%E7%94%A8"><span class="toc-number">2.8.</span> <span class="toc-text">计数器应用</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E6%B8%85%E6%B4%97%EF%BC%88ETL%EF%BC%89"><span class="toc-number">2.9.</span> <span class="toc-text">数据清洗（ETL）</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%9C%80%E6%B1%82-8"><span class="toc-number">2.9.1.</span> <span class="toc-text">需求</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%9C%80%E6%B1%82%E5%88%86%E6%9E%90-11"><span class="toc-number">2.9.2.</span> <span class="toc-text">需求分析</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%AE%9E%E7%8E%B0%E4%BB%A3%E7%A0%81-%E7%AE%80%E5%8D%95%E7%89%88"><span class="toc-number">2.9.3.</span> <span class="toc-text">实现代码-简单版</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%AE%9E%E7%8E%B0%E4%BB%A3%E7%A0%81-%E5%A4%8D%E6%9D%82%E7%89%88"><span class="toc-number">2.9.4.</span> <span class="toc-text">实现代码-复杂版</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#MapReduce%E5%BC%80%E5%8F%91%E6%80%BB%E7%BB%93"><span class="toc-number">2.10.</span> <span class="toc-text">MapReduce开发总结</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-%E8%BE%93%E5%85%A5%E6%95%B0%E6%8D%AE%E6%8E%A5%E5%8F%A3-InputFormat"><span class="toc-number">2.10.1.</span> <span class="toc-text">1.输入数据接口: InputFormat</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-%E9%80%BB%E8%BE%91%E5%A4%84%E7%90%86%E6%8E%A5%E5%8F%A3-Mapper"><span class="toc-number">2.10.2.</span> <span class="toc-text">2.逻辑处理接口: Mapper</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-Partitioner%E5%88%86%E5%8C%BA"><span class="toc-number">2.10.3.</span> <span class="toc-text">3.Partitioner分区</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-Comparable%E6%8E%92%E5%BA%8F"><span class="toc-number">2.10.4.</span> <span class="toc-text">4.Comparable排序</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-Combiner%E5%90%88%E5%B9%B6"><span class="toc-number">2.10.5.</span> <span class="toc-text">5.Combiner合并</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#6-Reduce%E7%AB%AF%E5%88%86%E7%BB%84-GroupingComparator"><span class="toc-number">2.10.6.</span> <span class="toc-text">6.Reduce端分组: GroupingComparator</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#7-%E9%80%BB%E8%BE%91%E5%A4%84%E7%90%86%E6%8E%A5%E5%8F%A3-Reducer"><span class="toc-number">2.10.7.</span> <span class="toc-text">7.逻辑处理接口: Reducer</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#8-%E8%BE%93%E5%87%BA%E6%95%B0%E6%8D%AE%E6%8E%A5%E5%8F%A3-OutputFormat"><span class="toc-number">2.10.8.</span> <span class="toc-text">8.输出数据接口: OutputFormat</span></a></li></ol></li></ol></li></ol></div></div><div class="author-info hide"><div class="author-info__avatar text-center"><img src="/img/Avatar.png"></div><div class="author-info__name text-center">HibisciDai</div><div class="author-info__description text-center">HibisciDai'Blog</div><hr><div class="author-info-articles"><a class="author-info-articles__archives article-meta" href="/archives"><span class="pull-left">文章</span><span class="pull-right">222</span></a><a class="author-info-articles__tags article-meta" href="/tags"><span class="pull-left">标签</span><span class="pull-right">76</span></a><a class="author-info-articles__categories article-meta" href="/categories"><span class="pull-left">分类</span><span class="pull-right">29</span></a></div><hr><div class="author-info-links"><div class="author-info-links__title text-center">友情链接</div><a class="author-info-links__name text-center" target="_blank" rel="noopener" href="https://github.com/HibisciDai/hexo-theme-melody">HexoTheme-github</a><a class="author-info-links__name text-center" target="_blank" rel="noopener" href="https://molunerfinn.com/">molunerfinn</a></div></div></div><div id="content-outer"><div id="top-container" style="background-image: url(/img/banner2.jpg)"><div id="page-header"><span class="pull-left"> <a id="site-name" href="/">HibisciDai</a></span><i class="fa fa-bars toggle-menu pull-right" aria-hidden="true"></i><span class="pull-right menus">   <a class="site-page" href="/">主页</a><a class="site-page" href="/about">关于我</a><a class="site-page" href="/archives">归档</a><a class="site-page" href="/tags">标签</a><a class="site-page" href="/categories">分类</a><a class="site-page" href="/gallery">相册</a></span><span class="pull-right"><a class="site-page social-icon search"><i class="fa fa-search"></i><span> 搜索</span></a></span></div><div id="post-info"><div id="post-title">Hadoop-MapReduce详解-2</div><div id="post-meta"><time class="post-meta__date"><i class="fa fa-calendar" aria-hidden="true"></i> 2020-10-30</time><span class="post-meta__separator">|</span><i class="fa fa-inbox post-meta__icon" aria-hidden="true"></i><a class="post-meta__categories" href="/categories/Hadoop/">Hadoop</a><div class="post-meta-wordcount"><span>字数总计: </span><span class="word-count">17.9k</span><span class="post-meta__separator">|</span><span>阅读时长: 79 分钟</span></div></div></div></div><div class="layout" id="content-inner"><article id="post"><div class="article-container" id="post-content"><img src="/2020/10/30/Hadoop-MapReduce%E8%AF%A6%E8%A7%A3-2/Hadoop-MapReduce%E8%AF%A6%E8%A7%A3-2.png" class="" title="Hadoop-MapReduce详解-2">
<p>Hadoop-MapReduce详解-2</p>
<span id="more"></span>
<p>[TOC]</p>
<h1 id="Hadoop-MapReduce详解-2"><a href="#Hadoop-MapReduce详解-2" class="headerlink" title="Hadoop-MapReduce详解-2"></a>Hadoop-MapReduce详解-2</h1><h1 id="第3章-MapReduce框架原理"><a href="#第3章-MapReduce框架原理" class="headerlink" title="第3章 MapReduce框架原理"></a>第3章 MapReduce框架原理</h1><h2 id="InputFormat数据输入"><a href="#InputFormat数据输入" class="headerlink" title="InputFormat数据输入"></a>InputFormat数据输入</h2><h3 id="切片与MapTask并行度决定机制"><a href="#切片与MapTask并行度决定机制" class="headerlink" title="切片与MapTask并行度决定机制"></a>切片与MapTask并行度决定机制</h3><p>1．问题引出</p>
<p>MapTask的并行度决定Map阶段的任务处理并发度，进而影响到整个Job的处理速度。</p>
<blockquote>
<p>思考：1G的数据，启动8个MapTask，可以提高集群的并发处理能力。那么1K的数据，也启动8个MapTask，会提高集群性能吗？MapTask并行任务是否越多越好呢？哪些因素影响了MapTask并行度？ </p>
</blockquote>
<p>2．MapTask并行度决定机制</p>
<p><code>数据块</code>：Block是HDFS物理上把数据分成一块一块。<br><code>数据切片</code>：数据切片只是在逻辑上对输入进行分片，并不会在磁盘上将其切分成片进行存储。</p>
<img src="/2020/10/30/Hadoop-MapReduce%E8%AF%A6%E8%A7%A3-2/MapTask%E5%B9%B6%E8%A1%8C%E5%BA%A6%E5%86%B3%E5%AE%9A%E6%9C%BA%E5%88%B6-1.png" class="" title="MapTask并行度决定机制-1">
<img src="/2020/10/30/Hadoop-MapReduce%E8%AF%A6%E8%A7%A3-2/MapTask%E5%B9%B6%E8%A1%8C%E5%BA%A6%E5%86%B3%E5%AE%9A%E6%9C%BA%E5%88%B6-2.png" class="" title="MapTask并行度决定机制-2">
<img src="/2020/10/30/Hadoop-MapReduce%E8%AF%A6%E8%A7%A3-2/MapTask%E5%B9%B6%E8%A1%8C%E5%BA%A6%E5%86%B3%E5%AE%9A%E6%9C%BA%E5%88%B6-3.png" class="" title="MapTask并行度决定机制-3">
<img src="/2020/10/30/Hadoop-MapReduce%E8%AF%A6%E8%A7%A3-2/MapTask%E5%B9%B6%E8%A1%8C%E5%BA%A6%E5%86%B3%E5%AE%9A%E6%9C%BA%E5%88%B6-4.png" class="" title="MapTask并行度决定机制-4">
<img src="/2020/10/30/Hadoop-MapReduce%E8%AF%A6%E8%A7%A3-2/MapTask%E5%B9%B6%E8%A1%8C%E5%BA%A6%E5%86%B3%E5%AE%9A%E6%9C%BA%E5%88%B6-5.png" class="" title="MapTask并行度决定机制-5">
<p>并行度由切片决定，默认的并行度等于块大小。<br>多个文件时，每个文件单独切片。</p>
<p>1）一个job的map阶段并行度由客户端在提交job时决定<br>2）每一个split切片分配一个mapTask并行实例处理<br>3）默认情况下，切片大小=blocksize<br>4）切片时不考虑数据集整体，而是逐个针对每一个文件单独切片</p>
<p>100M单独起一个MapTask切片进行存储。()</p>
<h3 id="Job提交流程源码和切片源码详解"><a href="#Job提交流程源码和切片源码详解" class="headerlink" title="Job提交流程源码和切片源码详解"></a>Job提交流程源码和切片源码详解</h3><ul>
<li>Job提交流程源码详解</li>
</ul>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line">waitForCompletion()</span><br><span class="line"></span><br><span class="line">submit();</span><br><span class="line"></span><br><span class="line"><span class="comment">// 1建立连接</span></span><br><span class="line">	connect();	</span><br><span class="line">		<span class="comment">// 1）创建提交Job的代理</span></span><br><span class="line">		<span class="keyword">new</span> <span class="title class_">Cluster</span>(getConfiguration());</span><br><span class="line">			<span class="comment">// （1）判断是本地yarn还是远程</span></span><br><span class="line">			initialize(jobTrackAddr, conf); </span><br><span class="line"></span><br><span class="line"><span class="comment">// 2 提交job</span></span><br><span class="line">submitter.submitJobInternal(Job.<span class="built_in">this</span>, cluster)</span><br><span class="line">	<span class="comment">// 1）创建给集群提交数据的Stag路径</span></span><br><span class="line">	<span class="type">Path</span> <span class="variable">jobStagingArea</span> <span class="operator">=</span> JobSubmissionFiles.getStagingDir(cluster, conf);</span><br><span class="line"></span><br><span class="line">	<span class="comment">// 2）获取jobid ，并创建Job路径</span></span><br><span class="line">	<span class="type">JobID</span> <span class="variable">jobId</span> <span class="operator">=</span> submitClient.getNewJobID();</span><br><span class="line"></span><br><span class="line">	<span class="comment">// 3）拷贝jar包到集群</span></span><br><span class="line">copyAndConfigureFiles(job, submitJobDir);	</span><br><span class="line">	rUploader.uploadFiles(job, jobSubmitDir);</span><br><span class="line"></span><br><span class="line"><span class="comment">// 4）计算切片，生成切片规划文件</span></span><br><span class="line">writeSplits(job, submitJobDir);</span><br><span class="line">		maps = writeNewSplits(job, jobSubmitDir);</span><br><span class="line">		input.getSplits(job);</span><br><span class="line"></span><br><span class="line"><span class="comment">// 5）向Stag路径写XML配置文件</span></span><br><span class="line">writeConf(conf, submitJobFile);</span><br><span class="line">	conf.writeXml(out);</span><br><span class="line"></span><br><span class="line"><span class="comment">// 6）提交Job,返回提交状态</span></span><br><span class="line">status = submitClient.submitJob(jobId, submitJobDir.toString(), job.getCredentials());</span><br></pre></td></tr></table></figure>
<img src="/2020/10/30/Hadoop-MapReduce%E8%AF%A6%E8%A7%A3-2/Job%E6%8F%90%E4%BA%A4%E6%B5%81%E7%A8%8B%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90.png" class="" title="Job提交流程源码解析">
<ul>
<li>FileInputFormat切片源码解析(input.getSplits(job))</li>
</ul>
<p>(1)程序先找到你数据存储的目录</p>
<p>(2)开始遍历处理(规划切片)目录下的每一个文件</p>
<p>(3)遍历第一个文件 <code>ss.txt</code></p>
<p>a)获取文件大小<code>fs.sizeOf(ss.txt)</code></p>
<p>b)计算切片大小</p>
<p><code>computeSplitSize(Math.max(minSize, Math.min(maxSize, b1ocksiz)))=blocksize=128M</code></p>
<p>c)默认情况下，切片大小=blocksize</p>
<p>d)开始切，形成第1个切片: ss.txt—0:128M，第2个切片ss.txt—128:256M，第3个切片ss.txt—256M: 300M(每次切片时，都要判断切完剩下的部分是否大于块的1.1倍， 不大于1.1倍就划分一块切片)</p>
<p>e)将切片信息写到一个切片规划文件中</p>
<p>f)整个切片的核心过程在<code>getSplit()</code>方法中完成</p>
<p>g) IputSplit只记录 了切片的元数据信息，比如起始位置、长度以及所在的节点列表等</p>
<p>(4)提交切片规划文件到YARN上，YARN上的MrAppMaster就可以根据切片规划文件计算开启MapTask个数。</p>
<h3 id="FileInputFormat切片机制"><a href="#FileInputFormat切片机制" class="headerlink" title="FileInputFormat切片机制"></a>FileInputFormat切片机制</h3><h4 id="切片机制"><a href="#切片机制" class="headerlink" title="切片机制"></a>切片机制</h4><p>(1)简单地按照文件的内容长度进行切片<br>(2)切片大小，默认等于Block大小<br>(3)切片时不考虑数据集整体，而是逐个针对每一个文件单独切片</p>
<h4 id="案例分析"><a href="#案例分析" class="headerlink" title="案例分析"></a>案例分析</h4><p>(1)输入数据有两个文件：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">file1.txt 320M</span><br><span class="line">file2.txt 10M</span><br></pre></td></tr></table></figure>
<p>(2)经过<code>FileInputFormat</code>的切片机制运算后，形成的切片信息如下：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">file1.txt.split1-- 0~128</span><br><span class="line">file1.txt.split2-- 128~256</span><br><span class="line">file1.txt.split3-- 256~320</span><br><span class="line">file1.txt.split1-- 0~10M</span><br></pre></td></tr></table></figure>
<ul>
<li>FileInputFormat切片大小的参数配置</li>
</ul>
<p>(1)源码中计算切片大小的公式</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">Math.max(minSize, Math.min(maxSize, b1ocksiz));</span><br><span class="line">mapredurce.input.fileinputformat.split.minsize = 1 默认值为1</span><br><span class="line">mapredurce.input.fileinputformat.split.maxsize = Long.MAXValue 默认值为Long.MAXValue</span><br><span class="line">因此，默认情况下，切片大小=blocksize。</span><br></pre></td></tr></table></figure>
<p>(2)源码中计算切片大小的公式</p>
<p>maxsize(切片最大值)：参数如果调得比blockSize小，则会让切片变小，而且就等于配置的这个参数的值。</p>
<p>minsize(切片最小值)：参数调的比blockSize大，则可以让切片变得比blockSize还大。</p>
<p>(3)获取切片信息API</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//获取切片的文件名称</span></span><br><span class="line"><span class="type">String</span> <span class="variable">name</span> <span class="operator">=</span> inputSplit.getPath().getName();</span><br><span class="line"><span class="comment">//根据文件类型获取切片信息</span></span><br><span class="line"><span class="type">FileSplit</span> <span class="variable">inputSplit</span> <span class="operator">=</span> (FileSplit)context.getInputSplit();</span><br></pre></td></tr></table></figure>
<h3 id="CombineTextInputFormat切片机制"><a href="#CombineTextInputFormat切片机制" class="headerlink" title="CombineTextInputFormat切片机制"></a>CombineTextInputFormat切片机制</h3><p>框架默认的<code>TextInputFormat</code>切片机制是对任务按文件规划切片，不管文件多小，都会是一个单独的切片，都会交给一个<code>MapTask</code>，这样如果有大量小文件，就会产生大量的<code>MapTask</code>，处理效率极其低下。</p>
<p>1、应用场景：</p>
<p><code>CombineTextInputFormat</code>用于小文件过多的场景，它可以将多个小文件从逻辑上规划到一个切片中，这样，多个小文件就可以交给一个MapTask处理。</p>
<p>2、虚拟存储切片最大值设置</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">CombineTextInputFormat.setMaxInputSplitSize(job, <span class="number">4194304</span>);<span class="comment">//4M</span></span><br></pre></td></tr></table></figure>
<p>注意：虚拟存储切片最大值设置最好根据实际的小文件大小情况来设置具体的值。</p>
<p>3、切片机制</p>
<p>生成切片过程包括：虚拟存储过程和切片过程二部分。</p>
<ul>
<li>CombineTextInputFormat切片机制</li>
</ul>
<img src="/2020/10/30/Hadoop-MapReduce%E8%AF%A6%E8%A7%A3-2/CombineTextInputFormat%E5%88%87%E7%89%87%E6%9C%BA%E5%88%B6.png" class="" title="CombineTextInputFormat切片机制">
<p>（1）虚拟存储过程：</p>
<p>将输入目录下所有文件大小，依次和设置的<code>setMaxInputSplitSize</code>值比较，如果不大于设置的最大值，逻辑上划分一个块。如果输入文件大于设置的最大值且大于两倍，那么以最大值切割一块；当剩余数据大小超过设置的最大值且不大于最大值2倍，此时将文件均分成2个虚拟存储块（防止出现太小切片）。</p>
<p>例如<code>setMaxInputSplitSize</code>值为4M，输入文件大小为8.02M，则先逻辑上分成一个4M。剩余的大小为4.02M，如果按照4M逻辑划分，就会出现0.02M的小的虚拟存储文件，所以将剩余的4.02M文件切分成（2.01M和2.01M）两个文件。</p>
<p>（2）切片过程：<br>（a）判断虚拟存储的文件大小是否大于<code>setMaxInputSplitSize</code>值，大于等于则单独形成一个切片。<br>（b）如果不大于则跟下一个虚拟存储文件进行合并，共同形成一个切片。<br>（c）测试举例：有4个小文件大小分别为1.7M、5.1M、3.4M以及6.8M这四个小文件，则虚拟存储之后形成6个文件块，大小分别为：<br>1.7M，（2.55M、2.55M），3.4M以及（3.4M、3.4M）<br>最终会形成3个切片，大小分别为：<br>（1.7+2.55）M，（2.55+3.4）M，（3.4+3.4）M</p>
<h3 id="CombineTextInputFormat案例实操"><a href="#CombineTextInputFormat案例实操" class="headerlink" title="CombineTextInputFormat案例实操"></a>CombineTextInputFormat案例实操</h3><h4 id="需求"><a href="#需求" class="headerlink" title="需求"></a>需求</h4><p>将输入的大量小文件合并成一个切片统一处理。</p>
<p>（1）输入数据<br>    准备4个小文件<br>（2）期望<br>    期望一个切片处理4个文件</p>
<h4 id="实现过程"><a href="#实现过程" class="headerlink" title="实现过程"></a>实现过程</h4><p>（1）不做任何处理，运行1.6节的WordCount案例程序，观察切片个数为4。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">number of splits:4</span><br></pre></td></tr></table></figure>
<p>（2）在WordcountDriver中增加如下代码，运行程序，并观察运行的切片个数为3。</p>
<p>（a）驱动类中添加代码如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 如果不设置InputFormat，它默认用的是TextInputFormat.class</span></span><br><span class="line">job.setInputFormatClass(CombineTextInputFormat.class);</span><br><span class="line"></span><br><span class="line"><span class="comment">//虚拟存储切片最大值设置4m</span></span><br><span class="line">CombineTextInputFormat.setMaxInputSplitSize(job, <span class="number">4194304</span>);</span><br></pre></td></tr></table></figure>
<p>（b）运行如果为3个切片。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">number of splits:3</span><br></pre></td></tr></table></figure>
<p>（3）在WordcountDriver中增加如下代码，运行程序，并观察运行的切片个数为1。</p>
<p>（a）驱动中添加代码如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 如果不设置InputFormat，它默认用的是TextInputFormat.class</span></span><br><span class="line">job.setInputFormatClass(CombineTextInputFormat.class);</span><br><span class="line"></span><br><span class="line"><span class="comment">//虚拟存储切片最大值设置20m</span></span><br><span class="line">CombineTextInputFormat.setMaxInputSplitSize(job, <span class="number">20971520</span>);</span><br></pre></td></tr></table></figure>
<p>（b）运行如果为1个切片。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">number of splits:1</span><br></pre></td></tr></table></figure>
<h3 id="FileInputFormat实现类"><a href="#FileInputFormat实现类" class="headerlink" title="FileInputFormat实现类"></a>FileInputFormat实现类</h3><p>思考:在运行MapReduce程序时，输入的文件格式包括:基于行的日志文件、二进制格式文件、数据库表等。<br>那么，针对不同的数据类型，MapReduce是如何读取这些数据的呢?</p>
<p>FilcInputFormat常见的接口实现类包括: TextInputFormat、KeyValueTextInputFormat、NLineInputFormat、CombineTextInputFormat和自定义InputFormat等。</p>
<h4 id="TextInputFormat"><a href="#TextInputFormat" class="headerlink" title="TextInputFormat"></a>TextInputFormat</h4><p>TextInputFormat是默认的FileInputFormat实现类。按行读取每条记录。键是存储该行在整个文件中的起始字节偏移量，LongWritable类型。值是这行的内容，不包括任何行终止符(换行符和回车符)，Text类型。</p>
<p>以下是一个示例，比如，一个分片包含了如下4条文本记录：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">Rich learning form</span><br><span class="line">Intelligent learning engine</span><br><span class="line">Learning more convenient</span><br><span class="line">From the real demand for more close to the enterprise</span><br></pre></td></tr></table></figure>
<p>每条记录表示为以下键/值对：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">(0,Rich learning form)</span><br><span class="line">(19,Intelligent learning engine)</span><br><span class="line">(47,Learning more convenient)</span><br><span class="line">(72,From the real demand for more close to the enterprise)</span><br></pre></td></tr></table></figure>
<h4 id="KeyValueTextInputFormat"><a href="#KeyValueTextInputFormat" class="headerlink" title="KeyValueTextInputFormat"></a>KeyValueTextInputFormat</h4><p>每一行均为一条记录，被分隔符分割为<code>key,value</code>。可以通过在驱动类中设置<code>conf.set(KeyValueLineRecordReader.KEY_VALAUE_SIOERATOR, &quot;\t&quot;);</code>来设定分隔符。默认分隔符是<code>tab(\t)</code>。</p>
<p>以下是一个示例，输入时一个包含4条记录的分片。其中 <code>——&gt;</code> 表示一个(水平方向的)制表符。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">line1 ——&gt;Rich learning form</span><br><span class="line">line2 ——&gt;Intelligent learning engine</span><br><span class="line">line3 ——&gt;Learning more convenient</span><br><span class="line">line4 ——&gt;From the real demand for more close to the enterprise</span><br></pre></td></tr></table></figure>
<p>每条记录表示为以下键/值对：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">(line1,Rich learning form)</span><br><span class="line">(line2,Intelligent learning engine)</span><br><span class="line">(line3,Learning more convenient)</span><br><span class="line">(line4,From the real demand for more close to the enterprise)</span><br></pre></td></tr></table></figure>
<p>此事的键是每行排在制表符之前的Text序列。</p>
<h3 id="KyeValueTextInputFormat使用案例"><a href="#KyeValueTextInputFormat使用案例" class="headerlink" title="KyeValueTextInputFormat使用案例"></a>KyeValueTextInputFormat使用案例</h3><h4 id="需求-1"><a href="#需求-1" class="headerlink" title="需求"></a>需求</h4><p>统计输入文件中每一行的第一个单词相同的行数。</p>
<p>（1）输入数据</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">banzhang ni hao</span><br><span class="line">xihuan hadoop banzhang</span><br><span class="line">banzhang ni hao</span><br><span class="line">xihuan hadoop banzhang</span><br></pre></td></tr></table></figure>
<p>（2）期望结果数据</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">banzhang	2</span><br><span class="line">xihuan	2</span><br></pre></td></tr></table></figure>
<h4 id="需求分析"><a href="#需求分析" class="headerlink" title="需求分析"></a>需求分析</h4><p>1.需求：统计输入文件中每一行<br>2.输入数据</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">banzhang ni hao</span><br><span class="line">xihuan hadoop banzhang</span><br><span class="line">banzhang ni hao</span><br><span class="line">xihuan hadoop banzhang</span><br></pre></td></tr></table></figure>
<p>3.期望输出数据</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">banzhang	2</span><br><span class="line">xihuan	2</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>4.Map阶段</p>
<p>banzhang ni hao</p>
<p>(1)设置key和value</p>
<banzhang,1>

<p>(2)写出</p>
<p>5.Reduce阶段</p>
<p><banzhang,1></p>
<banzhang,1>

<p>(1)汇总</p>
<banzhang,2>

<p>(2)写出</p>
<p>6.Driver</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//1.设置切割符号为空格</span></span><br><span class="line">cof.set(KeyValueLineRecordReader.KEY_VALUE_SEPERATOR,<span class="string">&quot; &quot;</span>);</span><br><span class="line"><span class="comment">//2.设置输入格式</span></span><br><span class="line">job.setInputFormatClass(KeyValueTextInputFormat.class);</span><br></pre></td></tr></table></figure>
<ul>
<li>KVTextMapper.java</li>
</ul>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.atguigu.mr.kv;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.IntWritable;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.Text;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Mapper;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"></span><br><span class="line"><span class="comment">//banzhang ni hao &lt;banzhang,1&gt;</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">KVTextMapper</span> <span class="keyword">extends</span> <span class="title class_">Mapper</span>&lt;Text, Text, Text, IntWritable&gt; &#123;</span><br><span class="line"></span><br><span class="line">    <span class="type">IntWritable</span> <span class="variable">intWritable</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">IntWritable</span>(<span class="number">1</span>);</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">protected</span> <span class="keyword">void</span> <span class="title function_">map</span><span class="params">(Text key, Text value, Context context)</span> <span class="keyword">throws</span> IOException, InterruptedException &#123;</span><br><span class="line">        <span class="comment">//1封装对象</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">//2写出</span></span><br><span class="line">        context.write(key, intWritable);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<ul>
<li>KVTextReducer.java</li>
</ul>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.atguigu.mr.kv;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.IntWritable;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.Text;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Reducer;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">KVTextReducer</span> <span class="keyword">extends</span> <span class="title class_">Reducer</span>&lt;Text, IntWritable, Text, IntWritable&gt; &#123;</span><br><span class="line">    <span class="type">IntWritable</span> <span class="variable">v</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">IntWritable</span>();</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">protected</span> <span class="keyword">void</span> <span class="title function_">reduce</span><span class="params">(Text key, Iterable&lt;IntWritable&gt; values, Context context)</span> <span class="keyword">throws</span> IOException, InterruptedException &#123;</span><br><span class="line">        <span class="comment">//&lt;banzhang,1&gt;</span></span><br><span class="line">        <span class="comment">//&lt;banzhang,1&gt;</span></span><br><span class="line"></span><br><span class="line">        <span class="type">int</span> <span class="variable">sum</span> <span class="operator">=</span> <span class="number">0</span>;</span><br><span class="line">        <span class="comment">//1累加求和</span></span><br><span class="line">        <span class="keyword">for</span> (IntWritable value : values) &#123;</span><br><span class="line">            sum += value.get();</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        v.set(sum);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//2写出</span></span><br><span class="line">        context.write(key, v);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<ul>
<li>KVTextDriver.java</li>
</ul>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.atguigu.mr.kv;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.conf.Configuration;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.fs.Path;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.IntWritable;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.Text;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Job;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.lib.input.FileInputFormat;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.lib.input.KeyValueLineRecordReader;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.lib.input.KeyValueTextInputFormat;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">KVTextDriver</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> IOException, ClassNotFoundException, InterruptedException &#123;</span><br><span class="line"></span><br><span class="line">        args = <span class="keyword">new</span> <span class="title class_">String</span>[]&#123;<span class="string">&quot;F:/mr0529/input&quot;</span>, <span class="string">&quot;F:/mr0529/output&quot;</span>&#125;;</span><br><span class="line"></span><br><span class="line">        <span class="comment">//1获取job对象</span></span><br><span class="line">        <span class="type">Configuration</span> <span class="variable">cof</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Configuration</span>();</span><br><span class="line"></span><br><span class="line">        <span class="comment">//设置分隔符</span></span><br><span class="line">        cof.set(KeyValueLineRecordReader.KEY_VALUE_SEPERATOR, <span class="string">&quot; &quot;</span>);</span><br><span class="line">        <span class="type">Job</span> <span class="variable">job</span> <span class="operator">=</span> Job.getInstance(cof);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//2设置jar路径</span></span><br><span class="line">        job.setJarByClass(KVTextDriver.class);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//3关联mapper和reducer类</span></span><br><span class="line">        job.setMapperClass(KVTextMapper.class);</span><br><span class="line">        job.setReducerClass(KVTextReducer.class);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//4设置mapper输出的key和value类型</span></span><br><span class="line">        job.setMapOutputKeyClass(Text.class);</span><br><span class="line">        job.setOutputValueClass(IntWritable.class);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//5设置最终输出的key和value类型</span></span><br><span class="line">        job.setOutputKeyClass(Text.class);</span><br><span class="line">        job.setOutputValueClass(IntWritable.class);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//</span></span><br><span class="line">        job.setInputFormatClass(KeyValueTextInputFormat.class);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//6设置输出路径</span></span><br><span class="line">        FileInputFormat.setInputPaths(job, <span class="keyword">new</span> <span class="title class_">Path</span>(args[<span class="number">0</span>]));</span><br><span class="line">        FileOutputFormat.setOutputPath(job, <span class="keyword">new</span> <span class="title class_">Path</span>(args[<span class="number">1</span>]));</span><br><span class="line"></span><br><span class="line">        <span class="comment">//提交job</span></span><br><span class="line">        <span class="type">boolean</span> <span class="variable">result</span> <span class="operator">=</span> job.waitForCompletion(<span class="literal">true</span>);</span><br><span class="line"></span><br><span class="line">        System.exit(result ? <span class="number">0</span> : <span class="number">1</span>);</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h4 id="NLineInputFormat"><a href="#NLineInputFormat" class="headerlink" title="NLineInputFormat"></a>NLineInputFormat</h4><p>如果使用<code>NLineInputFormat</code>，代表每个map进程处理的InputSplit不再按Block块去划分，而是按<code>NLineInputFormat</code>指定的行数N来划分。即<code>输入文件的总行数/N=切片数</code>，如果不整除，<code>切片数=商+1</code>。</p>
<p>以下是一个示例，仍然以上边的4行输入为例子。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">Rich learning form</span><br><span class="line">Intelligent learning engine</span><br><span class="line">Learning more convenient</span><br><span class="line">From the real demand for more close to the enterprise</span><br></pre></td></tr></table></figure>
<p>例如，如果N是2，则每个输入分片包含两行。开启3个MapTask。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">(0,Rich learning form)</span><br><span class="line">(19,Intelligent learning engine)</span><br></pre></td></tr></table></figure>
<p>另一个mapper则受到后两行：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">(47,Learning more convenient)</span><br><span class="line">(72,From the real demand for more close to the enterprise)</span><br></pre></td></tr></table></figure>
<p>这里的键值与TextInputFormat生成的一样，key是偏移量。</p>
<h3 id="NLineInputFormat使用案例"><a href="#NLineInputFormat使用案例" class="headerlink" title="NLineInputFormat使用案例"></a>NLineInputFormat使用案例</h3><h4 id="需求-2"><a href="#需求-2" class="headerlink" title="需求"></a>需求</h4><p>对每个单词进行个数统计，要求根据每个输入文件的行数来规定输出多少个切片。此案例要求每三行放入一个切片中。</p>
<p>（1）输入数据</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">banzhang ni hao</span><br><span class="line">xihuan hadoop banzhang</span><br><span class="line">banzhang ni hao</span><br><span class="line">xihuan hadoop banzhang</span><br><span class="line">banzhang ni hao</span><br><span class="line">xihuan hadoop banzhang</span><br><span class="line">banzhang ni hao</span><br><span class="line">xihuan hadoop banzhang</span><br><span class="line">banzhang ni hao</span><br><span class="line">xihuan hadoop banzhang banzhang ni hao</span><br><span class="line">xihuan hadoop banzhang</span><br></pre></td></tr></table></figure>
<p>（2）期望输出数据</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Number of splits:4</span><br></pre></td></tr></table></figure>
<h4 id="需求分析-1"><a href="#需求分析-1" class="headerlink" title="需求分析"></a>需求分析</h4><p>1.需求：对每个单词进行个数统计，要求每三行放入一个切片中。<br>2.输入数据<br>3.输出数据<br>4.Map阶段</p>
<p>(1)获取一行<br>(2)切割<br>(3)循环写出</p>
<p>5.Reduce阶段</p>
<p>(1)汇总<br>(2)输出</p>
<p>6.Driver</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//设置每个切片InputSplit中划分三条记录</span></span><br><span class="line">NLineInputFormat.setNumLinesPerSplit(job,<span class="number">3</span>);</span><br></pre></td></tr></table></figure>
<ul>
<li>NLineMapper.java</li>
</ul>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.atguigu.mr.nline;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.IntWritable;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.LongWritable;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.Text;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Mapper;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">NLineMapper</span> <span class="keyword">extends</span> <span class="title class_">Mapper</span>&lt;LongWritable, Text, Text, IntWritable&gt; &#123;</span><br><span class="line"></span><br><span class="line">    <span class="type">Text</span> <span class="variable">k</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Text</span>();</span><br><span class="line">    <span class="type">IntWritable</span> <span class="variable">v</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">IntWritable</span>(<span class="number">1</span>);</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">protected</span> <span class="keyword">void</span> <span class="title function_">map</span><span class="params">(LongWritable key, Text value, Context context)</span> <span class="keyword">throws</span> IOException, InterruptedException &#123;</span><br><span class="line"></span><br><span class="line">        <span class="comment">//banzhang no hao</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">//1获取一行</span></span><br><span class="line">        <span class="type">String</span> <span class="variable">line</span> <span class="operator">=</span> value.toString();</span><br><span class="line"></span><br><span class="line">        <span class="comment">//2切割</span></span><br><span class="line">        String[] words = line.split(<span class="string">&quot; &quot;</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//3循环写出</span></span><br><span class="line">        <span class="keyword">for</span> (String word : words) &#123;</span><br><span class="line">            k.set(word);</span><br><span class="line">            context.write(k, v);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<ul>
<li>NLineReducer.java</li>
</ul>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.atguigu.mr.nline;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.IntWritable;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.Text;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Reducer;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">NLineReducer</span> <span class="keyword">extends</span> <span class="title class_">Reducer</span>&lt;Text, IntWritable, Text, IntWritable&gt; &#123;</span><br><span class="line"></span><br><span class="line">    <span class="type">IntWritable</span> <span class="variable">v</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">IntWritable</span>();</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">protected</span> <span class="keyword">void</span> <span class="title function_">reduce</span><span class="params">(Text key, Iterable&lt;IntWritable&gt; values, Context context)</span> <span class="keyword">throws</span> IOException, InterruptedException &#123;</span><br><span class="line">        <span class="comment">//1累加求和</span></span><br><span class="line">        <span class="type">int</span> <span class="variable">sum</span> <span class="operator">=</span> <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> (IntWritable value : values) &#123;</span><br><span class="line">            sum += value.get();</span><br><span class="line">        &#125;</span><br><span class="line">        v.set(sum);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//2写出</span></span><br><span class="line">        context.write(key, v);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<ul>
<li>NLineDriver.java</li>
</ul>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.atguigu.mr.nline;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.conf.Configuration;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.fs.Path;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.IntWritable;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.Text;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Job;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.lib.input.FileInputFormat;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.lib.input.NLineInputFormat;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">NLineDriver</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> IOException, ClassNotFoundException, InterruptedException &#123;</span><br><span class="line"></span><br><span class="line">        args = <span class="keyword">new</span> <span class="title class_">String</span>[]&#123;<span class="string">&quot;F:/mr0529/input&quot;</span>, <span class="string">&quot;F:/mr0529/output&quot;</span>&#125;;</span><br><span class="line"></span><br><span class="line">        <span class="comment">//1获取job对象</span></span><br><span class="line">        <span class="type">Configuration</span> <span class="variable">cof</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Configuration</span>();</span><br><span class="line">        <span class="type">Job</span> <span class="variable">job</span> <span class="operator">=</span> Job.getInstance(cof);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//设置切片</span></span><br><span class="line">        NLineInputFormat.setNumLinesPerSplit(job, <span class="number">3</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//使用NLineInputFormat处理记录数</span></span><br><span class="line">        job.setInputFormatClass(NLineInputFormat.class);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//2设置jar路径</span></span><br><span class="line">        job.setJarByClass(NLineDriver.class);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//3关联mapper和reducer类</span></span><br><span class="line">        job.setMapperClass(NLineMapper.class);</span><br><span class="line">        job.setReducerClass(NLineReducer.class);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//4设置mapper输出的key和value类型</span></span><br><span class="line">        job.setMapOutputKeyClass(Text.class);</span><br><span class="line">        job.setOutputValueClass(IntWritable.class);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//5设置最终输出的key和value类型</span></span><br><span class="line">        job.setOutputKeyClass(Text.class);</span><br><span class="line">        job.setOutputValueClass(IntWritable.class);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//6设置输出路径</span></span><br><span class="line">        FileInputFormat.setInputPaths(job, <span class="keyword">new</span> <span class="title class_">Path</span>(args[<span class="number">0</span>]));</span><br><span class="line">        FileOutputFormat.setOutputPath(job, <span class="keyword">new</span> <span class="title class_">Path</span>(args[<span class="number">1</span>]));</span><br><span class="line"></span><br><span class="line">        <span class="comment">//7提交job</span></span><br><span class="line">        job.waitForCompletion(<span class="literal">true</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="自定义InputFormat"><a href="#自定义InputFormat" class="headerlink" title="自定义InputFormat"></a>自定义InputFormat</h3><p>在企业开发中，Hadoop框架自带的InputFormat类型不能满足所有应用场景，需要自定义<code>InputFormat</code>来解决实际问题。</p>
<p>自定义<code>InputFormat</code>步骤如下：</p>
<p>(1)自定义一个类继承<code>FileInputFormat</code>。<br>(2)改写<code>RecordReader</code>,实现一次读取一个完整文件封装为<code>KV</code>。<br>(3)在输出时使用<code>SequenceFileOutPutFormat</code>输出合并文件。</p>
<h3 id="自定义InputFormat案例实操"><a href="#自定义InputFormat案例实操" class="headerlink" title="自定义InputFormat案例实操"></a>自定义InputFormat案例实操</h3><p>无论HDFS还是MapReduce，在处理小文件时效率都非常低，但又难免面临处理大量小文件的场景，此时，就需要有相应解决方案。可以自定义InputFormat实现小文件的合并。</p>
<h4 id="需求-3"><a href="#需求-3" class="headerlink" title="需求"></a>需求</h4><p>将多个小文件合并成一个SequenceFile文件（SequenceFile文件是Hadoop用来存储二进制形式的key-value对的文件格式），SequenceFile里面存储着多个文件，存储的形式为文件路径+名称为key，文件内容为value。</p>
<ul>
<li>输入数据</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">---</span><br><span class="line">one.txt</span><br><span class="line">---</span><br><span class="line"></span><br><span class="line">yongpeng weidong weinan</span><br><span class="line">sanfeng luozong xiaoming</span><br><span class="line"></span><br><span class="line">---</span><br><span class="line">two.txt</span><br><span class="line">---</span><br><span class="line"></span><br><span class="line">longlong fanfan</span><br><span class="line">mazong kailun yuhang yixin</span><br><span class="line">longlong fanfan</span><br><span class="line">mazong kailun yuhang yixin</span><br><span class="line"></span><br><span class="line">---</span><br><span class="line">three.txt</span><br><span class="line">---</span><br><span class="line"></span><br><span class="line">longlong fanfan</span><br><span class="line">mazong kailun yuhang yixin</span><br><span class="line">longlong fanfan</span><br><span class="line">mazong kailun yuhang yixin</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<ul>
<li>期望输出文件格式</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">SEQorg.apache.hadoop.io.Text&quot;org.apache.hadoop.io.BytesWritable      ?奀Wu授X@鼧?  W   &quot;!file:/e:/inputinputformat/one.txt   1yongpeng weidong weinan</span><br><span class="line">sanfeng luozong xiaoming   Y   $#file:/e:/inputinputformat/three.txt   1shuaige changmo zhenqiang </span><br><span class="line">dongli lingu xuanxuan   €   &quot;!file:/e:/inputinputformat/two.txt   Zlonglong fanfan</span><br><span class="line">mazong kailun yuhang yixin</span><br><span class="line">longlong fanfan</span><br><span class="line">mazong kailun yuhang yixin</span><br></pre></td></tr></table></figure>
<h4 id="需求分析-2"><a href="#需求分析-2" class="headerlink" title="需求分析"></a>需求分析</h4><p>1、自定义一个类继承<code>FileInputFormat</code></p>
<p>(1)重写`isSplitable()方法，返回false不可切割</p>
<p>(2)重写<code>createRecordReader()</code>, 创建自定义的RecordReader对象，并初始化</p>
<p>2、改写RecordReader, 实现一次读取一个完整文件封装为KV</p>
<p>(1)采用IO流一次读取一个文件输出到value中，因为设置了不可切片，最终把所有文件都封装到了value中</p>
<p>(2)获取文件路径信息+名称,并设置key</p>
<p>3、设置Driver</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// (1) 设置输入的inputFormat</span></span><br><span class="line">job.setInputFormatClass(WholeFileInputformat.class);</span><br><span class="line"></span><br><span class="line"><span class="comment">// (2) 设置输出的outputFormat</span></span><br><span class="line">job.set0utputFormatClass(SequenceFileOutputFormat.class);</span><br></pre></td></tr></table></figure>
<h4 id="程序实现"><a href="#程序实现" class="headerlink" title="程序实现"></a>程序实现</h4><p>（1）自定义InputFormat</p>
<p><code>WholeFileInputformat.java</code></p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.atguigu.mr.inputformat;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.BytesWritable;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.Text;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.InputSplit;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.RecordReader;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.TaskAttemptContext;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.lib.input.FileInputFormat;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">WholeFileInputFormat</span> <span class="keyword">extends</span> <span class="title class_">FileInputFormat</span>&lt;Text, BytesWritable&gt; &#123;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> RecordReader&lt;Text, BytesWritable&gt; <span class="title function_">createRecordReader</span><span class="params">(InputSplit inputSplit, TaskAttemptContext taskAttemptContext)</span> <span class="keyword">throws</span> IOException, InterruptedException &#123;</span><br><span class="line">        <span class="type">WholeRecordReader</span> <span class="variable">recordReader</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">WholeRecordReader</span>();</span><br><span class="line">        recordReader.initialize(inputSplit, taskAttemptContext);</span><br><span class="line">        <span class="keyword">return</span> recordReader;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>（2）自定义RecordReader类</p>
<p><code>WholeRecordReader.java</code></p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.atguigu.mr.inputformat;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.conf.Configuration;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.fs.FSDataInputStream;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.fs.FileSystem;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.fs.Path;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.BytesWritable;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.IOUtils;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.Text;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.InputSplit;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.RecordReader;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.TaskAttemptContext;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.lib.input.FileSplit;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">WholeRecordReader</span> <span class="keyword">extends</span> <span class="title class_">RecordReader</span>&lt;Text, BytesWritable&gt; &#123;</span><br><span class="line">    FileSplit split;</span><br><span class="line">    Configuration configuration;</span><br><span class="line">    <span class="type">Text</span> <span class="variable">k</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Text</span>();</span><br><span class="line">    <span class="type">BytesWritable</span> <span class="variable">v</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">BytesWritable</span>();</span><br><span class="line">    <span class="type">Boolean</span> <span class="variable">isProgress</span> <span class="operator">=</span> <span class="literal">true</span>;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">initialize</span><span class="params">(InputSplit inputSplit, TaskAttemptContext taskAttemptContext)</span> <span class="keyword">throws</span> IOException, InterruptedException &#123;</span><br><span class="line">        <span class="comment">//初始化</span></span><br><span class="line">        <span class="built_in">this</span>.split = (FileSplit) inputSplit;</span><br><span class="line"></span><br><span class="line">        <span class="comment">//获取配置信息待用</span></span><br><span class="line">        configuration = taskAttemptContext.getConfiguration();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="type">boolean</span> <span class="title function_">nextKeyValue</span><span class="params">()</span> <span class="keyword">throws</span> IOException, InterruptedException &#123;</span><br><span class="line">        <span class="comment">//核心业务逻辑</span></span><br><span class="line">        <span class="keyword">if</span> (isProgress) &#123;</span><br><span class="line">            <span class="type">byte</span>[] buf = <span class="keyword">new</span> <span class="title class_">byte</span>[(<span class="type">int</span>) split.getLength()];</span><br><span class="line">            <span class="comment">//1.获取fs对象</span></span><br><span class="line">            <span class="type">Path</span> <span class="variable">path</span> <span class="operator">=</span> split.getPath();</span><br><span class="line">            <span class="type">FileSystem</span> <span class="variable">fs</span> <span class="operator">=</span> path.getFileSystem(configuration);</span><br><span class="line"></span><br><span class="line">            <span class="comment">//2.获取输入流</span></span><br><span class="line">            <span class="type">FSDataInputStream</span> <span class="variable">fis</span> <span class="operator">=</span> fs.open(path);</span><br><span class="line"></span><br><span class="line">            <span class="comment">//3.拷贝到缓存</span></span><br><span class="line">            IOUtils.readFully(fis, buf, <span class="number">0</span>, buf.length);<span class="comment">//创建缓存的原因是封装方法只接受bug</span></span><br><span class="line"></span><br><span class="line">            <span class="comment">//4.封装v</span></span><br><span class="line">            v.set(buf, <span class="number">0</span>, buf.length);</span><br><span class="line"></span><br><span class="line">            <span class="comment">//5.封装k</span></span><br><span class="line">            k.set(path.toString());</span><br><span class="line"></span><br><span class="line">            <span class="comment">//6.关闭资源</span></span><br><span class="line">            IOUtils.closeStream(fis);</span><br><span class="line"></span><br><span class="line">            isProgress = <span class="literal">false</span>;</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> Text <span class="title function_">getCurrentKey</span><span class="params">()</span> <span class="keyword">throws</span> IOException, InterruptedException &#123;</span><br><span class="line">        <span class="keyword">return</span> k;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> BytesWritable <span class="title function_">getCurrentValue</span><span class="params">()</span> <span class="keyword">throws</span> IOException, InterruptedException &#123;</span><br><span class="line">        <span class="keyword">return</span> v;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="type">float</span> <span class="title function_">getProgress</span><span class="params">()</span> <span class="keyword">throws</span> IOException, InterruptedException &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">close</span><span class="params">()</span> <span class="keyword">throws</span> IOException &#123;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>（3）编写SequenceFileMapper类处理流程</p>
<p><code>SequcnceFileMapper.java</code></p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.atguigu.mr.inputformat;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.BytesWritable;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.Text;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Mapper;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">SequcnceFileMapper</span> <span class="keyword">extends</span> <span class="title class_">Mapper</span>&lt;Text, BytesWritable, Text, BytesWritable&gt; &#123;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">protected</span> <span class="keyword">void</span> <span class="title function_">map</span><span class="params">(Text key, BytesWritable value, Context context)</span> <span class="keyword">throws</span> IOException, InterruptedException &#123;</span><br><span class="line">        context.write(key, value);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>（4）编写SequenceFileReducer类处理流程</p>
<p><code>SequcnceFileReducer.java</code></p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.atguigu.mr.inputformat;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.BytesWritable;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.Text;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Reducer;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">SequcnceFileReducer</span> <span class="keyword">extends</span> <span class="title class_">Reducer</span>&lt;Text, BytesWritable, Text, BytesWritable&gt; &#123;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">protected</span> <span class="keyword">void</span> <span class="title function_">reduce</span><span class="params">(Text key, Iterable&lt;BytesWritable&gt; values, Context context)</span> <span class="keyword">throws</span> IOException, InterruptedException &#123;</span><br><span class="line">        <span class="comment">//循环写出</span></span><br><span class="line">        <span class="keyword">for</span> (BytesWritable value : values) &#123;</span><br><span class="line">            context.write(key, value);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>（5）编写SequenceFileDriver类处理流程</p>
<p><code>SequcnceFileDriver.java</code></p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.atguigu.mr.inputformat;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.conf.Configuration;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.fs.Path;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.BytesWritable;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.Text;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Job;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.lib.input.FileInputFormat;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.lib.output.SequenceFileOutputFormat;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">SequcnceFileDriver</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> IOException, ClassNotFoundException, InterruptedException &#123;</span><br><span class="line">        <span class="comment">//输入输入路径</span></span><br><span class="line">        args = <span class="keyword">new</span> <span class="title class_">String</span>[]&#123;<span class="string">&quot;f:/IDEAWS/dashuju/input&quot;</span>, <span class="string">&quot;f:/IDEAWS/dashuju/output&quot;</span>&#125;;</span><br><span class="line"></span><br><span class="line">        <span class="comment">//1.获取job对象</span></span><br><span class="line">        <span class="type">Configuration</span> <span class="variable">conf</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Configuration</span>();</span><br><span class="line">        <span class="type">Job</span> <span class="variable">job</span> <span class="operator">=</span> Job.getInstance(conf);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//2.设置jar包存放位置、关联自定义的mapper和reducer</span></span><br><span class="line">        job.setJarByClass(SequcnceFileDriver.class);</span><br><span class="line">        job.setMapperClass(SequcnceFileMapper.class);</span><br><span class="line">        job.setReducerClass(SequcnceFileReducer.class);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//7.设置输入的inputFormat</span></span><br><span class="line">        job.setInputFormatClass(WholeFileInputFormat.class);</span><br><span class="line">        <span class="comment">//8.设置输出的outputFormat</span></span><br><span class="line">        job.setOutputFormatClass(SequenceFileOutputFormat.class);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//3.设置map端输出的kv类型</span></span><br><span class="line">        job.setMapOutputKeyClass(Text.class);</span><br><span class="line">        job.setMapOutputValueClass(BytesWritable.class);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//4.设置做最终输出端的kv类型</span></span><br><span class="line">        job.setOutputKeyClass(Text.class);</span><br><span class="line">        job.setOutputValueClass(BytesWritable.class);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//5.设置输入输出路径</span></span><br><span class="line">        FileInputFormat.setInputPaths(job, <span class="keyword">new</span> <span class="title class_">Path</span>(args[<span class="number">0</span>]));</span><br><span class="line">        FileOutputFormat.setOutputPath(job, <span class="keyword">new</span> <span class="title class_">Path</span>(args[<span class="number">1</span>]));</span><br><span class="line"></span><br><span class="line">        <span class="comment">//6.提交job</span></span><br><span class="line">        <span class="type">boolean</span> <span class="variable">result</span> <span class="operator">=</span> job.waitForCompletion(<span class="literal">true</span>);</span><br><span class="line">        System.exit(result ? <span class="number">0</span> : <span class="number">1</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="MapReduce工作流程"><a href="#MapReduce工作流程" class="headerlink" title="MapReduce工作流程"></a>MapReduce工作流程</h2><img src="/2020/10/30/Hadoop-MapReduce%E8%AF%A6%E8%A7%A3-2/MapReduce%E5%B7%A5%E4%BD%9C%E6%B5%81%E7%A8%8B-1.png" class="" title="MapReduce工作流程-1">
<img src="/2020/10/30/Hadoop-MapReduce%E8%AF%A6%E8%A7%A3-2/MapReduce%E5%B7%A5%E4%BD%9C%E6%B5%81%E7%A8%8B-2.png" class="" title="MapReduce工作流程-2">
<h3 id="流程详解"><a href="#流程详解" class="headerlink" title="流程详解"></a>流程详解</h3><p>上面的流程是整个MapReduce最全工作流程，但是Shuffle过程只是从第7步开始到第16步结束，具体Shuffle过程详解，如下：<br>1）MapTask收集我们的map()方法输出的kv对，放到内存缓冲区中<br>2）从内存缓冲区不断溢出本地磁盘文件，可能会溢出多个文件<br>3）多个溢出文件会被合并成大的溢出文件<br>4）在溢出过程及合并的过程中，都要调用Partitioner进行分区和针对key进行排序<br>5）ReduceTask根据自己的分区号，去各个MapTask机器上取相应的结果分区数据<br>6）ReduceTask会取到同一个分区的来自不同MapTask的结果文件，ReduceTask会将这些文件再进行合并（归并排序）<br>7）合并成大文件后，Shuffle的过程也就结束了，后面进入ReduceTask的逻辑运算过程（从文件中取出一个一个的键值对Group，调用用户自定义的reduce()方法）</p>
<h3 id="注意"><a href="#注意" class="headerlink" title="注意"></a>注意</h3><p>Shuffle中的缓冲区大小会影响到MapReduce程序的执行效率，原则上说，缓冲区越大，磁盘io的次数越少，执行速度就越快。<br>缓冲区的大小可以通过参数调整，参数：io.sort.mb默认100M。</p>
<h3 id="源码解析流程"><a href="#源码解析流程" class="headerlink" title="源码解析流程"></a>源码解析流程</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">context.write(k, NullWritable.get());</span><br><span class="line">	output.write(key, value);</span><br><span class="line">	collector.collect(key, value,partitioner.getPartition(key, value, partitions));</span><br><span class="line">		HashPartitioner();</span><br><span class="line">	collect()</span><br><span class="line">		close()</span><br><span class="line">			collect.flush()</span><br><span class="line">				sortAndSpill()</span><br><span class="line">					sort()   QuickSort</span><br><span class="line">				<span class="title function_">mergeParts</span><span class="params">()</span>;</span><br><span class="line">	 </span><br><span class="line">				collector.close();</span><br></pre></td></tr></table></figure>
<h2 id="Shuffle机制"><a href="#Shuffle机制" class="headerlink" title="Shuffle机制"></a>Shuffle机制</h2><h3 id="Shuffle机制-1"><a href="#Shuffle机制-1" class="headerlink" title="Shuffle机制"></a>Shuffle机制</h3><p>Map方法之后，Reduce方法之前的数据处理过程称之为Shuffle。</p>
<img src="/2020/10/30/Hadoop-MapReduce%E8%AF%A6%E8%A7%A3-2/Shuffle%E6%9C%BA%E5%88%B6.png" class="" title="Shuffle机制">
<p>Shuffle机制在MapTask和ReduceTask有重叠。</p>
<h3 id="Partition分区"><a href="#Partition分区" class="headerlink" title="Partition分区"></a>Partition分区</h3><p>1、问题引出</p>
<p>要求将统计结果按照条件输出到不同文件中(分区)。</p>
<p>比如：将统计结果按照手机归属地不同省份输出到不同文件中(分区) </p>
<p>2、默认Partitioner分区</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">HashPartitioner</span>&lt;K, V&gt; <span class="keyword">extends</span> <span class="title class_">Partitioner</span>&lt;K, V&gt; &#123;</span><br><span class="line"></span><br><span class="line">publiC <span class="type">int</span> <span class="title function_">getPartition</span><span class="params">(K key, V value,<span class="type">int</span> numReduceTasks)</span> &#123;<span class="keyword">return</span> (key .hashCode() &amp; Integer.MAX_ VALUE) % numReduceTasks;</span><br></pre></td></tr></table></figure>
<p>默认分区是根据key的hashCode对ReduceTasks个数取模得到的。用户没法控制哪个key存储到哪个分区。</p>
<ol>
<li>自定义Partitioner步骤</li>
</ol>
<p>（1）自定义类继承Partitioner, 重写getPartition()方法</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">CustomPartitioner</span> <span class="keyword">extends</span> <span class="title class_">Partitioner</span>&lt;Text, FlowBean&gt; [</span><br><span class="line"></span><br><span class="line">	<span class="meta">@Override</span></span><br><span class="line"></span><br><span class="line">	<span class="keyword">public</span> <span class="type">int</span> <span class="title function_">getPartition</span><span class="params">(Text key, FlowBean value, <span class="type">int</span> numPartitions)</span> &#123;</span><br><span class="line">	<span class="comment">//控制分区代码逻辑</span></span><br><span class="line">	... ...</span><br><span class="line">	<span class="keyword">return</span> partition;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>（2）在Job驱动中，设置自定义Partitioner</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">job.setPartitionerClass(CustomPartitioner.class);</span><br></pre></td></tr></table></figure>
<p>（3）自定义Partition后， 要根据自定义Partitioner的逻辑设置相应数量的ReduceTask</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">job.setNumReduceTasks(<span class="number">5</span>);</span><br></pre></td></tr></table></figure>
<p>4、分区总结</p>
<p>（1）如果<code>ReduceTask的数量 &gt; getPatition的结果数</code>,则会多产性几个空的输出文件<code>part-1-000xx</code>;</p>
<p>（2）如果1 &lt; <code>ReduceTask的数量 &lt; getPation的结果数</code>，则有一部分分区数据无处安放，会Exception;</p>
<p>（3）如果<code>ReduceTask的数量 = 1</code>，则不管MapTask端输出多少个分区文件，最终结果都交给这一个ReduceTask,最终也就只会产生一个结果文件pat-r-00000;</p>
<p>（4）分区号必须从零开始，逐一累加。</p>
<p>5、案例分析</p>
<p>例如:假设自定义分区数为5，则</p>
<p>（1）<code>job.setNumReduceTasks(1);</code>    会正常运行，只不过会产生一个输出文件<br>（2）<code>job.setNumReduceTasks(2);</code>    会报错<br>（3） <code>job.setNumReduceTask&lt;(6);</code>    大于5，程序会正常运行，会产生空文件</p>
<h3 id="Partition分区案例实操"><a href="#Partition分区案例实操" class="headerlink" title="Partition分区案例实操"></a>Partition分区案例实操</h3><h4 id="需求分析-3"><a href="#需求分析-3" class="headerlink" title="需求分析"></a>需求分析</h4><p>（1）需求</p>
<p>将统计结果按照手机归属地不同省份输出到不同文件中（分区）</p>
<p>（2）输入数据</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">1	13736230513	192.196.100.1	www.atguigu.com	2481	24681	200</span><br><span class="line">2	13846544121	192.196.100.2			264	0	200</span><br><span class="line">3 	13956435636	192.196.100.3			132	1512	200</span><br><span class="line">4 	13966251146	192.168.100.1			240	0	404</span><br><span class="line">5 	18271575951	192.168.100.2	www.atguigu.com	1527	2106	200</span><br><span class="line">6 	84188413	192.168.100.3	www.atguigu.com	4116	1432	200</span><br><span class="line">7 	13590439668	192.168.100.4			1116	954	200</span><br><span class="line">8 	15910133277	192.168.100.5	www.hao123.com	3156	2936	200</span><br><span class="line">9 	13729199489	192.168.100.6			240	0	200</span><br><span class="line">10 	13630577991	192.168.100.7	www.shouhu.com	6960	690	200</span><br><span class="line">11 	15043685818	192.168.100.8	www.baidu.com	3659	3538	200</span><br><span class="line">12 	15959002129	192.168.100.9	www.atguigu.com	1938	180	500</span><br><span class="line">13 	13560439638	192.168.100.10			918	4938	200</span><br><span class="line">14 	13470253144	192.168.100.11			180	180	200</span><br><span class="line">15 	13682846555	192.168.100.12	www.qq.com	1938	2910	200</span><br><span class="line">16 	13992314666	192.168.100.13	www.gaga.com	3008	3720	200</span><br><span class="line">17 	13509468723	192.168.100.14	www.qinghua.com	7335	110349	404</span><br><span class="line">18 	18390173782	192.168.100.15	www.sogou.com	9531	2412	200</span><br><span class="line">19 	13975057813	192.168.100.16	www.baidu.com	11058	48243	200</span><br><span class="line">20 	13768778790	192.168.100.17			120	120	200</span><br><span class="line">21 	13568436656	192.168.100.18	www.alibaba.com	2481	24681	200</span><br><span class="line">22 	13568436656	192.168.100.19			1116	954	200</span><br></pre></td></tr></table></figure>
<p>（3）期望输出数据</p>
<p>手机号136、137、138、139开头都分别放到一个独立的4个文件中，其他开头的放到一个文件中。</p>
<p>（4）增加一个ProvicePartitioner分区</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">136		分区0</span><br><span class="line">137		分区1</span><br><span class="line">138		分区2</span><br><span class="line">139		分区3</span><br><span class="line">其他     分区4</span><br></pre></td></tr></table></figure>
<p>（5）Driver驱动类</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//指定自定义数据分区</span></span><br><span class="line">job.setPartitionerClass(ProvincePartitioner.class);</span><br><span class="line"></span><br><span class="line"><span class="comment">//同时指定相应数量的reduceTask</span></span><br><span class="line">job.setNumReduceTasks(<span class="number">5</span>);</span><br></pre></td></tr></table></figure>
<p>3．在案例2.4的基础上，增加一个分区类</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.atguigu.mapreduce.flowsum;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.Text;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Partitioner;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">ProvincePartitioner</span> <span class="keyword">extends</span> <span class="title class_">Partitioner</span>&lt;Text, FlowBean&gt; &#123;</span><br><span class="line"></span><br><span class="line">	<span class="meta">@Override</span></span><br><span class="line">	<span class="keyword">public</span> <span class="type">int</span> <span class="title function_">getPartition</span><span class="params">(Text key, FlowBean value, <span class="type">int</span> numPartitions)</span> &#123;</span><br><span class="line"></span><br><span class="line">		<span class="comment">// 1 获取电话号码的前三位</span></span><br><span class="line">		<span class="type">String</span> <span class="variable">preNum</span> <span class="operator">=</span> key.toString().substring(<span class="number">0</span>, <span class="number">3</span>);</span><br><span class="line">		</span><br><span class="line">		<span class="type">int</span> <span class="variable">partition</span> <span class="operator">=</span> <span class="number">4</span>;</span><br><span class="line">		</span><br><span class="line">		<span class="comment">// 2 判断是哪个省</span></span><br><span class="line">		<span class="keyword">if</span> (<span class="string">&quot;136&quot;</span>.equals(preNum)) &#123;</span><br><span class="line">			partition = <span class="number">0</span>;</span><br><span class="line">		&#125;<span class="keyword">else</span> <span class="keyword">if</span> (<span class="string">&quot;137&quot;</span>.equals(preNum)) &#123;</span><br><span class="line">			partition = <span class="number">1</span>;</span><br><span class="line">		&#125;<span class="keyword">else</span> <span class="keyword">if</span> (<span class="string">&quot;138&quot;</span>.equals(preNum)) &#123;</span><br><span class="line">			partition = <span class="number">2</span>;</span><br><span class="line">		&#125;<span class="keyword">else</span> <span class="keyword">if</span> (<span class="string">&quot;139&quot;</span>.equals(preNum)) &#123;</span><br><span class="line">			partition = <span class="number">3</span>;</span><br><span class="line">		&#125;</span><br><span class="line"></span><br><span class="line">		<span class="keyword">return</span> partition;</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>4．在驱动函数中增加自定义数据分区设置和ReduceTask设置</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.atguigu.mapreduce.flowsum;</span><br><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.conf.Configuration;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.fs.Path;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.Text;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Job;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.lib.input.FileInputFormat;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">FlowsumDriver</span> &#123;</span><br><span class="line"></span><br><span class="line">	<span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> IllegalArgumentException, IOException, ClassNotFoundException, InterruptedException &#123;</span><br><span class="line"></span><br><span class="line">		<span class="comment">// 输入输出路径需要根据自己电脑上实际的输入输出路径设置</span></span><br><span class="line">		args = <span class="keyword">new</span> <span class="title class_">String</span>[]&#123;<span class="string">&quot;e:/output1&quot;</span>,<span class="string">&quot;e:/output2&quot;</span>&#125;;</span><br><span class="line"></span><br><span class="line">		<span class="comment">// 1 获取配置信息，或者job对象实例</span></span><br><span class="line">		<span class="type">Configuration</span> <span class="variable">configuration</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Configuration</span>();</span><br><span class="line">		<span class="type">Job</span> <span class="variable">job</span> <span class="operator">=</span> Job.getInstance(configuration);</span><br><span class="line"></span><br><span class="line">		<span class="comment">// 2 指定本程序的jar包所在的本地路径</span></span><br><span class="line">		job.setJarByClass(FlowsumDriver.class);</span><br><span class="line"></span><br><span class="line">		<span class="comment">// 3 指定本业务job要使用的mapper/Reducer业务类</span></span><br><span class="line">		job.setMapperClass(FlowCountMapper.class);</span><br><span class="line">		job.setReducerClass(FlowCountReducer.class);</span><br><span class="line"></span><br><span class="line">		<span class="comment">// 4 指定mapper输出数据的kv类型</span></span><br><span class="line">		job.setMapOutputKeyClass(Text.class);</span><br><span class="line">		job.setMapOutputValueClass(FlowBean.class);</span><br><span class="line"></span><br><span class="line">		<span class="comment">// 5 指定最终输出的数据的kv类型</span></span><br><span class="line">		job.setOutputKeyClass(Text.class);</span><br><span class="line">		job.setOutputValueClass(FlowBean.class);</span><br><span class="line"></span><br><span class="line">		<span class="comment">// 8 指定自定义数据分区</span></span><br><span class="line">		job.setPartitionerClass(ProvincePartitioner.class);</span><br><span class="line"></span><br><span class="line">		<span class="comment">// 9 同时指定相应数量的reduce task</span></span><br><span class="line">		job.setNumReduceTasks(<span class="number">5</span>);</span><br><span class="line">		</span><br><span class="line">		<span class="comment">// 6 指定job的输入原始文件所在目录</span></span><br><span class="line">		FileInputFormat.setInputPaths(job, <span class="keyword">new</span> <span class="title class_">Path</span>(args[<span class="number">0</span>]));</span><br><span class="line">		FileOutputFormat.setOutputPath(job, <span class="keyword">new</span> <span class="title class_">Path</span>(args[<span class="number">1</span>]));</span><br><span class="line"></span><br><span class="line">		<span class="comment">// 7 将job中配置的相关参数，以及job所用的java类所在的jar包， 提交给yarn去运行</span></span><br><span class="line">		<span class="type">boolean</span> <span class="variable">result</span> <span class="operator">=</span> job.waitForCompletion(<span class="literal">true</span>);</span><br><span class="line">		System.exit(result ? <span class="number">0</span> : <span class="number">1</span>);</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="WritableComparable排序"><a href="#WritableComparable排序" class="headerlink" title="WritableComparable排序"></a>WritableComparable排序</h3><h4 id="排序概述"><a href="#排序概述" class="headerlink" title="排序概述"></a>排序概述</h4><p>排序是MapReduce框架中最重要的操作之一。</p>
<p>MapTask和ReduceTask均会对数据按照key进行排序。该操作属于Hadoop的默认行为。任何应用程序中的数据均会被排序，而不管逻辑上是否需要。</p>
<p>默认排序是按照字典顺序排序，且实现该排序的方法是快速排序。</p>
<p>对于MapTask，它会将处理的结果暂时放到环形缓冲区中，当环形缓冲区使用率达到一定阈值后，再对缓冲区中的数据进行一次快速排序，并将这些有序数据溢写到磁盘上，而当数据处理完毕后，它会对磁盘上所有文件进行归并排序。</p>
<p>对于ReduceTask，它从每个MapTask上远程拷贝相应的数据文件，如果文件大小超过一定阈值，则溢写磁盘上，否则存储在内存中。如果磁盘上文件数目达到一定阈值，则进行一次归并排序以生成一个更大文件；如果内存中文件大小或者数目超过一定阈值，则进行一次合并后将数据溢写到磁盘上。当所有数据拷贝完毕后，ReduceTask统一对内存和磁盘上的所有数据进行一次归并排序。</p>
<h4 id="排序分类"><a href="#排序分类" class="headerlink" title="排序分类"></a>排序分类</h4><p>（1）部分排序</p>
<p>MapReduce根据输入记录的键对数据集排序。保证输出的每个文件内部有序。</p>
<p>（2）全排序</p>
<p>最终输出结果只有一个文件，文件内部有序。实现方式是只设置一个ReduceTask。但该方法在处理大型文件时效率极低，因为-台机器处理所有文件，完全丧失了MapReduce所提供的并行架构。</p>
<p>（3）辅助排序: (GroupingComparator分组)</p>
<p>在Reduce端对key进行分组。应用于：在接收的key为bean对象时，想让一个或几个字段相同(全部字段比较不相同)的key进入到同一个reduce方法时，可以采用分组排序。</p>
<p>（4）二次排序</p>
<p>在自定义排序过程中，如果compareTo中的判断条件为两个即为二次排序。</p>
<h4 id="自定义排序WritableComparable"><a href="#自定义排序WritableComparable" class="headerlink" title="自定义排序WritableComparable"></a>自定义排序WritableComparable</h4><p>（1）原理分析</p>
<p>bean对象做为key传输，需要实现WritableComparable接口重写compareTo方法，就可以实现排序。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="keyword">public</span> <span class="type">int</span> <span class="title function_">compareTo</span><span class="params">(FlowBean o)</span> &#123;</span><br><span class="line"></span><br><span class="line">	<span class="type">int</span> result;</span><br><span class="line">		</span><br><span class="line">	<span class="comment">// 按照总流量大小，倒序排列</span></span><br><span class="line">	<span class="keyword">if</span> (sumFlow &gt; bean.getSumFlow()) &#123;</span><br><span class="line">		result = -<span class="number">1</span>;</span><br><span class="line">	&#125;<span class="keyword">else</span> <span class="keyword">if</span> (sumFlow &lt; bean.getSumFlow()) &#123;</span><br><span class="line">		result = <span class="number">1</span>;</span><br><span class="line">	&#125;<span class="keyword">else</span> &#123;</span><br><span class="line">		result = <span class="number">0</span>;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	<span class="keyword">return</span> result;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="WritableComparable排序案例实操（全排序）"><a href="#WritableComparable排序案例实操（全排序）" class="headerlink" title="WritableComparable排序案例实操（全排序）"></a>WritableComparable排序案例实操（全排序）</h3><h4 id="需求分析-4"><a href="#需求分析-4" class="headerlink" title="需求分析"></a>需求分析</h4><p>（1）需求</p>
<p>根据案例2.3产生的结果再次对总流量进行排序。</p>
<p>（2）输入数据</p>
<p>原始数据                          第一次处理后的数据</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">1	13736230513	192.196.100.1	www.atguigu.com	2481	24681	200</span><br><span class="line">2	13846544121	192.196.100.2			264	0	200</span><br><span class="line">3 	13956435636	192.196.100.3			132	1512	200</span><br><span class="line">4 	13966251146	192.168.100.1			240	0	404</span><br><span class="line">5 	18271575951	192.168.100.2	www.atguigu.com	1527	2106	200</span><br><span class="line">6 	84188413	192.168.100.3	www.atguigu.com	4116	1432	200</span><br><span class="line">7 	13590439668	192.168.100.4			1116	954	200</span><br><span class="line">8 	15910133277	192.168.100.5	www.hao123.com	3156	2936	200</span><br><span class="line">9 	13729199489	192.168.100.6			240	0	200</span><br><span class="line">10 	13630577991	192.168.100.7	www.shouhu.com	6960	690	200</span><br><span class="line">11 	15043685818	192.168.100.8	www.baidu.com	3659	3538	200</span><br><span class="line">12 	15959002129	192.168.100.9	www.atguigu.com	1938	180	500</span><br><span class="line">13 	13560439638	192.168.100.10			918	4938	200</span><br><span class="line">14 	13470253144	192.168.100.11			180	180	200</span><br><span class="line">15 	13682846555	192.168.100.12	www.qq.com	1938	2910	200</span><br><span class="line">16 	13992314666	192.168.100.13	www.gaga.com	3008	3720	200</span><br><span class="line">17 	13509468723	192.168.100.14	www.qinghua.com	7335	110349	404</span><br><span class="line">18 	18390173782	192.168.100.15	www.sogou.com	9531	2412	200</span><br><span class="line">19 	13975057813	192.168.100.16	www.baidu.com	11058	48243	200</span><br><span class="line">20 	13768778790	192.168.100.17			120	120	200</span><br><span class="line">21 	13568436656	192.168.100.18	www.alibaba.com	2481	24681	200</span><br><span class="line">22 	13568436656	192.168.100.19			1116	954	200</span><br></pre></td></tr></table></figure>
<p>（3）期望输出数据</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">13509468723	7335	110349	117684</span><br><span class="line">13736230513	2481	24681	27162</span><br><span class="line">13956435636	132		1512	1644</span><br><span class="line">13846544121	264		0		264</span><br></pre></td></tr></table></figure>
<p>（4）FlowBean实现WritableComparable接口重写CompareTo方法</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="keyword">public</span> <span class="type">int</span> <span class="title function_">compareTo</span><span class="params">(FlowBean o)</span> &#123;</span><br><span class="line">	<span class="comment">//倒序排列，按照流量从大到小</span></span><br><span class="line">	<span class="keyword">return</span> <span class="built_in">this</span>.sumFlow &gt; o.getSumFolw() ? -<span class="number">1</span> : <span class="number">1</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>（5）Mapper类</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">context.write(bean, 手机号)</span><br></pre></td></tr></table></figure>
<p>（6）Reducer类</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//循环输出，避免总流量相同情况</span></span><br><span class="line"><span class="keyword">for</span> (Text text : values) &#123;</span><br><span class="line">	context.write(text, key);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h4 id="代码实现"><a href="#代码实现" class="headerlink" title="代码实现"></a>代码实现</h4><p>（1）FlowBean对象在在需求1基础上增加了比较功能</p>
<p><code>FlowBean.java</code></p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.atguigu.mr.sort;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.WritableComparable;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.io.DataInput;</span><br><span class="line"><span class="keyword">import</span> java.io.DataOutput;</span><br><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">FlowBean</span> <span class="keyword">implements</span> <span class="title class_">WritableComparable</span>&lt;FlowBean&gt; &#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="type">long</span> upFlow;    <span class="comment">//上行流量</span></span><br><span class="line">    <span class="keyword">private</span> <span class="type">long</span> downFlow;  <span class="comment">//下行流量</span></span><br><span class="line">    <span class="keyword">private</span> <span class="type">long</span> sumFlow;   <span class="comment">//总流量</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">//空参构造，为了后续反射使用</span></span><br><span class="line">    <span class="keyword">public</span> <span class="title function_">FlowBean</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="built_in">super</span>();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="title function_">FlowBean</span><span class="params">(<span class="type">long</span> upFlow, <span class="type">long</span> downFlow)</span> &#123;</span><br><span class="line">        <span class="built_in">super</span>();</span><br><span class="line"></span><br><span class="line">        <span class="built_in">this</span>.upFlow = upFlow;</span><br><span class="line">        <span class="built_in">this</span>.downFlow = downFlow;</span><br><span class="line">        sumFlow = upFlow + downFlow;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//序列化方法</span></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">write</span><span class="params">(DataOutput dataOutput)</span> <span class="keyword">throws</span> IOException &#123;</span><br><span class="line">        dataOutput.writeLong(upFlow);</span><br><span class="line">        dataOutput.writeLong(downFlow);</span><br><span class="line">        dataOutput.writeLong(sumFlow);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//反序列化方法</span></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">readFields</span><span class="params">(DataInput dataInput)</span> <span class="keyword">throws</span> IOException &#123;</span><br><span class="line">        <span class="comment">//注意书写顺序</span></span><br><span class="line">        upFlow = dataInput.readLong();</span><br><span class="line">        downFlow = dataInput.readLong();</span><br><span class="line">        sumFlow = dataInput.readLong();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//比较方法</span></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="type">int</span> <span class="title function_">compareTo</span><span class="params">(FlowBean bean)</span> &#123;</span><br><span class="line">        <span class="type">int</span> result;</span><br><span class="line"></span><br><span class="line">        <span class="comment">//核心比较条件判断</span></span><br><span class="line">        <span class="keyword">if</span> (sumFlow &gt; bean.getSumFlow())&#123;</span><br><span class="line">            result = -<span class="number">1</span>;</span><br><span class="line">        &#125; <span class="keyword">else</span> <span class="keyword">if</span> (sumFlow &lt; bean.getSumFlow()) &#123;</span><br><span class="line">            result = <span class="number">1</span>;</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            result = <span class="number">0</span>;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> result;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> String <span class="title function_">toString</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> upFlow + <span class="string">&quot;\t&quot;</span> + downFlow + <span class="string">&quot;\t&quot;</span> + sumFlow;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="type">long</span> <span class="title function_">getUpFlow</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> upFlow;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="type">long</span> <span class="title function_">getDownFlow</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> downFlow;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="type">long</span> <span class="title function_">getSumFlow</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> sumFlow;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">setUpFlow</span><span class="params">(<span class="type">long</span> upFlow)</span> &#123;</span><br><span class="line">        <span class="built_in">this</span>.upFlow = upFlow;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">setDownFlow</span><span class="params">(<span class="type">long</span> downFlow)</span> &#123;</span><br><span class="line">        <span class="built_in">this</span>.downFlow = downFlow;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">setSumFlow</span><span class="params">(<span class="type">long</span> sumFlow)</span> &#123;</span><br><span class="line">        <span class="built_in">this</span>.sumFlow = sumFlow;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>（2）编写Mapper类</p>
<p><code>FlowCountSortMapper.java</code></p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.atguigu.mr.sort;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.LongWritable;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.Text;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Mapper;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">FlowCountSortMapper</span> <span class="keyword">extends</span> <span class="title class_">Mapper</span>&lt;LongWritable, Text, FlowBean, Text&gt; &#123;</span><br><span class="line"></span><br><span class="line">    <span class="type">FlowBean</span> <span class="variable">k</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">FlowBean</span>();</span><br><span class="line">    <span class="type">Text</span> <span class="variable">v</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Text</span>();</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">protected</span> <span class="keyword">void</span> <span class="title function_">map</span><span class="params">(LongWritable key, Text value, Context context)</span> <span class="keyword">throws</span> IOException, InterruptedException &#123;</span><br><span class="line">        <span class="comment">//1.获取一行</span></span><br><span class="line">        <span class="type">String</span> <span class="variable">line</span> <span class="operator">=</span> value.toString();</span><br><span class="line"></span><br><span class="line">        <span class="comment">//2.切割</span></span><br><span class="line">        String[] fields = line.split(<span class="string">&quot;\t&quot;</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//3.封装对象</span></span><br><span class="line">        <span class="type">String</span> <span class="variable">phonenum</span> <span class="operator">=</span> fields[<span class="number">0</span>];</span><br><span class="line">        <span class="type">long</span> <span class="variable">upFlow</span> <span class="operator">=</span> Long.parseLong(fields[<span class="number">1</span>]);</span><br><span class="line">        <span class="type">long</span> <span class="variable">downFlow</span> <span class="operator">=</span> Long.parseLong(fields[<span class="number">2</span>]);</span><br><span class="line">        <span class="type">long</span> <span class="variable">sumFlow</span> <span class="operator">=</span> Long.parseLong(fields[<span class="number">3</span>]);</span><br><span class="line"></span><br><span class="line">        k.setDownFlow(downFlow);</span><br><span class="line">        k.setUpFlow(upFlow);</span><br><span class="line">        k.setSumFlow(sumFlow);</span><br><span class="line"></span><br><span class="line">        v.set(phonenum);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//4.写出</span></span><br><span class="line">        context.write(k, v);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>（3）编写Reducer类</p>
<p><code>FlowCountSortReducer.java</code></p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.atguigu.mr.sort;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.Text;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Reducer;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">FlowCountSortReducer</span> <span class="keyword">extends</span> <span class="title class_">Reducer</span>&lt;FlowBean, Text, Text, FlowBean&gt; &#123;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">protected</span> <span class="keyword">void</span> <span class="title function_">reduce</span><span class="params">(FlowBean key, Iterable&lt;Text&gt; values, Context context)</span> <span class="keyword">throws</span> IOException, InterruptedException &#123;</span><br><span class="line">        <span class="keyword">for</span> (Text value : values) &#123;</span><br><span class="line">            context.write(value, key);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>（4）编写Driver类</p>
<p><code>FlowCountSortDriver.java</code></p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.atguigu.mr.sort;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.conf.Configuration;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.fs.Path;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.Text;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Job;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.lib.input.FileInputFormat;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">FlowCountSortDriver</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> IOException, ClassNotFoundException, InterruptedException &#123;</span><br><span class="line">        args = <span class="keyword">new</span> <span class="title class_">String</span>[]&#123;<span class="string">&quot;F:/IDEAWS/dashju/input1&quot;</span>, <span class="string">&quot;F:/IDEAWS/dashju/output2&quot;</span>&#125;;</span><br><span class="line"></span><br><span class="line">        <span class="type">Configuration</span> <span class="variable">conf</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Configuration</span>();</span><br><span class="line">        <span class="comment">//1.获取job对象</span></span><br><span class="line">        <span class="type">Job</span> <span class="variable">job</span> <span class="operator">=</span> Job.getInstance(conf);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//2.设置jar路径</span></span><br><span class="line">        job.setJarByClass(FlowCountSortDriver.class);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//3.关联mapper和reducer</span></span><br><span class="line">        job.setMapperClass(FlowCountSortMapper.class);</span><br><span class="line">        job.setReducerClass(FlowCountSortReducer.class);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//4.设置mapper输出的key和value类型</span></span><br><span class="line">        job.setMapOutputKeyClass(FlowBean.class);</span><br><span class="line">        job.setMapOutputValueClass(Text.class);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//5.设置最终输出的key和value类型</span></span><br><span class="line">        job.setOutputKeyClass(Text.class);</span><br><span class="line">        job.setOutputValueClass(FlowBean.class);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//6.设置输入输出路径</span></span><br><span class="line">        FileInputFormat.setInputPaths(job, <span class="keyword">new</span> <span class="title class_">Path</span>(args[<span class="number">0</span>]));</span><br><span class="line">        FileOutputFormat.setOutputPath(job, <span class="keyword">new</span> <span class="title class_">Path</span>(args[<span class="number">1</span>]));</span><br><span class="line"></span><br><span class="line">        <span class="comment">//7.提交job</span></span><br><span class="line">        <span class="type">boolean</span> <span class="variable">result</span> <span class="operator">=</span> job.waitForCompletion(<span class="literal">true</span>);</span><br><span class="line"></span><br><span class="line">        System.out.println(result ? <span class="number">0</span> : <span class="number">1</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="WritableComparable排序案例实操（区内排序）"><a href="#WritableComparable排序案例实操（区内排序）" class="headerlink" title="WritableComparable排序案例实操（区内排序）"></a>WritableComparable排序案例实操（区内排序）</h3><h4 id="需求分析-5"><a href="#需求分析-5" class="headerlink" title="需求分析"></a>需求分析</h4><p>要求每个省份手机号输出的文件中按照总流量内部排序。</p>
<p>基于前一个需求，增加自定义分区类，分区按照省份手机号设置。</p>
<h4 id="案例实操"><a href="#案例实操" class="headerlink" title="案例实操"></a>案例实操</h4><p>（1）增加自定义分区类</p>
<p>（2）在驱动类中添加分区类</p>
<p><code>ProvincePartitioner.java</code></p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.atguigu.mr.sort2;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.Text;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Partitioner;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">ProvincePartitioner</span> <span class="keyword">extends</span> <span class="title class_">Partitioner</span>&lt;FlowBean, Text&gt; &#123;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="type">int</span> <span class="title function_">getPartition</span><span class="params">(FlowBean flowBean, Text value, <span class="type">int</span> numPartitions)</span> &#123;</span><br><span class="line">        <span class="comment">//按照手机号前三位分区</span></span><br><span class="line">        <span class="type">String</span> <span class="variable">prePhoneNum</span> <span class="operator">=</span> value.toString().substring(<span class="number">0</span>, <span class="number">3</span>);</span><br><span class="line"></span><br><span class="line">        <span class="type">int</span> <span class="variable">Partition</span> <span class="operator">=</span> <span class="number">4</span>;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> (<span class="string">&quot;136&quot;</span>.equals(prePhoneNum)) &#123;</span><br><span class="line">            Partition = <span class="number">0</span>;</span><br><span class="line">        &#125; <span class="keyword">else</span> <span class="keyword">if</span> (<span class="string">&quot;137&quot;</span>.equals(prePhoneNum)) &#123;</span><br><span class="line">            Partition = <span class="number">1</span>;</span><br><span class="line">        &#125; <span class="keyword">else</span> <span class="keyword">if</span> (<span class="string">&quot;138&quot;</span>.equals(prePhoneNum)) &#123;</span><br><span class="line">            Partition = <span class="number">2</span>;</span><br><span class="line">        &#125; <span class="keyword">else</span> <span class="keyword">if</span> (<span class="string">&quot;139&quot;</span>.equals(prePhoneNum)) &#123;</span><br><span class="line">            Partition = <span class="number">3</span>;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> Partition;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><code>FlowCountSortDriver.java</code></p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.atguigu.mr.sort2;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.conf.Configuration;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.fs.Path;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.Text;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Job;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.lib.input.FileInputFormat;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">FlowCountSortDriver</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> IOException, ClassNotFoundException, InterruptedException &#123;</span><br><span class="line">        args = <span class="keyword">new</span> <span class="title class_">String</span>[]&#123;<span class="string">&quot;F:/IDEAWS/dashju/input3&quot;</span>, <span class="string">&quot;F:/IDEAWS/dashju/output3&quot;</span>&#125;;</span><br><span class="line"></span><br><span class="line">        <span class="type">Configuration</span> <span class="variable">conf</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Configuration</span>();</span><br><span class="line">        <span class="comment">//1.获取job对象</span></span><br><span class="line">        <span class="type">Job</span> <span class="variable">job</span> <span class="operator">=</span> Job.getInstance(conf);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//2.设置jar路径</span></span><br><span class="line">        job.setJarByClass(FlowCountSortDriver.class);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//3.关联mapper和reducer</span></span><br><span class="line">        job.setMapperClass(FlowCountSortMapper.class);</span><br><span class="line">        job.setReducerClass(FlowCountSortReducer.class);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//4.设置mapper输出的key和value类型</span></span><br><span class="line">        job.setMapOutputKeyClass(FlowBean.class);</span><br><span class="line">        job.setMapOutputValueClass(Text.class);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//5.设置最终输出的key和value类型</span></span><br><span class="line">        job.setOutputKeyClass(Text.class);</span><br><span class="line">        job.setOutputValueClass(FlowBean.class);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//6.设置输入输出路径</span></span><br><span class="line">        FileInputFormat.setInputPaths(job, <span class="keyword">new</span> <span class="title class_">Path</span>(args[<span class="number">0</span>]));</span><br><span class="line">        FileOutputFormat.setOutputPath(job, <span class="keyword">new</span> <span class="title class_">Path</span>(args[<span class="number">1</span>]));</span><br><span class="line"></span><br><span class="line">        <span class="comment">// --!--</span></span><br><span class="line">        <span class="comment">// 8.指定自定义数据分区</span></span><br><span class="line">        job.setPartitionerClass(ProvincePartitioner.class);</span><br><span class="line">        <span class="comment">// 9.同时指定相应数量的reduce task</span></span><br><span class="line">        job.setNumReduceTasks(<span class="number">5</span>);</span><br><span class="line">        <span class="comment">// --!--</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">//7.提交job</span></span><br><span class="line">        <span class="type">boolean</span> <span class="variable">result</span> <span class="operator">=</span> job.waitForCompletion(<span class="literal">true</span>);</span><br><span class="line"></span><br><span class="line">        System.out.println(result ? <span class="number">0</span> : <span class="number">1</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="Combiner合并"><a href="#Combiner合并" class="headerlink" title="Combiner合并"></a>Combiner合并</h3><h4 id="需求-4"><a href="#需求-4" class="headerlink" title="需求"></a>需求</h4><p>统计过程中对每一个MapTask的输出进行局部汇总，以减小网络传输量即采用Combiner功能。</p>
<p>（1）Combiner是MR程序中Mapper和Reducer之外的一种组件。<br>（2）Combiner组件的父类就是Reducer。<br>（3）Combinen和Reducer的区别在于运行的位置，Combiner是在每一个MapTask所在的节点运行，Reducer是接收全局所有Mapper的输出结果;<br>（4）Combiner的意义就是对每一个MapTask的输出进行局部汇总，以减小网络传输量。<br>（5）Combiner能够应用的前提是不能影响最终的业务逻辑，而且，Combiner的输出kv应该跟Reducer的输入kv类型要对应起来。</p>
<ul>
<li>用大数据框架求平均值</li>
</ul>
<p>在Mapper阶段：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">3 5 7 -》 (3+5+7)/3=5</span><br><span class="line">2 6 -》(2+6)/2=4</span><br></pre></td></tr></table></figure>
<p>在Reduce阶段：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">(3+5+7+2+6)/5=23/5 不等于 (5+4)/2=9/2</span><br></pre></td></tr></table></figure>
<p>这种情况下使用combiner就会影响真实的业务逻辑</p>
<p>（6）自定义Combiner实现步骤</p>
<p>（a）自定义一个Combiner继承Reducer，重写Reduce方法</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">WordcountCombiner</span> <span class="keyword">extends</span> <span class="title class_">Reducer</span>&lt;Text, IntWritable, Text,IntWritable&gt;&#123;</span><br><span class="line"></span><br><span class="line">	<span class="meta">@Override</span></span><br><span class="line">	<span class="keyword">protected</span> <span class="keyword">void</span> <span class="title function_">reduce</span><span class="params">(Text key, Iterable&lt;IntWritable&gt; values,Context context)</span> <span class="keyword">throws</span> IOException, InterruptedException &#123;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 1 汇总操作</span></span><br><span class="line">		<span class="type">int</span> <span class="variable">count</span> <span class="operator">=</span> <span class="number">0</span>;</span><br><span class="line">		<span class="keyword">for</span>(IntWritable v :values)&#123;</span><br><span class="line">			count += v.get();</span><br><span class="line">		&#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 2 写出</span></span><br><span class="line">		context.write(key, <span class="keyword">new</span> <span class="title class_">IntWritable</span>(count));</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>（b）在Job驱动类中设置： </p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">job.setCombinerClass(WordcountCombiner.class);</span><br></pre></td></tr></table></figure>
<h3 id="Combiner合并案例实操"><a href="#Combiner合并案例实操" class="headerlink" title="Combiner合并案例实操"></a>Combiner合并案例实操</h3><h4 id="需求分析-6"><a href="#需求分析-6" class="headerlink" title="需求分析"></a>需求分析</h4><p>（1）需求</p>
<p>统计过程中对每一个MapTask的输出进行局部汇总，以减小网络传输量即采用Combiner功能。</p>
<p>（2）数据输入</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">banzhang ni hao</span><br><span class="line">xihuan hadoop</span><br><span class="line">banzhang</span><br><span class="line">banzhang ni hao</span><br><span class="line">xihuan hadoop</span><br><span class="line">banzhang</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&lt;banzhang,4&gt;</span><br><span class="line">&lt;ni,2&gt;</span><br><span class="line">&lt;hao,2&gt;</span><br><span class="line">&lt;xihuan,2&gt;</span><br><span class="line">&lt;hadoop,2&gt;</span><br></pre></td></tr></table></figure>
<p>（3）期望输出</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">Map-Reduce Framework</span><br><span class="line">		Map input records=6</span><br><span class="line">		Map output records=12</span><br><span class="line">		Map output bytes=126</span><br><span class="line">		Map output materialized bytes=66</span><br><span class="line">		Input split bytes=121</span><br><span class="line">		</span><br><span class="line">		Combine input records=12</span><br><span class="line">		Combine output records=5</span><br><span class="line">		</span><br><span class="line">		Reduce input groups=5</span><br><span class="line">		Reduce shuffle bytes=66</span><br><span class="line">		Reduce input records=5</span><br><span class="line">		Reduce output records=5</span><br><span class="line">		Spilled Records=10</span><br><span class="line">		Shuffled Maps =1</span><br><span class="line">		Failed Shuffles=0</span><br><span class="line">		Merged Map outputs=1</span><br><span class="line">		GC time elapsed (ms)=9</span><br><span class="line">		Total committed heap usage (bytes)=2058354688</span><br></pre></td></tr></table></figure>
<blockquote>
<p>正常wordcount控制台输出</p>
</blockquote>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">Map-Reduce Framework</span><br><span class="line">		Map input records=6</span><br><span class="line">		Map output records=12</span><br><span class="line">		Map output bytes=126</span><br><span class="line">		Map output materialized bytes=156</span><br><span class="line">		Input split bytes=121</span><br><span class="line">		</span><br><span class="line">		Combine input records=0</span><br><span class="line">		Combine output records=0</span><br><span class="line">		</span><br><span class="line">		Reduce input groups=5</span><br><span class="line">		Reduce shuffle bytes=156</span><br><span class="line">		Reduce input records=12</span><br><span class="line">		Reduce output records=5</span><br><span class="line">		Spilled Records=24</span><br><span class="line">		Shuffled Maps =1</span><br><span class="line">		Failed Shuffles=0</span><br><span class="line">		Merged Map outputs=1</span><br><span class="line">		GC time elapsed (ms)=14</span><br><span class="line">		Total committed heap usage (bytes)=2058354688</span><br></pre></td></tr></table></figure>
<p>（4）方案一</p>
<p>增加一个WordcountCombiner类继承Reducer<br>在WordcountCombiner中，统计单词汇总，将统计结果输出</p>
<p>（5）方案二</p>
<p>将WordcountReducer作为Combiner在WordcountDriver驱动类中指定job.setCombinerClass(WordcountCombiner.class);</p>
<h4 id="案例实操-方案一"><a href="#案例实操-方案一" class="headerlink" title="案例实操-方案一"></a>案例实操-方案一</h4><ul>
<li>增加一个WordcountCombiner类继承Reducer</li>
</ul>
<p><code>WordcountCombiner.java</code></p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.atguigu.mr.combiner1;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.IntWritable;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.Text;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Reducer;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">WordcountCombiner</span> <span class="keyword">extends</span> <span class="title class_">Reducer</span>&lt;Text, IntWritable, Text, IntWritable&gt; &#123;</span><br><span class="line"></span><br><span class="line">    <span class="type">IntWritable</span> <span class="variable">v</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">IntWritable</span>();</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">protected</span> <span class="keyword">void</span> <span class="title function_">reduce</span><span class="params">(Text key, Iterable&lt;IntWritable&gt; values, Context context)</span> <span class="keyword">throws</span> IOException, InterruptedException &#123;</span><br><span class="line">        <span class="comment">//1累加求和</span></span><br><span class="line">        <span class="type">int</span> <span class="variable">sum</span> <span class="operator">=</span> <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">for</span> (IntWritable value : values) &#123;</span><br><span class="line">            sum += value.get();</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        v.set(sum);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//2写出</span></span><br><span class="line">        context.write(key, v);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<ul>
<li>在WordcountDriver驱动类中指定Combiner</li>
</ul>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 指定需要使用combiner，以及用哪个类作为combiner的逻辑</span></span><br><span class="line">job.setCombinerClass(WordcountCombiner.class);</span><br></pre></td></tr></table></figure>
<h4 id="案例实操-方案二"><a href="#案例实操-方案二" class="headerlink" title="案例实操-方案二"></a>案例实操-方案二</h4><ul>
<li>将WordcountReducer作为Combiner在WordcountDriver驱动类中指定</li>
</ul>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 指定需要使用Combiner，以及用哪个类作为Combiner的逻辑</span></span><br><span class="line">job.setCombinerClass(WordcountReducer.class);</span><br></pre></td></tr></table></figure>
<h3 id="GroupingComparator分组（辅助排序）"><a href="#GroupingComparator分组（辅助排序）" class="headerlink" title="GroupingComparator分组（辅助排序）"></a>GroupingComparator分组（辅助排序）</h3><p>对Reduce阶段的数据根据某一个或几个字段进行分组。</p>
<blockquote>
<p><strong>分组排序步骤</strong>：<br>（1）自定义类继承WritableComparator<br>（2）重写compare()方法</p>
</blockquote>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="keyword">public</span> <span class="type">int</span> <span class="title function_">compare</span><span class="params">(WritableComparable a, WritableComparable b)</span> &#123;</span><br><span class="line">	<span class="comment">// 比较的业务逻辑</span></span><br><span class="line">	<span class="keyword">return</span> result;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>（3）创建一个构造将比较对象的类传给父类</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">protected</span> <span class="title function_">OrderGroupingComparator</span><span class="params">()</span> &#123;</span><br><span class="line">	<span class="built_in">super</span>(OrderBean.class, <span class="literal">true</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="GroupingComparator分组案例实操"><a href="#GroupingComparator分组案例实操" class="headerlink" title="GroupingComparator分组案例实操"></a>GroupingComparator分组案例实操</h3><h4 id="需求分析-7"><a href="#需求分析-7" class="headerlink" title="需求分析"></a>需求分析</h4><p>（1）需求</p>
<p>有如下订单数据</p>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center">订单id</th>
<th style="text-align:center">商品id</th>
<th style="text-align:center">成交金额</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">0000001</td>
<td style="text-align:center">Pdt_01</td>
<td style="text-align:center">222.8</td>
</tr>
<tr>
<td style="text-align:center"></td>
<td style="text-align:center">Pdt_02</td>
<td style="text-align:center">33.8</td>
</tr>
<tr>
<td style="text-align:center">0000002</td>
<td style="text-align:center">Pdt_03</td>
<td style="text-align:center">522.8</td>
</tr>
<tr>
<td style="text-align:center"></td>
<td style="text-align:center">Pdt_04</td>
<td style="text-align:center">122.4</td>
</tr>
<tr>
<td style="text-align:center"></td>
<td style="text-align:center">Pdt_05</td>
<td style="text-align:center">722.4</td>
</tr>
<tr>
<td style="text-align:center">0000003</td>
<td style="text-align:center">Pdt_06</td>
<td style="text-align:center">232.8</td>
</tr>
<tr>
<td style="text-align:center"></td>
<td style="text-align:center">Pdt_02</td>
<td style="text-align:center">33.8</td>
</tr>
</tbody>
</table>
</div>
<p>现在需要求出每一个订单中最贵的商品</p>
<p>（2）输入数据</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">0000001 Pdt_01 222.8</span><br><span class="line">0000002 Pdt_05 722.4</span><br><span class="line">0000001 Pdt_02 33.8</span><br><span class="line">0000003 Pdt_06 232.8</span><br><span class="line">0000003 Pdt_02 33.8</span><br><span class="line">0000002 Pdt_03 522.8</span><br><span class="line">0000002 Pdt_04 122.4</span><br></pre></td></tr></table></figure>
<p>（3）期望输出</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">1	222.8</span><br><span class="line">2	722.4</span><br><span class="line">3	232.8</span><br></pre></td></tr></table></figure>
<p>（4）思路分析</p>
<p>a.利用<code>订单id和成交金额</code>作为key，可以将Map阶段读取到的所有订单数据按照id升序排序，如果id相同再按照金额降序排序，发送到Reduce。<br>b.在Reduce端利用groupingComparator将订单id相同的kv聚合成组，然后取第一个即是该订单中最贵商品，</p>
<p>（5）MapTask阶段</p>
<p>a.Map中处理的事情:</p>
<p>获取一行<br>切割出每个字段<br>一行封装成bean对象</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">					订单id	价格</span><br><span class="line">bean1,nullwritable 0000001 222.8</span><br><span class="line">bean2,nullwritable 0000002 722.4</span><br><span class="line">bean3,nullwritable 0000001 33.8</span><br><span class="line">bean4,nullwritable 0000003 232.8</span><br><span class="line">bean5,nullwritable 0000003 33.8</span><br><span class="line">bean6,nullwritable 0000002 522.8</span><br><span class="line">bean7,nullwritable 0000002 122.4</span><br></pre></td></tr></table></figure>
<p>b.二次排序</p>
<p>先根据订单id排序，如果订单id相同再根据价格降序排序</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">0000001 222.8</span><br><span class="line">0000001 33.8</span><br><span class="line">0000002 722.4</span><br><span class="line">0000002 522.8</span><br><span class="line">0000002 122.4</span><br><span class="line">0000003 232.8</span><br><span class="line">0000004 33.8</span><br></pre></td></tr></table></figure>
<p>（6）ReduceTask阶段</p>
<p>a.辅助排序</p>
<p>对从map端拉去过来的数据再次进行排序，只要订单id相同就认为是相同key。</p>
<p>b.Reduce方法只把第一组key的第一个写出去</p>
<h4 id="代码实现-1"><a href="#代码实现-1" class="headerlink" title="代码实现"></a>代码实现</h4><p>（1）定义订单信息OrderBean类</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.atguigu.mr.order;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.WritableComparable;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.io.DataInput;</span><br><span class="line"><span class="keyword">import</span> java.io.DataOutput;</span><br><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">OrderBean</span> <span class="keyword">implements</span> <span class="title class_">WritableComparable</span>&lt;OrderBean&gt; &#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="type">int</span> order_id;   <span class="comment">//订单id 号</span></span><br><span class="line">    <span class="keyword">private</span> <span class="type">double</span> order_price;   <span class="comment">//价格</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="type">int</span> <span class="title function_">getOrder_id</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> order_id;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="type">double</span> <span class="title function_">getOrder_price</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> order_price;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">setOrder_id</span><span class="params">(<span class="type">int</span> order_id)</span> &#123;</span><br><span class="line">        <span class="built_in">this</span>.order_id = order_id;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">setOrder_price</span><span class="params">(<span class="type">double</span> order_price)</span> &#123;</span><br><span class="line">        <span class="built_in">this</span>.order_price = order_price;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="title function_">OrderBean</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="built_in">super</span>();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="title function_">OrderBean</span><span class="params">(<span class="type">int</span> oredr_id, <span class="type">double</span> price)</span> &#123;</span><br><span class="line">        <span class="built_in">this</span>.order_id = oredr_id;</span><br><span class="line">        <span class="built_in">this</span>.order_price = price;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">write</span><span class="params">(DataOutput out)</span> <span class="keyword">throws</span> IOException &#123;</span><br><span class="line">        out.writeInt(order_id);</span><br><span class="line">        out.writeDouble(order_price);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">readFields</span><span class="params">(DataInput in)</span> <span class="keyword">throws</span> IOException &#123;</span><br><span class="line">        order_id = in.readInt();</span><br><span class="line">        order_price = in.readDouble();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//二次排序</span></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="type">int</span> <span class="title function_">compareTo</span><span class="params">(OrderBean o)</span> &#123;</span><br><span class="line">        <span class="type">int</span> <span class="variable">result</span> <span class="operator">=</span> <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">        <span class="comment">//先按照订单号</span></span><br><span class="line">        <span class="keyword">if</span> (order_id &gt; o.getOrder_id()) &#123;</span><br><span class="line">            result = <span class="number">1</span>;</span><br><span class="line">        &#125; <span class="keyword">else</span> <span class="keyword">if</span> (order_id &lt; o.getOrder_id()) &#123;</span><br><span class="line">            result = -<span class="number">1</span>;</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            <span class="comment">//再按照价格排序</span></span><br><span class="line">            <span class="keyword">if</span> (order_price &gt; o.getOrder_price()) &#123;</span><br><span class="line">                result = <span class="number">1</span>;</span><br><span class="line">            &#125; <span class="keyword">else</span> <span class="keyword">if</span> (order_price &lt; o.getOrder_price()) &#123;</span><br><span class="line">                result = -<span class="number">1</span>;</span><br><span class="line">            &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                result = <span class="number">0</span>;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> result;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> String <span class="title function_">toString</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> order_id + <span class="string">&quot;\t&quot;</span> + order_price;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>（2）编写OrderSortMapper类</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.atguigu.mr.order;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.LongWritable;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.NullWritable;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.Text;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Mapper;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">OrderSortMapper</span> <span class="keyword">extends</span> <span class="title class_">Mapper</span>&lt;LongWritable, Text, OrderBean, NullWritable&gt; &#123;</span><br><span class="line"></span><br><span class="line">    <span class="type">OrderBean</span> <span class="variable">k</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">OrderBean</span>();</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">protected</span> <span class="keyword">void</span> <span class="title function_">map</span><span class="params">(LongWritable key, Text value, Context context)</span> <span class="keyword">throws</span> IOException, InterruptedException &#123;</span><br><span class="line">        <span class="comment">//1获取一行</span></span><br><span class="line">        <span class="type">String</span> <span class="variable">line</span> <span class="operator">=</span> value.toString();</span><br><span class="line"></span><br><span class="line">        <span class="comment">//2分割截取</span></span><br><span class="line">        String[] fields = line.split(<span class="string">&quot; &quot;</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//3封装对象</span></span><br><span class="line">        k.setOrder_id(Integer.parseInt(fields[<span class="number">0</span>]));</span><br><span class="line">        k.setOrder_price(Double.parseDouble(fields[<span class="number">2</span>]));</span><br><span class="line"></span><br><span class="line">        <span class="comment">//4写出</span></span><br><span class="line">        context.write(k, NullWritable.get());</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>（3）编写OrderSortReducer类</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.atguigu.mr.order;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.NullWritable;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Reducer;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">OrderReducer</span> <span class="keyword">extends</span> <span class="title class_">Reducer</span>&lt;OrderBean, NullWritable, OrderBean, NullWritable&gt; &#123;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">protected</span> <span class="keyword">void</span> <span class="title function_">reduce</span><span class="params">(OrderBean key, Iterable&lt;NullWritable&gt; values, Context context)</span> <span class="keyword">throws</span> IOException, InterruptedException &#123;</span><br><span class="line">        context.write(key, NullWritable.get());</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>（4）编写OrderSortDriver类</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.atguigu.mr.order;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.conf.Configuration;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.fs.Path;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.NullWritable;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Job;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.lib.input.FileInputFormat;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">OrderDriver</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> IOException, ClassNotFoundException, InterruptedException &#123;</span><br><span class="line">        <span class="comment">// 输入输出路径需要根据自己电脑上实际的输入输出路径设置</span></span><br><span class="line">        args = <span class="keyword">new</span> <span class="title class_">String</span>[]&#123;<span class="string">&quot;F:/IDEAWS/dashju/orderinput1&quot;</span>, <span class="string">&quot;F:/IDEAWS/dashju/orderoutput1&quot;</span>&#125;;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 1 获取配置信息</span></span><br><span class="line">        <span class="type">Configuration</span> <span class="variable">conf</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Configuration</span>();</span><br><span class="line">        <span class="type">Job</span> <span class="variable">job</span> <span class="operator">=</span> Job.getInstance(conf);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 2 设置jar包加载路径</span></span><br><span class="line">        job.setJarByClass(OrderDriver.class);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 3 加载map/reduce类</span></span><br><span class="line">        job.setMapperClass(OrderSortMapper.class);</span><br><span class="line">        job.setReducerClass(OrderSortReducer.class);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 4 设置map输出数据key和value类型</span></span><br><span class="line">        job.setMapOutputKeyClass(OrderBean.class);</span><br><span class="line">        job.setMapOutputValueClass(NullWritable.class);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 5 设置最终输出数据的key和value类型</span></span><br><span class="line">        job.setOutputKeyClass(OrderBean.class);</span><br><span class="line">        job.setOutputValueClass(NullWritable.class);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 6 设置输入数据和输出数据路径</span></span><br><span class="line">        FileInputFormat.setInputPaths(job, <span class="keyword">new</span> <span class="title class_">Path</span>(args[<span class="number">0</span>]));</span><br><span class="line">        FileOutputFormat.setOutputPath(job, <span class="keyword">new</span> <span class="title class_">Path</span>(args[<span class="number">1</span>]));</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 7 提交</span></span><br><span class="line">        <span class="type">boolean</span> <span class="variable">result</span> <span class="operator">=</span> job.waitForCompletion(<span class="literal">true</span>);</span><br><span class="line">        System.exit(result ? <span class="number">0</span> : <span class="number">1</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>在不分组前运行得到结果为</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">1	222.8</span><br><span class="line">1	33.8</span><br><span class="line">2	722.4</span><br><span class="line">2	522.8</span><br><span class="line">2	122.4</span><br><span class="line">3	232.8</span><br><span class="line">3	33.8</span><br></pre></td></tr></table></figure>
<p>结果表明key不相同，key.id相同，所以输出按照不同对象输出。</p>
<p>（5）编写OrderSortGroupingComparator类</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.atguigu.mr.order;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.WritableComparable;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.WritableComparator;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">OrderGroupingComparator</span> <span class="keyword">extends</span> <span class="title class_">WritableComparator</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//必须创建空参构造</span></span><br><span class="line">    <span class="keyword">protected</span> <span class="title function_">OrderGroupingComparator</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="built_in">super</span>(OrderBean.class, <span class="literal">true</span>);    <span class="comment">//如果不返回true则不会创建对象</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="type">int</span> <span class="title function_">compare</span><span class="params">(WritableComparable a, WritableComparable b)</span> &#123;</span><br><span class="line">        <span class="type">int</span> result;</span><br><span class="line"></span><br><span class="line">        <span class="type">OrderBean</span> <span class="variable">orderBean_a</span> <span class="operator">=</span> (OrderBean) a;</span><br><span class="line">        <span class="type">OrderBean</span> <span class="variable">orderBean_b</span> <span class="operator">=</span> (OrderBean) b;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> (orderBean_a.getOrder_id() &gt; orderBean_b.getOrder_id()) &#123;</span><br><span class="line">            result = <span class="number">1</span>;</span><br><span class="line">        &#125; <span class="keyword">else</span> <span class="keyword">if</span> (orderBean_a.getOrder_id() &lt; orderBean_b.getOrder_id()) &#123;</span><br><span class="line">            result = -<span class="number">1</span>;</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            <span class="comment">//如果是0就认为是一组数据</span></span><br><span class="line">            result = <span class="number">0</span>;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> result;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>（6）增加Driver驱动关联</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 8 设置reduce端的分组</span></span><br><span class="line">job.setGroupingComparatorClass(OrderGroupingComparator.class);</span><br></pre></td></tr></table></figure>
<blockquote>
<p>运行结果：</p>
</blockquote>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">1	222.8</span><br><span class="line">2	722.4</span><br><span class="line">3	232.8</span><br></pre></td></tr></table></figure>
<p>想要输出top3，在reducer中循环输出即可</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> (NullWritable nullWritable : values) &#123;</span><br><span class="line">	context.write(key, NullWritable.get());</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="MapTask工作机制"><a href="#MapTask工作机制" class="headerlink" title="MapTask工作机制"></a>MapTask工作机制</h2><p>MapTask + ReduceTask = MapReduce</p>
<img src="/2020/10/30/Hadoop-MapReduce%E8%AF%A6%E8%A7%A3-2/MapTask%E5%B7%A5%E4%BD%9C%E6%9C%BA%E5%88%B6.png" class="" title="MapTask工作机制">
<p>-（1）Read阶段：MapTask通过用户编写的<code>RecordReader</code>，从输入<code>InputSplit</code>中解析出一个个<code>key/value</code>。</p>
<p>-（2）Map阶段：该节点主要是将解析出的<code>key/value</code>交给用户编写<code>map()</code>函数处理，并产生一系列新的<code>key/value</code>。</p>
<p>-（3）Collect收集阶段：在用户编写<code>map()</code>函数中，当数据处理完成后，一般会调用<code>OutputCollector.collect()</code>输出结果。在该函数内部，它会将生成的<code>key/value</code>分区（调用<code>Partitioner</code>），并写入一个环形内存缓冲区中。</p>
<p>-（4）Spill阶段：即<code>溢写</code>，当环形缓冲区满后，MapReduce会将数据写到本地磁盘上，生成一个临时文件。需要注意的是，将数据写入本地磁盘之前，先要对数据进行一次本地排序，并在必要时对数据进行合并、压缩等操作。</p>
<ul>
<li>溢写阶段详情：</li>
</ul>
<p>步骤1：利用快速排序算法对缓存区内的数据进行排序，排序方式是，先按照分区编号Partition进行排序，然后按照key进行排序。这样，经过排序后，数据以分区为单位聚集在一起，且同一分区内所有数据按照key有序。</p>
<p>步骤2：按照分区编号由小到大依次将每个分区中的数据写入任务工作目录下的临时文件<code>output/spillN.out</code>（N表示当前溢写次数）中。如果用户设置了Combiner，则写入文件之前，对每个分区中的数据进行一次聚集操作。</p>
<p>步骤3：将分区数据的元信息写到内存索引数据结构SpillRecord中，其中每个分区的元信息包括在临时文件中的偏移量、压缩前数据大小和压缩后数据大小。如果当前内存索引大小超过1MB，则将内存索引写到文件<code>output/spillN.out.index</code>中。</p>
<p>-（5）Combine阶段：当所有数据处理完成后，MapTask对所有临时文件进行一次合并，以确保最终只会生成一个数据文件。</p>
<p>当所有数据处理完后，MapTask会将所有临时文件合并成一个大文件，并保存到文件<code>output/file.out</code>中，同时生成相应的索引文件<code>output/file.out.index</code>。</p>
<p>在进行文件合并过程中，MapTask以分区为单位进行合并。对于某个分区，它将采用多轮递归合并的方式。每轮合并<code>io.sort.factor</code>（默认10）个文件，并将产生的文件重新加入待合并列表中，对文件排序后，重复以上过程，直到最终得到一个大文件。</p>
<p>让每个MapTask最终只生成一个数据文件，可避免同时打开大量文件和同时读取大量小文件产生的随机读取带来的开销。</p>
<h2 id="ReduceTask工作机制"><a href="#ReduceTask工作机制" class="headerlink" title="ReduceTask工作机制"></a>ReduceTask工作机制</h2><h3 id="ReduceTask工作机制-1"><a href="#ReduceTask工作机制-1" class="headerlink" title="ReduceTask工作机制"></a>ReduceTask工作机制</h3><img src="/2020/10/30/Hadoop-MapReduce%E8%AF%A6%E8%A7%A3-2/ReduceTask%E5%B7%A5%E4%BD%9C%E6%9C%BA%E5%88%B6.png" class="" title="ReduceTask工作机制">
<ul>
<li><p>（1）Copy阶段：ReduceTask从各个MapTask上远程拷贝一片数据，并针对某一片数据，如果其大小超过一定阈值，则写到磁盘上，否则直接放到内存中。</p>
</li>
<li><p>（2）Merge阶段：在远程拷贝数据的同时，ReduceTask启动了两个后台线程对内存和磁盘上的文件进行合并，以防止内存使用过多或磁盘上文件过多。</p>
</li>
<li><p>（3）Sort阶段：按照MapReduce语义，用户编写<code>reduce()</code>函数输入数据是按key进行聚集的一组数据。为了将key相同的数据聚在一起，Hadoop采用了基于排序的策略。由于各个MapTask已经实现对自己的处理结果进行了局部排序，因此，ReduceTask只需对所有数据进行一次<code>归并排序</code>即可。</p>
</li>
<li><p>（4）Reduce阶段：<code>reduce()</code>函数将计算结果写到HDFS上。</p>
</li>
</ul>
<h3 id="设置ReduceTask并行度（个数）"><a href="#设置ReduceTask并行度（个数）" class="headerlink" title="设置ReduceTask并行度（个数）"></a>设置ReduceTask并行度（个数）</h3><p>ReduceTask的并行度同样影响整个Job的执行并发度和执行效率，但与MapTask的并发数由切片数决定不同，ReduceTask数量的决定是可以直接手动设置：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 默认值是1，手动设置为4</span></span><br><span class="line">job.setNumReduceTasks(<span class="number">4</span>);</span><br></pre></td></tr></table></figure>
<h3 id="实验：测试ReduceTask多少合适"><a href="#实验：测试ReduceTask多少合适" class="headerlink" title="实验：测试ReduceTask多少合适"></a>实验：测试ReduceTask多少合适</h3><p>（1）实验环境：1个Master节点，16个Slave节点：CPU:8GHZ，内存: 2G，数据量为1G。<br>（2）实验结论：</p>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center">MapTask =16</th>
<th style="text-align:center"></th>
<th style="text-align:center"></th>
<th style="text-align:center"></th>
<th style="text-align:center"></th>
<th style="text-align:center"></th>
<th style="text-align:center"></th>
<th style="text-align:center"></th>
<th style="text-align:center"></th>
<th style="text-align:center"></th>
<th style="text-align:center"></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">ReduceTask</td>
<td style="text-align:center">1</td>
<td style="text-align:center">5</td>
<td style="text-align:center">10</td>
<td style="text-align:center">15</td>
<td style="text-align:center">16</td>
<td style="text-align:center">20</td>
<td style="text-align:center">25</td>
<td style="text-align:center">30</td>
<td style="text-align:center">45</td>
<td style="text-align:center">60</td>
</tr>
<tr>
<td style="text-align:center">总时间</td>
<td style="text-align:center">892</td>
<td style="text-align:center">146</td>
<td style="text-align:center">110</td>
<td style="text-align:center">92</td>
<td style="text-align:center">88</td>
<td style="text-align:center">100</td>
<td style="text-align:center">128</td>
<td style="text-align:center">101</td>
<td style="text-align:center">145</td>
<td style="text-align:center">104</td>
</tr>
</tbody>
</table>
</div>
<p>实验结果符合正态分布，个数和集群环境因素有关。</p>
<h3 id="注意事项"><a href="#注意事项" class="headerlink" title="注意事项"></a>注意事项</h3><p>-（1）<code>ReduceTask=0</code>, 表示没有Reduce阶段，输出文件个数和Map个数一致。</p>
<p>-（2）ReduceTask默认值就是1， 所以输出文件个数为一个。</p>
<p>-（3）如果数据分布不均匀，就有可能在Reduce阶段产生数据倾斜。</p>
<p>-（4）ReduceTask数量并不是任意设置，还要考虑业务逻辑需求，有些情况下，需要计算全局汇总结果，就只能有1个ReduceTask。</p>
<p>-（5）具体多少个ReduceTask，需要根据集群性能而定。</p>
<p>-（6）如果分区数不是1，但是ReduceTask为1， 是否执行分区过程。答案是：不执行分区过程。因为在MapTask的源码中，执行分区的前提是先判断ReduceNum个数是否大于1。不大于1肯定不执行。</p>
<h2 id="OutputFormat数据输出"><a href="#OutputFormat数据输出" class="headerlink" title="OutputFormat数据输出"></a>OutputFormat数据输出</h2><h3 id="OutputFormat接口实现类"><a href="#OutputFormat接口实现类" class="headerlink" title="OutputFormat接口实现类"></a>OutputFormat接口实现类</h3><p>OutputFornat是MapReduce输出的基类，所有实现MapReduce输出都实现了OutputFormat接口。下面我们介 绍几种常见的OutputFormat实现类。</p>
<p>1.文本输出<code>TextOutputFormat</code></p>
<p>默认的输出格式是’TextOutputFomat，它把<code>每条记录写为文本行</code>。它的键和值可以是任意类型，因为TextOutputFormat调 用toString(方法把它们转换为字符串。</p>
<ol>
<li><code>SequenceFileOutputFormat</code></li>
</ol>
<p>将SequenceFileOutputFormat输出作为后续MapReduce任务的输入，这便是一种好的输出格式，因为它的格式紧凑，很容易被压缩。</p>
<p>3.自定义<code>OutputFormat</code></p>
<p>根据用户需求，自定义实现输出。</p>
<h3 id="自定义OutputFromat"><a href="#自定义OutputFromat" class="headerlink" title="自定义OutputFromat"></a>自定义OutputFromat</h3><h4 id="使用场景"><a href="#使用场景" class="headerlink" title="使用场景"></a>使用场景</h4><p>为了试验控制最终该文件的输出路径和输出格式，可以自定义OutputFormat。</p>
<p>例如：要在一个MapReduce程序中根据数据的不同输出两类结果到不同目录，这类灵活的输出需求可以通过自定义OutPutForamt来实现。</p>
<h4 id="自定义OutputFormat步骤"><a href="#自定义OutputFormat步骤" class="headerlink" title="自定义OutputFormat步骤"></a>自定义OutputFormat步骤</h4><p>（1）自定义一个类继承FileOutputFormat。<br>（2）改写RecordWriter，具体改写输出数据的方法<code>write()</code>。</p>
<h3 id="自定义OutputFormat案例实操"><a href="#自定义OutputFormat案例实操" class="headerlink" title="自定义OutputFormat案例实操"></a>自定义OutputFormat案例实操</h3><h4 id="需求分析-8"><a href="#需求分析-8" class="headerlink" title="需求分析"></a>需求分析</h4><h5 id="需求-5"><a href="#需求-5" class="headerlink" title="需求"></a>需求</h5><p>过滤输入的log日志，包含atguigu的网站输出到<code>f:/IDEAWS/dashuju/atguigu.log</code>，不包含atguigu的网站输出到<code>f:/IDEAWS/dashuju/other.log</code>。</p>
<h5 id="输入数据"><a href="#输入数据" class="headerlink" title="输入数据"></a>输入数据</h5><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">http://www.baidu.com</span><br><span class="line">http://www.google.com</span><br><span class="line">http://cn.bing.com</span><br><span class="line">http://www.atguigu.com</span><br><span class="line">http://www.sohu.com</span><br><span class="line">http://www.sina.com</span><br><span class="line">http://www.sin2a.com</span><br><span class="line">http://www.sin2desa.com</span><br><span class="line">http://www.sindsafa.com</span><br></pre></td></tr></table></figure>
<h5 id="期望输出数据"><a href="#期望输出数据" class="headerlink" title="期望输出数据"></a>期望输出数据</h5><p><code>atguigu.log</code></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">http://www.atguigu.com</span><br></pre></td></tr></table></figure>
<p><code>other.log</code></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">http://cn.bing.com</span><br><span class="line">http://www.baidu.com</span><br><span class="line">http://www.google.com</span><br><span class="line">http://www.sin2a.com</span><br><span class="line">http://www.sin2desa.com</span><br><span class="line">http://www.sina.com</span><br><span class="line">http://www.sindsafa.com</span><br><span class="line">http://www.sohu.com</span><br></pre></td></tr></table></figure>
<h5 id="自定义一个OutputFormat类"><a href="#自定义一个OutputFormat类" class="headerlink" title="自定义一个OutputFormat类"></a>自定义一个OutputFormat类</h5><p>（1）创建一个类FileRecordWriter继承RecordWriter</p>
<p>（a）创建两个文件的输出流：atguiguOut、otherOut；<br>（b）如果输入数据包含atguigu，输出到atguiguOut流；如果不包含atguigu，输出到otherOut流。</p>
<h5 id="驱动类Driver"><a href="#驱动类Driver" class="headerlink" title="驱动类Driver"></a>驱动类Driver</h5><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//要将自定义的输出格式组件设置到job中</span></span><br><span class="line">job.setOutputFormatClass(FilterOutputFormat.class);</span><br></pre></td></tr></table></figure>
<h4 id="案例实操-1"><a href="#案例实操-1" class="headerlink" title="案例实操"></a>案例实操</h4><ul>
<li>（1）编写FilterMapper类</li>
</ul>
<p><code>FilterMapper.java</code></p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.atguigu.mr.outputformat;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.LongWritable;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.NullWritable;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.Text;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Mapper;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">FilterMapper</span> <span class="keyword">extends</span> <span class="title class_">Mapper</span>&lt;LongWritable, Text, Text, NullWritable&gt; &#123;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">protected</span> <span class="keyword">void</span> <span class="title function_">map</span><span class="params">(LongWritable key, Text value, Context context)</span> <span class="keyword">throws</span> IOException, InterruptedException &#123;</span><br><span class="line"></span><br><span class="line">        context.write(value, NullWritable.get());</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<ul>
<li>（2）编写FilterReducer类</li>
</ul>
<p><code>FilterReducer.java</code></p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.atguigu.mr.outputformat;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.NullWritable;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.Text;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Reducer;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">FilterReducer</span> <span class="keyword">extends</span> <span class="title class_">Reducer</span>&lt;Text, NullWritable, Text, NullWritable&gt; &#123;</span><br><span class="line">    <span class="type">Text</span> <span class="variable">k</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Text</span>();</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">protected</span> <span class="keyword">void</span> <span class="title function_">reduce</span><span class="params">(Text key, Iterable&lt;NullWritable&gt; values, Context context)</span> <span class="keyword">throws</span> IOException, InterruptedException &#123;</span><br><span class="line">        <span class="comment">//防止输出为一行</span></span><br><span class="line">        <span class="type">String</span> <span class="variable">line</span> <span class="operator">=</span> key.toString();</span><br><span class="line">        line = line + <span class="string">&quot;\r\n&quot;</span>;</span><br><span class="line">        k.set(line);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//防止有重复的数据</span></span><br><span class="line">        <span class="keyword">for</span> (NullWritable nullWritable : values) &#123;</span><br><span class="line">            context.write(k, NullWritable.get());</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<ul>
<li>（3）自定义一个OutputFormat类</li>
</ul>
<p><code>FilterOutputFormat.java</code></p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.atguigu.mr.outputformat;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.NullWritable;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.Text;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.RecordWriter;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.TaskAttemptContext;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">FilterOutputFormat</span> <span class="keyword">extends</span> <span class="title class_">FileOutputFormat</span>&lt;Text, NullWritable&gt; &#123;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> RecordWriter&lt;Text, NullWritable&gt; <span class="title function_">getRecordWriter</span><span class="params">(TaskAttemptContext taskAttemptContext)</span> <span class="keyword">throws</span> IOException, InterruptedException &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">new</span> <span class="title class_">FRecordWriter</span>(taskAttemptContext);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<ul>
<li>（4）编写RecordWriter类</li>
</ul>
<p><code>FRecordWriter.java</code></p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.atguigu.mr.outputformat;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.fs.FSDataOutputStream;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.fs.FileSystem;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.fs.Path;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.IOUtils;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.NullWritable;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.Text;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.RecordWriter;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.TaskAttemptContext;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">FRecordWriter</span> <span class="keyword">extends</span> <span class="title class_">RecordWriter</span>&lt;Text, NullWritable&gt; &#123;</span><br><span class="line">    FSDataOutputStream fosatguigu;</span><br><span class="line">    FSDataOutputStream fosother;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="title function_">FRecordWriter</span><span class="params">(TaskAttemptContext job)</span> &#123;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            <span class="comment">// 1获取文件形同</span></span><br><span class="line">            <span class="type">FileSystem</span> <span class="variable">fs</span> <span class="operator">=</span> FileSystem.get(job.getConfiguration());</span><br><span class="line"></span><br><span class="line">            <span class="comment">// 2创建输出到atguigu.log的输出流</span></span><br><span class="line">            fosatguigu = fs.create(<span class="keyword">new</span> <span class="title class_">Path</span>(<span class="string">&quot;f:/IDEAWS/dashju/atguigu.log&quot;</span>));</span><br><span class="line"></span><br><span class="line">            <span class="comment">// 3创建输出到other.log的输出流</span></span><br><span class="line">            fosother = fs.create(<span class="keyword">new</span> <span class="title class_">Path</span>(<span class="string">&quot;f:/IDEAWS/dashju/other.log&quot;</span>));</span><br><span class="line"></span><br><span class="line">        &#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">write</span><span class="params">(Text text, NullWritable nullWritable)</span> <span class="keyword">throws</span> IOException, InterruptedException &#123;</span><br><span class="line">        <span class="comment">// 判断key当中是否有atguigu</span></span><br><span class="line">        <span class="keyword">if</span> (text.toString().contains(<span class="string">&quot;atguigu&quot;</span>)) &#123;</span><br><span class="line">            <span class="comment">// atguigu输出流</span></span><br><span class="line">            fosatguigu.write(text.toString().getBytes());</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            fosother.write(text.toString().getBytes());</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">close</span><span class="params">(TaskAttemptContext taskAttemptContext)</span> <span class="keyword">throws</span> IOException, InterruptedException &#123;</span><br><span class="line">        IOUtils.closeStream(fosatguigu);</span><br><span class="line">        IOUtils.closeStream(fosother);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<ul>
<li>（5）编写FilterDriver类</li>
</ul>
<p><code>FilterDrvier.java</code></p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.atguigu.mr.outputformat;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.conf.Configuration;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.fs.Path;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.NullWritable;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.Text;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Job;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.lib.input.FileInputFormat;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">FilterDrvier</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> IOException, ClassNotFoundException, InterruptedException &#123;</span><br><span class="line">        <span class="comment">// 输入输出路径需要根据自己电脑上实际的输入输出路径设置</span></span><br><span class="line">        args = <span class="keyword">new</span> <span class="title class_">String</span>[]&#123;<span class="string">&quot;F:/IDEAWS/dashju/inputformat&quot;</span>, <span class="string">&quot;F:/IDEAWS/dashju/outputformat&quot;</span>&#125;;</span><br><span class="line"></span><br><span class="line">        <span class="type">Configuration</span> <span class="variable">conf</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Configuration</span>();</span><br><span class="line">        <span class="type">Job</span> <span class="variable">job</span> <span class="operator">=</span> Job.getInstance(conf);</span><br><span class="line"></span><br><span class="line">        job.setJarByClass(FilterDrvier.class);</span><br><span class="line">        job.setMapperClass(FilterMapper.class);</span><br><span class="line">        job.setReducerClass(FilterReducer.class);</span><br><span class="line"></span><br><span class="line">        job.setMapOutputKeyClass(Text.class);</span><br><span class="line">        job.setMapOutputValueClass(NullWritable.class);</span><br><span class="line"></span><br><span class="line">        job.setOutputKeyClass(Text.class);</span><br><span class="line">        job.setOutputValueClass(NullWritable.class);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 要将自定义的输出格式组件设置到job中</span></span><br><span class="line">        job.setOutputFormatClass(FilterOutputFormat.class);</span><br><span class="line"></span><br><span class="line">        FileInputFormat.setInputPaths(job, <span class="keyword">new</span> <span class="title class_">Path</span>(args[<span class="number">0</span>]));</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 虽然我们自定义了outputformat，但是因为我们的outputformat继承自fileoutputformat</span></span><br><span class="line">        <span class="comment">// 而fileoutputformat要输出一个_SUCCESS文件，所以，在这还得指定一个输出目录</span></span><br><span class="line">        FileOutputFormat.setOutputPath(job, <span class="keyword">new</span> <span class="title class_">Path</span>(args[<span class="number">1</span>]));</span><br><span class="line"></span><br><span class="line">        <span class="type">boolean</span> <span class="variable">result</span> <span class="operator">=</span> job.waitForCompletion(<span class="literal">true</span>);</span><br><span class="line">        System.exit(result ? <span class="number">0</span> : <span class="number">1</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="Join多种应用"><a href="#Join多种应用" class="headerlink" title="Join多种应用"></a>Join多种应用</h2><h3 id="Reduce-Join"><a href="#Reduce-Join" class="headerlink" title="Reduce Join"></a>Reduce Join</h3><ul>
<li>工作原理</li>
</ul>
<p>Map端的主要工作：为来自不同表或文件的key/value对，<code>打标签以区别不同来源的记录</code>。然后用连接字段作为key，其余部分和新加的标志作为value，最后进行输出。</p>
<p>Reduce端的主要工作：在Reduce端以连接字段作为key的分组已经完成，我们只需要在每一个分组当中将那些<code>来源于不同文件的记录(在Map阶段已经打标志)分开</code>，最后进行台并就k了。</p>
<ul>
<li>缺点</li>
</ul>
<p>合并操作在reduce阶段完成，压力大，map端负载率极低，资源利用率不高，极易在reduce阶段产生数据倾斜。</p>
<h3 id="Reduce-Join案例实操"><a href="#Reduce-Join案例实操" class="headerlink" title="Reduce Join案例实操"></a>Reduce Join案例实操</h3><h4 id="需求分析-9"><a href="#需求分析-9" class="headerlink" title="需求分析"></a>需求分析</h4><p>通过将关联条件作为Map输出的key，将两表满足Join条件的数据并携带数据所来源的文件信息，发往同一个ReduceTask，在Reduce中进行数据的串联，</p>
<h5 id="需求-6"><a href="#需求-6" class="headerlink" title="需求"></a>需求</h5><p>将商品信息表中数据根据商品pid合并到订单数据表中。</p>
<h5 id="输入数据-1"><a href="#输入数据-1" class="headerlink" title="输入数据"></a>输入数据</h5><ul>
<li>订单数据表</li>
</ul>
<p><code>order.txt - t_order</code></p>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center">id</th>
<th style="text-align:center">pid</th>
<th style="text-align:center">amount</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">1001</td>
<td style="text-align:center">01</td>
<td style="text-align:center">1</td>
</tr>
<tr>
<td style="text-align:center">1002</td>
<td style="text-align:center">02</td>
<td style="text-align:center">2</td>
</tr>
<tr>
<td style="text-align:center">1003</td>
<td style="text-align:center">03</td>
<td style="text-align:center">3</td>
</tr>
<tr>
<td style="text-align:center">1004</td>
<td style="text-align:center">01</td>
<td style="text-align:center">4</td>
</tr>
<tr>
<td style="text-align:center">1005</td>
<td style="text-align:center">02</td>
<td style="text-align:center">5</td>
</tr>
<tr>
<td style="text-align:center">1006</td>
<td style="text-align:center">03</td>
<td style="text-align:center">6</td>
</tr>
</tbody>
</table>
</div>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">1001	01	1</span><br><span class="line">1002	02	2</span><br><span class="line">1003	03	3</span><br><span class="line">1004	01	4</span><br><span class="line">1005	02	5</span><br><span class="line">1006	03	6</span><br></pre></td></tr></table></figure>
<ul>
<li>商品数据表</li>
</ul>
<p><code>pd.txt - t_product</code></p>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center">pid</th>
<th style="text-align:center">pname</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">01</td>
<td style="text-align:center">小米</td>
</tr>
<tr>
<td style="text-align:center">02</td>
<td style="text-align:center">华为</td>
</tr>
<tr>
<td style="text-align:center">03</td>
<td style="text-align:center">格力</td>
</tr>
</tbody>
</table>
</div>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">01	小米</span><br><span class="line">02	华为</span><br><span class="line">03	格力</span><br></pre></td></tr></table></figure>
<h5 id="输出数据"><a href="#输出数据" class="headerlink" title="输出数据"></a>输出数据</h5><div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center">id</th>
<th style="text-align:center">pname</th>
<th style="text-align:center">amount</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">1001</td>
<td style="text-align:center">小米</td>
<td style="text-align:center">1</td>
</tr>
<tr>
<td style="text-align:center">1004</td>
<td style="text-align:center">小米</td>
<td style="text-align:center">4</td>
</tr>
<tr>
<td style="text-align:center">1002</td>
<td style="text-align:center">华为</td>
<td style="text-align:center">2</td>
</tr>
<tr>
<td style="text-align:center">1005</td>
<td style="text-align:center">华为</td>
<td style="text-align:center">5</td>
</tr>
<tr>
<td style="text-align:center">1003</td>
<td style="text-align:center">格力</td>
<td style="text-align:center">3</td>
</tr>
<tr>
<td style="text-align:center">1006</td>
<td style="text-align:center">格力</td>
<td style="text-align:center">6</td>
</tr>
</tbody>
</table>
</div>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">id	pname	amount</span><br><span class="line">1001	小米	1</span><br><span class="line">1004	小米	4</span><br><span class="line">1002	华为	2</span><br><span class="line">1005	华为	5</span><br><span class="line">1003	格力	3</span><br><span class="line">1006	格力	6</span><br></pre></td></tr></table></figure>
<h5 id="MapTask"><a href="#MapTask" class="headerlink" title="MapTask"></a>MapTask</h5><ul>
<li>Map中处理的事情</li>
</ul>
<p>获取输入文件类型<br>获取输入数据<br>不同文件分别处理<br>封装Bean对象输出</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">01	1001	1	order</span><br><span class="line">02	1002	2	order</span><br><span class="line">03	1003	3	order</span><br><span class="line"></span><br><span class="line">01	1001	1	order</span><br><span class="line">02	1002	2	order</span><br><span class="line">03	1003	3	order</span><br><span class="line"></span><br><span class="line">01	小米			pd</span><br><span class="line">02	华为			pd</span><br><span class="line">03	格力			pd</span><br></pre></td></tr></table></figure>
<ul>
<li>默认对产品id排序</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">01	1001	1	order</span><br><span class="line">01	1001	1	order</span><br><span class="line">01	小米			pd</span><br><span class="line"></span><br><span class="line">02	1002	2	order</span><br><span class="line">02	1002	2	order</span><br><span class="line">02	华为			pd</span><br><span class="line"></span><br><span class="line">03	1003	3	order</span><br><span class="line">03	1003	3	order</span><br><span class="line">03	格力			pd</span><br></pre></td></tr></table></figure>
<h5 id="ReduceTask"><a href="#ReduceTask" class="headerlink" title="ReduceTask"></a>ReduceTask</h5><p>缓存订单数据集合和产品表，然后合并</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">订单id	产品名称	数量</span><br><span class="line">1001	小米		1</span><br><span class="line">1001	小米		1</span><br><span class="line"></span><br><span class="line">1002	华为		2</span><br><span class="line">1002	华为		2</span><br><span class="line"></span><br><span class="line">1003	格力		3</span><br><span class="line">1003	格力		3</span><br></pre></td></tr></table></figure>
<h4 id="代码实现-2"><a href="#代码实现-2" class="headerlink" title="代码实现"></a>代码实现</h4><ul>
<li>1）创建商品和订合并后的Bean类</li>
</ul>
<p><code>TableBean.java</code></p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.atguigu.mr.table;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.Writable;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.io.DataInput;</span><br><span class="line"><span class="keyword">import</span> java.io.DataOutput;</span><br><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">TableBean</span> <span class="keyword">implements</span> <span class="title class_">Writable</span> &#123;</span><br><span class="line">    <span class="keyword">private</span> String id;  <span class="comment">//订单id</span></span><br><span class="line">    <span class="keyword">private</span> String pid; <span class="comment">//产品id</span></span><br><span class="line">    <span class="keyword">private</span> <span class="type">int</span> amount; <span class="comment">//产品数量</span></span><br><span class="line">    <span class="keyword">private</span> String pname;   <span class="comment">//产品名称</span></span><br><span class="line">    <span class="keyword">private</span> String flag;    <span class="comment">//标记，订单表or产品表</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="title function_">TableBean</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="built_in">super</span>();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="title function_">TableBean</span><span class="params">(String id, String pid, <span class="type">int</span> amount, String pname, String flag)</span> &#123;</span><br><span class="line">        <span class="built_in">this</span>.id = id;</span><br><span class="line">        <span class="built_in">this</span>.pid = pid;</span><br><span class="line">        <span class="built_in">this</span>.amount = amount;</span><br><span class="line">        <span class="built_in">this</span>.pname = pname;</span><br><span class="line">        <span class="built_in">this</span>.flag = flag;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> String <span class="title function_">getId</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> id;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> String <span class="title function_">getPid</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> pid;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="type">int</span> <span class="title function_">getAmount</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> amount;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> String <span class="title function_">getPname</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> pname;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> String <span class="title function_">getFlag</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> flag;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">setId</span><span class="params">(String id)</span> &#123;</span><br><span class="line">        <span class="built_in">this</span>.id = id;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">setPid</span><span class="params">(String pid)</span> &#123;</span><br><span class="line">        <span class="built_in">this</span>.pid = pid;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">setAmount</span><span class="params">(<span class="type">int</span> amount)</span> &#123;</span><br><span class="line">        <span class="built_in">this</span>.amount = amount;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">setPname</span><span class="params">(String pname)</span> &#123;</span><br><span class="line">        <span class="built_in">this</span>.pname = pname;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">setFlag</span><span class="params">(String flag)</span> &#123;</span><br><span class="line">        <span class="built_in">this</span>.flag = flag;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> String <span class="title function_">toString</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> id + <span class="string">&quot;\t&quot;</span> + amount + <span class="string">&quot;\t&quot;</span> + pname;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//序列化方法</span></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">write</span><span class="params">(DataOutput out)</span> <span class="keyword">throws</span> IOException &#123;</span><br><span class="line">        out.writeUTF(id);</span><br><span class="line">        out.writeUTF(pid);</span><br><span class="line">        out.writeInt(amount);</span><br><span class="line">        out.writeUTF(pname);</span><br><span class="line">        out.writeUTF(flag);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//反序列化方法</span></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">readFields</span><span class="params">(DataInput in)</span> <span class="keyword">throws</span> IOException &#123;</span><br><span class="line">        id = in.readUTF();</span><br><span class="line">        pid = in.readUTF();</span><br><span class="line">        amount = in.readInt();</span><br><span class="line">        pname = in.readUTF();</span><br><span class="line">        flag = in.readUTF();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<ul>
<li>2）编写TableMapper类</li>
</ul>
<p><code>TableMapper.java</code></p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.atguigu.mr.table;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.LongWritable;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.Text;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Mapper;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.lib.input.FileSplit;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">TableMapper</span> <span class="keyword">extends</span> <span class="title class_">Mapper</span>&lt;LongWritable, Text, Text, TableBean&gt; &#123;</span><br><span class="line">    String name;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//获取文件切片，用于区分表类型</span></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">protected</span> <span class="keyword">void</span> <span class="title function_">setup</span><span class="params">(Context context)</span> <span class="keyword">throws</span> IOException, InterruptedException &#123;</span><br><span class="line">        <span class="comment">//获取文件的名称</span></span><br><span class="line">        <span class="type">FileSplit</span> <span class="variable">inputSplit</span> <span class="operator">=</span> (FileSplit) context.getInputSplit();</span><br><span class="line">        name = inputSplit.getPath().getName();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="type">TableBean</span> <span class="variable">tableBean</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">TableBean</span>();</span><br><span class="line">    <span class="type">Text</span> <span class="variable">k</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Text</span>();</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">protected</span> <span class="keyword">void</span> <span class="title function_">map</span><span class="params">(LongWritable key, Text value, Context context)</span> <span class="keyword">throws</span> IOException, InterruptedException &#123;</span><br><span class="line">        <span class="comment">//id	pid	amount</span></span><br><span class="line">        <span class="comment">//1001	01	1</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">//pid	pname</span></span><br><span class="line">        <span class="comment">//01	小米</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">// 1 读取一行</span></span><br><span class="line">        <span class="type">String</span> <span class="variable">line</span> <span class="operator">=</span> value.toString();</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 2 封装对象</span></span><br><span class="line">        <span class="keyword">if</span> (name.startsWith(<span class="string">&quot;order&quot;</span>)) &#123; <span class="comment">//认为订单表</span></span><br><span class="line">            String[] splits = line.split(<span class="string">&quot;\t&quot;</span>);</span><br><span class="line"></span><br><span class="line">            tableBean.setId(splits[<span class="number">0</span>]); <span class="comment">//订单id</span></span><br><span class="line">            tableBean.setPid(splits[<span class="number">1</span>]);    <span class="comment">//产品id</span></span><br><span class="line">            tableBean.setAmount(Integer.parseInt(splits[<span class="number">2</span>]));   <span class="comment">//商品数量</span></span><br><span class="line">            tableBean.setPname(<span class="string">&quot;&quot;</span>);  <span class="comment">//补全序列化</span></span><br><span class="line">            tableBean.setFlag(<span class="string">&quot;order&quot;</span>); <span class="comment">//区分表标记</span></span><br><span class="line"></span><br><span class="line">            k.set(splits[<span class="number">1</span>]);</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;  <span class="comment">//认为产品表</span></span><br><span class="line">            String[] splits = line.split(<span class="string">&quot;\t&quot;</span>);</span><br><span class="line"></span><br><span class="line">            tableBean.setId(<span class="string">&quot;&quot;</span>); <span class="comment">//补全序列化</span></span><br><span class="line">            tableBean.setPid(splits[<span class="number">0</span>]);    <span class="comment">//产品id</span></span><br><span class="line">            tableBean.setAmount(<span class="number">0</span>);   <span class="comment">//补全序列化</span></span><br><span class="line">            tableBean.setPname(splits[<span class="number">1</span>]);  <span class="comment">//产品名称</span></span><br><span class="line">            tableBean.setFlag(<span class="string">&quot;pd&quot;</span>); <span class="comment">//区分表标记</span></span><br><span class="line"></span><br><span class="line">            k.set(splits[<span class="number">0</span>]);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 3 写出</span></span><br><span class="line">        context.write(k, tableBean);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<ul>
<li>3）编写TableReducer类</li>
</ul>
<p><code>TableReducer.java</code></p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.atguigu.mr.table;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.commons.beanutils.BeanUtils;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.NullWritable;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.Text;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Reducer;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"><span class="keyword">import</span> java.lang.reflect.InvocationTargetException;</span><br><span class="line"><span class="keyword">import</span> java.util.ArrayList;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">TableReducer</span> <span class="keyword">extends</span> <span class="title class_">Reducer</span>&lt;Text, TableBean, TableBean, NullWritable&gt; &#123;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">protected</span> <span class="keyword">void</span> <span class="title function_">reduce</span><span class="params">(Text key, Iterable&lt;TableBean&gt; values, Context context)</span> <span class="keyword">throws</span> IOException, InterruptedException &#123;</span><br><span class="line">        <span class="comment">// 1 准备存储订单的集合</span></span><br><span class="line">        ArrayList&lt;TableBean&gt; orderBeans = <span class="keyword">new</span> <span class="title class_">ArrayList</span>&lt;&gt;();</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 2 准备bean对象</span></span><br><span class="line">        <span class="type">TableBean</span> <span class="variable">pdBean</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">TableBean</span>();</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> (TableBean bean : values) &#123;</span><br><span class="line">            <span class="keyword">if</span> (<span class="string">&quot;order&quot;</span>.equals(bean.getFlag())) &#123;   <span class="comment">//订单表</span></span><br><span class="line">                <span class="comment">//拷贝传递过来的每条订单数据到集合中</span></span><br><span class="line">                <span class="type">TableBean</span> <span class="variable">tempBean</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">TableBean</span>();</span><br><span class="line">                <span class="keyword">try</span> &#123;</span><br><span class="line">                    BeanUtils.copyProperties(tempBean, bean);<span class="comment">//深拷贝</span></span><br><span class="line">                &#125; <span class="keyword">catch</span> (IllegalAccessException e) &#123;</span><br><span class="line">                    e.printStackTrace();</span><br><span class="line">                &#125; <span class="keyword">catch</span> (InvocationTargetException e) &#123;</span><br><span class="line">                    e.printStackTrace();</span><br><span class="line">                &#125;</span><br><span class="line"></span><br><span class="line">                orderBeans.add(tempBean);</span><br><span class="line">            &#125; <span class="keyword">else</span> &#123;    <span class="comment">//产品表</span></span><br><span class="line">                <span class="keyword">try</span> &#123;</span><br><span class="line">                    BeanUtils.copyProperties(pdBean, bean);<span class="comment">//深拷贝</span></span><br><span class="line">                &#125; <span class="keyword">catch</span> (IllegalAccessException e) &#123;</span><br><span class="line">                    e.printStackTrace();</span><br><span class="line">                &#125; <span class="keyword">catch</span> (InvocationTargetException e) &#123;</span><br><span class="line">                    e.printStackTrace();</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> (TableBean bean : orderBeans) &#123;</span><br><span class="line">            <span class="comment">// 3 表的拼接</span></span><br><span class="line">            bean.setPname(pdBean.getPname());</span><br><span class="line"></span><br><span class="line">            <span class="comment">// 4 数据写出</span></span><br><span class="line">            context.write(bean, NullWritable.get());</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<ul>
<li>4）编写TableDriver类</li>
</ul>
<p><code>TableDriver.java</code></p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.atguigu.mr.table;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.conf.Configuration;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.fs.Path;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.NullWritable;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.Text;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Job;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.lib.input.FileInputFormat;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">TableDriver</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> IOException, ClassNotFoundException, InterruptedException &#123;</span><br><span class="line">        <span class="comment">// 0 根据自己电脑路径重新配置</span></span><br><span class="line">        args = <span class="keyword">new</span> <span class="title class_">String</span>[]&#123;<span class="string">&quot;F:/IDEAWS/dashju/inputtable&quot;</span>, <span class="string">&quot;F:/IDEAWS/dashju/outputtable&quot;</span>&#125;;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 1 获取配置信息，或者job对象实例</span></span><br><span class="line">        <span class="type">Configuration</span> <span class="variable">configuration</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Configuration</span>();</span><br><span class="line">        <span class="type">Job</span> <span class="variable">job</span> <span class="operator">=</span> Job.getInstance(configuration);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 2 指定本程序的jar包所在的本地路径</span></span><br><span class="line">        job.setJarByClass(TableDriver.class);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 3 指定本业务job要使用的Mapper/Reducer业务类</span></span><br><span class="line">        job.setMapperClass(TableMapper.class);</span><br><span class="line">        job.setReducerClass(TableReducer.class);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 4 指定Mapper输出数据的kv类型</span></span><br><span class="line">        job.setMapOutputKeyClass(Text.class);</span><br><span class="line">        job.setMapOutputValueClass(TableBean.class);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 5 指定最终输出的数据的kv类型</span></span><br><span class="line">        job.setOutputKeyClass(TableBean.class);</span><br><span class="line">        job.setOutputValueClass(NullWritable.class);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 6 指定job的输入原始文件所在目录</span></span><br><span class="line">        FileInputFormat.setInputPaths(job, <span class="keyword">new</span> <span class="title class_">Path</span>(args[<span class="number">0</span>]));</span><br><span class="line">        FileOutputFormat.setOutputPath(job, <span class="keyword">new</span> <span class="title class_">Path</span>(args[<span class="number">1</span>]));</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 7 将job中配置的相关参数，以及job所用的java类所在的jar包， 提交给yarn去运行</span></span><br><span class="line">        <span class="type">boolean</span> <span class="variable">result</span> <span class="operator">=</span> job.waitForCompletion(<span class="literal">true</span>);</span><br><span class="line">        System.exit(result ? <span class="number">0</span> : <span class="number">1</span>);</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="Map-Join"><a href="#Map-Join" class="headerlink" title="Map Join"></a>Map Join</h3><h4 id="使用场景-1"><a href="#使用场景-1" class="headerlink" title="使用场景"></a>使用场景</h4><p>Map Join适用于一张表十分小、一张表很大的场景。</p>
<h4 id="优点"><a href="#优点" class="headerlink" title="优点"></a>优点</h4><p>思考：在Reduce端处理过多的表，非常容易产生数据倾斜。怎么办？<br>在Map端缓存多张表，提前处理业务逻辑，这样增加Map端业务，减少Reduce端数据的压力，尽可能的减少数据倾斜。</p>
<h4 id="具体办法：采用DistributedCache"><a href="#具体办法：采用DistributedCache" class="headerlink" title="具体办法：采用DistributedCache"></a>具体办法：采用DistributedCache</h4><p>（1）在Mapper的setup阶段，将文件读取到缓存集合中。<br>（2）在驱动函数中加载缓存。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 缓存普通文件到Task运行节点。</span></span><br><span class="line">job.addCacheFile(<span class="keyword">new</span> <span class="title class_">URI</span>(<span class="string">&quot;file://e:/IDEAWS/dashju/inputtable/pd.txt&quot;</span>));</span><br></pre></td></tr></table></figure>
<h4 id="需求分析-10"><a href="#需求分析-10" class="headerlink" title="需求分析"></a>需求分析</h4><h5 id="需求-7"><a href="#需求-7" class="headerlink" title="需求"></a>需求</h5><p>同redece join</p>
<p>1）DistributedCacheDriver 缓存文件</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 1 加载缓存数据</span></span><br><span class="line">job.addCacheFile(<span class="keyword">new</span> <span class="title class_">URI</span>(<span class="string">&quot;file://e:/IDEAWS/dashju/inputtable/pd.txt&quot;</span>));</span><br><span class="line"><span class="comment">// 2 Map端join的逻辑不需要Reduce阶段，设置ReduceTask数量为0</span></span><br><span class="line">job.setNumReduceTasks(<span class="number">0</span>);</span><br></pre></td></tr></table></figure>
<p>2）读取缓存的文件数据</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// setup()方法中</span></span><br><span class="line"><span class="comment">// 1 获取缓存的文件</span></span><br><span class="line"><span class="comment">// 2 循环读取缓存文件一行</span></span><br><span class="line"><span class="comment">// 3 切割</span></span><br><span class="line"><span class="comment">// 4 缓存数据到集合</span></span><br><span class="line"><span class="comment">// 5 关流</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// map方法中</span></span><br><span class="line"><span class="comment">// 1 获取一行</span></span><br><span class="line"><span class="comment">// 2 截取</span></span><br><span class="line"><span class="comment">// 3 获取订单id</span></span><br><span class="line"><span class="comment">// 4 获取商品名称</span></span><br><span class="line"><span class="comment">// 5 拼接</span></span><br><span class="line"><span class="comment">// 6 写出</span></span><br></pre></td></tr></table></figure>
<h4 id="代码实现-3"><a href="#代码实现-3" class="headerlink" title="代码实现"></a>代码实现</h4><ul>
<li>（1）先在驱动模块中添加缓存文件</li>
</ul>
<p><code>DistributedCacheDriver.java</code></p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.atguigu.mr.cache;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.conf.Configuration;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.fs.Path;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.NullWritable;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.Text;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Job;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.lib.input.FileInputFormat;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"><span class="keyword">import</span> java.net.URI;</span><br><span class="line"><span class="keyword">import</span> java.net.URISyntaxException;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">DistributedCacheDriver</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> InterruptedException, IOException, ClassNotFoundException, URISyntaxException &#123;</span><br><span class="line">        <span class="comment">// 0 根据自己电脑路径重新配置</span></span><br><span class="line">        args = <span class="keyword">new</span> <span class="title class_">String</span>[]&#123;<span class="string">&quot;F:/IDEAWS/dashju/inputtable2&quot;</span>, <span class="string">&quot;F:/IDEAWS/dashju/outputtable2&quot;</span>&#125;;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 1 获取job信息</span></span><br><span class="line">        <span class="type">Configuration</span> <span class="variable">configuration</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Configuration</span>();</span><br><span class="line">        <span class="type">Job</span> <span class="variable">job</span> <span class="operator">=</span> Job.getInstance(configuration);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 2 设置加载jar包路径</span></span><br><span class="line">        job.setJarByClass(DistributedCacheDriver.class);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 3 关联map</span></span><br><span class="line">        job.setMapperClass(DistributedCacheMapper.class);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 4 设置最终输出数据类型</span></span><br><span class="line">        job.setOutputKeyClass(Text.class);</span><br><span class="line">        job.setOutputValueClass(NullWritable.class);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 5 设置输入输出路径</span></span><br><span class="line">        FileInputFormat.setInputPaths(job, <span class="keyword">new</span> <span class="title class_">Path</span>(args[<span class="number">0</span>]));</span><br><span class="line">        FileOutputFormat.setOutputPath(job, <span class="keyword">new</span> <span class="title class_">Path</span>(args[<span class="number">1</span>]));</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 6 加载缓存数据</span></span><br><span class="line">        job.addCacheFile(<span class="keyword">new</span> <span class="title class_">URI</span>(<span class="string">&quot;file:///f:/IDEAWS/dashju/inputtable/pd.txt&quot;</span>));</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 7 Map端Join的逻辑不需要Reduce阶段，设置reduceTask数量为0</span></span><br><span class="line">        job.setNumReduceTasks(<span class="number">0</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 8 提交</span></span><br><span class="line">        <span class="type">boolean</span> <span class="variable">result</span> <span class="operator">=</span> job.waitForCompletion(<span class="literal">true</span>);</span><br><span class="line">        System.exit(result ? <span class="number">0</span> : <span class="number">1</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<ul>
<li>（2）读取缓存的文件数据</li>
</ul>
<p><code>DistributedCacheMapper.java</code></p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.atguigu.mr.cache;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.commons.lang.StringUtils;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.LongWritable;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.NullWritable;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.Text;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Mapper;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.io.BufferedReader;</span><br><span class="line"><span class="keyword">import</span> java.io.FileInputStream;</span><br><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"><span class="keyword">import</span> java.io.InputStreamReader;</span><br><span class="line"><span class="keyword">import</span> java.net.URI;</span><br><span class="line"><span class="keyword">import</span> java.util.HashMap;</span><br><span class="line"><span class="keyword">import</span> java.util.Map;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">DistributedCacheMapper</span> <span class="keyword">extends</span> <span class="title class_">Mapper</span>&lt;LongWritable, Text, Text, NullWritable&gt; &#123;</span><br><span class="line">    Map&lt;String, String&gt; pdMap = <span class="keyword">new</span> <span class="title class_">HashMap</span>&lt;&gt;();</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">protected</span> <span class="keyword">void</span> <span class="title function_">setup</span><span class="params">(Context context)</span> <span class="keyword">throws</span> IOException, InterruptedException &#123;</span><br><span class="line">        <span class="comment">// 1 缓存小表</span></span><br><span class="line">        URI[] cacheFiles = context.getCacheFiles();</span><br><span class="line">        <span class="type">String</span> <span class="variable">path</span> <span class="operator">=</span> cacheFiles[<span class="number">0</span>].getPath().toString();</span><br><span class="line"></span><br><span class="line">        <span class="type">BufferedReader</span> <span class="variable">reader</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">BufferedReader</span>(<span class="keyword">new</span> <span class="title class_">InputStreamReader</span>(<span class="keyword">new</span> <span class="title class_">FileInputStream</span>(path), <span class="string">&quot;UTF-8&quot;</span>));</span><br><span class="line"></span><br><span class="line">        String line;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">while</span> (StringUtils.isNotEmpty(line = reader.readLine())) &#123;</span><br><span class="line">            <span class="comment">// 2 切割</span></span><br><span class="line">            String[] fields = line.split(<span class="string">&quot;\t&quot;</span>);</span><br><span class="line"></span><br><span class="line">            <span class="comment">// 3 缓存到集合</span></span><br><span class="line">            pdMap.put(fields[<span class="number">0</span>], fields[<span class="number">1</span>]);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">// 4 关流</span></span><br><span class="line">        reader.close();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="type">Text</span> <span class="variable">k</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Text</span>();</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">protected</span> <span class="keyword">void</span> <span class="title function_">map</span><span class="params">(LongWritable key, Text value, Context context)</span> <span class="keyword">throws</span> IOException, InterruptedException &#123;</span><br><span class="line">        <span class="comment">// 1 获取一行</span></span><br><span class="line">        <span class="type">String</span> <span class="variable">line</span> <span class="operator">=</span> value.toString();</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 2 截取</span></span><br><span class="line">        String[] fields = line.split(<span class="string">&quot;\t&quot;</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 3 获取产品id</span></span><br><span class="line">        <span class="type">String</span> <span class="variable">pId</span> <span class="operator">=</span> fields[<span class="number">1</span>];</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 4 获取商品名称</span></span><br><span class="line">        <span class="type">String</span> <span class="variable">pdName</span> <span class="operator">=</span> pdMap.get(pId);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 5 拼接</span></span><br><span class="line">        k.set(fields[<span class="number">1</span>] + <span class="string">&quot;\t&quot;</span> + pdName + <span class="string">&quot;\t&quot;</span> + fields[<span class="number">2</span>]);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 6 写出</span></span><br><span class="line">        context.write(k, NullWritable.get());</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="计数器应用"><a href="#计数器应用" class="headerlink" title="计数器应用"></a>计数器应用</h2><p>Hadoop为每个作业维护若干内置计数器，以秒数多项指标。例如，某些计数器记录已处理的字节数和记录数，使用户可监控已处理的输入数据量和已产生的输出数据量。</p>
<ul>
<li>计数器API</li>
</ul>
<p>（1）采用枚举的方式统计计数</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">enum</span> <span class="title class_">MyCounter</span>&#123;MALFORORMED, NORMAL&#125;</span><br><span class="line"><span class="comment">//对枚举定义的自定义计数器增加1</span></span><br><span class="line">context.getCounter(MyCounter.MALFORORMED).increment(<span class="number">1</span>);</span><br></pre></td></tr></table></figure>
<p>（2）采用计数器组、计数器名称的方式统计</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//组名和计数器名称随便起，但最好有意义。</span></span><br><span class="line">context.getCounter(<span class="string">&quot;counterGroup&quot;</span>, <span class="string">&quot;counter&quot;</span>).increment(<span class="number">1</span>);</span><br></pre></td></tr></table></figure>
<p>（3）计数结果在程序运行后的控制台上查看</p>
<h2 id="数据清洗（ETL）"><a href="#数据清洗（ETL）" class="headerlink" title="数据清洗（ETL）"></a>数据清洗（ETL）</h2><p>在运行核心业务MapReduce之前，需要对数据进行清洗，清理掉不符合用户要求的数据。清理的过程只需要运行Mapper程序，不需要运行Reduce程序。</p>
<h3 id="需求-8"><a href="#需求-8" class="headerlink" title="需求"></a>需求</h3><ul>
<li><p>去除日志字段长度小于等于11的日志。</p>
</li>
<li><p>输入数据</p>
</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">web.log(14619 line)</span><br><span class="line"></span><br><span class="line">60.208.6.156 - - [18/Sep/2013:06:49:48 +0000] &quot;GET /wp-content/uploads/2013/07/rcassandra.png HTTP/1.0&quot; 200 185524 &quot;http://cos.name/category/software/packages/&quot; &quot;Mozilla/5.0 (Windows NT 6.1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/29.0.1547.66 Safari/537.36&quot;</span><br></pre></td></tr></table></figure>
<ul>
<li>输出数据</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">每行字段长度都大于11</span><br></pre></td></tr></table></figure>
<h3 id="需求分析-11"><a href="#需求分析-11" class="headerlink" title="需求分析"></a>需求分析</h3><p>需要在Map阶段对输入的数据根据规则进行过滤清洗。</p>
<h3 id="实现代码-简单版"><a href="#实现代码-简单版" class="headerlink" title="实现代码-简单版"></a>实现代码-简单版</h3><ul>
<li>（1）编写LogMapper类</li>
</ul>
<p><code>LogMapper.java</code></p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.atguigu.mr.log;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.LongWritable;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.NullWritable;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.Text;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Mapper;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">LogMapper</span> <span class="keyword">extends</span> <span class="title class_">Mapper</span>&lt;LongWritable, Text, Text, NullWritable&gt; &#123;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">protected</span> <span class="keyword">void</span> <span class="title function_">map</span><span class="params">(LongWritable key, Text value, Context context)</span> <span class="keyword">throws</span> IOException, InterruptedException &#123;</span><br><span class="line">        <span class="comment">// 1 获取一行</span></span><br><span class="line">        <span class="type">String</span> <span class="variable">line</span> <span class="operator">=</span> value.toString();</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 2 解析数据</span></span><br><span class="line">        <span class="type">Boolean</span> <span class="variable">result</span> <span class="operator">=</span> parseLog(line, context);</span><br><span class="line">        <span class="keyword">if</span> (!result) &#123;</span><br><span class="line">            <span class="keyword">return</span>;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 3 写出数据</span></span><br><span class="line">        context.write(value, NullWritable.get());</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 解析数据</span></span><br><span class="line">    <span class="keyword">private</span> Boolean <span class="title function_">parseLog</span><span class="params">(String line, Context context)</span> &#123;</span><br><span class="line">        <span class="comment">// 1 截取</span></span><br><span class="line">        String[] fields = line.split(<span class="string">&quot; &quot;</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 2 日志长度大于11的为合法</span></span><br><span class="line">        <span class="keyword">if</span> (fields.length &gt; <span class="number">11</span>) &#123;</span><br><span class="line">            <span class="comment">//系统计数器</span></span><br><span class="line">            context.getCounter(<span class="string">&quot;map&quot;</span>, <span class="string">&quot;true&quot;</span>).increment(<span class="number">1</span>);</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            context.getCounter(<span class="string">&quot;map&quot;</span>, <span class="string">&quot;false&quot;</span>).increment(<span class="number">1</span>);</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<ul>
<li>（2）编写LogDriver类</li>
</ul>
<p><code>LogDriver.java</code></p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.atguigu.mr.log;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.conf.Configuration;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.fs.Path;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.NullWritable;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.Text;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Job;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.lib.input.FileInputFormat;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">LogDriver</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> InterruptedException, IOException, ClassNotFoundException &#123;</span><br><span class="line">        <span class="comment">// 输入输出路径需要根据自己电脑上实际的输入输出路径设置</span></span><br><span class="line">        args = <span class="keyword">new</span> <span class="title class_">String</span>[]&#123;<span class="string">&quot;F:/IDEAWS/dashju/inputlog&quot;</span>, <span class="string">&quot;F:/IDEAWS/dashju/outputlog&quot;</span>&#125;;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 1 获取job信息</span></span><br><span class="line">        <span class="type">Configuration</span> <span class="variable">conf</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Configuration</span>();</span><br><span class="line">        <span class="type">Job</span> <span class="variable">job</span> <span class="operator">=</span> Job.getInstance(conf);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 2 加载jar包</span></span><br><span class="line">        job.setJarByClass(LogDriver.class);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 3 关联map</span></span><br><span class="line">        job.setMapperClass(LogMapper.class);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 4 设置最终输出类型</span></span><br><span class="line">        job.setOutputKeyClass(Text.class);</span><br><span class="line">        job.setOutputValueClass(NullWritable.class);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 设置reducetask个数为0</span></span><br><span class="line">        job.setNumReduceTasks(<span class="number">0</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 5 设置输入和输出路径</span></span><br><span class="line">        FileInputFormat.setInputPaths(job, <span class="keyword">new</span> <span class="title class_">Path</span>(args[<span class="number">0</span>]));</span><br><span class="line">        FileOutputFormat.setOutputPath(job, <span class="keyword">new</span> <span class="title class_">Path</span>(args[<span class="number">1</span>]));</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 6 提交</span></span><br><span class="line">        job.waitForCompletion(<span class="literal">true</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<ul>
<li>运行结果</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">//控制台输出</span><br><span class="line">map</span><br><span class="line">	false=849</span><br><span class="line">	true=13770</span><br></pre></td></tr></table></figure>
<p>结果汇总数据变为13770 line</p>
<h3 id="实现代码-复杂版"><a href="#实现代码-复杂版" class="headerlink" title="实现代码-复杂版"></a>实现代码-复杂版</h3><ul>
<li>（1）定义一个bean，用来记录日志数据中的各数据字段</li>
</ul>
<p><code>LogBean.java</code></p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.atguigu.mr.log2;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">LogBean</span> &#123;</span><br><span class="line">    <span class="keyword">private</span> String remote_addr; <span class="comment">//记录客户端的ip</span></span><br><span class="line">    <span class="keyword">private</span> String remote_user; <span class="comment">//记录客户端用户名称，忽略属性&quot;-&quot;</span></span><br><span class="line">    <span class="keyword">private</span> String time_local;  <span class="comment">//记录访问时间与时区</span></span><br><span class="line">    <span class="keyword">private</span> String request; <span class="comment">//记录请求的url与http协议</span></span><br><span class="line">    <span class="keyword">private</span> String status;  <span class="comment">//记录请求状态；成功是200</span></span><br><span class="line">    <span class="keyword">private</span> String body_bytes_sent; <span class="comment">//记录发送给客户端文件主题内容大小</span></span><br><span class="line">    <span class="keyword">private</span> String http_referer;<span class="comment">// 用来记录从那个页面链接访问过来的</span></span><br><span class="line">    <span class="keyword">private</span> String http_user_agent;<span class="comment">// 记录客户浏览器的相关信息</span></span><br><span class="line">    <span class="keyword">private</span> <span class="type">boolean</span> <span class="variable">valid</span> <span class="operator">=</span> <span class="literal">true</span>;<span class="comment">// 判断数据是否合法</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="title function_">LogBean</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="built_in">super</span>();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="title function_">LogBean</span><span class="params">(String remote_addr, String remote_user, String time_local, String request, String status, String body_bytes_sent, String http_referer, String http_user_agent, <span class="type">boolean</span> valid)</span> &#123;</span><br><span class="line">        <span class="built_in">this</span>.remote_addr = remote_addr;</span><br><span class="line">        <span class="built_in">this</span>.remote_user = remote_user;</span><br><span class="line">        <span class="built_in">this</span>.time_local = time_local;</span><br><span class="line">        <span class="built_in">this</span>.request = request;</span><br><span class="line">        <span class="built_in">this</span>.status = status;</span><br><span class="line">        <span class="built_in">this</span>.body_bytes_sent = body_bytes_sent;</span><br><span class="line">        <span class="built_in">this</span>.http_referer = http_referer;</span><br><span class="line">        <span class="built_in">this</span>.http_user_agent = http_user_agent;</span><br><span class="line">        <span class="built_in">this</span>.valid = valid;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">setRemote_addr</span><span class="params">(String remote_addr)</span> &#123;</span><br><span class="line">        <span class="built_in">this</span>.remote_addr = remote_addr;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">setRemote_user</span><span class="params">(String remote_user)</span> &#123;</span><br><span class="line">        <span class="built_in">this</span>.remote_user = remote_user;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">setTime_local</span><span class="params">(String time_local)</span> &#123;</span><br><span class="line">        <span class="built_in">this</span>.time_local = time_local;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">setRequest</span><span class="params">(String request)</span> &#123;</span><br><span class="line">        <span class="built_in">this</span>.request = request;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">setStatus</span><span class="params">(String status)</span> &#123;</span><br><span class="line">        <span class="built_in">this</span>.status = status;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">setBody_bytes_sent</span><span class="params">(String body_bytes_sent)</span> &#123;</span><br><span class="line">        <span class="built_in">this</span>.body_bytes_sent = body_bytes_sent;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">setHttp_referer</span><span class="params">(String http_referer)</span> &#123;</span><br><span class="line">        <span class="built_in">this</span>.http_referer = http_referer;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">setHttp_user_agent</span><span class="params">(String http_user_agent)</span> &#123;</span><br><span class="line">        <span class="built_in">this</span>.http_user_agent = http_user_agent;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">setValid</span><span class="params">(<span class="type">boolean</span> valid)</span> &#123;</span><br><span class="line">        <span class="built_in">this</span>.valid = valid;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> String <span class="title function_">getRemote_addr</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> remote_addr;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> String <span class="title function_">getRemote_user</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> remote_user;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> String <span class="title function_">getTime_local</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> time_local;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> String <span class="title function_">getRequest</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> request;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> String <span class="title function_">getStatus</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> status;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> String <span class="title function_">getBody_bytes_sent</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> body_bytes_sent;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> String <span class="title function_">getHttp_referer</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> http_referer;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> String <span class="title function_">getHttp_user_agent</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> http_user_agent;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="type">boolean</span> <span class="title function_">isValid</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> valid;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> String <span class="title function_">toString</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="type">StringBuilder</span> <span class="variable">sb</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">StringBuilder</span>();</span><br><span class="line">        sb.append(<span class="built_in">this</span>.valid);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//采用特殊字符连接，防止处理文本中含有分割字符</span></span><br><span class="line">        sb.append(<span class="string">&quot;\001&quot;</span>).append(<span class="built_in">this</span>.remote_addr);</span><br><span class="line">        sb.append(<span class="string">&quot;\001&quot;</span>).append(<span class="built_in">this</span>.remote_user);</span><br><span class="line">        sb.append(<span class="string">&quot;\001&quot;</span>).append(<span class="built_in">this</span>.time_local);</span><br><span class="line">        sb.append(<span class="string">&quot;\001&quot;</span>).append(<span class="built_in">this</span>.request);</span><br><span class="line">        sb.append(<span class="string">&quot;\001&quot;</span>).append(<span class="built_in">this</span>.status);</span><br><span class="line">        sb.append(<span class="string">&quot;\001&quot;</span>).append(<span class="built_in">this</span>.body_bytes_sent);</span><br><span class="line">        sb.append(<span class="string">&quot;\001&quot;</span>).append(<span class="built_in">this</span>.http_referer);</span><br><span class="line">        sb.append(<span class="string">&quot;\001&quot;</span>).append(<span class="built_in">this</span>.http_user_agent);</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> sb.toString();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<ul>
<li>（2）编写LogMapper类</li>
</ul>
<p><code>LogMapper.java</code></p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.atguigu.mr.log2;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.LongWritable;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.NullWritable;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.Text;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Mapper;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">LogMapper</span> <span class="keyword">extends</span> <span class="title class_">Mapper</span>&lt;LongWritable, Text, Text, NullWritable&gt; &#123;</span><br><span class="line">    <span class="type">Text</span> <span class="variable">k</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Text</span>();</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">protected</span> <span class="keyword">void</span> <span class="title function_">map</span><span class="params">(LongWritable key, Text value, Context context)</span> <span class="keyword">throws</span> IOException, InterruptedException &#123;</span><br><span class="line">        <span class="comment">// 1 获取一行</span></span><br><span class="line">        <span class="type">String</span> <span class="variable">line</span> <span class="operator">=</span> value.toString();</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 2 解析数据</span></span><br><span class="line">        <span class="type">LogBean</span> <span class="variable">logBean</span> <span class="operator">=</span> parseLog(line);</span><br><span class="line">        <span class="keyword">if</span> (!logBean.isValid()) &#123;</span><br><span class="line">            <span class="keyword">return</span>;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 3 写出数据</span></span><br><span class="line">        k.set(logBean.toString());</span><br><span class="line"></span><br><span class="line">        context.write(k, NullWritable.get());</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//解析数据</span></span><br><span class="line">    <span class="keyword">private</span> LogBean <span class="title function_">parseLog</span><span class="params">(String line)</span> &#123;</span><br><span class="line">        <span class="type">LogBean</span> <span class="variable">logBean</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">LogBean</span>();</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 1 截取</span></span><br><span class="line">        String[] fields = line.split(<span class="string">&quot; &quot;</span>);</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> (fields.length &gt; <span class="number">11</span>) &#123;</span><br><span class="line">            <span class="comment">// 2 封装数据</span></span><br><span class="line">            logBean.setRemote_addr(fields[<span class="number">0</span>]);</span><br><span class="line">            logBean.setRemote_user(fields[<span class="number">1</span>]);</span><br><span class="line">            logBean.setTime_local(fields[<span class="number">3</span>].substring(<span class="number">1</span>));</span><br><span class="line">            logBean.setRequest(fields[<span class="number">6</span>]);</span><br><span class="line">            logBean.setStatus(fields[<span class="number">8</span>]);</span><br><span class="line">            logBean.setBody_bytes_sent(fields[<span class="number">9</span>]);</span><br><span class="line">            logBean.setHttp_referer(fields[<span class="number">10</span>]);</span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> (fields.length &gt; <span class="number">12</span>) &#123;</span><br><span class="line">                logBean.setHttp_user_agent(fields[<span class="number">11</span>] + <span class="string">&quot; &quot;</span> + fields[<span class="number">12</span>]);</span><br><span class="line">            &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                logBean.setHttp_user_agent(fields[<span class="number">11</span>]);</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            <span class="comment">// 大于400，HTTP错误</span></span><br><span class="line">            <span class="keyword">if</span> (Integer.parseInt(logBean.getStatus()) &gt;= <span class="number">400</span>) &#123;</span><br><span class="line">                logBean.setValid(<span class="literal">false</span>);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            logBean.setValid(<span class="literal">false</span>);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> logBean;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<ul>
<li>（3）编写LogDriver类</li>
</ul>
<p><code>LogDriver.java</code></p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.atguigu.mr.log2;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.conf.Configuration;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.fs.Path;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.NullWritable;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.Text;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Job;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.lib.input.FileInputFormat;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">LogDriver</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> InterruptedException, IOException, ClassNotFoundException &#123;</span><br><span class="line">        <span class="comment">// 输入输出路径需要根据自己电脑上实际的输入输出路径设置</span></span><br><span class="line">        args = <span class="keyword">new</span> <span class="title class_">String</span>[]&#123;<span class="string">&quot;F:/IDEAWS/dashju/inputlog&quot;</span>, <span class="string">&quot;F:/IDEAWS/dashju/outputlog2&quot;</span>&#125;;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 1 获取job信息</span></span><br><span class="line">        <span class="type">Configuration</span> <span class="variable">conf</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Configuration</span>();</span><br><span class="line">        <span class="type">Job</span> <span class="variable">job</span> <span class="operator">=</span> Job.getInstance(conf);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 2 加载jar包</span></span><br><span class="line">        job.setJarByClass(LogDriver.class);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 3 关联map</span></span><br><span class="line">        job.setMapperClass(LogMapper.class);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 4 设置最终输出类型</span></span><br><span class="line">        job.setOutputKeyClass(Text.class);</span><br><span class="line">        job.setOutputValueClass(NullWritable.class);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 设置reducetask个数为0</span></span><br><span class="line">        job.setNumReduceTasks(<span class="number">0</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 5 设置输入和输出路径</span></span><br><span class="line">        FileInputFormat.setInputPaths(job, <span class="keyword">new</span> <span class="title class_">Path</span>(args[<span class="number">0</span>]));</span><br><span class="line">        FileOutputFormat.setOutputPath(job, <span class="keyword">new</span> <span class="title class_">Path</span>(args[<span class="number">1</span>]));</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 6 提交</span></span><br><span class="line">        job.waitForCompletion(<span class="literal">true</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="MapReduce开发总结"><a href="#MapReduce开发总结" class="headerlink" title="MapReduce开发总结"></a>MapReduce开发总结</h2><p>在编写MapReduce程序时，需要考虑如下几个方面</p>
<h3 id="1-输入数据接口-InputFormat"><a href="#1-输入数据接口-InputFormat" class="headerlink" title="1.输入数据接口: InputFormat"></a>1.输入数据接口: InputFormat</h3><p>（1）默认使用的实现类是: TextInputFormat</p>
<p>（2）TextInputFormat的功能逻辑是：一次读一行文本， 然后将该行的起始偏移量作为key，行内容作为value返回。</p>
<p>（3）KeyValueTextInputFormat每一行均为一条记录，被分隔符分割为<code>key,value</code>。默认分隔符是tab ( <code>\t</code> )。</p>
<p>（4）NineInputFormat按照指定的行数N来划分切片。</p>
<p>（5）CombineTextInputFormat可以把多个小文件合并成一个切片处理，提高处理效率。</p>
<p>（6）用户还可以自定义InputFormat。</p>
<h3 id="2-逻辑处理接口-Mapper"><a href="#2-逻辑处理接口-Mapper" class="headerlink" title="2.逻辑处理接口: Mapper"></a>2.逻辑处理接口: Mapper</h3><p>用户根据业务需求实现其中三个方法: map()、setup()、 cleanup()。</p>
<h3 id="3-Partitioner分区"><a href="#3-Partitioner分区" class="headerlink" title="3.Partitioner分区"></a>3.Partitioner分区</h3><p>（1）有默认实现<code>HashPartitioner</code>，逻辑是根据key的哈希值和numReduces来返回一个分区号;</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">key.hashCode()&amp;IntegerMAXVALUE % numReduces;</span><br></pre></td></tr></table></figure>
<p>（2）如果业务上有特别的需求，可以自定义分区。</p>
<h3 id="4-Comparable排序"><a href="#4-Comparable排序" class="headerlink" title="4.Comparable排序"></a>4.Comparable排序</h3><p>（1）当我们用自定义的对象作为key来输出时，就必须要实现WritableComparable接口，重写其中的compareTo()方法。</p>
<p>（2）部分排序：对最终输出的每一个文件进行内部排序。</p>
<p>（3）全排序：对所有数据进行排序，通常只有一个Reduce。</p>
<p>（4）二次排序：排序的条件有两个。</p>
<h3 id="5-Combiner合并"><a href="#5-Combiner合并" class="headerlink" title="5.Combiner合并"></a>5.Combiner合并</h3><p>Combiner合并可以提高程序执行效率，减少IO传输。<br>但是使用时必须不能影响原有的业务处理结果。（汇总）</p>
<h3 id="6-Reduce端分组-GroupingComparator"><a href="#6-Reduce端分组-GroupingComparator" class="headerlink" title="6.Reduce端分组: GroupingComparator"></a>6.Reduce端分组: GroupingComparator</h3><p>在Reduce端对key进行分组。<br>应用于：在接收的cey为bean对象时，想让一个或几个字段相同(全部字段比较不相同)的key进入到同一个reduce方法时，可以采用分组排序。</p>
<h3 id="7-逻辑处理接口-Reducer"><a href="#7-逻辑处理接口-Reducer" class="headerlink" title="7.逻辑处理接口: Reducer"></a>7.逻辑处理接口: Reducer</h3><p>用户根据业务需求实现其中三个方法: reduce()、setp()、cleanup()</p>
<h3 id="8-输出数据接口-OutputFormat"><a href="#8-输出数据接口-OutputFormat" class="headerlink" title="8.输出数据接口: OutputFormat"></a>8.输出数据接口: OutputFormat</h3><p>（1）默认实现类是TextOutputFormat，功能逻辑是：将每一个KV对， 向目标文本文件输出一行。</p>
<p>（2）将SequenceFileOutputFormat输出作为后续MapReduce任务的输入，这便是一种好的输出格式， 因为它的格式紧凑，很容易被压缩。</p>
<p>（3）用户还可以自定义OutputFormat。</p>
</div></article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="mailto:undefined">HibisciDai</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="http://hibiscidai.com/2020/10/30/Hadoop-MapReduce详解-2/">http://hibiscidai.com/2020/10/30/Hadoop-MapReduce详解-2/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a target="_blank" rel="noopener" href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="http://hibiscidai.com">HibisciDai</a>！</span></div></div><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/">学习笔记</a><a class="post-meta__tags" href="/tags/Hadoop/">Hadoop</a><a class="post-meta__tags" href="/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/">大数据</a></div><div class="social-share pull-right" data-disabled="linkedin,diandian"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/social-share.js@1.0.16/dist/css/share.min.css"><script src="https://cdn.jsdelivr.net/npm/social-share.js@1.0.16/dist/js/social-share.min.js"></script><nav id="pagination"><div class="prev-post pull-left"><a href="/2020/11/05/pertrel%E5%9C%B0%E8%B4%A8%E5%BB%BA%E6%A8%A1-%E5%AE%9E%E6%93%8D/"><i class="fa fa-chevron-left">  </i><span>pertrel地质建模-实操</span></a></div><div class="next-post pull-right"><a href="/2020/10/28/pertrel%E5%9C%B0%E8%B4%A8%E5%BB%BA%E6%A8%A1-%E7%90%86%E8%AE%BA/"><span>pertrel地质建模-理论</span><i class="fa fa-chevron-right"></i></a></div></nav><div class="post-adv"><a target="_blank" rel="noopener" href="https://xn--mesr8b36x.agency/#/register?code=R5RS1JHy">好用、实惠、稳定的梯子,点击这里<img src="https://www.vultr.com/media/logo_ondark.png" width="728" height="90"></a></div><div id="lv-container" data-id="city" data-uid="MTAyMC8zNTQ2NC8xMjAwMA=="><script>(function(d, s) {
    var j, e = d.getElementsByTagName(s)[0];
    if (typeof LivereTower === 'function') { return; }
    j = d.createElement(s);
    j.src = 'https://cdn-city.livere.com/js/embed.dist.js';
    j.async = true;
    e.parentNode.insertBefore(j, e);
})(document, 'script');</script></div></div></div><footer class="footer-bg" style="background-image: url(/img/banner2.jpg)"><div class="layout" id="footer"><div class="copyright">&copy;2017 - 2023 By HibisciDai</div><div class="framework-info"><span>驱动 - </span><a target="_blank" rel="noopener" href="http://hexo.io"><span>Hexo</span></a><span class="footer-separator">|</span><span>主题 - </span><a target="_blank" rel="noopener" href="https://github.com/Molunerfinn/hexo-theme-melody"><span>Melody</span></a></div><div class="footer_custom_text">hitokoto</div><div class="busuanzi"><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><span id="busuanzi_container_page_pv"><i class="fa fa-file"></i><span id="busuanzi_value_page_pv"></span><span></span></span></div></div></footer><i class="fa fa-arrow-up" id="go-up" aria-hidden="true"></i><script src="/js/third-party/anime.min.js"></script><script src="/js/third-party/jquery.min.js"></script><script src="/js/third-party/jquery.fancybox.min.js"></script><script src="/js/third-party/velocity.min.js"></script><script src="/js/third-party/velocity.ui.min.js"></script><script src="/js/utils.js?version=1.9.0"></script><script src="/js/fancybox.js?version=1.9.0"></script><script src="/js/sidebar.js?version=1.9.0"></script><script src="/js/copy.js?version=1.9.0"></script><script src="/js/fireworks.js?version=1.9.0"></script><script src="/js/transition.js?version=1.9.0"></script><script src="/js/scroll.js?version=1.9.0"></script><script src="/js/head.js?version=1.9.0"></script><script type="text/x-mathjax-config">MathJax.Hub.Config({
  tex2jax: {
    inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
    processEscapes: true,
    skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
  },
  CommonHTML: {
    linebreaks: { automatic: true, width: "90% container" }
  },
  "HTML-CSS": { 
    linebreaks: { automatic: true, width: "90% container" }
  },
  "SVG": { 
    linebreaks: { automatic: true, width: "90% container" }
  }
});
</script><script type="text/x-mathjax-config">MathJax.Hub.Queue(function() {
  var all = MathJax.Hub.getAllJax(), i;
  for (i=0; i < all.length; i += 1) {
    all[i].SourceElement().parentNode.className += ' has-jax';
  }
});
</script><script src="https://cdn.bootcss.com/mathjax/2.7.2/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/katex@latest/dist/katex.min.css"><script src="https://cdn.jsdelivr.net/npm/katex-copytex@latest/dist/katex-copytex.min.js"></script><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/katex-copytex@latest/dist/katex-copytex.min.css"><script src="/js/katex.js"></script><script src="/js/search/local-search.js"></script><script id="ribbon" src="/js/third-party/canvas-ribbon.js" size="150" alpha="0.6" zIndex="-1" data-click="false"></script><script>if(/Android|webOS|iPhone|iPod|iPad|BlackBerry/i.test(navigator.userAgent)) {
  $('#nav').addClass('is-mobile')
  $('footer').addClass('is-mobile')
  $('#top-container').addClass('is-mobile')
}</script><div class="search-dialog" id="local-search"><div class="search-dialog__title" id="local-search-title">本地搜索</div><div id="local-input-panel"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章"></div></div></div><hr><div id="local-search-results"><div id="local-hits"></div><div id="local-stats"><div class="local-search-stats__hr" id="hr"><span>由</span> <a target="_blank" rel="noopener" href="https://github.com/wzpan/hexo-generator-search" style="color:#49B1F5;">hexo-generator-search</a>
 <span>提供支持</span></div></div></div><span class="search-close-button"><i class="fa fa-times"></i></span></div><div class="search-mask"></div></body></html>