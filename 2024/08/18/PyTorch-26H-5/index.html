<!DOCTYPE html><html lang="zh-Hans"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta name="description" content="PyTorch-26H-5"><meta name="keywords" content="学习笔记,PyTorch"><meta name="author" content="HibisciDai"><meta name="copyright" content="HibisciDai"><title>PyTorch-26H-5 | HibisciDai</title><link rel="shortcut icon" href="/img/avatar.png"><link rel="stylesheet" href="/css/index.css?version=1.9.0"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/font-awesome@latest/css/font-awesome.min.css?version=1.9.0"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.7.2/css/all.css?version=1.9.0"><meta name="format-detection" content="telephone=no"><meta http-equiv="x-dns-prefetch-control" content="on"><link rel="dns-prefetch" href="https://cdn.jsdelivr.net"><link rel="manifest" href="/manifest.json"><link rel="manifest" href="/manifest.json"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><script src="https://v1.hitokoto.cn/?encode=js&amp;charset=utf-8&amp;select=.footer_custom_text" defer></script><script>var GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: {"path":"search.xml","languages":{"hits_empty":"找不到您查询的内容:${query}"}},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  hexoVersion: '6.1.0'
} </script><meta name="generator" content="Hexo 6.1.0"><link rel="alternate" href="/atom.xml" title="HibisciDai" type="application/atom+xml">
</head><body><canvas class="fireworks"></canvas><i class="fa fa-arrow-right" id="toggle-sidebar" aria-hidden="true"></i><div id="sidebar" data-display="true"><div class="toggle-sidebar-info text-center"><span data-toggle="切换文章详情">切换站点概览</span><hr></div><div class="sidebar-toc"><div class="sidebar-toc__title">目录</div><div class="sidebar-toc__progress"><span class="progress-notice">你已经读了</span><span class="progress-num">0</span><span class="progress-percentage">%</span><div class="sidebar-toc__progress-bar"></div></div><div class="sidebar-toc__content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#PyTorch-26H-5"><span class="toc-number">1.</span> <span class="toc-text">PyTorch-26H-5</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#What-is-a-custom-dataset-%E4%BB%80%E4%B9%88%E6%98%AF%E8%87%AA%E5%AE%9A%E4%B9%89%E6%95%B0%E6%8D%AE%E9%9B%86%EF%BC%9F"><span class="toc-number">2.</span> <span class="toc-text">What is a custom dataset? 什么是自定义数据集？</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#What-we%E2%80%99re-going-to-cover-%E5%B0%86%E8%A6%81%E8%AE%A8%E8%AE%BA%E7%9A%84%E5%86%85%E5%AE%B9"><span class="toc-number">3.</span> <span class="toc-text">What we’re going to cover? 将要讨论的内容</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#0-Importing-PyTorch-and-setting-up-device-agnostic-code-%E5%AF%BC%E5%85%A5-PyTorch-%E5%B9%B6%E8%AE%BE%E7%BD%AE%E4%B8%8E%E8%AE%BE%E5%A4%87%E6%97%A0%E5%85%B3%E7%9A%84%E4%BB%A3%E7%A0%81"><span class="toc-number">4.</span> <span class="toc-text">0. Importing PyTorch and setting up device-agnostic code 导入 PyTorch 并设置与设备无关的代码</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#1-Get-data"><span class="toc-number">5.</span> <span class="toc-text">1. Get data</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#2-Become-one-with-the-data-data-preparation-%E4%B8%8E%E6%95%B0%E6%8D%AE%E8%9E%8D%E4%B8%BA%E4%B8%80%E4%BD%93%EF%BC%88%E6%95%B0%E6%8D%AE%E5%87%86%E5%A4%87%EF%BC%89"><span class="toc-number">6.</span> <span class="toc-text">2. Become one with the data (data preparation) 与数据融为一体（数据准备）</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#2-1-Visualize-an-image-%E5%8F%AF%E8%A7%86%E5%8C%96%E5%9B%BE%E5%83%8F"><span class="toc-number">6.1.</span> <span class="toc-text">2.1 Visualize an image 可视化图像</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#3-Transforming-data-%E8%BD%AC%E6%8D%A2%E6%95%B0%E6%8D%AE"><span class="toc-number">7.</span> <span class="toc-text">3. Transforming data 转换数据</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#3-1-Transforming-data-with-torchvision-transforms"><span class="toc-number">7.1.</span> <span class="toc-text">3.1 Transforming data with torchvision.transforms</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#4-Option-1-Loading-Image-Data-Using-ImageFolder"><span class="toc-number">8.</span> <span class="toc-text">4. Option 1: Loading Image Data Using ImageFolder</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#4-1-Turn-loaded-images-into-DataLoader%E2%80%99s"><span class="toc-number">8.1.</span> <span class="toc-text">4.1 Turn loaded images into DataLoader’s</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#5-Option-2-Loading-Image-Data-with-a-Custom-Dataset-%E4%BD%BF%E7%94%A8%E8%87%AA%E5%AE%9A%E4%B9%89%E6%95%B0%E6%8D%AE%E9%9B%86"><span class="toc-number">9.</span> <span class="toc-text">5. Option 2: Loading Image Data with a Custom Dataset 使用自定义数据集</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#5-1-Creating-a-helper-function-to-get-class-names-%E5%88%9B%E5%BB%BA%E4%B8%80%E4%B8%AA%E8%BE%85%E5%8A%A9%E5%87%BD%E6%95%B0%E6%9D%A5%E8%8E%B7%E5%8F%96%E7%B1%BB"><span class="toc-number">9.1.</span> <span class="toc-text">5.1 Creating a helper function to get class names 创建一个辅助函数来获取类</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#5-2-Create-a-custom-Dataset-to-replicate-ImageFolder-%E5%88%9B%E5%BB%BA%E8%87%AA%E5%AE%9A%E4%B9%89Dataset%E6%9D%A5%E5%A4%8D%E5%88%B6-ImageFolder"><span class="toc-number">9.2.</span> <span class="toc-text">5.2 Create a custom Dataset  to replicate ImageFolder 创建自定义Dataset来复制 ImageFolder</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#5-3-Create-a-function-to-display-random-images-%E5%88%9B%E5%BB%BA%E4%B8%80%E4%B8%AA%E6%98%BE%E7%A4%BA%E9%9A%8F%E6%9C%BA%E5%9B%BE%E5%83%8F%E7%9A%84%E5%87%BD%E6%95%B0"><span class="toc-number">9.3.</span> <span class="toc-text">5.3 Create a function to display random images 创建一个显示随机图像的函数</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#5-4-Turn-custom-loaded-images-into-DataLoader%E2%80%99s-%E5%B0%86%E8%87%AA%E5%AE%9A%E4%B9%89%E5%8A%A0%E8%BD%BD%E7%9A%84%E5%9B%BE%E5%83%8F%E8%BD%AC%E6%8D%A2DataLoader"><span class="toc-number">9.4.</span> <span class="toc-text">5.4 Turn custom loaded images into DataLoader’s 将自定义加载的图像转换DataLoader</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#6-Other-forms-of-transforms-data-augmentation-%E5%85%B6%E4%BB%96%E5%BD%A2%E5%BC%8F%E7%9A%84%E5%8F%98%E6%8D%A2%EF%BC%88%E6%95%B0%E6%8D%AE%E5%A2%9E%E5%BC%BA%EF%BC%89"><span class="toc-number">10.</span> <span class="toc-text">6. Other forms of transforms (data augmentation) 其他形式的变换（数据增强）</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#7-Model-0-TinyVGG-without-data-augmentation"><span class="toc-number">11.</span> <span class="toc-text">7. Model 0: TinyVGG without data augmentation</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#7-1-Creating-transforms-and-loading-data-for-Model-0-%E4%B8%BA%E6%A8%A1%E5%9E%8B-0-%E5%88%9B%E5%BB%BA%E5%8F%98%E6%8D%A2%E5%B9%B6%E5%8A%A0%E8%BD%BD%E6%95%B0%E6%8D%AE"><span class="toc-number">11.1.</span> <span class="toc-text">7.1 Creating transforms and loading data for Model 0 为模型 0 创建变换并加载数据</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#7-2-Create-TinyVGG-model-class"><span class="toc-number">11.2.</span> <span class="toc-text">7.2 Create TinyVGG model class</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#7-3-Try-a-forward-pass-on-a-single-image-to-test-the-model-%E5%B0%9D%E8%AF%95%E5%9C%A8%E5%8D%95%E4%B8%AA%E5%9B%BE%E5%83%8F%E4%B8%8A%E8%BF%9B%E8%A1%8C%E5%89%8D%E5%90%91%E4%BC%A0%E9%80%92%EF%BC%88%E4%BB%A5%E6%B5%8B%E8%AF%95%E6%A8%A1%E5%9E%8B%EF%BC%89"><span class="toc-number">11.3.</span> <span class="toc-text">7.3 Try a forward pass on a single image (to test the model) 尝试在单个图像上进行前向传递（以测试模型）</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#7-4-Use-torchinfo-to-get-an-idea-of-the-shapes-going-through-our-model-%E4%BD%BF%E7%94%A8-torchinfo-%E4%BA%86%E8%A7%A3%E6%A8%A1%E5%9E%8B%E4%B8%AD%E7%9A%84%E5%BD%A2%E7%8A%B6"><span class="toc-number">11.4.</span> <span class="toc-text">7.4 Use torchinfo to get an idea of the shapes going through our model 使用 torchinfo 了解模型中的形状</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#7-5-Create-train-amp-test-loop-functions-%E5%88%9B%E5%BB%BA%E8%AE%AD%E7%BB%83%E5%92%8C%E6%B5%8B%E8%AF%95%E5%BE%AA%E7%8E%AF%E5%87%BD%E6%95%B0"><span class="toc-number">11.5.</span> <span class="toc-text">7.5 Create train &amp; test loop functions 创建训练和测试循环函数</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#train-step"><span class="toc-number">11.5.1.</span> <span class="toc-text">train_step()</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#test-step"><span class="toc-number">11.5.2.</span> <span class="toc-text">test_step()</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#train-Creating-a-train-function-to-combine-train-step-and-test-step-%E8%AE%AD%E7%BB%83-%E5%88%9B%E5%BB%BA%E4%B8%80%E4%B8%AA-train-%E5%87%BD%E6%95%B0%E6%9D%A5%E7%BB%93%E5%90%88-train-step-%E5%92%8C-test-step"><span class="toc-number">11.5.3.</span> <span class="toc-text">train | Creating a train() function to combine train_step() and test_step() 训练 | 创建一个 train() 函数来结合 train_step() 和 test_step()</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#7-6-Train-and-Evaluate-Model-0-%E8%AE%AD%E7%BB%83%E5%92%8C%E8%AF%84%E4%BC%B0%E6%A8%A1%E5%9E%8B-0"><span class="toc-number">11.6.</span> <span class="toc-text">7.6 Train and Evaluate Model 0 训练和评估模型 0</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#7-7-Plot-the-loss-curves-of-Model-0-%E7%BB%98%E5%88%B6%E6%A8%A1%E5%9E%8B-0-%E7%9A%84%E6%8D%9F%E5%A4%B1%E6%9B%B2%E7%BA%BF"><span class="toc-number">11.7.</span> <span class="toc-text">7.7 Plot the loss curves of Model 0 绘制模型 0 的损失曲线</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#8-What-should-an-ideal-loss-curve-look-like-%E7%90%86%E6%83%B3%E7%9A%84%E6%8D%9F%E5%A4%B1%E6%9B%B2%E7%BA%BF%E5%BA%94%E8%AF%A5%E6%98%AF%E4%BB%80%E4%B9%88%E6%A0%B7%E7%9A%84%EF%BC%9F"><span class="toc-number">12.</span> <span class="toc-text">8. What should an ideal loss curve look like?理想的损失曲线应该是什么样的？</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#8-1-How-to-deal-with-overfitting-%E5%A6%82%E4%BD%95%E5%A4%84%E7%90%86%E8%BF%87%E5%BA%A6%E6%8B%9F%E5%90%88"><span class="toc-number">12.1.</span> <span class="toc-text">8.1 How to deal with overfitting 如何处理过度拟合</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#8-2-How-to-deal-with-underfitting-%E5%A6%82%E4%BD%95%E5%A4%84%E7%90%86%E6%AC%A0%E6%8B%9F%E5%90%88"><span class="toc-number">12.2.</span> <span class="toc-text">8.2 How to deal with underfitting 如何处理欠拟合</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#8-3-The-balance-between-overfitting-and-underfitting-%E8%BF%87%E5%BA%A6%E6%8B%9F%E5%90%88%E4%B8%8E%E6%AC%A0%E6%8B%9F%E5%90%88%E4%B9%8B%E9%97%B4%E7%9A%84%E5%B9%B3%E8%A1%A1"><span class="toc-number">12.3.</span> <span class="toc-text">8.3 The balance between overfitting and underfitting 过度拟合与欠拟合之间的平衡</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#9-Model-1-TinyVGG-with-Data-Augmentation-%E6%A8%A1%E5%9E%8B1%EF%BC%9A%E5%85%B7%E6%9C%89%E6%95%B0%E6%8D%AE%E5%A2%9E%E5%BC%BA%E7%9A%84TinyVGG"><span class="toc-number">13.</span> <span class="toc-text">9. Model 1: TinyVGG with Data Augmentation 模型1：具有数据增强的TinyVGG</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#9-1-Create-transform-with-data-augmentation-%E4%BD%BF%E7%94%A8%E6%95%B0%E6%8D%AE%E5%A2%9E%E5%BC%BA%E5%88%9B%E5%BB%BA%E5%8F%98%E6%8D%A2"><span class="toc-number">13.1.</span> <span class="toc-text">9.1 Create transform with data augmentation 使用数据增强创建变换</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#9-2-Create-train-and-test-Dataset%E2%80%99s-and-DataLoader%E2%80%99s-%E5%88%9B%E5%BB%BA%E8%AE%AD%E7%BB%83%E5%92%8C%E6%B5%8B%E8%AF%95%E6%95%B0%E6%8D%AE%E9%9B%86%E5%92%8C%E6%95%B0%E6%8D%AE%E5%8A%A0%E8%BD%BD%E5%99%A8"><span class="toc-number">13.2.</span> <span class="toc-text">9.2 Create train and test Dataset’s and DataLoader’s 创建训练和测试数据集和数据加载器</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#9-3-Construct-and-train-Model-1"><span class="toc-number">13.3.</span> <span class="toc-text">9.3 Construct and train Model 1</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#9-4-Plot-the-loss-curves-of-Model-1"><span class="toc-number">13.4.</span> <span class="toc-text">9.4 Plot the loss curves of Model 1</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#10-Compare-model-results-%E6%AF%94%E8%BE%83%E6%A8%A1%E5%9E%8B%E7%BB%93%E6%9E%9C"><span class="toc-number">14.</span> <span class="toc-text">10. Compare model results 比较模型结果</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#11-Make-a-prediction-on-a-custom-image-%E5%AF%B9%E8%87%AA%E5%AE%9A%E4%B9%89%E5%9B%BE%E5%83%8F%E8%BF%9B%E8%A1%8C%E9%A2%84%E6%B5%8B"><span class="toc-number">15.</span> <span class="toc-text">11. Make a prediction on a custom image 对自定义图像进行预测</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#11-1-Loading-in-a-custom-image-with-PyTorch-%E4%BD%BF%E7%94%A8-PyTorch-%E5%8A%A0%E8%BD%BD%E8%87%AA%E5%AE%9A%E4%B9%89%E5%9B%BE%E5%83%8F"><span class="toc-number">15.1.</span> <span class="toc-text">11.1 Loading in a custom image with PyTorch 使用 PyTorch 加载自定义图像</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#11-2-Predicting-on-custom-images-with-a-trained-PyTorch-model-%E4%BD%BF%E7%94%A8%E8%AE%AD%E7%BB%83%E5%A5%BD%E7%9A%84-PyTorch-%E6%A8%A1%E5%9E%8B%E5%AF%B9%E8%87%AA%E5%AE%9A%E4%B9%89%E5%9B%BE%E5%83%8F%E8%BF%9B%E8%A1%8C%E9%A2%84%E6%B5%8B"><span class="toc-number">15.2.</span> <span class="toc-text">11.2 Predicting on custom images with a trained PyTorch model 使用训练好的 PyTorch 模型对自定义图像进行预测</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#11-3-Putting-custom-image-prediction-together-building-a-function-%E5%B0%86%E8%87%AA%E5%AE%9A%E4%B9%89%E5%9B%BE%E5%83%8F%E9%A2%84%E6%B5%8B%E6%95%B4%E5%90%88%E5%9C%A8%E4%B8%80%E8%B5%B7%EF%BC%9A%E6%9E%84%E5%BB%BA%E5%87%BD%E6%95%B0"><span class="toc-number">15.3.</span> <span class="toc-text">11.3 Putting custom image prediction together: building a function 将自定义图像预测整合在一起：构建函数</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Main-takeaways"><span class="toc-number">16.</span> <span class="toc-text">Main takeaways</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Exercises"><span class="toc-number">17.</span> <span class="toc-text">Exercises</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Extra-curriculum"><span class="toc-number">18.</span> <span class="toc-text">Extra-curriculum</span></a></li></ol></div></div><div class="author-info hide"><div class="author-info__avatar text-center"><img src="/img/Avatar.png"></div><div class="author-info__name text-center">HibisciDai</div><div class="author-info__description text-center">HibisciDai'Blog</div><hr><div class="author-info-articles"><a class="author-info-articles__archives article-meta" href="/archives"><span class="pull-left">文章</span><span class="pull-right">244</span></a><a class="author-info-articles__tags article-meta" href="/tags"><span class="pull-left">标签</span><span class="pull-right">88</span></a><a class="author-info-articles__categories article-meta" href="/categories"><span class="pull-left">分类</span><span class="pull-right">33</span></a></div><hr><div class="author-info-links"><div class="author-info-links__title text-center">友情链接</div><a class="author-info-links__name text-center" target="_blank" rel="noopener" href="https://github.com/HibisciDai/hexo-theme-melody">HexoTheme-github</a><a class="author-info-links__name text-center" target="_blank" rel="noopener" href="https://molunerfinn.com/">molunerfinn</a></div></div></div><div id="content-outer"><div id="top-container" style="background-image: url(/img/banner2.jpg)"><div id="page-header"><span class="pull-left"> <a id="site-name" href="/">HibisciDai</a></span><i class="fa fa-bars toggle-menu pull-right" aria-hidden="true"></i><span class="pull-right menus">   <a class="site-page" href="/">主页</a><a class="site-page" href="/about">关于我</a><a class="site-page" href="/archives">归档</a><a class="site-page" href="/tags">标签</a><a class="site-page" href="/categories">分类</a><a class="site-page" href="/gallery">相册</a></span><span class="pull-right"><a class="site-page social-icon search"><i class="fa fa-search"></i><span> 搜索</span></a></span></div><div id="post-info"><div id="post-title">PyTorch-26H-5</div><div id="post-meta"><time class="post-meta__date"><i class="fa fa-calendar" aria-hidden="true"></i> 2024-08-18</time><span class="post-meta__separator">|</span><i class="fa fa-inbox post-meta__icon" aria-hidden="true"></i><a class="post-meta__categories" href="/categories/PyTorch/">PyTorch</a><div class="post-meta-wordcount"><span>字数总计: </span><span class="word-count">20.2k</span><span class="post-meta__separator">|</span><span>阅读时长: 84 分钟</span></div></div></div></div><div class="layout" id="content-inner"><article id="post"><div class="article-container" id="post-content"><img src="/2024/08/18/PyTorch-26H-5/PyTorch-26H-5.png" class="" title="PyTorch-26H-5">
<p>PyTorch-26H-5</p>
<span id="more"></span>
<h1 id="PyTorch-26H-5"><a href="#PyTorch-26H-5" class="headerlink" title="PyTorch-26H-5"></a>PyTorch-26H-5</h1><p>主页：<a target="_blank" rel="noopener" href="https://www.freecodecamp.org/news/learn-pytorch-for-deep-learning-in-day/">https://www.freecodecamp.org/news/learn-pytorch-for-deep-learning-in-day/</a></p>
<p>youtub：<a target="_blank" rel="noopener" href="https://youtu.be/V_xro1bcAuA">https://youtu.be/V_xro1bcAuA</a></p>
<p>github：<a target="_blank" rel="noopener" href="https://github.com/mrdbourke/pytorch-deep-learning">https://github.com/mrdbourke/pytorch-deep-learning</a></p>
<p>Learn PyTorch for Deep Learning: Zero to Mastery book：<a target="_blank" rel="noopener" href="https://www.learnpytorch.io/">https://www.learnpytorch.io/</a></p>
<p>PyTorch documentation：<a target="_blank" rel="noopener" href="https://pytorch.org/docs/stable/index.html">https://pytorch.org/docs/stable/index.html</a></p>
<p>找到一个数据集，将数据集转换为数字，建立一个模型（或找到一个现有模型）以在这些数字中找到可用于预测的模式。</p>
<p>PyTorch 有许多内置数据集，可用于广泛的机器学习基准测试，但是，您通常希望使用自己的自定义数据集。</p>
<h1 id="What-is-a-custom-dataset-什么是自定义数据集？"><a href="#What-is-a-custom-dataset-什么是自定义数据集？" class="headerlink" title="What is a custom dataset? 什么是自定义数据集？"></a>What is a custom dataset? 什么是自定义数据集？</h1><p>自定义数据集是与您正在处理的特定问题相关的数据集合。</p>
<p>本质上，自定义数据集几乎可以包含任何内容。</p>
<p>例如，如果我们正在构建像<a target="_blank" rel="noopener" href="https://nutrify.app/">Nutrify</a>这样的食物图像分类应用程序，我们的自定义数据集可能是食物图像。</p>
<p>或者，如果我们尝试建立一个模型来对网站上的基于文本的评论是正面的还是负面的进行分类，我们的自定义数据集可能是现有客户评论及其评级的示例。</p>
<p>或者，如果我们尝试构建声音分类应用程序，我们的自定义数据集可能是声音样本及其样本标签。</p>
<p>或者，如果我们尝试为在我们的网站上购买商品的客户建立推荐系统，我们的自定义数据集可能是其他人购买过的产品的示例。</p>
<img src="/2024/08/18/PyTorch-26H-5/PyTorch-26H-5-1.png" class="" title="PyTorch-26H-5-1">
<p>PyTorch 包含许多现有函数，可加载 <em><a target="_blank" rel="noopener" href="https://pytorch.org/vision/stable/index.html"><code>TorchVision</code></a>, <a target="_blank" rel="noopener" href="https://pytorch.org/text/stable/index.html"><code>TorchText</code></a>, <a target="_blank" rel="noopener" href="https://pytorch.org/audio/stable/index.html"><code>TorchAudio</code></a> and <a target="_blank" rel="noopener" href="https://pytorch.org/torchrec/"><code>TorchRec</code></a></em>  域库中的各种自定义数据集。</p>
<p>但有时这些现有的功能可能还不够。</p>
<p>在这种情况下，我们总是可以 <code>torch.utils.data.Dataset</code> 根据自己的喜好对其进行子类化和定制。</p>
<h1 id="What-we’re-going-to-cover-将要讨论的内容"><a href="#What-we’re-going-to-cover-将要讨论的内容" class="headerlink" title="What we’re going to cover? 将要讨论的内容"></a>What we’re going to cover? 将要讨论的内容</h1><img src="/2024/08/18/PyTorch-26H-5/PyTorch-26H-5-2.png" class="" title="PyTorch-26H-5-2">
<p>使用 <code>torchvision.datasets</code> 以及我们自己的自定义 <code>Dataset</code> 类来加载食物图像，然后构建一个 PyTorch 计算机视觉模型，希望能够对它们进行分类。</p>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center">话题</th>
<th style="text-align:center">内容</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">0. 导入 PyTorch 并设置与设备无关的代码</td>
<td style="text-align:center">加载 PyTorch，代码设置为与设备无关。</td>
</tr>
<tr>
<td style="text-align:center">1. 获取数据</td>
<td style="text-align:center">使用自己的披萨、牛排和寿司图像数据集</td>
</tr>
<tr>
<td style="text-align:center">2. 与数据融为一体（数据准备）</td>
<td style="text-align:center">在开始任何新的机器学习问题时，了解正在处理的数据至关重要。一些步骤来弄清楚我们拥有哪些数据。</td>
</tr>
<tr>
<td style="text-align:center">3. 转换数据</td>
<td style="text-align:center">通常，获得的数据并不能 100% 地用于机器学习模型，在这里我们将介绍可以采取的一些步骤来转换图像，以便它们可以用于模型。</td>
</tr>
<tr>
<td style="text-align:center">4. 使用 ImageFolder 加载数据（选项 1）</td>
<td style="text-align:center">PyTorch 有许多针对常见数据类型的内置数据加载函数。如果我们的图像是标准图像分类格式，ImageFolder 会很有用。</td>
</tr>
<tr>
<td style="text-align:center">5. 使用自定义数据集加载图像数据</td>
<td style="text-align:center">如果 PyTorch 没有内置函数来加载数据怎么办？这时我们可以构建自己的 torch.utils.data.Dataset 自定义子类。</td>
</tr>
<tr>
<td style="text-align:center">6. 其他形式的变换（数据增强）</td>
<td style="text-align:center">数据增强是扩展训练数据多样性的常用技术。探索 torchvision 的一些内置数据增强功能。</td>
</tr>
<tr>
<td style="text-align:center">7. 模型 0：未进行数据增强的 TinyVGG</td>
<td style="text-align:center">已经准备好数据，建立一个能够拟合它的模型。创建一些训练和测试函数来训练和评估我们的模型。</td>
</tr>
<tr>
<td style="text-align:center">8. 探索损失曲线</td>
<td style="text-align:center">损失曲线是查看模型如何随时间训练/改进的好方法。它也是查看模型是欠拟合还是过拟合的好方法。</td>
</tr>
<tr>
<td style="text-align:center">9. 模型 1：具有数据增强的 TinyVGG</td>
<td style="text-align:center">已经尝试了一个没有数据增强的模型，那尝试一个有数据增强的模型怎么样？</td>
</tr>
<tr>
<td style="text-align:center">10. 比较模型结果</td>
<td style="text-align:center">比较不同模型的损失曲线，看看哪个表现更好，并讨论一些提高性能的选项。</td>
</tr>
<tr>
<td style="text-align:center">11. 对自定义图像进行预测</td>
<td style="text-align:center">模型是在披萨、牛排和寿司图像的数据集上进行训练的。介绍如何使用我们训练过的模型来预测现有数据集之外的图像。</td>
</tr>
</tbody>
</table>
</div>
<h1 id="0-Importing-PyTorch-and-setting-up-device-agnostic-code-导入-PyTorch-并设置与设备无关的代码"><a href="#0-Importing-PyTorch-and-setting-up-device-agnostic-code-导入-PyTorch-并设置与设备无关的代码" class="headerlink" title="0. Importing PyTorch and setting up device-agnostic code 导入 PyTorch 并设置与设备无关的代码"></a>0. Importing PyTorch and setting up device-agnostic code 导入 PyTorch 并设置与设备无关的代码</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"></span><br><span class="line"><span class="comment"># Note: this notebook requires torch &gt;= 1.10.0</span></span><br><span class="line">torch.__version__</span><br></pre></td></tr></table></figure>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&#x27;2.4.1&#x27;</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Setup device-agnostic code</span></span><br><span class="line">device = <span class="string">&quot;cuda&quot;</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&quot;cpu&quot;</span></span><br><span class="line">device</span><br></pre></td></tr></table></figure>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&#x27;cuda&#x27;</span><br></pre></td></tr></table></figure>
<h1 id="1-Get-data"><a href="#1-Get-data" class="headerlink" title="1. Get data"></a>1. Get data</h1><p>机器学习是一个迭代过程，从小处着手，逐渐取得成效，并在必要时不断增强。</p>
<p>使用的数据是<a target="_blank" rel="noopener" href="https://data.vision.ee.ethz.ch/cvl/datasets_extra/food-101/">Food101 数据集</a>的一个子集。<br>Food101 是流行的计算机视觉基准，它包含 101 种不同食物的 1000 张图像，总计 101,000 张图像（75,750 张训练集和 25,250 张测试集）。<br>不会从 101 个食物类别开始，而是从 3 个开始：披萨、牛排和寿司。<br>我们不是每个类别有 1,000 张图像，而是从随机的 10% 开始（从小处开始，必要时增加）。</p>
<ul>
<li>原始<a target="_blank" rel="noopener" href="https://data.vision.ee.ethz.ch/cvl/datasets_extra/food-101/">Food101 数据集和论文网站</a>。</li>
<li><a target="_blank" rel="noopener" href="https://pytorch.org/vision/main/generated/torchvision.datasets.Food101.html"><code>torchvision.datasets.Food101</code></a>- 我为这本笔记本下载的数据版本。</li>
<li><a target="_blank" rel="noopener" href="https://github.com/mrdbourke/pytorch-deep-learning/blob/main/extras/04_custom_data_creation.ipynb"><code>extras/04_custom_data_creation.ipynb</code></a>- 我用来格式化 Food101 数据集以供此笔记本使用的笔记本。</li>
<li><a target="_blank" rel="noopener" href="https://github.com/mrdbourke/pytorch-deep-learning/blob/main/data/pizza_steak_sushi.zip"><code>data/pizza_steak_sushi.zip</code></a>- 使用上面链接的笔记本创建的 Food101 披萨、牛排和寿司图片的 zip 档案。</li>
</ul>
<blockquote>
<p>注意：即将使用的数据集已预先格式化，以适应我们的用途。但是，无论你正在处理什么问题，你通常都必须格式化自己的数据集。这是机器学习领域的常规做法。</p>
</blockquote>
<ul>
<li>需要去google Colab下载</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">import</span> zipfile</span><br><span class="line"><span class="keyword">from</span> pathlib <span class="keyword">import</span> Path</span><br><span class="line"></span><br><span class="line"><span class="comment"># Setup path to data folder</span></span><br><span class="line">data_path = Path(<span class="string">&quot;data/&quot;</span>)</span><br><span class="line">image_path = data_path / <span class="string">&quot;pizza_steak_sushi&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># If the image folder doesn&#x27;t exist, download it and prepare it... </span></span><br><span class="line"><span class="keyword">if</span> image_path.is_dir():</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;<span class="subst">&#123;image_path&#125;</span> directory exists.&quot;</span>)</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;Did not find <span class="subst">&#123;image_path&#125;</span> directory, creating one...&quot;</span>)</span><br><span class="line">    image_path.mkdir(parents=<span class="literal">True</span>, exist_ok=<span class="literal">True</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Download pizza, steak, sushi data</span></span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(data_path / <span class="string">&quot;pizza_steak_sushi.zip&quot;</span>, <span class="string">&quot;wb&quot;</span>) <span class="keyword">as</span> f:</span><br><span class="line">        request = requests.get(<span class="string">&quot;https://github.com/mrdbourke/pytorch-deep-learning/raw/main/data/pizza_steak_sushi.zip&quot;</span>)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;Downloading pizza, steak, sushi data...&quot;</span>)</span><br><span class="line">        f.write(request.content)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Unzip pizza, steak, sushi data</span></span><br><span class="line">    <span class="keyword">with</span> zipfile.ZipFile(data_path / <span class="string">&quot;pizza_steak_sushi.zip&quot;</span>, <span class="string">&quot;r&quot;</span>) <span class="keyword">as</span> zip_ref:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;Unzipping pizza, steak, sushi data...&quot;</span>) </span><br><span class="line">        zip_ref.extractall(image_path)</span><br></pre></td></tr></table></figure>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Did not find data/pizza_steak_sushi directory, creating one...</span><br><span class="line">Downloading pizza, steak, sushi data...</span><br><span class="line">Unzipping pizza, steak, sushi data...</span><br></pre></td></tr></table></figure>
<h1 id="2-Become-one-with-the-data-data-preparation-与数据融为一体（数据准备）"><a href="#2-Become-one-with-the-data-data-preparation-与数据融为一体（数据准备）" class="headerlink" title="2. Become one with the data (data preparation) 与数据融为一体（数据准备）"></a>2. Become one with the data (data preparation) 与数据融为一体（数据准备）</h1><p>在开始一个项目或建立任何类型的模型之前，了解正在处理的数据非常重要。</p>
<p>在我案例中，有标准图像分类格式的披萨、牛排和寿司图像。<br>图像分类格式包含位于单独目录中的不同类别的图像，这些类别以特定的类名命名。<br>例如，所有<code>pizza</code>图像都包含在<code>pizza/</code>目录中。<br>这种格式在许多不同的图像分类基准中很流行，包括<a target="_blank" rel="noopener" href="https://www.image-net.org/">ImageNet</a>（最流行的计算机视觉基准数据集）。<br>可以在下面看到存储格式的示例，图像数量是任意的。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">pizza_steak_sushi/ &lt;- overall dataset folder</span><br><span class="line">    train/ &lt;- training images</span><br><span class="line">        pizza/ &lt;- class name as folder name</span><br><span class="line">            image01.jpeg</span><br><span class="line">            image02.jpeg</span><br><span class="line">            ...</span><br><span class="line">        steak/</span><br><span class="line">            image24.jpeg</span><br><span class="line">            image25.jpeg</span><br><span class="line">            ...</span><br><span class="line">        sushi/</span><br><span class="line">            image37.jpeg</span><br><span class="line">            ...</span><br><span class="line"></span><br><span class="line">    test/ &lt;- testing images</span><br><span class="line">        pizza/</span><br><span class="line">            image101.jpeg</span><br><span class="line">            image102.jpeg</span><br><span class="line">            ...</span><br><span class="line">        steak/</span><br><span class="line">            image154.jpeg</span><br><span class="line">            image155.jpeg</span><br><span class="line">            ...</span><br><span class="line">        sushi/</span><br><span class="line">            image167.jpeg</span><br><span class="line">            ...</span><br></pre></td></tr></table></figure>
<p>采用这种数据存储结构并将其转换为可供 PyTorch 使用的数据集。</p>
<blockquote>
<p>注意：您处理的数据结构将根据您正在处理的问题而有所不同。但前提仍然存在：与数据融为一体，然后找到一种最佳方法将其转换为与 PyTorch 兼容的数据集。</p>
</blockquote>
<p>通过编写一个小辅助函数来遍历每个子目录并计算存在的文件数量，从而检查数据目录中的内容。</p>
<p>使用 Python 的内置<a target="_blank" rel="noopener" href="https://docs.python.org/3/library/os.html#os.walk"><code>os.walk()</code></a>。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">walk_through_dir</span>(<span class="params">dir_path</span>):</span><br><span class="line">  <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">  Walks through dir_path returning its contents.</span></span><br><span class="line"><span class="string">  Args:</span></span><br><span class="line"><span class="string">    dir_path (str or pathlib.Path): target directory</span></span><br><span class="line"><span class="string">  </span></span><br><span class="line"><span class="string">  Returns:</span></span><br><span class="line"><span class="string">    A print out of:</span></span><br><span class="line"><span class="string">      number of subdiretories in dir_path</span></span><br><span class="line"><span class="string">      number of images (files) in each subdirectory</span></span><br><span class="line"><span class="string">      name of each subdirectory</span></span><br><span class="line"><span class="string">  &quot;&quot;&quot;</span></span><br><span class="line">  <span class="keyword">for</span> dirpath, dirnames, filenames <span class="keyword">in</span> os.walk(dir_path):</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;There are <span class="subst">&#123;<span class="built_in">len</span>(dirnames)&#125;</span> directories and <span class="subst">&#123;<span class="built_in">len</span>(filenames)&#125;</span> images in &#x27;<span class="subst">&#123;dirpath&#125;</span>&#x27;.&quot;</span>)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">walk_through_dir(image_path)</span><br></pre></td></tr></table></figure>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">There are 2 directories and 0 images in &#x27;data\pizza_steak_sushi&#x27;.</span><br><span class="line">There are 3 directories and 0 images in &#x27;data\pizza_steak_sushi\test&#x27;.</span><br><span class="line">There are 0 directories and 25 images in &#x27;data\pizza_steak_sushi\test\pizza&#x27;.</span><br><span class="line">There are 0 directories and 19 images in &#x27;data\pizza_steak_sushi\test\steak&#x27;.</span><br><span class="line">There are 0 directories and 31 images in &#x27;data\pizza_steak_sushi\test\sushi&#x27;.</span><br><span class="line">There are 3 directories and 0 images in &#x27;data\pizza_steak_sushi\train&#x27;.</span><br><span class="line">There are 0 directories and 78 images in &#x27;data\pizza_steak_sushi\train\pizza&#x27;.</span><br><span class="line">There are 0 directories and 75 images in &#x27;data\pizza_steak_sushi\train\steak&#x27;.</span><br><span class="line">There are 0 directories and 72 images in &#x27;data\pizza_steak_sushi\train\sushi&#x27;.</span><br></pre></td></tr></table></figure>
<p>每个训练类大约有 75 张图像，每个测试类大约有 25 张图像。图像是原始 Food101 数据集的子集。</p>
<p>设置一下训练和测试路径。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Setup train and testing paths</span></span><br><span class="line">train_dir = image_path / <span class="string">&quot;train&quot;</span></span><br><span class="line">test_dir = image_path / <span class="string">&quot;test&quot;</span></span><br><span class="line"></span><br><span class="line">train_dir, test_dir</span><br></pre></td></tr></table></figure>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">(WindowsPath(&#x27;data/pizza_steak_sushi/train&#x27;),</span><br><span class="line"> WindowsPath(&#x27;data/pizza_steak_sushi/test&#x27;))</span><br></pre></td></tr></table></figure>
<h2 id="2-1-Visualize-an-image-可视化图像"><a href="#2-1-Visualize-an-image-可视化图像" class="headerlink" title="2.1 Visualize an image 可视化图像"></a>2.1 Visualize an image 可视化图像</h2><ul>
<li>使用  <a target="_blank" rel="noopener" href="https://docs.python.org/3/library/pathlib.html#pathlib.Path.glob"><code>pathlib.Path.glob()</code></a> 获取所有图像路径，以查找所有以 .jpg 结尾的文件。</li>
<li>使用 Python 的 <a target="_blank" rel="noopener" href="https://docs.python.org/3/library/random.html#random.choice"><code>random.choice()</code></a>.选择一个随机图像路径。</li>
<li>使用 <a target="_blank" rel="noopener" href="https://docs.python.org/3/library/pathlib.html#pathlib.PurePath.parent"><code>pathlib.Path.parent.stem</code></a>. 获取图像类名。</li>
<li>由于我们正在处理图像，我们将使用 <a target="_blank" rel="noopener" href="https://pillow.readthedocs.io/en/stable/reference/Image.html#PIL.Image.open"><code>PIL.Image.open()</code></a>（PIL 代表 Python 图像库）打开随机图像路径。</li>
<li>然后我们将显示图像并打印一些元数据。</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> random</span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"></span><br><span class="line"><span class="comment"># Set seed</span></span><br><span class="line">random.seed(<span class="number">42</span>) <span class="comment"># &lt;- try changing this and see what happens</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 1. Get all image paths (* means &quot;any combination&quot;) 获取所有图像路径（* 表示“任意组合”）</span></span><br><span class="line">image_path_list = <span class="built_in">list</span>(image_path.glob(<span class="string">&quot;*/*/*.jpg&quot;</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 2. Get random image path 获取随机图像路径</span></span><br><span class="line">random_image_path = random.choice(image_path_list)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 3. Get image class from path name (the image class is the name of the directory where the image is stored) 从路径名获取图像类（图像类是存储图像的目录名称）</span></span><br><span class="line">image_class = random_image_path.parent.stem</span><br><span class="line"></span><br><span class="line"><span class="comment"># 4. Open image 打开图片</span></span><br><span class="line">img = Image.<span class="built_in">open</span>(random_image_path)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 5. Print metadata 打印元数据</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Random image path: <span class="subst">&#123;random_image_path&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Image class: <span class="subst">&#123;image_class&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Image height: <span class="subst">&#123;img.height&#125;</span>&quot;</span>) </span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Image width: <span class="subst">&#123;img.width&#125;</span>&quot;</span>)</span><br><span class="line">img</span><br></pre></td></tr></table></figure>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">Random image path: data\pizza_steak_sushi\test\sushi\2394442.jpg</span><br><span class="line">Image class: sushi</span><br><span class="line">Image height: 408</span><br><span class="line">Image width: 512</span><br></pre></td></tr></table></figure>
<img src="/2024/08/18/PyTorch-26H-5/PyTorch-26H-5-3.png" class="" title="PyTorch-26H-5-3">
<p>我们可以使用 <a target="_blank" rel="noopener" href="https://matplotlib.org/3.5.0/api/_as_gen/matplotlib.pyplot.imshow.html"><code>matplotlib.pyplot.imshow()</code></a> 执行相同操作，但我们必须先将图像转换为 NumPy 数组。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="comment"># Turn the image into an array</span></span><br><span class="line">img_as_array = np.asarray(img)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Plot the image with matplotlib</span></span><br><span class="line">plt.figure(figsize=(<span class="number">10</span>, <span class="number">7</span>))</span><br><span class="line">plt.imshow(img_as_array)</span><br><span class="line">plt.title(<span class="string">f&quot;Image class: <span class="subst">&#123;image_class&#125;</span> | Image shape: <span class="subst">&#123;img_as_array.shape&#125;</span> -&gt; [height, width, color_channels]&quot;</span>)</span><br><span class="line">plt.axis(<span class="literal">False</span>);</span><br></pre></td></tr></table></figure>
<img src="/2024/08/18/PyTorch-26H-5/PyTorch-26H-5-4.png" class="" title="PyTorch-26H-5-4">
<h1 id="3-Transforming-data-转换数据"><a href="#3-Transforming-data-转换数据" class="headerlink" title="3. Transforming data 转换数据"></a>3. Transforming data 转换数据</h1><p>使用 PyTorch 使用图像数据之前，我们需要：</p>
<ul>
<li>将其转换为张量（我们图像的数值表示）。</li>
<li>将其变成<code>torch.utils.data.Dataset</code>和随后的<code>torch.utils.data.DataLoader</code>，我们简称为<code>Dataset</code>和<code>DataLoader</code>。</li>
</ul>
<p>PyTorch 有几种不同类型的预构建数据集和数据集加载器，具体取决于您正在处理的问题。</p>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center">问题空间</th>
<th style="text-align:center">预建数据集和函数</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">视觉 Vision</td>
<td style="text-align:center"><a target="_blank" rel="noopener" href="https://pytorch.org/vision/stable/datasets.html"><code>torchvision.datasets</code></a></td>
</tr>
<tr>
<td style="text-align:center">音频 Audio</td>
<td style="text-align:center"><a target="_blank" rel="noopener" href="https://pytorch.org/audio/stable/datasets.html"><code>torchaudio.datasets</code></a></td>
</tr>
<tr>
<td style="text-align:center">文本 Text</td>
<td style="text-align:center"><a target="_blank" rel="noopener" href="https://pytorch.org/text/stable/datasets.html"><code>torchtext.datasets</code></a></td>
</tr>
<tr>
<td style="text-align:center">推荐系统 Recommendation system</td>
<td style="text-align:center"><a target="_blank" rel="noopener" href="https://pytorch.org/torchrec/torchrec.datasets.html"><code>torchrec.datasets</code></a></td>
</tr>
</tbody>
</table>
</div>
<p>由于我们正在处理视觉问题，因此我们将研究<code>torchvision.datasets</code>数据加载功能以及<a target="_blank" rel="noopener" href="https://pytorch.org/vision/stable/transforms.html"><code>torchvision.transforms</code></a>如何准备数据。</p>
<p>引入基本库</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> DataLoader</span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> datasets, transforms</span><br></pre></td></tr></table></figure>
<h2 id="3-1-Transforming-data-with-torchvision-transforms"><a href="#3-1-Transforming-data-with-torchvision-transforms" class="headerlink" title="3.1 Transforming data with torchvision.transforms"></a>3.1 Transforming data with <code>torchvision.transforms</code></h2><p>有图像文件夹，但在使用 PyTorch 之前，我们需要将它们转换为张量。<br>可以做到这一点的方法之一是使用 <code>torchvision.transforms</code> 模块。<br><code>torchvision.transforms</code>包含许多预先构建的方法，用于格式化图像、将它们转换为张量，甚至操纵它们以进行数据增强（改变数据以使模型更难学习的做法，我们稍后会看到）目的。</p>
<p>编写一系列转换步骤：</p>
<ul>
<li>使用 <a target="_blank" rel="noopener" href="https://pytorch.org/vision/stable/generated/torchvision.transforms.Resize.html#torchvision.transforms.Resize"><code>transforms.Resize()</code></a> 调整图像大小（从大约 512x512 到 64x64，与  <a target="_blank" rel="noopener" href="https://poloclub.github.io/cnn-explainer/">CNN Explainer website</a> 网站上的图像形状相同）。</li>
<li>使用 <a target="_blank" rel="noopener" href="https://pytorch.org/vision/stable/generated/torchvision.transforms.RandomHorizontalFlip.html#torchvision.transforms.RandomHorizontalFlip"><code>transforms.RandomHorizontalFlip()</code></a> 在水平方向上随机翻转图像（这可以被视为一种数据增强形式，因为它会人为地改变我们的图像数据）。</li>
<li>使用  <a target="_blank" rel="noopener" href="https://pytorch.org/vision/stable/generated/torchvision.transforms.ToTensor.html#torchvision.transforms.ToTensor"><code>transforms.ToTensor()</code></a>将图像从 PIL 图像转换为 PyTorch 张量。</li>
</ul>
<p>我们可以使用 <a target="_blank" rel="noopener" href="https://pytorch.org/vision/stable/generated/torchvision.transforms.Compose.html#torchvision.transforms.Compose"><code>torchvision.transforms.Compose()</code></a> 编译所有这些步骤。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Write transform for image</span></span><br><span class="line"><span class="comment"># 编写图像变换</span></span><br><span class="line">data_transform = transforms.Compose([</span><br><span class="line">    <span class="comment"># Resize the images to 64x64</span></span><br><span class="line">    <span class="comment"># 将图像大小调整为 64x64</span></span><br><span class="line">    transforms.Resize(size=(<span class="number">64</span>, <span class="number">64</span>)),</span><br><span class="line">    <span class="comment"># Flip the images randomly on the horizontal</span></span><br><span class="line">    <span class="comment"># 水平随机翻转图像</span></span><br><span class="line">    transforms.RandomHorizontalFlip(p=<span class="number">0.5</span>), <span class="comment"># p = probability of flip, 0.5 = 50% chance## p = 翻转概率，0.5 = 50% 概率</span></span><br><span class="line">    <span class="comment"># Turn the image into a torch.Tensor</span></span><br><span class="line">    <span class="comment"># 将图像转换为 torch.Tensor</span></span><br><span class="line">    transforms.ToTensor() <span class="comment"># this also converts all pixel values from 0 to 255 to be between 0.0 and 1.0  # 这还将所有像素值从 0 到 255 转换为 0.0 到 1.0 之间</span></span><br><span class="line">])</span><br></pre></td></tr></table></figure>
<p>现在我们已经有了变换的组合，让我们编写一个函数来在各种图像上尝试它们。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">plot_transformed_images</span>(<span class="params">image_paths, transform, n=<span class="number">3</span>, seed=<span class="number">42</span></span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Plots a series of random images from image_paths.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Will open n image paths from image_paths, transform them</span></span><br><span class="line"><span class="string">    with transform and plot them side by side.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        image_paths (list): List of target image paths. </span></span><br><span class="line"><span class="string">        transform (PyTorch Transforms): Transforms to apply to images.</span></span><br><span class="line"><span class="string">        n (int, optional): Number of images to plot. Defaults to 3.</span></span><br><span class="line"><span class="string">        seed (int, optional): Random seed for the random generator. Defaults to 42.</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    random.seed(seed)</span><br><span class="line">    random_image_paths = random.sample(image_paths, k=n)</span><br><span class="line">    <span class="keyword">for</span> image_path <span class="keyword">in</span> random_image_paths:</span><br><span class="line">        <span class="keyword">with</span> Image.<span class="built_in">open</span>(image_path) <span class="keyword">as</span> f:</span><br><span class="line">            fig, ax = plt.subplots(<span class="number">1</span>, <span class="number">2</span>)</span><br><span class="line">            ax[<span class="number">0</span>].imshow(f) </span><br><span class="line">            ax[<span class="number">0</span>].set_title(<span class="string">f&quot;Original \nSize: <span class="subst">&#123;f.size&#125;</span>&quot;</span>)</span><br><span class="line">            ax[<span class="number">0</span>].axis(<span class="string">&quot;off&quot;</span>)</span><br><span class="line"></span><br><span class="line">            <span class="comment"># Transform and plot image</span></span><br><span class="line">            <span class="comment"># Note: permute() will change shape of image to suit matplotlib </span></span><br><span class="line">            <span class="comment"># (PyTorch default is [C, H, W] but Matplotlib is [H, W, C])</span></span><br><span class="line">            transformed_image = transform(f).permute(<span class="number">1</span>, <span class="number">2</span>, <span class="number">0</span>) </span><br><span class="line">            ax[<span class="number">1</span>].imshow(transformed_image) </span><br><span class="line">            ax[<span class="number">1</span>].set_title(<span class="string">f&quot;Transformed \nSize: <span class="subst">&#123;transformed_image.shape&#125;</span>&quot;</span>)</span><br><span class="line">            ax[<span class="number">1</span>].axis(<span class="string">&quot;off&quot;</span>)</span><br><span class="line"></span><br><span class="line">            fig.suptitle(<span class="string">f&quot;Class: <span class="subst">&#123;image_path.parent.stem&#125;</span>&quot;</span>, fontsize=<span class="number">16</span>)</span><br><span class="line"></span><br><span class="line">plot_transformed_images(image_path_list, </span><br><span class="line">                        transform=data_transform, </span><br><span class="line">                        n=<span class="number">3</span>)</span><br></pre></td></tr></table></figure>
<img src="/2024/08/18/PyTorch-26H-5/PyTorch-26H-5-5.png" class="" title="PyTorch-26H-5-5">
<p>可以使用 <code>torchvision.transforms</code> 将图像转换为张量。</p>
<p>如果需要，还会操纵它们的大小和方向（某些模型更喜欢不同大小和形状的图像）。<br>一般来说，图像的形状越大，模型能够恢复的信息就越多。<br>例如，大小为 [256, 256, 3] 的图像的像素数将比大小为 [64, 64, 3] 的图像多 16 倍 ((256 <em> 256 </em> 3) / (64 <em> 64 </em> 3) = 16)。<br>代价是像素越多，计算量就越大。</p>
<blockquote>
<p>注释掉 data_transform 中的一个转换并再次运行绘图函数 plot_transformed_images()，会发生什么？</p>
</blockquote>
<h1 id="4-Option-1-Loading-Image-Data-Using-ImageFolder"><a href="#4-Option-1-Loading-Image-Data-Using-ImageFolder" class="headerlink" title="4. Option 1: Loading Image Data Using ImageFolder"></a>4. Option 1: Loading Image Data Using <code>ImageFolder</code></h1><p>是时候将我们的图像数据转换为能够与 PyTorch 一起使用的数据集了。<br>由于数据是标准图像分类格式，可以使用类<a target="_blank" rel="noopener" href="https://pytorch.org/vision/stable/generated/torchvision.datasets.ImageFolder.html#torchvision.datasets.ImageFolder"><code>torchvision.datasets.ImageFolder</code></a>。<br>可以在其中传递目标图像目录的文件路径以及我们想要对图像执行的一系列转换。<br>在数据文件夹 <code>train_dir</code> 和 <code>test_dir</code> 上进行测试，传入 <code>transform=data_transform</code> 以将图像转换为张量。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Use ImageFolder to create dataset(s)</span></span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> datasets</span><br><span class="line">train_data = datasets.ImageFolder(root=train_dir, <span class="comment"># target folder of images</span></span><br><span class="line">                                  transform=data_transform, <span class="comment"># transforms to perform on data (images)</span></span><br><span class="line">                                  target_transform=<span class="literal">None</span>) <span class="comment"># transforms to perform on labels (if necessary)</span></span><br><span class="line"></span><br><span class="line">test_data = datasets.ImageFolder(root=test_dir, </span><br><span class="line">                                 transform=data_transform)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Train data:\n<span class="subst">&#123;train_data&#125;</span>\nTest data:\n<span class="subst">&#123;test_data&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">Train data:</span><br><span class="line">Dataset ImageFolder</span><br><span class="line">    Number of datapoints: 225</span><br><span class="line">    Root location: data\pizza_steak_sushi\train</span><br><span class="line">    StandardTransform</span><br><span class="line">Transform: Compose(</span><br><span class="line">               Resize(size=(64, 64), interpolation=bilinear, max_size=None, antialias=True)</span><br><span class="line">               RandomHorizontalFlip(p=0.5)</span><br><span class="line">               ToTensor()</span><br><span class="line">           )</span><br><span class="line">Test data:</span><br><span class="line">Dataset ImageFolder</span><br><span class="line">    Number of datapoints: 75</span><br><span class="line">    Root location: data\pizza_steak_sushi\test</span><br><span class="line">    StandardTransform</span><br><span class="line">Transform: Compose(</span><br><span class="line">               Resize(size=(64, 64), interpolation=bilinear, max_size=None, antialias=True)</span><br><span class="line">               RandomHorizontalFlip(p=0.5)</span><br><span class="line">               ToTensor()</span><br><span class="line">           )</span><br></pre></td></tr></table></figure>
<p>通过检查 <code>classes</code> 和 <code>class_to_idx</code> 属性以及训练和测试集的长度来检查它们。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Get class names as a list</span></span><br><span class="line">class_names = train_data.classes</span><br><span class="line">class_names</span><br></pre></td></tr></table></figure>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[&#x27;pizza&#x27;, &#x27;steak&#x27;, &#x27;sushi&#x27;]</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Can also get class names as a dict</span></span><br><span class="line">class_dict = train_data.class_to_idx</span><br><span class="line">class_dict</span><br></pre></td></tr></table></figure>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&#123;&#x27;pizza&#x27;: 0, &#x27;steak&#x27;: 1, &#x27;sushi&#x27;: 2&#125;</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Check the lengths</span></span><br><span class="line"><span class="built_in">len</span>(train_data), <span class="built_in">len</span>(test_data)</span><br></pre></td></tr></table></figure>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">(225, 75)</span><br></pre></td></tr></table></figure>
<p>在 <code>train_data</code> 和 <code>test_data</code> 数据集上建立索引来查找样本及其目标标签。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">img, label = train_data[<span class="number">0</span>][<span class="number">0</span>], train_data[<span class="number">0</span>][<span class="number">1</span>]</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Image tensor:\n<span class="subst">&#123;img&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Image shape: <span class="subst">&#123;img.shape&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Image datatype: <span class="subst">&#123;img.dtype&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Image label: <span class="subst">&#123;label&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Label datatype: <span class="subst">&#123;<span class="built_in">type</span>(label)&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">Image tensor:</span><br><span class="line">tensor([[[0.1176, 0.1216, 0.1255,  ..., 0.0980, 0.1020, 0.1137],</span><br><span class="line">         [0.1294, 0.1294, 0.1294,  ..., 0.0980, 0.0980, 0.1059],</span><br><span class="line">         [0.1333, 0.1333, 0.1333,  ..., 0.0941, 0.0980, 0.1020],</span><br><span class="line">         ...,</span><br><span class="line">         [0.1686, 0.1647, 0.1686,  ..., 0.1255, 0.1098, 0.1098],</span><br><span class="line">         [0.1686, 0.1647, 0.1686,  ..., 0.1098, 0.0941, 0.0863],</span><br><span class="line">         [0.1647, 0.1647, 0.1686,  ..., 0.0980, 0.0863, 0.0863]],</span><br><span class="line"></span><br><span class="line">        [[0.0588, 0.0588, 0.0588,  ..., 0.0745, 0.0706, 0.0745],</span><br><span class="line">         [0.0627, 0.0627, 0.0627,  ..., 0.0745, 0.0706, 0.0706],</span><br><span class="line">         [0.0706, 0.0706, 0.0706,  ..., 0.0745, 0.0745, 0.0706],</span><br><span class="line">         ...,</span><br><span class="line">         [0.2392, 0.2392, 0.2510,  ..., 0.1373, 0.1333, 0.1255],</span><br><span class="line">         [0.2314, 0.2392, 0.2510,  ..., 0.1255, 0.1176, 0.1098],</span><br><span class="line">         [0.2275, 0.2353, 0.2431,  ..., 0.1137, 0.1059, 0.1020]],</span><br><span class="line"></span><br><span class="line">        [[0.0196, 0.0196, 0.0196,  ..., 0.0902, 0.0902, 0.0941],</span><br><span class="line">         [0.0196, 0.0157, 0.0196,  ..., 0.0902, 0.0863, 0.0902],</span><br><span class="line">         [0.0196, 0.0157, 0.0157,  ..., 0.0902, 0.0902, 0.0902],</span><br><span class="line">         ...,</span><br><span class="line">         [0.1804, 0.1882, 0.1961,  ..., 0.1490, 0.1333, 0.1294],</span><br><span class="line">         [0.1804, 0.1843, 0.1922,  ..., 0.1255, 0.1137, 0.1098],</span><br><span class="line">         [0.1765, 0.1804, 0.1843,  ..., 0.1059, 0.1020, 0.1059]]])</span><br><span class="line">Image shape: torch.Size([3, 64, 64])</span><br><span class="line">Image datatype: torch.float32</span><br><span class="line">Image label: 0</span><br><span class="line">Label datatype: &lt;class &#x27;int&#x27;&gt;</span><br></pre></td></tr></table></figure>
<p>图像现在采用张量的形式（形状为 [3, 64, 64]），标签采用与特定类相关的整数形式（由 class_to_idx 属性引用）。</p>
<p>我们如何使用 matplotlib 绘制单个图像张量？<br>我们首先必须进行置换（重新排列其维度的顺序）以使其兼容。<br>现在我们的图像尺寸采用 CHW（颜色通道、高度、宽度）格式，但 matplotlib 更喜欢 HWC（高度、宽度、颜色通道）。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Rearrange the order of dimensions</span></span><br><span class="line">img_permute = img.permute(<span class="number">1</span>, <span class="number">2</span>, <span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Print out different shapes (before and after permute)</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Original shape: <span class="subst">&#123;img.shape&#125;</span> -&gt; [color_channels, height, width]&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Image permute shape: <span class="subst">&#123;img_permute.shape&#125;</span> -&gt; [height, width, color_channels]&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Plot the image</span></span><br><span class="line">plt.figure(figsize=(<span class="number">10</span>, <span class="number">7</span>))</span><br><span class="line">plt.imshow(img.permute(<span class="number">1</span>, <span class="number">2</span>, <span class="number">0</span>))</span><br><span class="line">plt.axis(<span class="string">&quot;off&quot;</span>)</span><br><span class="line">plt.title(class_names[label], fontsize=<span class="number">14</span>);</span><br></pre></td></tr></table></figure>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Original shape: torch.Size([3, 64, 64]) -&gt; [color_channels, height, width]</span><br><span class="line">Image permute shape: torch.Size([64, 64, 3]) -&gt; [height, width, color_channels]</span><br></pre></td></tr></table></figure>
<img src="/2024/08/18/PyTorch-26H-5/PyTorch-26H-5-6.png" class="" title="PyTorch-26H-5-6">
<p>请注意，图像现在更加像素化（质量更低）。</p>
<p>这是因为图像的大小从 512x512 调整为 64x64 像素。</p>
<p>这里的直觉是，如果认为图像更难识别发生了什么，那么模型也可能会发现它更难理解。</p>
<h2 id="4-1-Turn-loaded-images-into-DataLoader’s"><a href="#4-1-Turn-loaded-images-into-DataLoader’s" class="headerlink" title="4.1 Turn loaded images into DataLoader’s"></a>4.1 Turn loaded images into DataLoader’s</h2><p>我们已经将图像作为 PyTorch 数据集，但现在让我们将它们转换为 DataLoader。</p>
<p>我们将使用 <a target="_blank" rel="noopener" href="https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader"><code>torch.utils.data.DataLoader</code></a> 进行此操作。</p>
<p>将数据集转换为 DataLoader 使它们可迭代，因此模型可以遍历并了解样本和目标（特征和标签）之间的关系。</p>
<p>为简单起见，我们将使用 <code>batch_size=1</code> 和 <code>num_workers=1</code>。</p>
<p><code>num_workers</code> 是什么：它定义了将创建多少个子进程来加载您的数据。<br><code>num_workers</code> 设置的值越高，PyTorch 将使用越多的计算能力来加载您的数据。<br>通常通过 Python 的 <a target="_blank" rel="noopener" href="https://docs.python.org/3/library/os.html#os.cpu_count"><code>os.cpu_count()</code></a> 将其设置为我机器上的 CPU 总数。<br>这可确保 <code>DataLoader</code> 使用尽可能多的核心来加载数据。</p>
<blockquote>
<p>注意：使用<a target="_blank" rel="noopener" href="https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader">PyTorch documentation</a>中的 torch.utils.data.DataLoader 熟悉更多参数。</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Turn train and test Datasets into DataLoaders</span></span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> DataLoader</span><br><span class="line">train_dataloader = DataLoader(dataset=train_data, </span><br><span class="line">                              batch_size=<span class="number">1</span>, <span class="comment"># how many samples per batch?</span></span><br><span class="line">                              num_workers=<span class="number">1</span>, <span class="comment"># how many subprocesses to use for data loading? (higher = more)</span></span><br><span class="line">                              shuffle=<span class="literal">True</span>) <span class="comment"># shuffle the data?</span></span><br><span class="line"></span><br><span class="line">test_dataloader = DataLoader(dataset=test_data, </span><br><span class="line">                             batch_size=<span class="number">1</span>, </span><br><span class="line">                             num_workers=<span class="number">1</span>, </span><br><span class="line">                             shuffle=<span class="literal">False</span>) <span class="comment"># don&#x27;t usually need to shuffle testing data</span></span><br><span class="line"></span><br><span class="line">train_dataloader, test_dataloader</span><br></pre></td></tr></table></figure>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">(&lt;torch.utils.data.dataloader.DataLoader at 0x277ca8a84c0&gt;,</span><br><span class="line"> &lt;torch.utils.data.dataloader.DataLoader at 0x277ca8a83a0&gt;)</span><br></pre></td></tr></table></figure>
<p>现在我们的数据是可迭代的，让我们尝试一下并检查形状。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">img, label = <span class="built_in">next</span>(<span class="built_in">iter</span>(train_dataloader))</span><br><span class="line"></span><br><span class="line"><span class="comment"># Batch size will now be 1, try changing the batch_size parameter above and see what happens</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Image shape: <span class="subst">&#123;img.shape&#125;</span> -&gt; [batch_size, color_channels, height, width]&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Label shape: <span class="subst">&#123;label.shape&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Image shape: torch.Size([1, 3, 64, 64]) -&gt; [batch_size, color_channels, height, width]</span><br><span class="line">Label shape: torch.Size([1])</span><br></pre></td></tr></table></figure>
<p>现在可以将这些 DataLoader 与训练和测试循环一起使用来训练模型。</p>
<p>但在此之前，先看看加载图像（或几乎任何其他类型的数据）的另一种选择。</p>
<h1 id="5-Option-2-Loading-Image-Data-with-a-Custom-Dataset-使用自定义数据集"><a href="#5-Option-2-Loading-Image-Data-with-a-Custom-Dataset-使用自定义数据集" class="headerlink" title="5. Option 2: Loading Image Data with a Custom Dataset 使用自定义数据集"></a>5. Option 2: Loading Image Data with a Custom <code>Dataset</code> 使用自定义数据集</h1><p>如果没有预先构建的 <code>Dataset</code> 创建器（如  <a target="_blank" rel="noopener" href="https://pytorch.org/vision/stable/datasets.html#torchvision.datasets.ImageFolder"><code>torchvision.datasets.ImageFolder()</code></a>）怎么办？</p>
<p>或者没有针对特定问题的数据集创建器？自己构建。<br>创建自己的 Custom <code>Dataset</code> 加载方式有什么优缺点？</p>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center">创建自定义数据集的优点</th>
<th style="text-align:center">创建自定义数据集的缺点</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">几乎任何东西都可以创建数据集。</td>
<td style="text-align:center">尽管你可以用几乎任何东西创建数据集，但这并不意味着它会起作用。</td>
</tr>
<tr>
<td style="text-align:center">不限于 PyTorch 预构建的 Dataset 函数。</td>
<td style="text-align:center">使用自定义数据集通常会导致编写更多代码，这很容易出现错误或性能问题。</td>
</tr>
</tbody>
</table>
</div>
<p>要查看实际效果，让我们通过子类化 <code>torch.utils.data.Dataset</code>（PyTorch 中所有 Dataset 的基类）来复制 <code>torchvision.datasets.ImageFolder()</code>。</p>
<p>导入所需的模块：</p>
<ul>
<li>用于处理目录的 Python <code>os</code>（我们的数据存储在目录中）。</li>
<li>用于处理文件路径的 Python <code>pathlib</code>（我们的每张图片都有一个唯一的文件路径）。</li>
<li>用于所有 PyTorch 内容的 <code>torch</code>。</li>
<li>用于加载图像的 PIL <code>Image</code>类。</li>
<li>用于子类化并创建我们自己的自定义 <code>Dataset</code> 的 <code>torchvision.transforms</code> 将我们的图像转换为张量。</li>
<li>来自 Python 的 <code>typing</code> 模块的各种类型，用于将类型提示添加到我们的代码中。</li>
</ul>
<blockquote>
<p>注意：您可以根据自己的数据集自定义以下步骤。前提是：编写代码以您想要的格式加载数据。</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> pathlib</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> Dataset</span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> transforms</span><br><span class="line"><span class="keyword">from</span> typing <span class="keyword">import</span> <span class="type">Tuple</span>, <span class="type">Dict</span>, <span class="type">List</span></span><br></pre></td></tr></table></figure>
<p>还记得我们的 <code>torchvision.datasets.ImageFolder()</code> 实例如何允许我们使用 <code>classes</code> 和 <code>class_to_idx</code> 属性吗？</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Instance of torchvision.datasets.ImageFolder()</span></span><br><span class="line">train_data.classes, train_data.class_to_idx</span><br></pre></td></tr></table></figure>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">([&#x27;pizza&#x27;, &#x27;steak&#x27;, &#x27;sushi&#x27;], &#123;&#x27;pizza&#x27;: 0, &#x27;steak&#x27;: 1, &#x27;sushi&#x27;: 2&#125;)</span><br></pre></td></tr></table></figure>
<h2 id="5-1-Creating-a-helper-function-to-get-class-names-创建一个辅助函数来获取类"><a href="#5-1-Creating-a-helper-function-to-get-class-names-创建一个辅助函数来获取类" class="headerlink" title="5.1 Creating a helper function to get class names 创建一个辅助函数来获取类"></a>5.1 Creating a helper function to get class names 创建一个辅助函数来获取类</h2><p>编写一个辅助函数，该函数能够在给定目录路径的情况下创建类名列表和类名及其索引的字典。</p>
<ul>
<li>使用 <code>os.scandir()</code> 遍历目标目录（理想情况下，目录采用标准图像分类格式）获取类名。</li>
<li>如果未找到类名，则引发错误（如果发生这种情况，则目录结构可能有问题）。</li>
<li>将类名转换为数字标签字典，每个类一个。</li>
</ul>
<p>在编写完整函数之前，让我们先看第 1 步的一个小例子。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Setup path for target directory</span></span><br><span class="line">target_directory = train_dir</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Target directory: <span class="subst">&#123;target_directory&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Get the class names from the target directory</span></span><br><span class="line">class_names_found = <span class="built_in">sorted</span>([entry.name <span class="keyword">for</span> entry <span class="keyword">in</span> <span class="built_in">list</span>(os.scandir(image_path / <span class="string">&quot;train&quot;</span>))])</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Class names found: <span class="subst">&#123;class_names_found&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Target directory: data\pizza_steak_sushi\train</span><br><span class="line">Class names found: [&#x27;pizza&#x27;, &#x27;steak&#x27;, &#x27;sushi&#x27;]</span><br></pre></td></tr></table></figure>
<p>如何将它变成一个完整的功能？</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Make function to find classes in target directory</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">find_classes</span>(<span class="params">directory: <span class="built_in">str</span></span>) -&gt; <span class="type">Tuple</span>[<span class="type">List</span>[<span class="built_in">str</span>], <span class="type">Dict</span>[<span class="built_in">str</span>, <span class="built_in">int</span>]]:</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Finds the class folder names in a target directory.</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    Assumes target directory is in standard image classification format.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        directory (str): target directory to load classnames from.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">        Tuple[List[str], Dict[str, int]]: (list_of_class_names, dict(class_name: idx...))</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    Example:</span></span><br><span class="line"><span class="string">        find_classes(&quot;food_images/train&quot;)</span></span><br><span class="line"><span class="string">        &gt;&gt;&gt; ([&quot;class_1&quot;, &quot;class_2&quot;], &#123;&quot;class_1&quot;: 0, ...&#125;)</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="comment"># 1. Get the class names by scanning the target directory</span></span><br><span class="line">    <span class="comment"># 1. 通过扫描目标目录获取类名</span></span><br><span class="line">    classes = <span class="built_in">sorted</span>(entry.name <span class="keyword">for</span> entry <span class="keyword">in</span> os.scandir(directory) <span class="keyword">if</span> entry.is_dir())</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 2. Raise an error if class names not found</span></span><br><span class="line">    <span class="comment"># 2. 如果找不到类名则抛出错误</span></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> classes:</span><br><span class="line">        <span class="keyword">raise</span> FileNotFoundError(<span class="string">f&quot;Couldn&#x27;t find any classes in <span class="subst">&#123;directory&#125;</span>.&quot;</span>)</span><br><span class="line">        </span><br><span class="line">    <span class="comment"># 3. Create a dictionary of index labels (computers prefer numerical rather than string labels)</span></span><br><span class="line">    <span class="comment"># 3. 创建索引标签词典（计算机更喜欢数字而不是字符串标签）</span></span><br><span class="line">    class_to_idx = &#123;cls_name: i <span class="keyword">for</span> i, cls_name <span class="keyword">in</span> <span class="built_in">enumerate</span>(classes)&#125;</span><br><span class="line">    <span class="keyword">return</span> classes, class_to_idx</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">find_classes(train_dir)</span><br></pre></td></tr></table></figure>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">([&#x27;pizza&#x27;, &#x27;steak&#x27;, &#x27;sushi&#x27;], &#123;&#x27;pizza&#x27;: 0, &#x27;steak&#x27;: 1, &#x27;sushi&#x27;: 2&#125;)</span><br></pre></td></tr></table></figure>
<h2 id="5-2-Create-a-custom-Dataset-to-replicate-ImageFolder-创建自定义Dataset来复制-ImageFolder"><a href="#5-2-Create-a-custom-Dataset-to-replicate-ImageFolder-创建自定义Dataset来复制-ImageFolder" class="headerlink" title="5.2 Create a custom Dataset  to replicate ImageFolder 创建自定义Dataset来复制 ImageFolder"></a>5.2 Create a custom <code>Dataset</code>  to replicate <code>ImageFolder</code> 创建自定义Dataset来复制 ImageFolder</h2><p>准备好构建自己的自定义<code>Dataset</code>。<br>构建一个数据集来复制 <code>torchvision.datasets.ImageFolder()</code> 的功能。<br>这将是一个很好的做法，此外，它还会揭示创建自己的自定义数据集所需的一些步骤。</p>
<p>实现步骤：</p>
<ul>
<li><code>torch.utils.data.Dataset</code> 的子类。</li>
<li>使用 <code>targ_dir</code> 参数（目标数据目录）和 <code>transform</code> 参数初始化我们的子类（这样我们就可以选择在需要时转换数据）。</li>
<li>为<code>paths</code>（目标图像的路径）、<code>transform</code>（我们可能想要使用的转换，可以是 <code>None</code>）、<code>classes</code> 和 <code>class_to_idx</code>（来自我们的 <code>find_classes()</code> 函数）创建几个属性。</li>
<li>创建一个函数来从文件加载图像并返回它们，这可以使用 <code>PIL</code> 或  <a target="_blank" rel="noopener" href="https://pytorch.org/vision/stable/io.html#image"><code>torchvision.io</code></a>（用于视觉数据的输入/输出）。</li>
<li>覆盖 <code>torch.utils.data.Dataset</code> 的 <code>__len__</code> 方法以返回 <code>Dataset</code> 中的样本数，这是推荐的，但不是必需的。这样就可以调用 <code>len(Dataset)</code>。</li>
<li>覆盖 <code>torch.utils.data.Dataset</code> 的<code>__getitem__</code> 方法以从数据集返回单个样本，这是必需的。</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Write a custom dataset class (inherits from torch.utils.data.Dataset)</span></span><br><span class="line"><span class="comment"># 编写自定义数据集类（继承自 torch.utils.data.Dataset）</span></span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> Dataset</span><br><span class="line"></span><br><span class="line"><span class="comment"># 1. Subclass torch.utils.data.Dataset</span></span><br><span class="line"><span class="comment"># 1. 子类 torch.utils.data.Dataset</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">ImageFolderCustom</span>(<span class="title class_ inherited__">Dataset</span>):</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 2. Initialize with a targ_dir and transform (optional) parameter</span></span><br><span class="line">    <span class="comment"># 2. 使用 targ_dir 和 transform （可选）参数进行初始化</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, targ_dir: <span class="built_in">str</span>, transform=<span class="literal">None</span></span>) -&gt; <span class="literal">None</span>:</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 3. Create class attributes</span></span><br><span class="line">        <span class="comment"># 3. 创建类属性</span></span><br><span class="line">        <span class="comment"># Get all image paths</span></span><br><span class="line">        <span class="comment"># 获取所有图片路径</span></span><br><span class="line">        self.paths = <span class="built_in">list</span>(pathlib.Path(targ_dir).glob(<span class="string">&quot;*/*.jpg&quot;</span>)) <span class="comment"># note: you&#x27;d have to update this if you&#x27;ve got .png&#x27;s or .jpeg&#x27;s # 注意：如果你有 .png 或 .jpeg 则必须更新它</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Setup transforms</span></span><br><span class="line">        <span class="comment"># 设置变换</span></span><br><span class="line">        self.transform = transform</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Create classes and class_to_idx attributes</span></span><br><span class="line">        <span class="comment"># 创建类和 class_to_idx 属性</span></span><br><span class="line">        self.classes, self.class_to_idx = find_classes(targ_dir)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 4. Make function to load images</span></span><br><span class="line">    <span class="comment"># 4. 制作加载图像的函数</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">load_image</span>(<span class="params">self, index: <span class="built_in">int</span></span>) -&gt; Image.Image:</span><br><span class="line">        <span class="string">&quot;Opens an image via a path and returns it.&quot;</span></span><br><span class="line">        image_path = self.paths[index]</span><br><span class="line">        <span class="keyword">return</span> Image.<span class="built_in">open</span>(image_path) </span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 5. Overwrite the __len__() method (optional but recommended for subclasses of torch.utils.data.Dataset)</span></span><br><span class="line">    <span class="comment"># 5. 重写__len__()方法（可选，但建议用于torch.utils.data.Dataset的子类）</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__len__</span>(<span class="params">self</span>) -&gt; <span class="built_in">int</span>:</span><br><span class="line">        <span class="string">&quot;Returns the total number of samples.&quot;</span></span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">len</span>(self.paths)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 6. Overwrite the __getitem__() method (required for subclasses of torch.utils.data.Dataset)</span></span><br><span class="line">    <span class="comment"># 6. 重写 __getitem__() 方法（torch.utils.data.Dataset 子类所需）</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__getitem__</span>(<span class="params">self, index: <span class="built_in">int</span></span>) -&gt; <span class="type">Tuple</span>[torch.Tensor, <span class="built_in">int</span>]:</span><br><span class="line">        <span class="string">&quot;Returns one sample of data, data and label (X, y).&quot;</span></span><br><span class="line">        img = self.load_image(index)</span><br><span class="line">        class_name  = self.paths[index].parent.name <span class="comment"># expects path in data_folder/class_name/image.jpeg # 期望路径在 data_folder/class_name/image.jpeg 中</span></span><br><span class="line">        class_idx = self.class_to_idx[class_name]</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Transform if necessary</span></span><br><span class="line">        <span class="comment"># 必要时进行转换</span></span><br><span class="line">        <span class="keyword">if</span> self.transform:</span><br><span class="line">            <span class="keyword">return</span> self.transform(img), class_idx <span class="comment"># return data, label (X, y)</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">return</span> img, class_idx <span class="comment"># return data, label (X, y)</span></span><br></pre></td></tr></table></figure>
<p>加载图像需要一大堆代码。这是创建自定义<code>Dataset</code>的缺点之一。</p>
<p>但是，现在我们已经编写了一次，我们可以将其与其他一些有用的数据函数一起移到 <code>.py</code> 文件中，例如 <code>data_loader.py</code>，并在以后重复使用。</p>
<p>在测试新的 <code>ImageFolderCustom</code> 类之前，让我们创建一些转换来准备图像。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Augment train data</span></span><br><span class="line">train_transforms = transforms.Compose([</span><br><span class="line">    transforms.Resize((<span class="number">64</span>, <span class="number">64</span>)),</span><br><span class="line">    transforms.RandomHorizontalFlip(p=<span class="number">0.5</span>),</span><br><span class="line">    transforms.ToTensor()</span><br><span class="line">])</span><br><span class="line"></span><br><span class="line"><span class="comment"># Don&#x27;t augment test data, only reshape</span></span><br><span class="line">test_transforms = transforms.Compose([</span><br><span class="line">    transforms.Resize((<span class="number">64</span>, <span class="number">64</span>)),</span><br><span class="line">    transforms.ToTensor()</span><br><span class="line">])</span><br></pre></td></tr></table></figure>
<p>使用自己的 <code>ImageFolderCustom</code> 类将我们的训练图像（包含在 <code>train_dir</code> 中）和测试图像（包含在 <code>test_dir</code> 中）转换为数据集。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">train_data_custom = ImageFolderCustom(targ_dir=train_dir, </span><br><span class="line">                                      transform=train_transforms)</span><br><span class="line">test_data_custom = ImageFolderCustom(targ_dir=test_dir, </span><br><span class="line">                                     transform=test_transforms)</span><br><span class="line">train_data_custom, test_data_custom</span><br></pre></td></tr></table></figure>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">(&lt;__main__.ImageFolderCustom at 0x277ca8b76a0&gt;,</span><br><span class="line"> &lt;__main__.ImageFolderCustom at 0x277ca8b7d90&gt;)</span><br></pre></td></tr></table></figure>
<p>让我们尝试在新的数据集上调用 <code>len()</code> 并找到 <code>classes</code> 和 <code>class_to_idx</code> 属性。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">len</span>(train_data_custom), <span class="built_in">len</span>(test_data_custom)</span><br></pre></td></tr></table></figure>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">(225, 75)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">train_data_custom.classes</span><br></pre></td></tr></table></figure>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[&#x27;pizza&#x27;, &#x27;steak&#x27;, &#x27;sushi&#x27;]</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">train_data_custom.class_to_idx</span><br></pre></td></tr></table></figure>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&#123;&#x27;pizza&#x27;: 0, &#x27;steak&#x27;: 1, &#x27;sushi&#x27;: 2&#125;</span><br></pre></td></tr></table></figure>
<p><code>len(test_data_custom) == len(test_data)</code> and <code>len(test_data_custom) == len(test_data)</code></p>
<p>我们也可以检查与由 <code>torchvision.datasets.ImageFolder()</code> 类创建的 <code>Dataset</code> 是否相等。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Check for equality amongst our custom Dataset and ImageFolder Dataset</span></span><br><span class="line"><span class="built_in">print</span>((<span class="built_in">len</span>(train_data_custom) == <span class="built_in">len</span>(train_data)) &amp; (<span class="built_in">len</span>(test_data_custom) == <span class="built_in">len</span>(test_data)))</span><br><span class="line"><span class="built_in">print</span>(train_data_custom.classes == train_data.classes)</span><br><span class="line"><span class="built_in">print</span>(train_data_custom.class_to_idx == train_data.class_to_idx)</span><br></pre></td></tr></table></figure>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">True</span><br><span class="line">True</span><br><span class="line">True</span><br></pre></td></tr></table></figure>
<p>我们如何进一步绘制一些随机图像来测试我们的<code>__getitem__</code>覆写？</p>
<h2 id="5-3-Create-a-function-to-display-random-images-创建一个显示随机图像的函数"><a href="#5-3-Create-a-function-to-display-random-images-创建一个显示随机图像的函数" class="headerlink" title="5.3 Create a function to display random images 创建一个显示随机图像的函数"></a>5.3 Create a function to display random images 创建一个显示随机图像的函数</h2><p>创建一个名为的辅助函数<code>display_random_images()</code>，帮助我们在<code>Dataset</code>‘s 中可视化图像。</p>
<ul>
<li>接收一个 <code>Dataset</code> 和许多其他参数，例如 <code>classes</code> （我们的目标类的名称）、要显示的图像数量（<code>n</code>）和随机种子。</li>
<li>为了防止显示失控，我们将 <code>n</code> 限制为 10 张图像。</li>
<li>设置可重现图的随机种子（如果设置了<code>seed</code>）。</li>
<li>获取随机样本索引列表（我们可以使用 Python 的 <code>random.sample()</code> 进行绘制）。</li>
<li>设置 <code>matplotlib</code> 图。</li>
<li>循环遍历步骤 4 中找到的随机样本索引并使用 <code>matplotlib</code> 绘制它们。</li>
<li>确保样本图像的形状为 <code>HWC</code>（高度、宽度、颜色通道），以便我们可以绘制它们。</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 1. Take in a Dataset as well as a list of class names</span></span><br><span class="line"><span class="comment"># 1. 获取数据集以及类名列表</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">display_random_images</span>(<span class="params">dataset: torch.utils.data.dataset.Dataset,</span></span><br><span class="line"><span class="params">                          classes: <span class="type">List</span>[<span class="built_in">str</span>] = <span class="literal">None</span>,</span></span><br><span class="line"><span class="params">                          n: <span class="built_in">int</span> = <span class="number">10</span>,</span></span><br><span class="line"><span class="params">                          display_shape: <span class="built_in">bool</span> = <span class="literal">True</span>,</span></span><br><span class="line"><span class="params">                          seed: <span class="built_in">int</span> = <span class="literal">None</span></span>):</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 2. Adjust display if n too high</span></span><br><span class="line">    <span class="comment"># 2. 如果 n 太高则调整显示</span></span><br><span class="line">    <span class="keyword">if</span> n &gt; <span class="number">10</span>:</span><br><span class="line">        n = <span class="number">10</span></span><br><span class="line">        display_shape = <span class="literal">False</span></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;For display purposes, n shouldn&#x27;t be larger than 10, setting to 10 and removing shape display.&quot;</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 3. Set random seed</span></span><br><span class="line">    <span class="comment"># 3. 设置随机种子</span></span><br><span class="line">    <span class="keyword">if</span> seed:</span><br><span class="line">        random.seed(seed)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 4. Get random sample indexes</span></span><br><span class="line">    <span class="comment"># 4. 获取随机样本索引</span></span><br><span class="line">    random_samples_idx = random.sample(<span class="built_in">range</span>(<span class="built_in">len</span>(dataset)), k=n)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 5. Setup plot</span></span><br><span class="line">    <span class="comment"># 5. 设置plot</span></span><br><span class="line">    plt.figure(figsize=(<span class="number">16</span>, <span class="number">8</span>))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 6. Loop through samples and display random samples </span></span><br><span class="line">    <span class="comment"># 6. 循环遍历样本并显示随机样本</span></span><br><span class="line">    <span class="keyword">for</span> i, targ_sample <span class="keyword">in</span> <span class="built_in">enumerate</span>(random_samples_idx):</span><br><span class="line">        targ_image, targ_label = dataset[targ_sample][<span class="number">0</span>], dataset[targ_sample][<span class="number">1</span>]</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 7. Adjust image tensor shape for plotting: [color_channels, height, width] -&gt; [color_channels, height, width]</span></span><br><span class="line">        <span class="comment"># 7. 调整图像张量形状以便绘图：[color_channels，height，width] -&gt; [color_channels，height，width]</span></span><br><span class="line">        targ_image_adjust = targ_image.permute(<span class="number">1</span>, <span class="number">2</span>, <span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Plot adjusted samples</span></span><br><span class="line">        <span class="comment"># 绘制调整后的样本</span></span><br><span class="line">        plt.subplot(<span class="number">1</span>, n, i+<span class="number">1</span>)</span><br><span class="line">        plt.imshow(targ_image_adjust)</span><br><span class="line">        plt.axis(<span class="string">&quot;off&quot;</span>)</span><br><span class="line">        <span class="keyword">if</span> classes:</span><br><span class="line">            title = <span class="string">f&quot;class: <span class="subst">&#123;classes[targ_label]&#125;</span>&quot;</span></span><br><span class="line">            <span class="keyword">if</span> display_shape:</span><br><span class="line">                title = title + <span class="string">f&quot;\nshape: <span class="subst">&#123;targ_image_adjust.shape&#125;</span>&quot;</span></span><br><span class="line">        plt.title(title)</span><br></pre></td></tr></table></figure>
<p>先使用用 <code>torchvision.datasets.ImageFolder()</code> 创建的数据集进行测试。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Display random images from ImageFolder created Dataset</span></span><br><span class="line">display_random_images(train_data, </span><br><span class="line">                      n=<span class="number">5</span>, </span><br><span class="line">                      classes=class_names,</span><br><span class="line">                      seed=<span class="literal">None</span>)</span><br></pre></td></tr></table></figure>
<img src="/2024/08/18/PyTorch-26H-5/PyTorch-26H-5-7.png" class="" title="PyTorch-26H-5-7">
<p>使用自己的 <code>ImageFolderCustom</code> 创建的数据集。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Display random images from ImageFolderCustom Dataset</span></span><br><span class="line">display_random_images(train_data_custom, </span><br><span class="line">                      n=<span class="number">12</span>, </span><br><span class="line">                      classes=class_names,</span><br><span class="line">                      seed=<span class="literal">None</span>) <span class="comment"># Try setting the seed for reproducible images</span></span><br></pre></td></tr></table></figure>
<img src="/2024/08/18/PyTorch-26H-5/PyTorch-26H-5-8.png" class="" title="PyTorch-26H-5-8">
<h2 id="5-4-Turn-custom-loaded-images-into-DataLoader’s-将自定义加载的图像转换DataLoader"><a href="#5-4-Turn-custom-loaded-images-into-DataLoader’s-将自定义加载的图像转换DataLoader" class="headerlink" title="5.4 Turn custom loaded images into DataLoader’s 将自定义加载的图像转换DataLoader"></a>5.4 Turn custom loaded images into DataLoader’s 将自定义加载的图像转换DataLoader</h2><p>有一种方法可以通过 <code>ImageFolderCustom</code> 类将原始图像转换为 <code>Dataset</code>（将特征映射到标签或将 <code>X</code> 映射到 <code>y</code>）。<br>如何将自定义 <code>Dataset</code> 转换为 <code>DataLoader</code>？<br>使用 <code>torch.utils.data.DataLoader()</code><br>由于自定义 <code>Dataset</code> 是 <code>torch.utils.data.Dataset</code> 的子类，因此可以直接通过 <code>torch.utils.data.DataLoader()</code> 使用。<br>可以使用与之前非常相似的步骤，只是这次我们将使用我们自定义创建的 <code>Dataset</code>。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Turn train and test custom Dataset&#x27;s into DataLoader&#x27;s</span></span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> DataLoader</span><br><span class="line">train_dataloader_custom = DataLoader(dataset=train_data_custom, <span class="comment"># use custom created train Dataset</span></span><br><span class="line">                                     batch_size=<span class="number">1</span>, <span class="comment"># how many samples per batch?</span></span><br><span class="line">                                     num_workers=<span class="number">0</span>, <span class="comment"># how many subprocesses to use for data loading? (higher = more)</span></span><br><span class="line">                                     shuffle=<span class="literal">True</span>) <span class="comment"># shuffle the data?</span></span><br><span class="line"></span><br><span class="line">test_dataloader_custom = DataLoader(dataset=test_data_custom, <span class="comment"># use custom created test Dataset</span></span><br><span class="line">                                    batch_size=<span class="number">1</span>, </span><br><span class="line">                                    num_workers=<span class="number">0</span>, </span><br><span class="line">                                    shuffle=<span class="literal">False</span>) <span class="comment"># don&#x27;t usually need to shuffle testing data</span></span><br><span class="line"></span><br><span class="line">train_dataloader_custom, test_dataloader_custom</span><br></pre></td></tr></table></figure>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">(&lt;torch.utils.data.dataloader.DataLoader at 0x277cc3e9580&gt;,</span><br><span class="line"> &lt;torch.utils.data.dataloader.DataLoader at 0x277cc3e94c0&gt;)</span><br></pre></td></tr></table></figure>
<p>样本的形状看起来是否相同？</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Get image and label from custom DataLoader</span></span><br><span class="line">img_custom, label_custom = <span class="built_in">next</span>(<span class="built_in">iter</span>(train_dataloader_custom))</span><br><span class="line"></span><br><span class="line"><span class="comment"># Batch size will now be 1, try changing the batch_size parameter above and see what happens</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Image shape: <span class="subst">&#123;img_custom.shape&#125;</span> -&gt; [batch_size, color_channels, height, width]&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Label shape: <span class="subst">&#123;label_custom.shape&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Image shape: torch.Size([1, 3, 64, 64]) -&gt; [batch_size, color_channels, height, width]</span><br><span class="line">Label shape: torch.Size([1])</span><br></pre></td></tr></table></figure>
<p>现在让我们看一下其他形式的数据转换。</p>
<h1 id="6-Other-forms-of-transforms-data-augmentation-其他形式的变换（数据增强）"><a href="#6-Other-forms-of-transforms-data-augmentation-其他形式的变换（数据增强）" class="headerlink" title="6. Other forms of transforms (data augmentation) 其他形式的变换（数据增强）"></a>6. Other forms of transforms (data augmentation) 其他形式的变换（数据增强）</h1><p>还有很多数据上的变换，参考 <a target="_blank" rel="noopener" href="https://pytorch.org/vision/stable/transforms.html"><code>torchvision.transforms</code> documentation</a>。</p>
<p>变换的目的是以某种方式改变图像。将图像变成张量，或者裁剪它或随机删除一部分或随机旋转它们，进行这些类型的转换通常称为数据增强。</p>
<p>数据增强是以人为增加训练集多样性的方式改变数据的过程。<br>在这个人工改变的数据集上训练模型有望产生一个能够更好地泛化的模型（它学习的模式对未来看不见的示例更具鲁棒性）。</p>
<p>在 <a target="_blank" rel="noopener" href="https://pytorch.org/vision/main/auto_examples/transforms/plot_transforms_illustrations.html">Illustration of Transforms example</a>.中看到使用 <code>torchvision.transforms</code> 对图像执行数据增强的许多不同示例。</p>
<p>机器学习就是要利用随机性的力量，研究表明，随机变换（如 t <a target="_blank" rel="noopener" href="https://pytorch.org/vision/stable/auto_examples/plot_transforms.html#randaugment"><code>transforms.RandAugment()</code></a>和 <a target="_blank" rel="noopener" href="https://pytorch.org/vision/stable/auto_examples/plot_transforms.html#trivialaugmentwide"><code>transforms.TrivialAugmentWide()</code></a>）通常比手工挑选的变换表现更好。背后的想法是：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2103.10158">TrivialAugment</a></p>
<p>您有一组变换，您可以随机选择其中的一些变换在图像上执行，并在给定范围内以随机幅度执行（幅度越大，强度越大）。</p>
<p>PyTorch 团队甚至使用<a target="_blank" rel="noopener" href="https://pytorch.org/blog/how-to-train-state-of-the-art-models-using-torchvision-latest-primitives/#break-down-of-key-accuracy-improvements">used TrivialAugment it to train their latest state-of-the-art vision models</a>.来训练他们最新的先进视觉模型。</p>
<p>TrivialAugment 是最近对各种 PyTorch 视觉模型进行先进训练升级时使用的要素之一。</p>
<p>我们如何在我们自己的一些图像上测试它？</p>
<p>在 <code>transforms.TrivialAugmentWide()</code> 中要注意的主要参数是 <code>num_magnitude_bins=31</code>。它定义了将选择强度值的范围以应用特定变换，<code>0</code> 表示无范围，<code>31</code> 表示最大范围（最高强度的可能性最高）。<br>我们可以将 <code>transforms.TrivialAugmentWide()</code> 合并到 <code>transforms.Compose()</code> 中。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> transforms</span><br><span class="line"></span><br><span class="line">train_transforms = transforms.Compose([</span><br><span class="line">    transforms.Resize((<span class="number">224</span>, <span class="number">224</span>)),</span><br><span class="line">    transforms.TrivialAugmentWide(num_magnitude_bins=<span class="number">31</span>), <span class="comment"># how intense </span></span><br><span class="line">    transforms.ToTensor() <span class="comment"># use ToTensor() last to get everything between 0 &amp; 1</span></span><br><span class="line">])</span><br><span class="line"></span><br><span class="line"><span class="comment"># Don&#x27;t need to perform augmentation on the test data</span></span><br><span class="line">test_transforms = transforms.Compose([</span><br><span class="line">    transforms.Resize((<span class="number">224</span>, <span class="number">224</span>)), </span><br><span class="line">    transforms.ToTensor()</span><br><span class="line">])</span><br></pre></td></tr></table></figure>
<blockquote>
<p>注意：通常不会对测试集执行数据增强。数据增强的理念是人为地增加训练集的多样性，以便更好地预测测试集。<br>但是，需要确保将测试集图像转换为张量。将测试图像的大小调整为与训练图像相同的大小，但是，如果需要，可以对不同大小的图像进行推理（尽管这可能会改变性能）。</p>
</blockquote>
<p>目前有了训练转换（有数据增强）和测试转换（没有数据增强）。</p>
<p>测试一下数据增强：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Get all image paths</span></span><br><span class="line">image_path_list = <span class="built_in">list</span>(image_path.glob(<span class="string">&quot;*/*/*.jpg&quot;</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># Plot random images</span></span><br><span class="line">plot_transformed_images(</span><br><span class="line">    image_paths=image_path_list,</span><br><span class="line">    transform=train_transforms,</span><br><span class="line">    n=<span class="number">3</span>,</span><br><span class="line">    seed=<span class="literal">None</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<img src="/2024/08/18/PyTorch-26H-5/PyTorch-26H-5-9.png" class="" title="PyTorch-26H-5-9">
<p>尝试运行上述单元格几次，并观察原始图像在转换过程中如何变化。</p>
<h1 id="7-Model-0-TinyVGG-without-data-augmentation"><a href="#7-Model-0-TinyVGG-without-data-augmentation" class="headerlink" title="7. Model 0: TinyVGG without data augmentation"></a>7. Model 0: TinyVGG without data augmentation</h1><p>已经了解了如何将数据从文件夹中的图像转换为转换后的张量。</p>
<p>构建一个计算机视觉模型，看看能否对图像是披萨、牛排还是寿司进行分类。</p>
<p>首先，将从一个简单的转换开始，只将图像的大小调整为 (64, 64) 并将它们转换为张量。</p>
<h2 id="7-1-Creating-transforms-and-loading-data-for-Model-0-为模型-0-创建变换并加载数据"><a href="#7-1-Creating-transforms-and-loading-data-for-Model-0-为模型-0-创建变换并加载数据" class="headerlink" title="7.1 Creating transforms and loading data for Model 0 为模型 0 创建变换并加载数据"></a>7.1 Creating transforms and loading data for Model 0 为模型 0 创建变换并加载数据</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Create simple transform</span></span><br><span class="line">simple_transform = transforms.Compose([ </span><br><span class="line">    transforms.Resize((<span class="number">64</span>, <span class="number">64</span>)),</span><br><span class="line">    transforms.ToTensor(),</span><br><span class="line">])</span><br></pre></td></tr></table></figure>
<p>有了一个简单的转换：</p>
<ul>
<li>加载数据，首先使用 <code>torchvision.datasets.ImageFolder()</code> 将我们的每个训练和测试文件夹转换为数据集。</li>
<li>然后使用 <code>torch.utils.data.DataLoader()</code> 转换为 <code>DataLoader</code>。</li>
<li>我们将 <code>batch_size=32</code> 和 <code>num_workers</code> 设置为机器上的 CPU 数量（这取决于使用的机器）。</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 1. Load and transform data</span></span><br><span class="line"><span class="comment"># 1. 加载和转换数据</span></span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> datasets</span><br><span class="line">train_data_simple = datasets.ImageFolder(root=train_dir, transform=simple_transform)</span><br><span class="line">test_data_simple = datasets.ImageFolder(root=test_dir, transform=simple_transform)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 2. Turn data into DataLoaders</span></span><br><span class="line"><span class="comment"># 2. 将数据转换为 DataLoaders</span></span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> DataLoader</span><br><span class="line"></span><br><span class="line"><span class="comment"># Setup batch size and number of workers </span></span><br><span class="line"><span class="comment"># 设置批次大小和工人数量</span></span><br><span class="line">BATCH_SIZE = <span class="number">32</span></span><br><span class="line">NUM_WORKERS = os.cpu_count()</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Creating DataLoader&#x27;s with batch size <span class="subst">&#123;BATCH_SIZE&#125;</span> and <span class="subst">&#123;NUM_WORKERS&#125;</span> workers.&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Create DataLoader&#x27;s</span></span><br><span class="line"><span class="comment"># 创建 DataLoader</span></span><br><span class="line">train_dataloader_simple = DataLoader(train_data_simple, </span><br><span class="line">                                     batch_size=BATCH_SIZE, </span><br><span class="line">                                     shuffle=<span class="literal">True</span>, </span><br><span class="line">                                     num_workers=NUM_WORKERS)</span><br><span class="line"></span><br><span class="line">test_dataloader_simple = DataLoader(test_data_simple, </span><br><span class="line">                                    batch_size=BATCH_SIZE, </span><br><span class="line">                                    shuffle=<span class="literal">False</span>, </span><br><span class="line">                                    num_workers=NUM_WORKERS)</span><br><span class="line"></span><br><span class="line">train_dataloader_simple, test_dataloader_simple</span><br></pre></td></tr></table></figure>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Creating DataLoader&#x27;s with batch size 32 and 96 workers.</span><br><span class="line">(&lt;torch.utils.data.dataloader.DataLoader at 0x277ce4fc220&gt;,</span><br><span class="line"> &lt;torch.utils.data.dataloader.DataLoader at 0x277ce4fcca0&gt;)</span><br></pre></td></tr></table></figure>
<h2 id="7-2-Create-TinyVGG-model-class"><a href="#7-2-Create-TinyVGG-model-class" class="headerlink" title="7.2 Create TinyVGG model class"></a>7.2 Create TinyVGG model class</h2><p>在上一节中，我们使用了 <a target="_blank" rel="noopener" href="https://poloclub.github.io/cnn-explainer/">CNN Explainer website</a>上的 TinyVGG 模型。</p>
<p>让我们重新创建相同的模型，但这次我们将使用彩色图像而不是灰度图像（对于 RGB 像素，<code>in_channels=3</code> 而不是 <code>in_channels=1</code>）。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">TinyVGG</span>(nn.Module):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Model architecture copying TinyVGG from: </span></span><br><span class="line"><span class="string">    https://poloclub.github.io/cnn-explainer/</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, input_shape: <span class="built_in">int</span>, hidden_units: <span class="built_in">int</span>, output_shape: <span class="built_in">int</span></span>) -&gt; <span class="literal">None</span>:</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.conv_block_1 = nn.Sequential(</span><br><span class="line">            nn.Conv2d(in_channels=input_shape, </span><br><span class="line">                      out_channels=hidden_units, </span><br><span class="line">                      kernel_size=<span class="number">3</span>, <span class="comment"># how big is the square that&#x27;s going over the image?</span></span><br><span class="line">                      stride=<span class="number">1</span>, <span class="comment"># default</span></span><br><span class="line">                      padding=<span class="number">1</span>), <span class="comment"># options = &quot;valid&quot; (no padding) or &quot;same&quot; (output has same shape as input) or int for specific number </span></span><br><span class="line">            nn.ReLU(),</span><br><span class="line">            nn.Conv2d(in_channels=hidden_units, </span><br><span class="line">                      out_channels=hidden_units,</span><br><span class="line">                      kernel_size=<span class="number">3</span>,</span><br><span class="line">                      stride=<span class="number">1</span>,</span><br><span class="line">                      padding=<span class="number">1</span>),</span><br><span class="line">            nn.ReLU(),</span><br><span class="line">            nn.MaxPool2d(kernel_size=<span class="number">2</span>,</span><br><span class="line">                         stride=<span class="number">2</span>) <span class="comment"># default stride value is same as kernel_size</span></span><br><span class="line">        )</span><br><span class="line">        self.conv_block_2 = nn.Sequential(</span><br><span class="line">            nn.Conv2d(hidden_units, hidden_units, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>),</span><br><span class="line">            nn.ReLU(),</span><br><span class="line">            nn.Conv2d(hidden_units, hidden_units, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>),</span><br><span class="line">            nn.ReLU(),</span><br><span class="line">            nn.MaxPool2d(<span class="number">2</span>)</span><br><span class="line">        )</span><br><span class="line">        self.classifier = nn.Sequential(</span><br><span class="line">            nn.Flatten(),</span><br><span class="line">            <span class="comment"># Where did this in_features shape come from? </span></span><br><span class="line">            <span class="comment"># It&#x27;s because each layer of our network compresses and changes the shape of our input data.</span></span><br><span class="line">            nn.Linear(in_features=hidden_units*<span class="number">16</span>*<span class="number">16</span>,</span><br><span class="line">                      out_features=output_shape)</span><br><span class="line">        )</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x: torch.Tensor</span>):</span><br><span class="line">        x = self.conv_block_1(x)</span><br><span class="line">        <span class="comment"># print(x.shape)</span></span><br><span class="line">        x = self.conv_block_2(x)</span><br><span class="line">        <span class="comment"># print(x.shape)</span></span><br><span class="line">        x = self.classifier(x)</span><br><span class="line">        <span class="comment"># print(x.shape)</span></span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line">        <span class="comment"># return self.classifier(self.conv_block_2(self.conv_block_1(x))) # &lt;- leverage the benefits of operator fusion</span></span><br><span class="line"></span><br><span class="line">torch.manual_seed(<span class="number">42</span>)</span><br><span class="line">model_0 = TinyVGG(input_shape=<span class="number">3</span>, <span class="comment"># number of color channels (3 for RGB) </span></span><br><span class="line">                  hidden_units=<span class="number">10</span>, </span><br><span class="line">                  output_shape=<span class="built_in">len</span>(train_data.classes)).to(device)</span><br><span class="line">model_0</span><br></pre></td></tr></table></figure>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">TinyVGG(</span><br><span class="line">  (conv_block_1): Sequential(</span><br><span class="line">    (0): Conv2d(3, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))</span><br><span class="line">    (1): ReLU()</span><br><span class="line">    (2): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))</span><br><span class="line">    (3): ReLU()</span><br><span class="line">    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)</span><br><span class="line">  )</span><br><span class="line">  (conv_block_2): Sequential(</span><br><span class="line">    (0): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))</span><br><span class="line">    (1): ReLU()</span><br><span class="line">    (2): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))</span><br><span class="line">    (3): ReLU()</span><br><span class="line">    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)</span><br><span class="line">  )</span><br><span class="line">  (classifier): Sequential(</span><br><span class="line">    (0): Flatten(start_dim=1, end_dim=-1)</span><br><span class="line">    (1): Linear(in_features=2560, out_features=3, bias=True)</span><br><span class="line">  )</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<p>注意：加速深度学习模型在 GPU 上的计算的方法之一是利用运算符融合<code>operator fusion</code>。<br>这意味着在我们上述模型的 <code>forward()</code> 方法中，我们不是每次都调用一个层块并重新分配 <code>x</code>，而是连续调用每个块（请参阅上述模型中 <code>forward()</code> 方法的最后一行作为示例）。<br>这节省了重新分配 <code>x</code> 所花费的时间（占用大量内存），并且只专注于计算 <code>x</code>。<br>请参阅 Horace He 的《从第一原理开始让深度学习变得很棒 <a target="_blank" rel="noopener" href="https://horace.io/brrr_intro.html">Making Deep Learning Go Brrrr From First Principles</a>》，了解更多有关如何加速机器学习模型的方法。</p>
<p>现在，这是一个漂亮的模型！用单张图片的前向传递来测试一下怎么样？</p>
<h2 id="7-3-Try-a-forward-pass-on-a-single-image-to-test-the-model-尝试在单个图像上进行前向传递（以测试模型）"><a href="#7-3-Try-a-forward-pass-on-a-single-image-to-test-the-model-尝试在单个图像上进行前向传递（以测试模型）" class="headerlink" title="7.3 Try a forward pass on a single image (to test the model) 尝试在单个图像上进行前向传递（以测试模型）"></a>7.3 Try a forward pass on a single image (to test the model) 尝试在单个图像上进行前向传递（以测试模型）</h2><p>测试模型的一个好方法是对单个数据进行前向传递，这也是测试不同层的输入和输出形状的便捷方法。</p>
<p>要对单个图像进行前向传递：</p>
<ul>
<li>从 <code>DataLoader</code> 获取一批图像和标签。</li>
<li>从批次中获取单个图像并 <code>unsqueeze()</code> 该图像，使其批次大小为 <code>1</code>（因此其形状适合模型）。</li>
<li>对单个图像执行推理（确保将图像发送到目标设备）。</li>
<li>打印出正在发生的事情并使用 <code>torch.softmax()</code> 将模型的原始输出 <code>logits</code> 转换为预测概率（因为我们正在处理多类数据），并使用 <code>torch.argmax()</code> 将预测概率转换为预测标签。</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 1. Get a batch of images and labels from the DataLoader</span></span><br><span class="line"><span class="comment"># 1.从DataLoader获取一批图像和标签</span></span><br><span class="line">img_batch, label_batch = <span class="built_in">next</span>(<span class="built_in">iter</span>(train_dataloader_simple))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 2. Get a single image from the batch and unsqueeze the image so its shape fits the model</span></span><br><span class="line"><span class="comment"># 2. 从批次中获取单个图像并解压图像，使其形状适合模型</span></span><br><span class="line">img_single, label_single = img_batch[<span class="number">0</span>].unsqueeze(dim=<span class="number">0</span>), label_batch[<span class="number">0</span>]</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Single image shape: <span class="subst">&#123;img_single.shape&#125;</span>\n&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 3. Perform a forward pass on a single image</span></span><br><span class="line"><span class="comment"># 3. 对单个图像执行前向传递</span></span><br><span class="line">model_0.<span class="built_in">eval</span>()</span><br><span class="line"><span class="keyword">with</span> torch.inference_mode():</span><br><span class="line">    pred = model_0(img_single.to(device))</span><br><span class="line">    </span><br><span class="line"><span class="comment"># 4. Print out what&#x27;s happening and convert model logits -&gt; pred probs -&gt; pred label</span></span><br><span class="line"><span class="comment"># 4. 打印出正在发生的事情并转换模型 logits -&gt; pred probs -&gt; pred label</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Output logits:\n<span class="subst">&#123;pred&#125;</span>\n&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Output prediction probabilities:\n<span class="subst">&#123;torch.softmax(pred, dim=<span class="number">1</span>)&#125;</span>\n&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Output prediction label:\n<span class="subst">&#123;torch.argmax(torch.softmax(pred, dim=<span class="number">1</span>), dim=<span class="number">1</span>)&#125;</span>\n&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Actual label:\n<span class="subst">&#123;label_single&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">Single image shape: torch.Size([1, 3, 64, 64])</span><br><span class="line"></span><br><span class="line">Output logits:</span><br><span class="line">tensor([[0.0578, 0.0634, 0.0352]], device=&#x27;cuda:0&#x27;)</span><br><span class="line"></span><br><span class="line">Output prediction probabilities:</span><br><span class="line">tensor([[0.3352, 0.3371, 0.3277]], device=&#x27;cuda:0&#x27;)</span><br><span class="line"></span><br><span class="line">Output prediction label:</span><br><span class="line">tensor([1], device=&#x27;cuda:0&#x27;)</span><br><span class="line"></span><br><span class="line">Actual label:</span><br><span class="line">2</span><br></pre></td></tr></table></figure>
<p>太棒了，看起来我们的模型输出的正是我们期望它输出的内容。<br>可以运行上面的单元格几次，每次预测不同的图像。<br>会注意到预测经常是错误的。<br>这是可以预料到的，因为模型尚未经过训练，它本质上是使用随机权重进行猜测。</p>
<h2 id="7-4-Use-torchinfo-to-get-an-idea-of-the-shapes-going-through-our-model-使用-torchinfo-了解模型中的形状"><a href="#7-4-Use-torchinfo-to-get-an-idea-of-the-shapes-going-through-our-model-使用-torchinfo-了解模型中的形状" class="headerlink" title="7.4 Use torchinfo to get an idea of the shapes going through our model 使用 torchinfo 了解模型中的形状"></a>7.4 Use torchinfo to get an idea of the shapes going through our model 使用 torchinfo 了解模型中的形状</h2><p>使用 <code>print(model)</code> 打印出我们的模型可以让我们了解模型的运行情况。</p>
<p>我们可以在整个 <code>forward()</code> 方法中打印出数据的形状。</p>
<p>但是，从模型中获取信息的一个有用方法是使用  <a target="_blank" rel="noopener" href="https://github.com/TylerYep/torchinfo"><code>torchinfo</code></a>。</p>
<p><code>torchinfo</code> 附带一个 <code>summary()</code> 方法，该方法采用 PyTorch 模型以及 <code>input_shape</code> 并返回张量在模型中移动时发生的情况。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Install torchinfo if it&#x27;s not available, import it if it is</span></span><br><span class="line"><span class="keyword">try</span>: </span><br><span class="line">    <span class="keyword">import</span> torchinfo</span><br><span class="line"><span class="keyword">except</span>:</span><br><span class="line">    !pip install torchinfo</span><br><span class="line">    <span class="keyword">import</span> torchinfo</span><br><span class="line"></span><br><span class="line"><span class="comment"># pip install torchinfo    </span></span><br><span class="line"><span class="keyword">from</span> torchinfo <span class="keyword">import</span> summary</span><br><span class="line">summary(model_0, input_size=[<span class="number">1</span>, <span class="number">3</span>, <span class="number">64</span>, <span class="number">64</span>]) <span class="comment"># do a test pass through of an example input size </span></span><br></pre></td></tr></table></figure>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">==========================================================================================</span><br><span class="line">Layer (type:depth-idx)                   Output Shape              Param #</span><br><span class="line">==========================================================================================</span><br><span class="line">TinyVGG                                  [1, 3]                    --</span><br><span class="line">├─Sequential: 1-1                        [1, 10, 32, 32]           --</span><br><span class="line">│    └─Conv2d: 2-1                       [1, 10, 64, 64]           280</span><br><span class="line">│    └─ReLU: 2-2                         [1, 10, 64, 64]           --</span><br><span class="line">│    └─Conv2d: 2-3                       [1, 10, 64, 64]           910</span><br><span class="line">│    └─ReLU: 2-4                         [1, 10, 64, 64]           --</span><br><span class="line">│    └─MaxPool2d: 2-5                    [1, 10, 32, 32]           --</span><br><span class="line">├─Sequential: 1-2                        [1, 10, 16, 16]           --</span><br><span class="line">│    └─Conv2d: 2-6                       [1, 10, 32, 32]           910</span><br><span class="line">│    └─ReLU: 2-7                         [1, 10, 32, 32]           --</span><br><span class="line">│    └─Conv2d: 2-8                       [1, 10, 32, 32]           910</span><br><span class="line">│    └─ReLU: 2-9                         [1, 10, 32, 32]           --</span><br><span class="line">│    └─MaxPool2d: 2-10                   [1, 10, 16, 16]           --</span><br><span class="line">├─Sequential: 1-3                        [1, 3]                    --</span><br><span class="line">│    └─Flatten: 2-11                     [1, 2560]                 --</span><br><span class="line">│    └─Linear: 2-12                      [1, 3]                    7,683</span><br><span class="line">==========================================================================================</span><br><span class="line">Total params: 10,693</span><br><span class="line">Trainable params: 10,693</span><br><span class="line">Non-trainable params: 0</span><br><span class="line">Total mult-adds (M): 6.75</span><br><span class="line">==========================================================================================</span><br><span class="line">Input size (MB): 0.05</span><br><span class="line">Forward/backward pass size (MB): 0.82</span><br><span class="line">Params size (MB): 0.04</span><br><span class="line">Estimated Total Size (MB): 0.91</span><br><span class="line">==========================================================================================</span><br></pre></td></tr></table></figure>
<p><code>torchinfo.summary()</code> 的输出为我们提供了有关模型的大量信息。<br>例如<code>Total params</code>、模型中的参数总数、<code>Estimated Total Size (MB)</code>，即模型的大小。<br>当特定 <code>input_size</code> 的数据在我们的模型中移动时，您还可以看到输入和输出形状的变化。<br>目前，我们的参数数量和模型总大小很低。<br>这是因为我们从一个小模型开始。</p>
<h2 id="7-5-Create-train-amp-test-loop-functions-创建训练和测试循环函数"><a href="#7-5-Create-train-amp-test-loop-functions-创建训练和测试循环函数" class="headerlink" title="7.5 Create train &amp; test loop functions 创建训练和测试循环函数"></a>7.5 Create train &amp; test loop functions 创建训练和测试循环函数</h2><p>我们有数据，也有模型。</p>
<p>现在让我们制作一些训练和测试循环函数，以便在训练数据上训练我们的模型，并在测试数据上评估我们的模型。</p>
<p>为了确保我们可以再次使用这些训练和测试循环，我们将对它们进行函数化。</p>
<p>具体来说，我们将制作三个函数：</p>
<ul>
<li><code>train_step()</code> - 接受一个模型、一个 <code>DataLoader</code>、一个损失函数和一个优化器，并在 <code>DataLoader</code> 上训练模型。</li>
<li><code>test_step()</code> - 接受一个模型、一个 <code>DataLoader</code> 和一个损失函数，并在 <code>DataLoader</code> 上评估模型。</li>
<li><code>train()</code> - 在给定的周期数内同时执行 1. 和 2.，并返回结果字典。</li>
</ul>
<blockquote>
<p>注意：我们在笔记本 01 中介绍了 PyTorch 优化循环中的步骤，以及非官方 PyTorch 优化循环歌曲，并且我们在笔记本 03 中构建了类似的功能。</p>
</blockquote>
<h3 id="train-step"><a href="#train-step" class="headerlink" title="train_step()"></a>train_step()</h3><p>因为在 <code>DataLoader</code> 中处理批次，所以会在训练期间累积模型损失和准确度值（通过为每个批次将它们相加），然后在最后调整它们，然后再返回它们。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">train_step</span>(<span class="params">model: torch.nn.Module, </span></span><br><span class="line"><span class="params">               dataloader: torch.utils.data.DataLoader, </span></span><br><span class="line"><span class="params">               loss_fn: torch.nn.Module, </span></span><br><span class="line"><span class="params">               optimizer: torch.optim.Optimizer</span>):</span><br><span class="line">    <span class="comment"># Put model in train mode</span></span><br><span class="line">    <span class="comment"># 将模型置于训练模式</span></span><br><span class="line">    model.train()</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Setup train loss and train accuracy values</span></span><br><span class="line">    <span class="comment"># 设置训练损失和训练准确度值</span></span><br><span class="line">    train_loss, train_acc = <span class="number">0</span>, <span class="number">0</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Loop through data loader data batches</span></span><br><span class="line">    <span class="comment"># 循环遍历数据加载器数据批次</span></span><br><span class="line">    <span class="keyword">for</span> batch, (X, y) <span class="keyword">in</span> <span class="built_in">enumerate</span>(dataloader):</span><br><span class="line">        <span class="comment"># Send data to target device</span></span><br><span class="line">        <span class="comment"># 发送数据到目标设备</span></span><br><span class="line">        X, y = X.to(device), y.to(device)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 1. Forward pass</span></span><br><span class="line">        <span class="comment"># 1. 前向传递</span></span><br><span class="line">        y_pred = model(X)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 2. Calculate and accumulate loss</span></span><br><span class="line">        <span class="comment"># 2. 计算并累计损失</span></span><br><span class="line">        loss = loss_fn(y_pred, y)</span><br><span class="line">        train_loss += loss.item() </span><br><span class="line"></span><br><span class="line">        <span class="comment"># 3. Optimizer zero grad</span></span><br><span class="line">        <span class="comment"># 3. 优化器零梯度</span></span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 4. Loss backward</span></span><br><span class="line">        <span class="comment"># 4. 损失反向</span></span><br><span class="line">        loss.backward()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 5. Optimizer step</span></span><br><span class="line">        <span class="comment"># 5. 优化器步骤</span></span><br><span class="line">        optimizer.step()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Calculate and accumulate accuracy metrics across all batches</span></span><br><span class="line">        <span class="comment"># 计算并累积所有批次的准确度指标</span></span><br><span class="line">        y_pred_class = torch.argmax(torch.softmax(y_pred, dim=<span class="number">1</span>), dim=<span class="number">1</span>)</span><br><span class="line">        train_acc += (y_pred_class == y).<span class="built_in">sum</span>().item()/<span class="built_in">len</span>(y_pred)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Adjust metrics to get average loss and accuracy per batch</span></span><br><span class="line">    <span class="comment"># 调整指标以获得每批的平均损失和准确率</span></span><br><span class="line">    train_loss = train_loss / <span class="built_in">len</span>(dataloader)</span><br><span class="line">    train_acc = train_acc / <span class="built_in">len</span>(dataloader)</span><br><span class="line">    <span class="keyword">return</span> train_loss, train_acc</span><br></pre></td></tr></table></figure>
<h3 id="test-step"><a href="#test-step" class="headerlink" title="test_step()"></a>test_step()</h3><p>这里的主要区别在于 <code>test_step()</code> 不会采用优化器，因此不会执行梯度下降。<br>但由于我们要进行推理，因此我们将确保打开 <code>torch.inference_mode()</code> 上下文管理器来进行预测。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">test_step</span>(<span class="params">model: torch.nn.Module, </span></span><br><span class="line"><span class="params">              dataloader: torch.utils.data.DataLoader, </span></span><br><span class="line"><span class="params">              loss_fn: torch.nn.Module</span>):</span><br><span class="line">    <span class="comment"># Put model in eval mode</span></span><br><span class="line">    <span class="comment"># 将模型置于评估模式</span></span><br><span class="line">    model.<span class="built_in">eval</span>() </span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Setup test loss and test accuracy values</span></span><br><span class="line">    <span class="comment"># 设置测试损失和测试准确度值</span></span><br><span class="line">    test_loss, test_acc = <span class="number">0</span>, <span class="number">0</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Turn on inference context manager</span></span><br><span class="line">    <span class="comment"># 开启推理上下文管理器</span></span><br><span class="line">    <span class="keyword">with</span> torch.inference_mode():</span><br><span class="line">        <span class="comment"># Loop through DataLoader batches</span></span><br><span class="line">        <span class="comment"># 循环遍历 DataLoader 批次</span></span><br><span class="line">        <span class="keyword">for</span> batch, (X, y) <span class="keyword">in</span> <span class="built_in">enumerate</span>(dataloader):</span><br><span class="line">            <span class="comment"># Send data to target device</span></span><br><span class="line">            <span class="comment"># 发送数据到目标设备</span></span><br><span class="line">            X, y = X.to(device), y.to(device)</span><br><span class="line">    </span><br><span class="line">            <span class="comment"># 1. Forward pass</span></span><br><span class="line">            <span class="comment"># 1. 前向传递</span></span><br><span class="line">            test_pred_logits = model(X)</span><br><span class="line"></span><br><span class="line">            <span class="comment"># 2. Calculate and accumulate loss</span></span><br><span class="line">            <span class="comment"># 2. 计算并累计损失</span></span><br><span class="line">            loss = loss_fn(test_pred_logits, y)</span><br><span class="line">            test_loss += loss.item()</span><br><span class="line">            </span><br><span class="line">            <span class="comment"># Calculate and accumulate accuracy</span></span><br><span class="line">            <span class="comment"># 计算并累计准确率</span></span><br><span class="line">            test_pred_labels = test_pred_logits.argmax(dim=<span class="number">1</span>)</span><br><span class="line">            test_acc += ((test_pred_labels == y).<span class="built_in">sum</span>().item()/<span class="built_in">len</span>(test_pred_labels))</span><br><span class="line">            </span><br><span class="line">    <span class="comment"># Adjust metrics to get average loss and accuracy per batch </span></span><br><span class="line">    <span class="comment"># 调整指标以获得每批的平均损失和准确率</span></span><br><span class="line">    test_loss = test_loss / <span class="built_in">len</span>(dataloader)</span><br><span class="line">    test_acc = test_acc / <span class="built_in">len</span>(dataloader)</span><br><span class="line">    <span class="keyword">return</span> test_loss, test_acc</span><br></pre></td></tr></table></figure>
<h3 id="train-Creating-a-train-function-to-combine-train-step-and-test-step-训练-创建一个-train-函数来结合-train-step-和-test-step"><a href="#train-Creating-a-train-function-to-combine-train-step-and-test-step-训练-创建一个-train-函数来结合-train-step-和-test-step" class="headerlink" title="train | Creating a train() function to combine train_step() and test_step() 训练 | 创建一个 train() 函数来结合 train_step() 和 test_step()"></a>train | Creating a train() function to combine train_step() and test_step() 训练 | 创建一个 train() 函数来结合 train_step() 和 test_step()</h3><p>现在我们需要一种方法来将 train_step() 和 test_step() 函数放在一起。<br>为此，我们将它们打包在 train() 函数中。<br>此函数将训练模型并对其进行评估。</p>
<p>具体来说：</p>
<ul>
<li>接收一个模型、一个用于训练和测试集的 <code>DataLoader</code>、一个优化器、一个损失函数以及每个训练和测试步骤要执行多少个 epoch。</li>
<li>为 <code>train_loss</code>、<code>train_acc</code>、<code>test_loss</code> 和 <code>test_acc</code> 值创建一个空的结果字典（我们可以在训练过程中填充它）。</li>
<li>循环执行多个 epoch 的训练和测试步骤函数。</li>
<li>打印出每个 epoch 结束时发生的情况。</li>
<li>使用每个 epoch 更新后的指标更新空的结果字典。</li>
<li>返回已填充的。</li>
</ul>
<p>为了跟踪我们经历过的 <code>epochs</code> 数，让我们从 <code>tqdm.auto</code> 导入 <code>tqdm</code>（<code>tqdm</code> 是 Python 最流行的进度条库之一，<code>tqdm.auto</code> 会自动决定哪种进度条最适合的计算环境，例如 <code>Jupyter Notebook</code> 与 <code>Python</code> 脚本）。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># conda install tqdm</span></span><br><span class="line"><span class="keyword">from</span> tqdm.auto <span class="keyword">import</span> tqdm</span><br><span class="line"></span><br><span class="line"><span class="comment"># 1. Take in various parameters required for training and test steps</span></span><br><span class="line"><span class="comment"># 1. 接受训练和测试步骤所需的各种参数</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">train</span>(<span class="params">model: torch.nn.Module, </span></span><br><span class="line"><span class="params">          train_dataloader: torch.utils.data.DataLoader, </span></span><br><span class="line"><span class="params">          test_dataloader: torch.utils.data.DataLoader, </span></span><br><span class="line"><span class="params">          optimizer: torch.optim.Optimizer,</span></span><br><span class="line"><span class="params">          loss_fn: torch.nn.Module = nn.CrossEntropyLoss(<span class="params"></span>),</span></span><br><span class="line"><span class="params">          epochs: <span class="built_in">int</span> = <span class="number">5</span></span>):</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 2. Create empty results dictionary</span></span><br><span class="line">    <span class="comment"># 2. 创建空的结果字典</span></span><br><span class="line">    results = &#123;<span class="string">&quot;train_loss&quot;</span>: [],</span><br><span class="line">        <span class="string">&quot;train_acc&quot;</span>: [],</span><br><span class="line">        <span class="string">&quot;test_loss&quot;</span>: [],</span><br><span class="line">        <span class="string">&quot;test_acc&quot;</span>: []</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 3. Loop through training and testing steps for a number of epochs</span></span><br><span class="line">    <span class="comment"># 3. 循环进行多个 epoch 的训练和测试步骤</span></span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> tqdm(<span class="built_in">range</span>(epochs)):</span><br><span class="line">        train_loss, train_acc = train_step(model=model,</span><br><span class="line">                                           dataloader=train_dataloader,</span><br><span class="line">                                           loss_fn=loss_fn,</span><br><span class="line">                                           optimizer=optimizer)</span><br><span class="line">        test_loss, test_acc = test_step(model=model,</span><br><span class="line">            dataloader=test_dataloader,</span><br><span class="line">            loss_fn=loss_fn)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 4. Print out what&#x27;s happening</span></span><br><span class="line">        <span class="comment"># 4. 打印出正在发生的事情</span></span><br><span class="line">        <span class="built_in">print</span>(</span><br><span class="line">            <span class="string">f&quot;Epoch: <span class="subst">&#123;epoch+<span class="number">1</span>&#125;</span> | &quot;</span></span><br><span class="line">            <span class="string">f&quot;train_loss: <span class="subst">&#123;train_loss:<span class="number">.4</span>f&#125;</span> | &quot;</span></span><br><span class="line">            <span class="string">f&quot;train_acc: <span class="subst">&#123;train_acc:<span class="number">.4</span>f&#125;</span> | &quot;</span></span><br><span class="line">            <span class="string">f&quot;test_loss: <span class="subst">&#123;test_loss:<span class="number">.4</span>f&#125;</span> | &quot;</span></span><br><span class="line">            <span class="string">f&quot;test_acc: <span class="subst">&#123;test_acc:<span class="number">.4</span>f&#125;</span>&quot;</span></span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 5. Update results dictionary</span></span><br><span class="line">        <span class="comment"># 5. 更新结果字典</span></span><br><span class="line">        <span class="comment"># Ensure all data is moved to CPU and converted to float for storage</span></span><br><span class="line">        <span class="comment"># 确保所有数据都移至 CPU 并转换为浮点数进行存储</span></span><br><span class="line">        results[<span class="string">&quot;train_loss&quot;</span>].append(train_loss.item() <span class="keyword">if</span> <span class="built_in">isinstance</span>(train_loss, torch.Tensor) <span class="keyword">else</span> train_loss)</span><br><span class="line">        results[<span class="string">&quot;train_acc&quot;</span>].append(train_acc.item() <span class="keyword">if</span> <span class="built_in">isinstance</span>(train_acc, torch.Tensor) <span class="keyword">else</span> train_acc)</span><br><span class="line">        results[<span class="string">&quot;test_loss&quot;</span>].append(test_loss.item() <span class="keyword">if</span> <span class="built_in">isinstance</span>(test_loss, torch.Tensor) <span class="keyword">else</span> test_loss)</span><br><span class="line">        results[<span class="string">&quot;test_acc&quot;</span>].append(test_acc.item() <span class="keyword">if</span> <span class="built_in">isinstance</span>(test_acc, torch.Tensor) <span class="keyword">else</span> test_acc)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 6. Return the filled results at the end of the epochs</span></span><br><span class="line">    <span class="comment"># 6. 返回 epoch 结束时的填充结果</span></span><br><span class="line">    <span class="keyword">return</span> results</span><br></pre></td></tr></table></figure>
<h2 id="7-6-Train-and-Evaluate-Model-0-训练和评估模型-0"><a href="#7-6-Train-and-Evaluate-Model-0-训练和评估模型-0" class="headerlink" title="7.6 Train and Evaluate Model 0 训练和评估模型 0"></a>7.6 Train and Evaluate Model 0 训练和评估模型 0</h2><p>目前已经拥有了训练和评估模型所需的所有要素。<br>将 <code>TinyVGG</code> 模型、<code>DataLoader</code> 和 <code>train()</code> 函数放在一起，看看我们是否可以构建一个能够区分披萨、牛排和寿司的模型！<br>让我们重新创建 <code>model_0</code>（不需要，但为了完整起见我们会这样做），然后调用 <code>train()</code> 函数并传入必要的参数。<br>为了让我们的实验快速进行，我们将训练我们的模型 5 epochs（可以根据需要增加这个时期）。<br>至于 <code>optimizer</code> 优化器和 <code>loss function</code> 损失函数，我们将分别使用 <code>torch.nn.CrossEntropyLoss()</code>（因为我们正在处理多类分类数据）和 <code>torch.optim.Adam()</code>，学习率为 <code>1e-3</code>。<br>为了了解需要多长时间，我们将导入 Python 的 <a target="_blank" rel="noopener" href="https://docs.python.org/3/library/timeit.html#timeit.default_timer"><code>timeit.default_timer()</code></a> 方法来计算训练时间。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Set random seeds</span></span><br><span class="line">torch.manual_seed(<span class="number">42</span>) </span><br><span class="line">torch.cuda.manual_seed(<span class="number">42</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Set number of epochs</span></span><br><span class="line">NUM_EPOCHS = <span class="number">5</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Recreate an instance of TinyVGG</span></span><br><span class="line">model_0 = TinyVGG(input_shape=<span class="number">3</span>, <span class="comment"># number of color channels (3 for RGB) </span></span><br><span class="line">                  hidden_units=<span class="number">10</span>, </span><br><span class="line">                  output_shape=<span class="built_in">len</span>(train_data.classes)).to(device)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Setup loss function and optimizer</span></span><br><span class="line">loss_fn = nn.CrossEntropyLoss()</span><br><span class="line">optimizer = torch.optim.Adam(params=model_0.parameters(), lr=<span class="number">0.001</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Start the timer</span></span><br><span class="line"><span class="keyword">from</span> timeit <span class="keyword">import</span> default_timer <span class="keyword">as</span> timer </span><br><span class="line">start_time = timer()</span><br><span class="line"></span><br><span class="line"><span class="comment"># Train model_0 </span></span><br><span class="line">model_0_results = train(model=model_0, </span><br><span class="line">                        train_dataloader=train_dataloader_simple,</span><br><span class="line">                        test_dataloader=test_dataloader_simple,</span><br><span class="line">                        optimizer=optimizer,</span><br><span class="line">                        loss_fn=loss_fn, </span><br><span class="line">                        epochs=NUM_EPOCHS)</span><br><span class="line"></span><br><span class="line"><span class="comment"># End the timer and print out how long it took</span></span><br><span class="line">end_time = timer()</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Total training time: <span class="subst">&#123;end_time-start_time:<span class="number">.3</span>f&#125;</span> seconds&quot;</span>)</span><br></pre></td></tr></table></figure>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"></span><br></pre></td></tr></table></figure>
<p>模型表现相当糟糕。有哪些方法可以改进它？</p>
<blockquote>
<p>注意：查看 <a target="_blank" rel="noopener" href="https://www.learnpytorch.io/02_pytorch_classification/#5-improving-a-model-from-a-model-perspective"><em>Improving a model (from a model perspective)</em> section in notebook 02</a>笔记本 02 中的改进模型（从模型角度）部分，了解有关改进我们的 TinyVGG 模型的想法。</p>
</blockquote>
<h2 id="7-7-Plot-the-loss-curves-of-Model-0-绘制模型-0-的损失曲线"><a href="#7-7-Plot-the-loss-curves-of-Model-0-绘制模型-0-的损失曲线" class="headerlink" title="7.7 Plot the loss curves of Model 0 绘制模型 0 的损失曲线"></a>7.7 Plot the loss curves of Model 0 绘制模型 0 的损失曲线</h2><p>从我们 <code>model_0</code> 训练的打印输出来看，它似乎表现不太好。</p>
<p>但我们可以通过绘制模型的 <code>loss curves</code> 损失曲线来进一步评估它。</p>
<p><code>Loss curves</code> 损失曲线显示了模型随时间的变化结果。</p>
<p>它们是查看模型在不同数据集（例如训练和测试）上的表现的好方法。</p>
<p>让我们创建一个函数来绘制 <code>model_0_results</code> 字典中的值。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Check the model_0_results keys</span></span><br><span class="line">model_0_results.keys()</span><br></pre></td></tr></table></figure>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">Epoch: 1 | train_loss: 1.1078 | train_acc: 0.2578 | test_loss: 1.1360 | test_acc: 0.2604</span><br><span class="line">Epoch: 2 | train_loss: 1.0847 | train_acc: 0.4258 | test_loss: 1.1620 | test_acc: 0.1979</span><br><span class="line">Epoch: 3 | train_loss: 1.1157 | train_acc: 0.2930 | test_loss: 1.1697 | test_acc: 0.1979</span><br><span class="line">Epoch: 4 | train_loss: 1.0955 | train_acc: 0.4141 | test_loss: 1.1385 | test_acc: 0.1979</span><br><span class="line">Epoch: 5 | train_loss: 1.0985 | train_acc: 0.2930 | test_loss: 1.1430 | test_acc: 0.1979</span><br><span class="line">Total training time: 199.209 seconds</span><br></pre></td></tr></table></figure>
<p>我们需要提取每个key并将它们转换成一个图。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Check the model_0_results keys</span></span><br><span class="line">model_0_results.keys()</span><br></pre></td></tr></table></figure>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">dict_keys([&#x27;train_loss&#x27;, &#x27;train_acc&#x27;, &#x27;test_loss&#x27;, &#x27;test_acc&#x27;])</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">plot_loss_curves</span>(<span class="params">results: <span class="type">Dict</span>[<span class="built_in">str</span>, <span class="type">List</span>[<span class="built_in">float</span>]]</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Plots training curves of a results dictionary.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        results (dict): dictionary containing list of values, e.g.</span></span><br><span class="line"><span class="string">            &#123;&quot;train_loss&quot;: [...],</span></span><br><span class="line"><span class="string">             &quot;train_acc&quot;: [...],</span></span><br><span class="line"><span class="string">             &quot;test_loss&quot;: [...],</span></span><br><span class="line"><span class="string">             &quot;test_acc&quot;: [...]&#125;</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Get the loss values of the results dictionary (training and test)</span></span><br><span class="line">    <span class="comment"># 获取结果字典（训练和测试）的损失值</span></span><br><span class="line">    loss = results[<span class="string">&#x27;train_loss&#x27;</span>]</span><br><span class="line">    test_loss = results[<span class="string">&#x27;test_loss&#x27;</span>]</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Get the accuracy values of the results dictionary (training and test)</span></span><br><span class="line">    <span class="comment"># 获取结果字典（训练和测试）的准确度值</span></span><br><span class="line">    accuracy = results[<span class="string">&#x27;train_acc&#x27;</span>]</span><br><span class="line">    test_accuracy = results[<span class="string">&#x27;test_acc&#x27;</span>]</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Figure out how many epochs there were</span></span><br><span class="line">    <span class="comment"># 计算出有多少个 epoch</span></span><br><span class="line">    epochs = <span class="built_in">range</span>(<span class="built_in">len</span>(results[<span class="string">&#x27;train_loss&#x27;</span>]))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Setup a plot </span></span><br><span class="line">    <span class="comment"># 设置情节</span></span><br><span class="line">    plt.figure(figsize=(<span class="number">15</span>, <span class="number">7</span>))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Plot loss</span></span><br><span class="line">    <span class="comment"># 绘制损失</span></span><br><span class="line">    plt.subplot(<span class="number">1</span>, <span class="number">2</span>, <span class="number">1</span>)</span><br><span class="line">    plt.plot(epochs, loss, label=<span class="string">&#x27;train_loss&#x27;</span>)</span><br><span class="line">    plt.plot(epochs, test_loss, label=<span class="string">&#x27;test_loss&#x27;</span>)</span><br><span class="line">    plt.title(<span class="string">&#x27;Loss&#x27;</span>)</span><br><span class="line">    plt.xlabel(<span class="string">&#x27;Epochs&#x27;</span>)</span><br><span class="line">    plt.legend()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Plot accuracy</span></span><br><span class="line">    <span class="comment"># 绘制准确度</span></span><br><span class="line">    plt.subplot(<span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>)</span><br><span class="line">    plt.plot(epochs, accuracy, label=<span class="string">&#x27;train_accuracy&#x27;</span>)</span><br><span class="line">    plt.plot(epochs, test_accuracy, label=<span class="string">&#x27;test_accuracy&#x27;</span>)</span><br><span class="line">    plt.title(<span class="string">&#x27;Accuracy&#x27;</span>)</span><br><span class="line">    plt.xlabel(<span class="string">&#x27;Epochs&#x27;</span>)</span><br><span class="line">    plt.legend();</span><br></pre></td></tr></table></figure>
<p>测试一下<code>plot_loss_curves()</code> 函数。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">plot_loss_curves(model_0_results)</span><br></pre></td></tr></table></figure>
<img src="/2024/08/18/PyTorch-26H-5/PyTorch-26H-5-10.png" class="" title="PyTorch-26H-5-10">
<p>看起来一切都乱七八糟……<br>但我们大概知道这一点，因为我们的模型在训练期间打印出来的结果并没有显示出太大的希望。<br>您可以尝试更长时间地训练模型，看看在更长的时间范围内绘制损失曲线时会发生什么。</p>
<h1 id="8-What-should-an-ideal-loss-curve-look-like-理想的损失曲线应该是什么样的？"><a href="#8-What-should-an-ideal-loss-curve-look-like-理想的损失曲线应该是什么样的？" class="headerlink" title="8. What should an ideal loss curve look like?理想的损失曲线应该是什么样的？"></a>8. What should an ideal loss curve look like?理想的损失曲线应该是什么样的？</h1><p>查看训练和测试损失曲线是查看模型是否 <code>overfitting</code> 过度拟合的好方法。<br>过度拟合模型是指在训练集上的表现优于（通常相差很大）验证/测试集的模型。<br>如果您的训练损失远低于测试损失，则您的模型 <code>overfitting</code> 过度拟合。<br>也就是说，它在训练中学习模式太好，而这些模式并没有推广到测试数据。<br>另一方面，当您的训练和测试损失没有您想要的那么低时，这被认为是 <code>underfitting</code> 欠拟合。<br>训练和测试损失曲线的理想位置是它们彼此紧密对齐。</p>
<img src="/2024/08/18/PyTorch-26H-5/PyTorch-26H-5-11.png" class="" title="PyTorch-26H-5-11">
<p>左图：如果您的训练和测试损失曲线没有您想要的那么低，则被视为欠拟合。<br>中图：当您的测试/验证损失高于训练损失时，这被视为过度拟合。<br>右图：理想的情况是您的训练和测试损失曲线随时间排列整齐。这意味着您的模型具有良好的泛化能力。<br>损失曲线可以有更多组合和不同功能，有关更多信息，请参阅 Google 的<a target="_blank" rel="noopener" href="https://developers.google.com/machine-learning/testing-debugging/metrics/interpretic">Interpreting Loss Curves guide</a>。</p>
<h2 id="8-1-How-to-deal-with-overfitting-如何处理过度拟合"><a href="#8-1-How-to-deal-with-overfitting-如何处理过度拟合" class="headerlink" title="8.1 How to deal with overfitting 如何处理过度拟合"></a>8.1 How to deal with overfitting 如何处理过度拟合</h2><p>由于过度拟合的主要问题在于您的模型与训练数据的拟合<em>度过高</em>，因此您需要使用技术来“控制它”。</p>
<p>防止过度拟合的一种常见技术称为<a target="_blank" rel="noopener" href="https://ml-cheatsheet.readthedocs.io/en/latest/regularization.html"><strong>正则化</strong></a>。</p>
<p>我喜欢将其视为“使我们的模型更加规则”，即能够适应<em>更多</em>种类的数据。</p>
<p>几种防止过度拟合的方法：</p>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center">防止过拟合的方法</th>
<th style="text-align:center">是什么？</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">获取更多数据</td>
<td style="text-align:center">拥有更多数据可以为模型提供更多机会来学习模式，这些模式可能更适用于新的例子。</td>
</tr>
<tr>
<td style="text-align:center">简化模型</td>
<td style="text-align:center">如果当前模型已经过度拟合训练数据，则可能是模型过于复杂。这意味着它对数据模式的学习太好，无法很好地推广到未见过的数据。简化模型的一种方法是减少其使用的层数或减少每层中的隐藏单元数量。</td>
</tr>
<tr>
<td style="text-align:center">使用数据增强</td>
<td style="text-align:center"><a target="_blank" rel="noopener" href="https://developers.google.com/machine-learning/glossary#data-augmentation"><strong>数据增强</strong></a>会以某种方式操纵训练数据，使模型更难学习，因为它会人为地增加数据的多样性。如果模型能够学习增强数据中的模式，那么该模型可能能够更好地推广到未见过的数据。</td>
</tr>
<tr>
<td style="text-align:center">使用迁移学习</td>
<td style="text-align:center"><a target="_blank" rel="noopener" href="https://developers.google.com/machine-learning/glossary#transfer-learning"><strong>迁移学习</strong></a>涉及利用模型已学会的模式（也称为预训练权重）作为您自己的任务的基础。在我们的案例中，我们可以使用一个在大量图像上预训练的计算机视觉模型，然后对其进行稍微调整，使其更专门用于食物图像。</td>
</tr>
<tr>
<td style="text-align:center">使用 dropout 层</td>
<td style="text-align:center">Dropout 层会随机移除神经网络中隐藏层之间的连接，从而有效简化模型，同时改善剩余连接。<a target="_blank" rel="noopener" href="https://pytorch.org/docs/stable/generated/torch.nn.Dropout.html"><code>torch.nn.Dropout()</code></a>更多信息请参见。</td>
</tr>
<tr>
<td style="text-align:center">使用学习率衰减</td>
<td style="text-align:center">这里的想法是随着模型的训练慢慢降低学习率。这类似于伸手去拿沙发后面的硬币。你越接近，你的步子就越小。学习率也是一样，你越接近收敛，你就越希望你的体重更新越小。</td>
</tr>
<tr>
<td style="text-align:center">使用早期停止</td>
<td style="text-align:center"><a target="_blank" rel="noopener" href="https://developers.google.com/machine-learning/glossary#early_stopping"><strong>提前停止</strong></a>会在模型开始过度拟合之前停止训练。例如，假设模型的损失在过去 10 个时期（这个数字是任意的）已经停止下降，您可能希望在这里停止模型训练，并使用损失最低的模型权重（10 个时期之前）。</td>
</tr>
</tbody>
</table>
</div>
<p>还有更多处理过度拟合的方法，但这些是一些主要方法。<br>当你开始构建越来越多的深度模型时，你会发现，由于深度学习非常擅长学习数据中的模式，处理过度拟合是深度学习的主要问题之一。</p>
<h2 id="8-2-How-to-deal-with-underfitting-如何处理欠拟合"><a href="#8-2-How-to-deal-with-underfitting-如何处理欠拟合" class="headerlink" title="8.2 How to deal with underfitting 如何处理欠拟合"></a>8.2 How to deal with underfitting 如何处理欠拟合</h2><p>当模型<a target="_blank" rel="noopener" href="https://developers.google.com/machine-learning/glossary#underfitting"><strong>拟合不足</strong></a>时，它被认为对训练和测试集的预测能力较差。</p>
<p>本质上，欠拟合模型将无法将损失值降低到所需的水平。</p>
<p>现在，查看我们当前的损失曲线，我认为我们的<code>TinyVGG</code>模型<code>model_0</code>对数据拟合不足。</p>
<p>处理欠拟合背后的主要思想是 提高 模型的预测能力。</p>
<p>有几种方法可以做到这一点：</p>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center">防止欠拟合的方法</th>
<th style="text-align:center">它是什么？</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">向模型添加更多层/单元</td>
<td style="text-align:center">如果模型拟合不足，则它可能没有足够的能力来学习所需的数据 模式/权重/表示 patterns/weights/representations 以实现预测。增加模型预测能力的一种方法是增加这些层中的隐藏层/单元的数量。</td>
</tr>
<tr>
<td style="text-align:center">调整学习率</td>
<td style="text-align:center">也许模型的学习率一开始就太高了。它试图在每个时期更新太多权重，结果什么都没学到。在这种情况下，你可以降低学习率，看看会发生什么。</td>
</tr>
<tr>
<td style="text-align:center">使用迁移学习</td>
<td style="text-align:center">迁移学习能够防止过度拟合和欠拟合。它涉及使用以前工作模型中的模式并根据自己的问题进行调整。</td>
</tr>
<tr>
<td style="text-align:center">训练更长时间</td>
<td style="text-align:center">有时模型只是需要更多时间来学习数据表示。如果在较小的实验中，模型没有学到任何东西，那么让它训练更多的时期可能会带来更好的性能。</td>
</tr>
<tr>
<td style="text-align:center">减少正则化</td>
<td style="text-align:center">也许模型拟合不足，是因为人为试图防止过度拟合。抑制正则化技术可以帮助模型更好地拟合数据。</td>
</tr>
</tbody>
</table>
</div>
<h2 id="8-3-The-balance-between-overfitting-and-underfitting-过度拟合与欠拟合之间的平衡"><a href="#8-3-The-balance-between-overfitting-and-underfitting-过度拟合与欠拟合之间的平衡" class="headerlink" title="8.3 The balance between overfitting and underfitting 过度拟合与欠拟合之间的平衡"></a>8.3 The balance between overfitting and underfitting 过度拟合与欠拟合之间的平衡</h2><p>上面讨论的方法都不是灵丹妙药，也就是说，它们并不总是有效。</p>
<p>防止过度拟合和欠拟合可能是机器学习研究最活跃的领域。</p>
<p>由于每个人都希望他们的模型拟合得更好（更少的欠拟合），但又不是太好，所以它们不能很好地概括并在现实世界中表现不佳（更少的过度拟合）。</p>
<p>过度拟合与欠拟合之间存在着一线之隔。</p>
<p>因为任何一种因素过多都可能引发另一种因素。</p>
<p>当涉及到解决过度拟合和欠拟合的问题时，迁移学习可能是最强大的技术之一。</p>
<p>迁移学习不需要手工制作不同的过度拟合和欠拟合技术，而是可以让你采用与你的问题空间类似的问题空间中已经可以工作的模型（比如来自paperswithcode.com/sota或Hugging Face 模型的模型）并将其应用到你自己的数据集中。</p>
<p>我们将在后面的笔记本中看到迁移学习的威力。</p>
<h1 id="9-Model-1-TinyVGG-with-Data-Augmentation-模型1：具有数据增强的TinyVGG"><a href="#9-Model-1-TinyVGG-with-Data-Augmentation-模型1：具有数据增强的TinyVGG" class="headerlink" title="9. Model 1: TinyVGG with Data Augmentation 模型1：具有数据增强的TinyVGG"></a>9. Model 1: TinyVGG with Data Augmentation 模型1：具有数据增强的TinyVGG</h1><p>是时候尝试另一个模型了！</p>
<p>这次，让我们加载数据并使用<strong>数据增强</strong>来看看它是否可以改善我们的结果。</p>
<p>首先，我们将编写一个训练变换来包含<code>transforms.TrivialAugmentWide()</code>、调整图像大小并将其转换为张量。</p>
<p>我们将对测试转换执行相同的操作，只是没有数据增强。</p>
<h2 id="9-1-Create-transform-with-data-augmentation-使用数据增强创建变换"><a href="#9-1-Create-transform-with-data-augmentation-使用数据增强创建变换" class="headerlink" title="9.1 Create transform with data augmentation 使用数据增强创建变换"></a>9.1 Create transform with data augmentation 使用数据增强创建变换</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Create training transform with TrivialAugment</span></span><br><span class="line">train_transform_trivial_augment = transforms.Compose([</span><br><span class="line">    transforms.Resize((<span class="number">64</span>, <span class="number">64</span>)),</span><br><span class="line">    transforms.TrivialAugmentWide(num_magnitude_bins=<span class="number">31</span>),</span><br><span class="line">    transforms.ToTensor() </span><br><span class="line">])</span><br><span class="line"></span><br><span class="line"><span class="comment"># Create testing transform (no data augmentation)</span></span><br><span class="line">test_transform = transforms.Compose([</span><br><span class="line">    transforms.Resize((<span class="number">64</span>, <span class="number">64</span>)),</span><br><span class="line">    transforms.ToTensor()</span><br><span class="line">])</span><br></pre></td></tr></table></figure>
<p>使用 <code>torchvision.datasets.ImageFolder()</code> 将图像转换为 <code>Dataset</code>，然后使用 <code>torch.utils.data.DataLoader()</code> 将其转换为 <code>DataLoader</code>。</p>
<h2 id="9-2-Create-train-and-test-Dataset’s-and-DataLoader’s-创建训练和测试数据集和数据加载器"><a href="#9-2-Create-train-and-test-Dataset’s-and-DataLoader’s-创建训练和测试数据集和数据加载器" class="headerlink" title="9.2 Create train and test Dataset’s and DataLoader’s 创建训练和测试数据集和数据加载器"></a>9.2 Create train and test Dataset’s and DataLoader’s 创建训练和测试数据集和数据加载器</h2><p>我们将确保训练 <code>Dataset</code> 使用 <code>train_transform_trivial_augment</code>，而测试 <code>Dataset</code> 使用<code>test_transform</code>。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Turn image folders into Datasets</span></span><br><span class="line">train_data_augmented = datasets.ImageFolder(train_dir, transform=train_transform_trivial_augment)</span><br><span class="line">test_data_simple = datasets.ImageFolder(test_dir, transform=test_transform)</span><br><span class="line"></span><br><span class="line">train_data_augmented, test_data_simple</span><br></pre></td></tr></table></figure>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">(Dataset ImageFolder</span><br><span class="line">     Number of datapoints: 225</span><br><span class="line">     Root location: data\pizza_steak_sushi\train</span><br><span class="line">     StandardTransform</span><br><span class="line"> Transform: Compose(</span><br><span class="line">                Resize(size=(64, 64), interpolation=bilinear, max_size=None, antialias=True)</span><br><span class="line">                TrivialAugmentWide(num_magnitude_bins=31, interpolation=InterpolationMode.NEAREST, fill=None)</span><br><span class="line">                ToTensor()</span><br><span class="line">            ),</span><br><span class="line"> Dataset ImageFolder</span><br><span class="line">     Number of datapoints: 75</span><br><span class="line">     Root location: data\pizza_steak_sushi\test</span><br><span class="line">     StandardTransform</span><br><span class="line"> Transform: Compose(</span><br><span class="line">                Resize(size=(64, 64), interpolation=bilinear, max_size=None, antialias=True)</span><br><span class="line">                ToTensor()</span><br><span class="line">            ))</span><br></pre></td></tr></table></figure>
<p>我们将 <code>DataLoader</code> 的 <code>batch_size</code> 设置为 32，并将 <code>num_workers</code> 设置为我们机器上可用的 CPU 数量（我们可以使用 Python 的 <code>os.cpu_count()</code> 获取该数量）。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Turn Datasets into DataLoader&#x27;s</span></span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line">BATCH_SIZE = <span class="number">32</span></span><br><span class="line">NUM_WORKERS = os.cpu_count()</span><br><span class="line"></span><br><span class="line">torch.manual_seed(<span class="number">42</span>)</span><br><span class="line">train_dataloader_augmented = DataLoader(train_data_augmented, </span><br><span class="line">                                        batch_size=BATCH_SIZE, </span><br><span class="line">                                        shuffle=<span class="literal">True</span>,</span><br><span class="line">                                        num_workers=NUM_WORKERS)</span><br><span class="line"></span><br><span class="line">test_dataloader_simple = DataLoader(test_data_simple, </span><br><span class="line">                                    batch_size=BATCH_SIZE, </span><br><span class="line">                                    shuffle=<span class="literal">False</span>, </span><br><span class="line">                                    num_workers=NUM_WORKERS)</span><br><span class="line"></span><br><span class="line">train_dataloader_augmented, test_dataloader</span><br></pre></td></tr></table></figure>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">(&lt;torch.utils.data.dataloader.DataLoader at 0x277ca662370&gt;,</span><br><span class="line"> &lt;torch.utils.data.dataloader.DataLoader at 0x277ca8a83a0&gt;)</span><br></pre></td></tr></table></figure>
<h2 id="9-3-Construct-and-train-Model-1"><a href="#9-3-Construct-and-train-Model-1" class="headerlink" title="9.3 Construct and train Model 1"></a>9.3 Construct and train Model 1</h2><p>构建下一个模型 <code>model_1</code>，我们可以重用之前的 <code>TinyVGG</code> 类。<br>我们将确保将其发送到目标设备。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Create model_1 and send it to the target device</span></span><br><span class="line">torch.manual_seed(<span class="number">42</span>)</span><br><span class="line">model_1 = TinyVGG(</span><br><span class="line">    input_shape=<span class="number">3</span>,</span><br><span class="line">    hidden_units=<span class="number">10</span>,</span><br><span class="line">    output_shape=<span class="built_in">len</span>(train_data_augmented.classes)).to(device)</span><br><span class="line">model_1</span><br></pre></td></tr></table></figure>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">TinyVGG(</span><br><span class="line">  (conv_block_1): Sequential(</span><br><span class="line">    (0): Conv2d(3, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))</span><br><span class="line">    (1): ReLU()</span><br><span class="line">    (2): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))</span><br><span class="line">    (3): ReLU()</span><br><span class="line">    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)</span><br><span class="line">  )</span><br><span class="line">  (conv_block_2): Sequential(</span><br><span class="line">    (0): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))</span><br><span class="line">    (1): ReLU()</span><br><span class="line">    (2): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))</span><br><span class="line">    (3): ReLU()</span><br><span class="line">    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)</span><br><span class="line">  )</span><br><span class="line">  (classifier): Sequential(</span><br><span class="line">    (0): Flatten(start_dim=1, end_dim=-1)</span><br><span class="line">    (1): Linear(in_features=2560, out_features=3, bias=True)</span><br><span class="line">  )</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<p>由于我们已经获得了训练循环 (<code>train_step()</code>) 和测试循环 (<code>test_step()</code>) 的函数以及将它们组合在 <code>train()</code> 中的函数，因此让我们重复使用它们。</p>
<p>我们将使用与 <code>model_0</code> 相同的设置，只有 <code>train_dataloader</code>参数有所不同：</p>
<ul>
<li>训练 5 个时期。</li>
<li>使用 <code>train_dataloader=train_dataloader_augmented</code> 作为 train() 中的训练数据。</li>
<li>使用 <code>torch.nn.CrossEntropyLoss()</code> 作为损失函数（因为我们处理的是多类分类）。</li>
<li>使用 <code>torch.optim.Adam()</code> 并以 <code>lr=0.001</code> 作为优化器的学习率。</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Set random seeds</span></span><br><span class="line">torch.manual_seed(<span class="number">42</span>) </span><br><span class="line">torch.cuda.manual_seed(<span class="number">42</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Set number of epochs</span></span><br><span class="line">NUM_EPOCHS = <span class="number">5</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Setup loss function and optimizer</span></span><br><span class="line">loss_fn = nn.CrossEntropyLoss()</span><br><span class="line">optimizer = torch.optim.Adam(params=model_1.parameters(), lr=<span class="number">0.001</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Start the timer</span></span><br><span class="line"><span class="keyword">from</span> timeit <span class="keyword">import</span> default_timer <span class="keyword">as</span> timer </span><br><span class="line">start_time = timer()</span><br><span class="line"></span><br><span class="line"><span class="comment"># Train model_1</span></span><br><span class="line">model_1_results = train(model=model_1, </span><br><span class="line">                        train_dataloader=train_dataloader_augmented,</span><br><span class="line">                        test_dataloader=test_dataloader_simple,</span><br><span class="line">                        optimizer=optimizer,</span><br><span class="line">                        loss_fn=loss_fn, </span><br><span class="line">                        epochs=NUM_EPOCHS)</span><br><span class="line"></span><br><span class="line"><span class="comment"># End the timer and print out how long it took</span></span><br><span class="line">end_time = timer()</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Total training time: <span class="subst">&#123;end_time-start_time:<span class="number">.3</span>f&#125;</span> seconds&quot;</span>)</span><br></pre></td></tr></table></figure>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">Epoch: 1 | train_loss: 1.1074 | train_acc: 0.2500 | test_loss: 1.1058 | test_acc: 0.2604</span><br><span class="line">Epoch: 2 | train_loss: 1.0791 | train_acc: 0.4258 | test_loss: 1.1381 | test_acc: 0.2604</span><br><span class="line">Epoch: 3 | train_loss: 1.0800 | train_acc: 0.4258 | test_loss: 1.1693 | test_acc: 0.2604</span><br><span class="line">Epoch: 4 | train_loss: 1.1284 | train_acc: 0.3047 | test_loss: 1.1616 | test_acc: 0.2604</span><br><span class="line">Epoch: 5 | train_loss: 1.0882 | train_acc: 0.4258 | test_loss: 1.1471 | test_acc: 0.2604</span><br><span class="line">Total training time: 199.736 seconds</span><br></pre></td></tr></table></figure>
<p>效果依旧很差。</p>
<h2 id="9-4-Plot-the-loss-curves-of-Model-1"><a href="#9-4-Plot-the-loss-curves-of-Model-1" class="headerlink" title="9.4 Plot the loss curves of Model 1"></a>9.4 Plot the loss curves of Model 1</h2><p>由于已将 <code>model_1</code> 的结果保存在结果字典 <code>model_1_results</code> 中，因此可以使用 <code>plot_loss_curves()</code> 绘制。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">plot_loss_curves(model_1_results)</span><br></pre></td></tr></table></figure>
<img src="/2024/08/18/PyTorch-26H-5/PyTorch-26H-5-12.png" class="" title="PyTorch-26H-5-12">
<p>模型是欠拟合还是过拟合？还是两者兼而有之？<br>理想情况下，希望它具有更高的准确度和更低的损失。</p>
<h1 id="10-Compare-model-results-比较模型结果"><a href="#10-Compare-model-results-比较模型结果" class="headerlink" title="10. Compare model results 比较模型结果"></a>10. Compare model results 比较模型结果</h1><p>尽管我们的模型表现很差，我们仍然可以编写代码来比较它们。</p>
<p>让我们首先将模型结果转换为 pandas DataFrames。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line">model_0_df = pd.DataFrame(model_0_results)</span><br><span class="line">model_1_df = pd.DataFrame(model_1_results)</span><br><span class="line">model_0_df</span><br></pre></td></tr></table></figure>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center"></th>
<th style="text-align:center">train_loss</th>
<th style="text-align:center">train_acc</th>
<th style="text-align:center">test_loss</th>
<th style="text-align:center">test_acc</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">0</td>
<td style="text-align:center">1.107833</td>
<td style="text-align:center">0.257812</td>
<td style="text-align:center">1.136041</td>
<td style="text-align:center">0.260417</td>
</tr>
<tr>
<td style="text-align:center">1</td>
<td style="text-align:center">1.084713</td>
<td style="text-align:center">0.425781</td>
<td style="text-align:center">1.162014</td>
<td style="text-align:center">0.197917</td>
</tr>
<tr>
<td style="text-align:center">2</td>
<td style="text-align:center">1.115697</td>
<td style="text-align:center">0.292969</td>
<td style="text-align:center">1.169704</td>
<td style="text-align:center">0.197917</td>
</tr>
<tr>
<td style="text-align:center">3</td>
<td style="text-align:center">1.095564</td>
<td style="text-align:center">0.414062</td>
<td style="text-align:center">1.138373</td>
<td style="text-align:center">0.197917</td>
</tr>
<tr>
<td style="text-align:center">4</td>
<td style="text-align:center">1.098520</td>
<td style="text-align:center">0.292969</td>
<td style="text-align:center">1.142631</td>
<td style="text-align:center">0.197917</td>
</tr>
</tbody>
</table>
</div>
<p>现在我们可以使用 <code>matplotlib</code> 编写一些绘图代码来一起可视化 <code>model_0</code> 和 <code>model_1</code> 的结果。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Setup a plot </span></span><br><span class="line">plt.figure(figsize=(<span class="number">15</span>, <span class="number">10</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># Get number of epochs</span></span><br><span class="line">epochs = <span class="built_in">range</span>(<span class="built_in">len</span>(model_0_df))</span><br><span class="line"></span><br><span class="line"><span class="comment"># Plot train loss</span></span><br><span class="line">plt.subplot(<span class="number">2</span>, <span class="number">2</span>, <span class="number">1</span>)</span><br><span class="line">plt.plot(epochs, model_0_df[<span class="string">&quot;train_loss&quot;</span>], label=<span class="string">&quot;Model 0&quot;</span>)</span><br><span class="line">plt.plot(epochs, model_1_df[<span class="string">&quot;train_loss&quot;</span>], label=<span class="string">&quot;Model 1&quot;</span>)</span><br><span class="line">plt.title(<span class="string">&quot;Train Loss&quot;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&quot;Epochs&quot;</span>)</span><br><span class="line">plt.legend()</span><br><span class="line"></span><br><span class="line"><span class="comment"># Plot test loss</span></span><br><span class="line">plt.subplot(<span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>)</span><br><span class="line">plt.plot(epochs, model_0_df[<span class="string">&quot;test_loss&quot;</span>], label=<span class="string">&quot;Model 0&quot;</span>)</span><br><span class="line">plt.plot(epochs, model_1_df[<span class="string">&quot;test_loss&quot;</span>], label=<span class="string">&quot;Model 1&quot;</span>)</span><br><span class="line">plt.title(<span class="string">&quot;Test Loss&quot;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&quot;Epochs&quot;</span>)</span><br><span class="line">plt.legend()</span><br><span class="line"></span><br><span class="line"><span class="comment"># Plot train accuracy</span></span><br><span class="line">plt.subplot(<span class="number">2</span>, <span class="number">2</span>, <span class="number">3</span>)</span><br><span class="line">plt.plot(epochs, model_0_df[<span class="string">&quot;train_acc&quot;</span>], label=<span class="string">&quot;Model 0&quot;</span>)</span><br><span class="line">plt.plot(epochs, model_1_df[<span class="string">&quot;train_acc&quot;</span>], label=<span class="string">&quot;Model 1&quot;</span>)</span><br><span class="line">plt.title(<span class="string">&quot;Train Accuracy&quot;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&quot;Epochs&quot;</span>)</span><br><span class="line">plt.legend()</span><br><span class="line"></span><br><span class="line"><span class="comment"># Plot test accuracy</span></span><br><span class="line">plt.subplot(<span class="number">2</span>, <span class="number">2</span>, <span class="number">4</span>)</span><br><span class="line">plt.plot(epochs, model_0_df[<span class="string">&quot;test_acc&quot;</span>], label=<span class="string">&quot;Model 0&quot;</span>)</span><br><span class="line">plt.plot(epochs, model_1_df[<span class="string">&quot;test_acc&quot;</span>], label=<span class="string">&quot;Model 1&quot;</span>)</span><br><span class="line">plt.title(<span class="string">&quot;Test Accuracy&quot;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&quot;Epochs&quot;</span>)</span><br><span class="line">plt.legend();</span><br></pre></td></tr></table></figure>
<img src="/2024/08/18/PyTorch-26H-5/PyTorch-26H-5-13.png" class="" title="PyTorch-26H-5-13">
<p>看起来我们的模型表现同样糟糕，而且有点不稳定（指标急剧上升和下降）。</p>
<h1 id="11-Make-a-prediction-on-a-custom-image-对自定义图像进行预测"><a href="#11-Make-a-prediction-on-a-custom-image-对自定义图像进行预测" class="headerlink" title="11. Make a prediction on a custom image 对自定义图像进行预测"></a>11. Make a prediction on a custom image 对自定义图像进行预测</h1><p>如果您已经在某个数据集上训练了模型，那么您很可能想要对自己的自定义数据进行预测。</p>
<p>在我们的例子中，由于我们已经在披萨、牛排和寿司图像上训练了模型，那么我们如何使用我们的模型对我们自己的一张图像进行预测呢？</p>
<p>为此，我们可以加载图像，然后以与我们的模型训练的数据类型相匹配的方式对其进行预处理。</p>
<p>换句话说，我们必须将我们自己的自定义图像转换为张量，并确保它具有正确的数据类型，然后再将其传递给我们的模型。</p>
<p>让我们从下载自定义图像开始。</p>
<p>由于我们的模型可以预测图像中是否包含披萨、牛排或寿司，所以我们<a target="_blank" rel="noopener" href="https://github.com/mrdbourke/pytorch-deep-learning/blob/main/images/04-pizza-dad.jpeg">从学习 PyTorch 进行深度学习 GitHub 下载一张我爸爸对大披萨竖起两个大拇指</a>的照片。</p>
<p>我们使用 Python 的模块下载图像<code>requests</code>。</p>
<blockquote>
<p>注意：如果您使用的是 Google Colab，您也可以通过转到左侧菜单 -&gt; 文件 -&gt; 上传到会话存储将图像上传到当前会话。但请注意，当您的 Google Colab 会话结束时，此图像将被删除。</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Download custom image</span></span><br><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"></span><br><span class="line"><span class="comment"># Setup custom image path</span></span><br><span class="line">custom_image_path = data_path / <span class="string">&quot;04-pizza-dad.jpeg&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Download the image if it doesn&#x27;t already exist</span></span><br><span class="line"><span class="keyword">if</span> <span class="keyword">not</span> custom_image_path.is_file():</span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(custom_image_path, <span class="string">&quot;wb&quot;</span>) <span class="keyword">as</span> f:</span><br><span class="line">        <span class="comment"># When downloading from GitHub, need to use the &quot;raw&quot; file link</span></span><br><span class="line">        request = requests.get(<span class="string">&quot;https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/images/04-pizza-dad.jpeg&quot;</span>)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;Downloading <span class="subst">&#123;custom_image_path&#125;</span>...&quot;</span>)</span><br><span class="line">        f.write(request.content)</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;<span class="subst">&#123;custom_image_path&#125;</span> already exists, skipping download.&quot;</span>)</span><br></pre></td></tr></table></figure>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">data/04-pizza-dad.jpeg already exists, skipping download.</span><br></pre></td></tr></table></figure>
<h2 id="11-1-Loading-in-a-custom-image-with-PyTorch-使用-PyTorch-加载自定义图像"><a href="#11-1-Loading-in-a-custom-image-with-PyTorch-使用-PyTorch-加载自定义图像" class="headerlink" title="11.1 Loading in a custom image with PyTorch 使用 PyTorch 加载自定义图像"></a>11.1 Loading in a custom image with PyTorch 使用 PyTorch 加载自定义图像</h2><p>看起来我们已经下载了一个自定义图像，并准备在 <code>data/04-pizza-dad.jpeg</code> 中使用。</p>
<p>是时候加载它了。</p>
<p>PyTorch 的 <code>torchvision</code> 有几种输入和输出（简称“IO”或“io”）方法，用于在<a target="_blank" rel="noopener" href="https://pytorch.org/vision/stable/io.html"><code>torchvision.io</code></a> 中读取和写入图像和视频。</p>
<p>由于我们要加载图像，我们将使用 <a target="_blank" rel="noopener" href="https://pytorch.org/vision/stable/generated/torchvision.io.read_image.html#torchvision.io.read_image"><code>torchvision.io.read_image()</code></a>。</p>
<p>此方法将读取 JPEG 或 PNG 图像并将其转换为 3 维 RGB 或灰度 <code>torch.Tensor</code>，其数据类型为 uint8，值在 [0, 255] 范围内。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"></span><br><span class="line"><span class="comment"># Read in custom image</span></span><br><span class="line">custom_image_uint8 = torchvision.io.read_image(<span class="built_in">str</span>(custom_image_path))</span><br><span class="line"></span><br><span class="line"><span class="comment"># Print out image data</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Custom image tensor:\n<span class="subst">&#123;custom_image_uint8&#125;</span>\n&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Custom image shape: <span class="subst">&#123;custom_image_uint8.shape&#125;</span>\n&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Custom image dtype: <span class="subst">&#123;custom_image_uint8.dtype&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">Custom image tensor:</span><br><span class="line">tensor([[[154, 173, 181,  ...,  21,  18,  14],</span><br><span class="line">         [146, 165, 181,  ...,  21,  18,  15],</span><br><span class="line">         [124, 146, 172,  ...,  18,  17,  15],</span><br><span class="line">         ...,</span><br><span class="line">         [ 72,  59,  45,  ..., 152, 150, 148],</span><br><span class="line">         [ 64,  55,  41,  ..., 150, 147, 144],</span><br><span class="line">         [ 64,  60,  46,  ..., 149, 146, 143]],</span><br><span class="line"></span><br><span class="line">        [[171, 190, 193,  ...,  22,  19,  15],</span><br><span class="line">         [163, 182, 193,  ...,  22,  19,  16],</span><br><span class="line">         [141, 163, 184,  ...,  19,  18,  16],</span><br><span class="line">         ...,</span><br><span class="line">         [ 55,  42,  28,  ..., 107, 104, 103],</span><br><span class="line">         [ 47,  38,  24,  ..., 108, 104, 102],</span><br><span class="line">         [ 47,  43,  29,  ..., 107, 104, 101]],</span><br><span class="line"></span><br><span class="line">        [[119, 138, 147,  ...,  17,  14,  10],</span><br><span class="line">         [111, 130, 145,  ...,  17,  14,  11],</span><br><span class="line">         [ 87, 111, 136,  ...,  14,  13,  11],</span><br><span class="line">         ...,</span><br><span class="line">         [ 35,  22,   8,  ...,  52,  52,  48],</span><br><span class="line">         [ 27,  18,   4,  ...,  50,  49,  44],</span><br><span class="line">         [ 27,  23,   9,  ...,  49,  46,  43]]], dtype=torch.uint8)</span><br><span class="line"></span><br><span class="line">Custom image shape: torch.Size([3, 4032, 3024])</span><br><span class="line"></span><br><span class="line">Custom image dtype: torch.uint8</span><br></pre></td></tr></table></figure>
<p>很好！看起来我们的图像是张量格式，但是，这种图像格式与我们的模型兼容吗？</p>
<p>我们的 <code>custom_image</code> 张量的数据类型是 <code>torch.uint8</code>，其值介于 [0, 255] 之间。</p>
<p>但是我们的模型采用数据类型为 <code>torch.float32</code> 的图像张量，其值介于 [0, 1] 之间。</p>
<p>因此，在将自定义图像与模型一起使用之前，我们需要将其转换为与模型训练数据相同的格式。</p>
<p>如果我们不这样做，我们的模型就会出错。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Try to make a prediction on image in uint8 format (this will error)</span></span><br><span class="line">model_1.<span class="built_in">eval</span>()</span><br><span class="line"><span class="keyword">with</span> torch.inference_mode():</span><br><span class="line">    model_1(custom_image_uint8.to(device))</span><br></pre></td></tr></table></figure>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">RuntimeError: Input type (unsigned char) and bias type (float) should be the same</span><br></pre></td></tr></table></figure>
<p>如果我们尝试对与我们的模型训练不同的数据类型的图像进行预测，我们会收到如下错误：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">RuntimeError: Input type (torch.cuda.ByteTensor) and weight type (torch.cuda.FloatTensor) should be the same</span><br></pre></td></tr></table></figure>
<p>让我们通过将自定义图像转换为与我们的模型训练相同的数据类型来解决这个问题（<code>torch.float32</code>）。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Load in custom image and convert the tensor values to float32</span></span><br><span class="line">custom_image = torchvision.io.read_image(<span class="built_in">str</span>(custom_image_path)).<span class="built_in">type</span>(torch.float32)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Divide the image pixel values by 255 to get them between [0, 1]</span></span><br><span class="line">custom_image = custom_image / <span class="number">255.</span> </span><br><span class="line"></span><br><span class="line"><span class="comment"># Print out image data</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Custom image tensor:\n<span class="subst">&#123;custom_image&#125;</span>\n&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Custom image shape: <span class="subst">&#123;custom_image.shape&#125;</span>\n&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Custom image dtype: <span class="subst">&#123;custom_image.dtype&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">Custom image tensor:</span><br><span class="line">tensor([[[0.6039, 0.6784, 0.7098,  ..., 0.0824, 0.0706, 0.0549],</span><br><span class="line">         [0.5725, 0.6471, 0.7098,  ..., 0.0824, 0.0706, 0.0588],</span><br><span class="line">         [0.4863, 0.5725, 0.6745,  ..., 0.0706, 0.0667, 0.0588],</span><br><span class="line">         ...,</span><br><span class="line">         [0.2824, 0.2314, 0.1765,  ..., 0.5961, 0.5882, 0.5804],</span><br><span class="line">         [0.2510, 0.2157, 0.1608,  ..., 0.5882, 0.5765, 0.5647],</span><br><span class="line">         [0.2510, 0.2353, 0.1804,  ..., 0.5843, 0.5725, 0.5608]],</span><br><span class="line"></span><br><span class="line">        [[0.6706, 0.7451, 0.7569,  ..., 0.0863, 0.0745, 0.0588],</span><br><span class="line">         [0.6392, 0.7137, 0.7569,  ..., 0.0863, 0.0745, 0.0627],</span><br><span class="line">         [0.5529, 0.6392, 0.7216,  ..., 0.0745, 0.0706, 0.0627],</span><br><span class="line">         ...,</span><br><span class="line">         [0.2157, 0.1647, 0.1098,  ..., 0.4196, 0.4078, 0.4039],</span><br><span class="line">         [0.1843, 0.1490, 0.0941,  ..., 0.4235, 0.4078, 0.4000],</span><br><span class="line">         [0.1843, 0.1686, 0.1137,  ..., 0.4196, 0.4078, 0.3961]],</span><br><span class="line"></span><br><span class="line">        [[0.4667, 0.5412, 0.5765,  ..., 0.0667, 0.0549, 0.0392],</span><br><span class="line">         [0.4353, 0.5098, 0.5686,  ..., 0.0667, 0.0549, 0.0431],</span><br><span class="line">         [0.3412, 0.4353, 0.5333,  ..., 0.0549, 0.0510, 0.0431],</span><br><span class="line">         ...,</span><br><span class="line">         [0.1373, 0.0863, 0.0314,  ..., 0.2039, 0.2039, 0.1882],</span><br><span class="line">         [0.1059, 0.0706, 0.0157,  ..., 0.1961, 0.1922, 0.1725],</span><br><span class="line">         [0.1059, 0.0902, 0.0353,  ..., 0.1922, 0.1804, 0.1686]]])</span><br><span class="line"></span><br><span class="line">Custom image shape: torch.Size([3, 4032, 3024])</span><br><span class="line"></span><br><span class="line">Custom image dtype: torch.float32</span><br></pre></td></tr></table></figure>
<h2 id="11-2-Predicting-on-custom-images-with-a-trained-PyTorch-model-使用训练好的-PyTorch-模型对自定义图像进行预测"><a href="#11-2-Predicting-on-custom-images-with-a-trained-PyTorch-model-使用训练好的-PyTorch-模型对自定义图像进行预测" class="headerlink" title="11.2 Predicting on custom images with a trained PyTorch model 使用训练好的 PyTorch 模型对自定义图像进行预测"></a>11.2 Predicting on custom images with a trained PyTorch model 使用训练好的 PyTorch 模型对自定义图像进行预测</h2><p>看起来我们的图像数据现在与我们的模型训练的格式相同。</p>
<p>除了一件事……</p>
<p>它是shape。</p>
<p>我们的模型是在具有形状的图像上进行训练的[3, 64, 64]，而我们的自定义图像目前是[3, 4032, 3024]。</p>
<p>我们如何确保我们的自定义图像与我们的模型训练的图像具有相同的形状？</p>
<p>有沒有任何<code>torchvision.transforms</code>可以幫助的？</p>
<p>在回答这个问题之前，让我们先绘制图像<code>matplotlib</code>以确保它看起来不错，记住我们必须将尺寸从<code>CHW</code>到<code>HWC</code>排列以满足的<code>matplotlib</code>要求。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Plot custom image</span></span><br><span class="line">plt.imshow(custom_image.permute(<span class="number">1</span>, <span class="number">2</span>, <span class="number">0</span>)) <span class="comment"># need to permute image dimensions from CHW -&gt; HWC otherwise matplotlib will error</span></span><br><span class="line">plt.title(<span class="string">f&quot;Image shape: <span class="subst">&#123;custom_image.shape&#125;</span>&quot;</span>)</span><br><span class="line">plt.axis(<span class="literal">False</span>);</span><br></pre></td></tr></table></figure>
<img src="/2024/08/18/PyTorch-26H-5/PyTorch-26H-5-14.png" class="" title="PyTorch-26H-5-14">
<p>竖起两个大拇指！</p>
<p>现在我们如何才能让我们的图像与我们的模型训练的图像具有相同的大小？</p>
<p>其中一种方法是使用<code>torchvision.transforms.Resize()</code>。</p>
<p>让我们编写一个转换管道<code>transform pipeline</code>来实现这一点。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Create transform pipleine to resize image</span></span><br><span class="line">custom_image_transform = transforms.Compose([</span><br><span class="line">    transforms.Resize((<span class="number">64</span>, <span class="number">64</span>)),</span><br><span class="line">])</span><br><span class="line"></span><br><span class="line"><span class="comment"># Transform target image</span></span><br><span class="line">custom_image_transformed = custom_image_transform(custom_image)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Print out original shape and new shape</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Original shape: <span class="subst">&#123;custom_image.shape&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;New shape: <span class="subst">&#123;custom_image_transformed.shape&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Original shape: torch.Size([3, 4032, 3024])</span><br><span class="line">New shape: torch.Size([3, 64, 64])</span><br></pre></td></tr></table></figure>
<p>最后我们来对我们自己的自定义图像进行预测。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">model_1.<span class="built_in">eval</span>()</span><br><span class="line"><span class="keyword">with</span> torch.inference_mode():</span><br><span class="line">    custom_image_pred = model_1(custom_image_transformed)</span><br></pre></td></tr></table></figure>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument weight in method wrapper_CUDA___slow_conv2d_forward)</span><br></pre></td></tr></table></figure>
<p>尽管我们做好了准备，但我们的自定义图像和模型仍在不同的设备上。</p>
<p>让我们通过将我们的放到<code>custom_image_transformed</code>目标设备上来解决这个问题。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">model_1.<span class="built_in">eval</span>()</span><br><span class="line"><span class="keyword">with</span> torch.inference_mode():</span><br><span class="line">    custom_image_pred = model_1(custom_image_transformed.to(device))</span><br></pre></td></tr></table></figure>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">RuntimeError: mat1 and mat2 shapes cannot be multiplied (10x256 and 2560x3)</span><br></pre></td></tr></table></figure>
<p>形状错误。</p>
<p>我们将自定义图像转换为与我们的模型训练图像相同的尺寸……</p>
<p>哦，等等……</p>
<p>我们忘记了一个维度。</p>
<p>批次大小。</p>
<p>我们的模型期望图像张量在开始时具有批量大小维度（NCHW其中N是批量大小）。</p>
<p>除了我们的自定义图像目前只有CHW。</p>
<p>我们可以添加批量大小维度<code>torch.unsqueeze(dim=0)</code>来为图像添加额外的维度，最后做出预测。</p>
<p>本质上，我们将告诉我们的模型根据单个图像（1个<code>batch_size=1</code>的图像）进行预测。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">model_1.<span class="built_in">eval</span>()</span><br><span class="line"><span class="keyword">with</span> torch.inference_mode():</span><br><span class="line">    <span class="comment"># Add an extra dimension to image</span></span><br><span class="line">    custom_image_transformed_with_batch_size = custom_image_transformed.unsqueeze(dim=<span class="number">0</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Print out different shapes</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;Custom image transformed shape: <span class="subst">&#123;custom_image_transformed.shape&#125;</span>&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;Unsqueezed custom image shape: <span class="subst">&#123;custom_image_transformed_with_batch_size.shape&#125;</span>&quot;</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Make a prediction on image with an extra dimension</span></span><br><span class="line">    custom_image_pred = model_1(custom_image_transformed.unsqueeze(dim=<span class="number">0</span>).to(device))</span><br></pre></td></tr></table></figure>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Custom image transformed shape: torch.Size([3, 64, 64])</span><br><span class="line">Unsqueezed custom image shape: torch.Size([1, 3, 64, 64])</span><br></pre></td></tr></table></figure>
<p>注意：我们刚刚经历了三个经典且最常见的深度学习和 PyTorch 问题：</p>
<ul>
<li>错误的数据类型 ： 我们的模型需要 <code>torch.float32</code>，而我们原始的自定义图像是 <code>uint8</code>。</li>
<li>错误的设备 ： 我们的模型在目标设备上（在我们的例子中是 GPU），而我们的目标数据尚未移动到目标设备。</li>
<li>错误的形状 ： 我们的模型需要形状为 <code>[N, C, H, W]</code> 或 <code>[batch_size, color_channels, height, width]</code> 的输入图像，而我们的自定义图像张量的形状为 <code>[color_channels, height, width]</code>。</li>
</ul>
<p>请记住，这些错误不仅仅用于预测自定义图像。<br>它们存在于您处理的几乎所有数据类型（文本、音频、结构化数据）和问题中。</p>
<p>现在让我们来看看我们的模型的预测。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">custom_image_pred</span><br></pre></td></tr></table></figure>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tensor([[ 0.1188,  0.0250, -0.1444]], device=&#x27;cuda:0&#x27;)</span><br></pre></td></tr></table></figure>
<p>好的，这些仍然是logit 形式（模型的原始输出称为 logit）。</p>
<p>让我们将它们从日志-&gt;预测概率-&gt;预测标签进行转换。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Print out prediction logits</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Prediction logits: <span class="subst">&#123;custom_image_pred&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Convert logits -&gt; prediction probabilities (using torch.softmax() for multi-class classification)</span></span><br><span class="line">custom_image_pred_probs = torch.softmax(custom_image_pred, dim=<span class="number">1</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Prediction probabilities: <span class="subst">&#123;custom_image_pred_probs&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Convert prediction probabilities -&gt; prediction labels</span></span><br><span class="line">custom_image_pred_label = torch.argmax(custom_image_pred_probs, dim=<span class="number">1</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Prediction label: <span class="subst">&#123;custom_image_pred_label&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Prediction logits: tensor([[ 0.1188,  0.0250, -0.1444]], device=&#x27;cuda:0&#x27;)</span><br><span class="line">Prediction probabilities: tensor([[0.3733, 0.3398, 0.2869]], device=&#x27;cuda:0&#x27;)</span><br><span class="line">Prediction label: tensor([0], device=&#x27;cuda:0&#x27;)</span><br></pre></td></tr></table></figure>
<p>但当然我们的预测标签仍然是索引/张量形式。</p>
<p>我们可以通过在 <code>class_names</code> 列表上建立索引将其转换为字符串类名预测。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Find the predicted label</span></span><br><span class="line">custom_image_pred_class = class_names[custom_image_pred_label.cpu()] <span class="comment"># put pred label to CPU, otherwise will error</span></span><br><span class="line">custom_image_pred_class</span><br></pre></td></tr></table></figure>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&#x27;pizza&#x27;</span><br></pre></td></tr></table></figure>
<p>尽管根据我们的评估指标，模型的表现很差，但它似乎预测正确。</p>
<blockquote>
<p>注意：无论给出什么图像，当前形式的模型都会预测“披萨”、“牛排”或“寿司”。如果您希望模型预测不同的类别，则必须对其进行训练。</p>
</blockquote>
<p>但如果我们检查一下<code>custom_image_pred_probs</code>，我们会注意到模型给予每个类别几乎相同的权重（值相似）。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># The values of the prediction probabilities are quite similar</span></span><br><span class="line">custom_image_pred_probs</span><br></pre></td></tr></table></figure>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tensor([[0.3733, 0.3398, 0.2869]], device=&#x27;cuda:0&#x27;)</span><br></pre></td></tr></table></figure>
<p>具有如此相似的预测概率可能意味着几件事：</p>
<ul>
<li>该模型试图同时预测所有三个类别（可能有一张包含披萨、牛排和寿司的图像）。</li>
<li>该模型实际上并不知道它想要预测什么，而只是为每个类别分配相似的值。</li>
</ul>
<p>我们的案例是 2，由于我们的模型训练不佳，所以它基本上是在猜测预测。</p>
<h2 id="11-3-Putting-custom-image-prediction-together-building-a-function-将自定义图像预测整合在一起：构建函数"><a href="#11-3-Putting-custom-image-prediction-together-building-a-function-将自定义图像预测整合在一起：构建函数" class="headerlink" title="11.3 Putting custom image prediction together: building a function 将自定义图像预测整合在一起：构建函数"></a>11.3 Putting custom image prediction together: building a function 将自定义图像预测整合在一起：构建函数</h2><p>每次您想要对自定义图像进行预测时执行上述所有步骤很快就会变得乏味。</p>
<p>所以让我们将它们放在一起，形成一个可以轻松反复使用的函数。</p>
<p>具体来说，让我们创建一个函数：</p>
<ul>
<li>获取目标图像路径并转换为适合我们模型的正确数据类型（torch.float32）。</li>
<li>确保目标图像像素值在范围内[0, 1]。</li>
<li>如果有必要的话，变换目标图像。</li>
<li>确保模型在目标设备上。</li>
<li>使用训练好的模型对目标图像进行预测（确保图像大小正确且与模型位于同一设备上）。</li>
<li>将模型的输出逻辑转换为预测概率。</li>
<li>将预测概率转换为预测标签。</li>
<li>绘制目标图像以及模型预测和预测概率。</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">pred_and_plot_image</span>(<span class="params">model: torch.nn.Module, </span></span><br><span class="line"><span class="params">                        image_path: <span class="built_in">str</span>, </span></span><br><span class="line"><span class="params">                        class_names: <span class="type">List</span>[<span class="built_in">str</span>] = <span class="literal">None</span>, </span></span><br><span class="line"><span class="params">                        transform=<span class="literal">None</span>,</span></span><br><span class="line"><span class="params">                        device: torch.device = device</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Makes a prediction on a target image and plots the image with its prediction.&quot;&quot;&quot;</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 1. Load in image and convert the tensor values to float32</span></span><br><span class="line">    target_image = torchvision.io.read_image(<span class="built_in">str</span>(image_path)).<span class="built_in">type</span>(torch.float32)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 2. Divide the image pixel values by 255 to get them between [0, 1]</span></span><br><span class="line">    target_image = target_image / <span class="number">255.</span> </span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 3. Transform if necessary</span></span><br><span class="line">    <span class="keyword">if</span> transform:</span><br><span class="line">        target_image = transform(target_image)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 4. Make sure the model is on the target device</span></span><br><span class="line">    model.to(device)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 5. Turn on model evaluation mode and inference mode</span></span><br><span class="line">    model.<span class="built_in">eval</span>()</span><br><span class="line">    <span class="keyword">with</span> torch.inference_mode():</span><br><span class="line">        <span class="comment"># Add an extra dimension to the image</span></span><br><span class="line">        target_image = target_image.unsqueeze(dim=<span class="number">0</span>)</span><br><span class="line">    </span><br><span class="line">        <span class="comment"># Make a prediction on image with an extra dimension and send it to the target device</span></span><br><span class="line">        target_image_pred = model(target_image.to(device))</span><br><span class="line">        </span><br><span class="line">    <span class="comment"># 6. Convert logits -&gt; prediction probabilities (using torch.softmax() for multi-class classification)</span></span><br><span class="line">    target_image_pred_probs = torch.softmax(target_image_pred, dim=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 7. Convert prediction probabilities -&gt; prediction labels</span></span><br><span class="line">    target_image_pred_label = torch.argmax(target_image_pred_probs, dim=<span class="number">1</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 8. Plot the image alongside the prediction and prediction probability</span></span><br><span class="line">    plt.imshow(target_image.squeeze().permute(<span class="number">1</span>, <span class="number">2</span>, <span class="number">0</span>)) <span class="comment"># make sure it&#x27;s the right size for matplotlib</span></span><br><span class="line">    <span class="keyword">if</span> class_names:</span><br><span class="line">        title = <span class="string">f&quot;Pred: <span class="subst">&#123;class_names[target_image_pred_label.cpu()]&#125;</span> | Prob: <span class="subst">&#123;target_image_pred_probs.<span class="built_in">max</span>().cpu():<span class="number">.3</span>f&#125;</span>&quot;</span></span><br><span class="line">    <span class="keyword">else</span>: </span><br><span class="line">        title = <span class="string">f&quot;Pred: <span class="subst">&#123;target_image_pred_label&#125;</span> | Prob: <span class="subst">&#123;target_image_pred_probs.<span class="built_in">max</span>().cpu():<span class="number">.3</span>f&#125;</span>&quot;</span></span><br><span class="line">    plt.title(title)</span><br><span class="line">    plt.axis(<span class="literal">False</span>);</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Pred on our custom image</span></span><br><span class="line">pred_and_plot_image(model=model_1,</span><br><span class="line">                    image_path=custom_image_path,</span><br><span class="line">                    class_names=class_names,</span><br><span class="line">                    transform=custom_image_transform,</span><br><span class="line">                    device=device)</span><br></pre></td></tr></table></figure>
<img src="/2024/08/18/PyTorch-26H-5/PyTorch-26H-5-15.png" class="" title="PyTorch-26H-5-15">
<p>看起来我们的模型仅凭猜测就得到了正确的预测。</p>
<p>但其他图像并不总是如此……</p>
<p>图像也像素化了，因为我们<code>[64, 64]</code>使用调整了它的大小<code>custom_image_transform</code>。</p>
<h1 id="Main-takeaways"><a href="#Main-takeaways" class="headerlink" title="Main takeaways"></a>Main takeaways</h1><ul>
<li>PyTorch 有许多内置函数来处理各种数据，从视觉到文本到音频到推荐系统。</li>
<li>如果 PyTorch 的内置数据加载函数不符合您的要求，您可以编写代码通过子类化来创建自己的自定义数据集<code>torch.utils.data.Dataset</code>。</li>
<li><code>torch.utils.data.DataLoaderPyTorch</code> 中的 帮助将您的 转变<code>Dataset</code>为可在训练和测试模型时使用的可迭代对象。</li>
<li>许多机器学习都在处理过度拟合和欠拟合之间的平衡（我们针对上述情况讨论了不同的方法，因此一个很好的练习是进行更多研究并编写代码来尝试不同的技术）。</li>
<li>只要你将数据格式化为与模型训练时类似的格式，就可以使用经过训练的模型预测你自己的自定义数据。确保处理好 PyTorch 和深度学习的三大错误：</li>
<li>错误的数据类型–<code>torch.float32</code>当您的数据为 时，您的模型是预期的<code>torch.uint8</code>。</li>
<li>错误的数据形状<code>[batch_size, color_channels, height, width]</code>-当您的数据为 时，您的模型是预期的<code>[color_channels, height, width]</code>。</li>
<li>错误的设备- 您的模型在 GPU 上，但您的数据在 CPU 上。</li>
</ul>
<h1 id="Exercises"><a href="#Exercises" class="headerlink" title="Exercises"></a>Exercises</h1><p>所有练习都集中于练习以上部分中的代码。</p>
<p>您应该能够通过参考每个部分或按照链接的资源来完成它们。</p>
<p>所有练习都应使用与<a target="_blank" rel="noopener" href="https://pytorch.org/docs/stable/notes/cuda.html#device-agnostic-code">设备无关的代码</a>来完成。</p>
<p><strong>资源：</strong></p>
<ul>
<li><a target="_blank" rel="noopener" href="https://github.com/mrdbourke/pytorch-deep-learning/blob/main/extras/exercises/04_pytorch_custom_datasets_exercises.ipynb">04 年练习模板笔记本</a></li>
<li><a target="_blank" rel="noopener" href="https://github.com/mrdbourke/pytorch-deep-learning/blob/main/extras/solutions/04_pytorch_custom_datasets_exercise_solutions.ipynb">04 示例解决方案笔记本</a>（在查看<em>之前先</em>尝试练习）</li>
</ul>
<ol>
<li>我们的模型表现不佳（不能很好地拟合数据）。防止拟合不足的 3 种方法是什么？写下来并用一句话解释每种方法。</li>
<li>重新创建我们在第 1、2、3 和 4 节中构建的数据加载函数。您应该已经<code>DataLoader</code>准备好训练和测试了。</li>
<li>重新创建<code>model_0</code>我们在第 7 节中构建的内容。</li>
<li>为 建立训练和测试功能<code>model_0</code>。</li>
<li>尝试对你在练习 3 中创建的模型进行 5、20 和 50 个时期的训练，结果会怎样？<ul>
<li>使用<code>torch.optim.Adam()</code>学习率为 0.001 作为优化器。</li>
</ul>
</li>
<li>将模型中的隐藏单元数量加倍，并训练 20 个时期，结果会发生什么变化？</li>
<li>将您在模型中使用的数据增加一倍，并进行 20 个时期的训练，结果会怎样？<ul>
<li><strong>注意：</strong>您可以使用<a target="_blank" rel="noopener" href="https://github.com/mrdbourke/pytorch-deep-learning/blob/main/extras/04_custom_data_creation.ipynb">自定义数据创建笔记本</a>来扩大您的 Food101 数据集。</li>
<li>您还可以在 GitHub 上找到<a target="_blank" rel="noopener" href="https://github.com/mrdbourke/pytorch-deep-learning/blob/main/data/pizza_steak_sushi_20_percent.zip">已经格式化的双倍数据（20% 而不是 10% 子集）数据集</a>，您需要像练习 2 中那样编写下载代码才能将其放入此笔记本中。</li>
</ul>
</li>
<li>对您自己定制的披萨/牛排/寿司图像做出预测（您甚至可以从互联网上下载一个）并分享您的预测。<ul>
<li>你在练习 7 中训练的模型正确吗？</li>
<li>如果不是，您认为可以做些什么来改善它？</li>
</ul>
</li>
</ol>
<h1 id="Extra-curriculum"><a href="#Extra-curriculum" class="headerlink" title="Extra-curriculum"></a>Extra-curriculum</h1><ul>
<li><p>通过 PyTorch<a target="_blank" rel="noopener" href="https://pytorch.org/tutorials/beginner/basics/data_tutorial.html">数据集和数据加载器教程笔记本</a>练习对 PyTorch<code>Dataset</code>和 的知识。<code>DataLoader</code></p>
</li>
<li><p>花 10 分钟阅读  PyTorch<code>torchvision.transforms</code>文档</p>
<ul>
<li><a target="_blank" rel="noopener" href="https://pytorch.org/vision/main/auto_examples/transforms/plot_transforms_illustrations.html">您可以在变换教程的插图</a>中看到变换的实际演示。</li>
</ul>
</li>
<li><p>花 10 分钟阅读 PyTorch <code>torchvision.datasets</code>文档</p>
<ul>
<li>哪些数据集令您印象深刻？</li>
<li>您如何尝试基于这些来建立模型？</li>
</ul>
</li>
<li><p><a target="_blank" rel="noopener" href="https://pytorch.org/data/beta/index.html">TorchData 目前处于测试阶段</a>（截至 2022 年 4 月），它将成为未来在 PyTorch 中加载数据的一种方式，但您现在就可以开始检查它。</p>
</li>
<li><p>为了加速深度学习模型，你可以使用一些技巧来改进计算、内存和开销计算，更多信息请阅读Horace He 的文章<a target="_blank" rel="noopener" href="https://horace.io/brrr_intro.html"><em>《从第一原理开始让深度学习变得更好》 。</em></a></p>
</li>
</ul>
</div></article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="mailto:undefined">HibisciDai</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="http://hibiscidai.com/2024/08/18/PyTorch-26H-5/">http://hibiscidai.com/2024/08/18/PyTorch-26H-5/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a target="_blank" rel="noopener" href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="http://hibiscidai.com">HibisciDai</a>！</span></div></div><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/">学习笔记</a><a class="post-meta__tags" href="/tags/PyTorch/">PyTorch</a></div><div class="social-share pull-right" data-disabled="linkedin,diandian"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/social-share.js@1.0.16/dist/css/share.min.css"><script src="https://cdn.jsdelivr.net/npm/social-share.js@1.0.16/dist/js/social-share.min.js"></script><nav id="pagination"><div class="prev-post pull-left"><a href="/2024/08/19/PyTorch-26H-6/"><i class="fa fa-chevron-left">  </i><span>PyTorch-26H-6</span></a></div><div class="next-post pull-right"><a href="/2024/08/17/PyTorch-26H-4/"><span>PyTorch-26H-4</span><i class="fa fa-chevron-right"></i></a></div></nav><div class="post-adv"><a target="_blank" rel="noopener" href="https://www.paofu.cloud/auth/register?code=j4I7">好用、实惠、稳定的梯子,点击这里<img src="https://pic.imgdb.cn/item/65572abac458853aefef30cd.png" width="1000" height="124" object-fit="cover" ></a></div><div id="lv-container" data-id="city" data-uid="MTAyMC8zNTQ2NC8xMjAwMA=="><script>(function(d, s) {
    var j, e = d.getElementsByTagName(s)[0];
    if (typeof LivereTower === 'function') { return; }
    j = d.createElement(s);
    j.src = 'https://cdn-city.livere.com/js/embed.dist.js';
    j.async = true;
    e.parentNode.insertBefore(j, e);
})(document, 'script');</script></div></div></div><footer class="footer-bg" style="background-image: url(/img/banner2.jpg)"><div class="layout" id="footer"><div class="copyright">&copy;2017 - 2025 By HibisciDai</div><div class="framework-info"><span>驱动 - </span><a target="_blank" rel="noopener" href="http://hexo.io"><span>Hexo</span></a><span class="footer-separator">|</span><span>主题 - </span><a target="_blank" rel="noopener" href="https://github.com/Molunerfinn/hexo-theme-melody"><span>Melody</span></a></div><div class="footer_custom_text">hitokoto</div><div class="busuanzi"><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><span id="busuanzi_container_page_pv"><i class="fa fa-file"></i><span id="busuanzi_value_page_pv"></span><span></span></span></div></div></footer><i class="fa fa-arrow-up" id="go-up" aria-hidden="true"></i><script src="/js/third-party/anime.min.js"></script><script src="/js/third-party/jquery.min.js"></script><script src="/js/third-party/jquery.fancybox.min.js"></script><script src="/js/third-party/velocity.min.js"></script><script src="/js/third-party/velocity.ui.min.js"></script><script src="/js/utils.js?version=1.9.0"></script><script src="/js/fancybox.js?version=1.9.0"></script><script src="/js/sidebar.js?version=1.9.0"></script><script src="/js/copy.js?version=1.9.0"></script><script src="/js/fireworks.js?version=1.9.0"></script><script src="/js/transition.js?version=1.9.0"></script><script src="/js/scroll.js?version=1.9.0"></script><script src="/js/head.js?version=1.9.0"></script><script type="text/x-mathjax-config">MathJax.Hub.Config({
  tex2jax: {
    inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
    processEscapes: true,
    skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
  },
  CommonHTML: {
    linebreaks: { automatic: true, width: "90% container" }
  },
  "HTML-CSS": { 
    linebreaks: { automatic: true, width: "90% container" }
  },
  "SVG": { 
    linebreaks: { automatic: true, width: "90% container" }
  }
});
</script><script type="text/x-mathjax-config">MathJax.Hub.Queue(function() {
  var all = MathJax.Hub.getAllJax(), i;
  for (i=0; i < all.length; i += 1) {
    all[i].SourceElement().parentNode.className += ' has-jax';
  }
});
</script><script src="https://cdn.bootcss.com/mathjax/2.7.2/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/katex@latest/dist/katex.min.css"><script src="https://cdn.jsdelivr.net/npm/katex-copytex@latest/dist/katex-copytex.min.js"></script><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/katex-copytex@latest/dist/katex-copytex.min.css"><script src="/js/katex.js"></script><script src="/js/search/local-search.js"></script><script id="ribbon" src="/js/third-party/canvas-ribbon.js" size="150" alpha="0.6" zIndex="-1" data-click="false"></script><script>if(/Android|webOS|iPhone|iPod|iPad|BlackBerry/i.test(navigator.userAgent)) {
  $('#nav').addClass('is-mobile')
  $('footer').addClass('is-mobile')
  $('#top-container').addClass('is-mobile')
}</script><div class="search-dialog" id="local-search"><div class="search-dialog__title" id="local-search-title">本地搜索</div><div id="local-input-panel"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章"></div></div></div><hr><div id="local-search-results"><div id="local-hits"></div><div id="local-stats"><div class="local-search-stats__hr" id="hr"><span>由</span> <a target="_blank" rel="noopener" href="https://github.com/wzpan/hexo-generator-search" style="color:#49B1F5;">hexo-generator-search</a>
 <span>提供支持</span></div></div></div><span class="search-close-button"><i class="fa fa-times"></i></span></div><div class="search-mask"></div></body></html>