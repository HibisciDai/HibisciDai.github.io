<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>HibisciDai</title>
  
  <subtitle>Waiting/Patience/Trusting/Times All Takes</subtitle>
  <link href="http://hibiscidai.com/atom.xml" rel="self"/>
  
  <link href="http://hibiscidai.com/"/>
  <updated>2025-02-28T13:24:30.000Z</updated>
  <id>http://hibiscidai.com/</id>
  
  <author>
    <name>HibisciDai</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Python科学绘图</title>
    <link href="http://hibiscidai.com/2025/03/06/Python%E7%A7%91%E5%AD%A6%E7%BB%98%E5%9B%BE/"/>
    <id>http://hibiscidai.com/2025/03/06/Python%E7%A7%91%E5%AD%A6%E7%BB%98%E5%9B%BE/</id>
    <published>2025-03-06T10:35:32.666Z</published>
    <updated>2025-02-28T13:24:30.000Z</updated>
    
    <content type="html"><![CDATA[<img src="/2025/03/06/Python%E7%A7%91%E5%AD%A6%E7%BB%98%E5%9B%BE/Python%E7%A7%91%E5%AD%A6%E7%BB%98%E5%9B%BE.png" class="" title="Python科学绘图"><p>Python科学绘图</p><span id="more"></span><h1 id="Python科学绘图"><a href="#Python科学绘图" class="headerlink" title="Python科学绘图"></a>Python科学绘图</h1><p>常见python主流绘图工具库</p><p><a href="https://matplotlib.org/stable/tutorials/index">matplotlib</a></p><p><a href="https://seaborn.pydata.org/index.html">seraborn</a></p><p><a href="https://proplot.readthedocs.io/en/latest/">proplot</a></p><p><a href="https://github.com/garrettj403/SciencePlots">SciencePlots</a></p><h1 id="matplotlib"><a href="#matplotlib" class="headerlink" title="matplotlib"></a>matplotlib</h1><h2 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> matplotlib.ticker <span class="keyword">as</span> ticker</span><br><span class="line"><span class="keyword">from</span> matplotlib.ticker <span class="keyword">import</span> ScalarFormatter</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br></pre></td></tr></table></figure><h2 id="散点图"><a href="#散点图" class="headerlink" title="散点图"></a>散点图</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 输入文件位置，红点坐标，输出图</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">sandian1</span>(<span class="params">file_path: <span class="built_in">str</span>,</span></span><br><span class="line"><span class="params">             red_point_por: <span class="built_in">float</span>,</span></span><br><span class="line"><span class="params">             red_point_K: <span class="built_in">float</span>,</span></span><br><span class="line"><span class="params">             red_point_name: <span class="built_in">str</span>,</span></span><br><span class="line"><span class="params">             </span>):</span><br><span class="line">    df = pd.read_csv(file_path, header=<span class="literal">None</span>, names=[<span class="string">&#x27;img_name&#x27;</span>, <span class="string">&#x27;por&#x27;</span>, <span class="string">&#x27;K&#x27;</span>])</span><br><span class="line"></span><br><span class="line">    df[<span class="string">&#x27;por&#x27;</span>] = pd.to_numeric(df[<span class="string">&#x27;por&#x27;</span>], errors=<span class="string">&#x27;coerce&#x27;</span>)</span><br><span class="line">    df[<span class="string">&#x27;por&#x27;</span>] = df[<span class="string">&#x27;por&#x27;</span>] * <span class="number">100</span></span><br><span class="line">    df[<span class="string">&#x27;K&#x27;</span>] = pd.to_numeric(df[<span class="string">&#x27;K&#x27;</span>], errors=<span class="string">&#x27;coerce&#x27;</span>)</span><br><span class="line">    por = df[<span class="string">&#x27;por&#x27;</span>]</span><br><span class="line">    K = df[<span class="string">&#x27;K&#x27;</span>]</span><br><span class="line">    por2 = red_point_por</span><br><span class="line">    K2 = red_point_K</span><br><span class="line">    name2 = red_point_name</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 创建图形和坐标轴 1in=2.54 figsize=(宽度, 高度) 10 , 7</span></span><br><span class="line">    fig, ax = plt.subplots(figsize=(<span class="number">3.9</span>, <span class="number">2.7</span>), dpi=<span class="number">300</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 设置全局字体为 Times New Roman</span></span><br><span class="line">    plt.rcParams[<span class="string">&#x27;font.family&#x27;</span>] = <span class="string">&#x27;serif&#x27;</span></span><br><span class="line">    plt.rcParams[<span class="string">&#x27;font.serif&#x27;</span>] = [<span class="string">&#x27;Times New Roman&#x27;</span>] + plt.rcParams[<span class="string">&#x27;font.serif&#x27;</span>]</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 绘制数据组1（黑色方块）</span></span><br><span class="line">    ax.scatter(por, K, marker=<span class="string">&#x27;s&#x27;</span>, color=<span class="string">&#x27;black&#x27;</span>, facecolors=<span class="string">&#x27;none&#x27;</span>, s=<span class="number">50</span>, label=img_name)</span><br><span class="line">    <span class="comment"># 绘制数据组2（红色圆点）</span></span><br><span class="line">    ax.scatter(por2, K2, marker=<span class="string">&#x27;o&#x27;</span>, color=<span class="string">&#x27;red&#x27;</span>, s=<span class="number">80</span>, label=name2)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 设置为对数y轴</span></span><br><span class="line">    ax.set_yscale(<span class="string">&#x27;log&#x27;</span>)</span><br><span class="line">    <span class="comment"># 取消 y 轴的科学计数法</span></span><br><span class="line">    formatter = ScalarFormatter(useOffset=<span class="literal">False</span>, useMathText=<span class="literal">False</span>)</span><br><span class="line">    ax.yaxis.set_major_formatter(formatter)</span><br><span class="line">    <span class="comment"># 设置坐标轴范围</span></span><br><span class="line">    ax.set_xlim(<span class="number">10</span>, <span class="number">30</span>)</span><br><span class="line">    ax.set_ylim(<span class="number">1</span>, <span class="number">1000</span>)</span><br><span class="line">    <span class="comment"># 设置主刻度和次刻度的位置和格式</span></span><br><span class="line">    ax.xaxis.set_major_locator(ticker.MultipleLocator(<span class="number">5</span>))  <span class="comment"># 主刻度间隔为5</span></span><br><span class="line">    <span class="comment">#ax.xaxis.set_minor_locator(ticker.MultipleLocator(1))  # 次刻度间隔为1</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 分别设置 x 轴和 y 轴的刻度标签大小</span></span><br><span class="line">    ax.tick_params(axis=<span class="string">&#x27;x&#x27;</span>, labelsize=<span class="number">10</span>)  <span class="comment"># 设置 x 轴刻度标签大小</span></span><br><span class="line">    ax.tick_params(axis=<span class="string">&#x27;y&#x27;</span>, labelsize=<span class="number">10</span>)  <span class="comment"># 设置 y 轴刻度标签大小</span></span><br><span class="line">    <span class="comment"># 获取当前刻度标签</span></span><br><span class="line">    x_labels = ax.get_xticklabels()</span><br><span class="line">    y_labels = ax.get_yticklabels()</span><br><span class="line">    <span class="comment"># 设置字体属性</span></span><br><span class="line">    <span class="keyword">for</span> label <span class="keyword">in</span> x_labels:</span><br><span class="line">        label.set_fontname(<span class="string">&#x27;Times New Roman&#x27;</span>)  <span class="comment"># 设置字体</span></span><br><span class="line">        label.set_fontweight(<span class="string">&#x27;bold&#x27;</span>)           <span class="comment"># 设置粗体</span></span><br><span class="line">    <span class="keyword">for</span> label <span class="keyword">in</span> y_labels:</span><br><span class="line">        label.set_fontname(<span class="string">&#x27;Times New Roman&#x27;</span>)            <span class="comment"># 设置字体</span></span><br><span class="line">        label.set_fontweight(<span class="string">&#x27;bold&#x27;</span>)           <span class="comment"># 设置粗体</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 设置刻度长度和宽度方向</span></span><br><span class="line">    ax.tick_params(axis=<span class="string">&#x27;x&#x27;</span>, which=<span class="string">&#x27;major&#x27;</span>, length=<span class="number">4</span>, width=<span class="number">1</span>, direction=<span class="string">&#x27;in&#x27;</span>)</span><br><span class="line">    ax.tick_params(axis=<span class="string">&#x27;x&#x27;</span>, which=<span class="string">&#x27;minor&#x27;</span>, length=<span class="number">3</span>, width=<span class="number">1</span>, direction=<span class="string">&#x27;in&#x27;</span>)</span><br><span class="line">    ax.tick_params(axis=<span class="string">&#x27;y&#x27;</span>, which=<span class="string">&#x27;major&#x27;</span>, length=<span class="number">4</span>, width=<span class="number">1</span>, direction=<span class="string">&#x27;in&#x27;</span>)</span><br><span class="line">    ax.tick_params(axis=<span class="string">&#x27;y&#x27;</span>, which=<span class="string">&#x27;minor&#x27;</span>, length=<span class="number">3</span>, width=<span class="number">1</span>, direction=<span class="string">&#x27;in&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 设置坐标轴线条样式</span></span><br><span class="line">    ax.spines[<span class="string">&#x27;bottom&#x27;</span>].set_linewidth(<span class="number">1</span>)  <span class="comment"># 底部轴线宽度</span></span><br><span class="line">    ax.spines[<span class="string">&#x27;left&#x27;</span>].set_linewidth(<span class="number">1</span>)    <span class="comment"># 左侧轴线宽度</span></span><br><span class="line">    ax.spines[<span class="string">&#x27;top&#x27;</span>].set_linewidth(<span class="number">1</span>)     <span class="comment"># 顶部轴线宽度</span></span><br><span class="line">    ax.spines[<span class="string">&#x27;right&#x27;</span>].set_linewidth(<span class="number">1</span>)   <span class="comment"># 右侧轴线宽度</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 坐标轴标题</span></span><br><span class="line">    ax.set_xlabel(<span class="string">&#x27;POR(%)&#x27;</span>, fontsize=<span class="number">11</span>, fontname=<span class="string">&#x27;Times New Roman&#x27;</span>, fontweight=<span class="string">&#x27;bold&#x27;</span>)</span><br><span class="line">    ax.set_ylabel(<span class="string">&#x27;Permeability(mD)&#x27;</span>, fontsize=<span class="number">11</span>, fontname=<span class="string">&#x27;Times New Roman&#x27;</span>, fontweight=<span class="string">&#x27;bold&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 添加图例</span></span><br><span class="line">    legend = ax.legend(fontsize=<span class="number">8</span>)</span><br><span class="line">    <span class="comment"># 去掉框线和背景</span></span><br><span class="line">    legend.get_frame().set_linewidth(<span class="number">0.0</span>)  <span class="comment"># 设置框线宽度为0</span></span><br><span class="line">    legend.get_frame().set_facecolor(<span class="string">&#x27;none&#x27;</span>)  <span class="comment"># 设置背景为透明</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 添加网格</span></span><br><span class="line">    ax.grid(<span class="literal">True</span>, which=<span class="string">&#x27;both&#x27;</span>, linestyle=<span class="string">&#x27;-&#x27;</span>, linewidth=<span class="number">0.5</span>, alpha=<span class="number">0.5</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 调整布局</span></span><br><span class="line">    plt.tight_layout()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> plt</span><br></pre></td></tr></table></figure><img src="/2025/03/06/Python%E7%A7%91%E5%AD%A6%E7%BB%98%E5%9B%BE/%E6%95%A3%E7%82%B9%E5%9B%BE-1.png" class="" title="散点图-1"><h2 id="箱线图"><a href="#箱线图" class="headerlink" title="箱线图"></a>箱线图</h2><p><a href="https://matplotlib.org/stable/gallery/statistics/boxplot_demo.html#sphx-glr-gallery-statistics-boxplot-demo-py">Boxplots</a></p><p><a href="https://matplotlib.org/stable/gallery/statistics/boxplot_color.html#sphx-glr-gallery-statistics-boxplot-color-py">Box plots with custom fill colors</a></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">xiangxiantu_one_por</span>(<span class="params">file_path: <span class="built_in">str</span>,</span></span><br><span class="line"><span class="params">                        img_name:  <span class="built_in">str</span>,</span></span><br><span class="line"><span class="params">                        key_point_value: <span class="built_in">float</span></span></span><br><span class="line"><span class="params">                        </span>):</span><br><span class="line">    df = pd.read_csv(file_path, header=<span class="literal">None</span>, names=[<span class="string">&#x27;img_name&#x27;</span>, <span class="string">&#x27;por&#x27;</span>, <span class="string">&#x27;K&#x27;</span>])</span><br><span class="line"></span><br><span class="line">    df[<span class="string">&#x27;por&#x27;</span>] = pd.to_numeric(df[<span class="string">&#x27;por&#x27;</span>], errors=<span class="string">&#x27;coerce&#x27;</span>)</span><br><span class="line">    df[<span class="string">&#x27;por&#x27;</span>] = df[<span class="string">&#x27;por&#x27;</span>] * <span class="number">100</span></span><br><span class="line">    por = df[<span class="string">&#x27;por&#x27;</span>].dropna()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 创建图形和坐标轴 1in=2.54 figsize=(宽度, 高度) 5 , 7</span></span><br><span class="line">    fig, ax = plt.subplots(figsize=(<span class="number">3</span>, <span class="number">2.7</span>), dpi=<span class="number">300</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 设置全局字体为 Times New Roman</span></span><br><span class="line">    plt.rcParams[<span class="string">&#x27;font.family&#x27;</span>] = <span class="string">&#x27;serif&#x27;</span></span><br><span class="line">    plt.rcParams[<span class="string">&#x27;font.serif&#x27;</span>] = [<span class="string">&#x27;Times New Roman&#x27;</span>] + plt.rcParams[<span class="string">&#x27;font.serif&#x27;</span>]</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 基础框体</span></span><br><span class="line">    data = [por]</span><br><span class="line">    labels = [img_name]</span><br><span class="line">    boxplot = ax.boxplot(data, notch=<span class="literal">True</span>, patch_artist=<span class="literal">True</span>, tick_labels=labels)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># y轴范围</span></span><br><span class="line">    ax.set_ylim(<span class="number">10</span>, <span class="number">30</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 设置箱体颜色</span></span><br><span class="line">    colors = [<span class="string">&#x27;lightgreen&#x27;</span>]</span><br><span class="line">    <span class="keyword">for</span> box, color <span class="keyword">in</span> <span class="built_in">zip</span>(boxplot[<span class="string">&#x27;boxes&#x27;</span>], colors):</span><br><span class="line">        box.<span class="built_in">set</span>(facecolor=color)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 在第一组数据上标记点</span></span><br><span class="line">    ax.scatter(<span class="number">1</span>, key_point_value, color=<span class="string">&#x27;red&#x27;</span>, s=<span class="number">50</span>, zorder=<span class="number">5</span>, marker=<span class="string">&#x27;o&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 添加网格</span></span><br><span class="line">    ax.grid(<span class="literal">True</span>, which=<span class="string">&#x27;both&#x27;</span>, linestyle=<span class="string">&#x27;-&#x27;</span>, linewidth=<span class="number">0.5</span>, alpha=<span class="number">0.5</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 设置主刻度和次刻度的位置和格式</span></span><br><span class="line">    ax.yaxis.set_major_locator(ticker.MultipleLocator(<span class="number">5</span>))  <span class="comment"># 主刻度间隔为5</span></span><br><span class="line">    <span class="comment"># ax.xaxis.set_minor_locator(ticker.MultipleLocator(1))  # 次刻度间隔为1</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 分别设置 x 轴和 y 轴的刻度标签大小</span></span><br><span class="line">    ax.tick_params(axis=<span class="string">&#x27;x&#x27;</span>, labelsize=<span class="number">7</span>)  <span class="comment"># 设置 x 轴刻度标签大小</span></span><br><span class="line">    ax.tick_params(axis=<span class="string">&#x27;y&#x27;</span>, labelsize=<span class="number">8</span>)  <span class="comment"># 设置 y 轴刻度标签大小</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 设置刻度长度和宽度方向</span></span><br><span class="line">    ax.tick_params(axis=<span class="string">&#x27;x&#x27;</span>, which=<span class="string">&#x27;major&#x27;</span>, length=<span class="number">4</span>, width=<span class="number">1</span>, direction=<span class="string">&#x27;in&#x27;</span>)</span><br><span class="line">    ax.tick_params(axis=<span class="string">&#x27;x&#x27;</span>, which=<span class="string">&#x27;minor&#x27;</span>, length=<span class="number">3</span>, width=<span class="number">1</span>, direction=<span class="string">&#x27;in&#x27;</span>)</span><br><span class="line">    ax.tick_params(axis=<span class="string">&#x27;y&#x27;</span>, which=<span class="string">&#x27;major&#x27;</span>, length=<span class="number">4</span>, width=<span class="number">1</span>, direction=<span class="string">&#x27;in&#x27;</span>)</span><br><span class="line">    ax.tick_params(axis=<span class="string">&#x27;y&#x27;</span>, which=<span class="string">&#x27;minor&#x27;</span>, length=<span class="number">3</span>, width=<span class="number">1</span>, direction=<span class="string">&#x27;in&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 设置坐标轴线条样式</span></span><br><span class="line">    ax.spines[<span class="string">&#x27;bottom&#x27;</span>].set_linewidth(<span class="number">1</span>)  <span class="comment"># 底部轴线宽度</span></span><br><span class="line">    ax.spines[<span class="string">&#x27;left&#x27;</span>].set_linewidth(<span class="number">1</span>)    <span class="comment"># 左侧轴线宽度</span></span><br><span class="line">    ax.spines[<span class="string">&#x27;top&#x27;</span>].set_linewidth(<span class="number">1</span>)     <span class="comment"># 顶部轴线宽度</span></span><br><span class="line">    ax.spines[<span class="string">&#x27;right&#x27;</span>].set_linewidth(<span class="number">1</span>)   <span class="comment"># 右侧轴线宽度</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 坐标轴标题</span></span><br><span class="line">    ax.set_ylabel(<span class="string">&#x27;POR(%)&#x27;</span>, fontsize=<span class="number">10</span>, fontname=<span class="string">&#x27;Times New Roman&#x27;</span>, fontweight=<span class="string">&#x27;bold&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    plt.tight_layout()</span><br><span class="line">    <span class="keyword">return</span> plt</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">xiangxiantu_one_K</span>(<span class="params">file_path:    <span class="built_in">str</span>,</span></span><br><span class="line"><span class="params">                        img_name:   <span class="built_in">str</span>,</span></span><br><span class="line"><span class="params">                        key_point_value:    <span class="built_in">float</span></span></span><br><span class="line"><span class="params">                        </span>):</span><br><span class="line">    df = pd.read_csv(file_path, header=<span class="literal">None</span>, names=[<span class="string">&#x27;img_name&#x27;</span>, <span class="string">&#x27;por&#x27;</span>, <span class="string">&#x27;K&#x27;</span>])</span><br><span class="line">    df[<span class="string">&#x27;K&#x27;</span>] = pd.to_numeric(df[<span class="string">&#x27;K&#x27;</span>], errors=<span class="string">&#x27;coerce&#x27;</span>)</span><br><span class="line">    K = df[<span class="string">&#x27;K&#x27;</span>].dropna()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 创建图形和坐标轴 1in=2.54 figsize=(宽度, 高度) 5 , 7</span></span><br><span class="line">    fig, ax = plt.subplots(figsize=(<span class="number">3</span>, <span class="number">2.7</span>), dpi=<span class="number">300</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 设置全局字体为 Times New Roman</span></span><br><span class="line">    plt.rcParams[<span class="string">&#x27;font.family&#x27;</span>] = <span class="string">&#x27;serif&#x27;</span></span><br><span class="line">    plt.rcParams[<span class="string">&#x27;font.serif&#x27;</span>] = [<span class="string">&#x27;Times New Roman&#x27;</span>] + plt.rcParams[<span class="string">&#x27;font.serif&#x27;</span>]</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 基础框体</span></span><br><span class="line">    data = [K]</span><br><span class="line">    labels = [img_name]</span><br><span class="line">    boxplot = ax.boxplot(data, notch=<span class="literal">True</span>, patch_artist=<span class="literal">True</span>, tick_labels=labels)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 设置箱体颜色</span></span><br><span class="line">    colors = [<span class="string">&#x27;lightgreen&#x27;</span>]</span><br><span class="line">    <span class="keyword">for</span> box, color <span class="keyword">in</span> <span class="built_in">zip</span>(boxplot[<span class="string">&#x27;boxes&#x27;</span>], colors):</span><br><span class="line">        box.<span class="built_in">set</span>(facecolor=color)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 在第一组数据上标记点</span></span><br><span class="line">    ax.scatter(<span class="number">1</span>, key_point_value, color=<span class="string">&#x27;red&#x27;</span>, s=<span class="number">50</span>, zorder=<span class="number">5</span>, marker=<span class="string">&#x27;o&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 添加网格</span></span><br><span class="line">    ax.grid(<span class="literal">True</span>, which=<span class="string">&#x27;both&#x27;</span>, linestyle=<span class="string">&#x27;-&#x27;</span>, linewidth=<span class="number">0.5</span>, alpha=<span class="number">0.5</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 设置为对数y轴</span></span><br><span class="line">    ax.set_yscale(<span class="string">&#x27;log&#x27;</span>)</span><br><span class="line">    <span class="comment"># 取消 y 轴的科学计数法</span></span><br><span class="line">    formatter = ScalarFormatter(useOffset=<span class="literal">False</span>, useMathText=<span class="literal">False</span>)</span><br><span class="line">    ax.yaxis.set_major_formatter(formatter)</span><br><span class="line">    <span class="comment"># 设置坐标轴范围</span></span><br><span class="line">    ax.set_ylim(<span class="number">1</span>, <span class="number">1000</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 分别设置 x 轴和 y 轴的刻度标签大小</span></span><br><span class="line">    ax.tick_params(axis=<span class="string">&#x27;x&#x27;</span>, labelsize=<span class="number">7</span>)  <span class="comment"># 设置 x 轴刻度标签大小</span></span><br><span class="line">    ax.tick_params(axis=<span class="string">&#x27;y&#x27;</span>, labelsize=<span class="number">8</span>)  <span class="comment"># 设置 y 轴刻度标签大小</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 设置刻度长度和宽度方向</span></span><br><span class="line">    ax.tick_params(axis=<span class="string">&#x27;x&#x27;</span>, which=<span class="string">&#x27;major&#x27;</span>, length=<span class="number">4</span>, width=<span class="number">1</span>, direction=<span class="string">&#x27;in&#x27;</span>)</span><br><span class="line">    ax.tick_params(axis=<span class="string">&#x27;x&#x27;</span>, which=<span class="string">&#x27;minor&#x27;</span>, length=<span class="number">3</span>, width=<span class="number">1</span>, direction=<span class="string">&#x27;in&#x27;</span>)</span><br><span class="line">    ax.tick_params(axis=<span class="string">&#x27;y&#x27;</span>, which=<span class="string">&#x27;major&#x27;</span>, length=<span class="number">4</span>, width=<span class="number">1</span>, direction=<span class="string">&#x27;in&#x27;</span>)</span><br><span class="line">    ax.tick_params(axis=<span class="string">&#x27;y&#x27;</span>, which=<span class="string">&#x27;minor&#x27;</span>, length=<span class="number">3</span>, width=<span class="number">1</span>, direction=<span class="string">&#x27;in&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 设置坐标轴线条样式</span></span><br><span class="line">    ax.spines[<span class="string">&#x27;bottom&#x27;</span>].set_linewidth(<span class="number">1</span>)  <span class="comment"># 底部轴线宽度</span></span><br><span class="line">    ax.spines[<span class="string">&#x27;left&#x27;</span>].set_linewidth(<span class="number">1</span>)    <span class="comment"># 左侧轴线宽度</span></span><br><span class="line">    ax.spines[<span class="string">&#x27;top&#x27;</span>].set_linewidth(<span class="number">1</span>)     <span class="comment"># 顶部轴线宽度</span></span><br><span class="line">    ax.spines[<span class="string">&#x27;right&#x27;</span>].set_linewidth(<span class="number">1</span>)   <span class="comment"># 右侧轴线宽度</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 坐标轴标题</span></span><br><span class="line">    ax.set_ylabel(<span class="string">&#x27;Permeability(mD)&#x27;</span>, fontsize=<span class="number">10</span>, fontname=<span class="string">&#x27;Times New Roman&#x27;</span>, fontweight=<span class="string">&#x27;bold&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    plt.tight_layout()</span><br><span class="line">    <span class="keyword">return</span> plt</span><br></pre></td></tr></table></figure><img src="/2025/03/06/Python%E7%A7%91%E5%AD%A6%E7%BB%98%E5%9B%BE/%E7%AE%B1%E7%BA%BF%E5%9B%BE-1.png" class="" title="箱线图-1"><img src="/2025/03/06/Python%E7%A7%91%E5%AD%A6%E7%BB%98%E5%9B%BE/%E7%AE%B1%E7%BA%BF%E5%9B%BE-2.png" class="" title="箱线图-2"><h2 id="小提琴图"><a href="#小提琴图" class="headerlink" title="小提琴图"></a>小提琴图</h2><p><a href="https://matplotlib.org/stable/gallery/statistics/boxplot_vs_violin.html#sphx-glr-gallery-statistics-boxplot-vs-violin-py">Box plot vs. violin plot comparison</a></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">xiaotiqintu_one_por</span>(<span class="params">file_path: <span class="built_in">str</span>,</span></span><br><span class="line"><span class="params">                        img_name:  <span class="built_in">str</span>,</span></span><br><span class="line"><span class="params">                        key_point_value: <span class="built_in">float</span></span></span><br><span class="line"><span class="params">                        </span>):</span><br><span class="line">    df = pd.read_csv(file_path, header=<span class="literal">None</span>, names=[<span class="string">&#x27;img_name&#x27;</span>, <span class="string">&#x27;por&#x27;</span>, <span class="string">&#x27;K&#x27;</span>])</span><br><span class="line"></span><br><span class="line">    df[<span class="string">&#x27;por&#x27;</span>] = pd.to_numeric(df[<span class="string">&#x27;por&#x27;</span>], errors=<span class="string">&#x27;coerce&#x27;</span>)</span><br><span class="line">    df[<span class="string">&#x27;por&#x27;</span>] = df[<span class="string">&#x27;por&#x27;</span>] * <span class="number">100</span></span><br><span class="line">    por = df[<span class="string">&#x27;por&#x27;</span>].dropna()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 创建图形和坐标轴 1in=2.54 figsize=(宽度, 高度) 5 , 7</span></span><br><span class="line">    fig, ax = plt.subplots(figsize=(<span class="number">3</span>, <span class="number">2.7</span>), dpi=<span class="number">300</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 设置全局字体为 Times New Roman</span></span><br><span class="line">    plt.rcParams[<span class="string">&#x27;font.family&#x27;</span>] = <span class="string">&#x27;serif&#x27;</span></span><br><span class="line">    plt.rcParams[<span class="string">&#x27;font.serif&#x27;</span>] = [<span class="string">&#x27;Times New Roman&#x27;</span>] + plt.rcParams[<span class="string">&#x27;font.serif&#x27;</span>]</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 基础框体</span></span><br><span class="line">    data = [por]</span><br><span class="line">    labels = [img_name]</span><br><span class="line">    boxplot = ax.violinplot(data, showmeans=<span class="literal">False</span>, showmedians=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 设置填充区域颜色</span></span><br><span class="line">    <span class="keyword">for</span> pc <span class="keyword">in</span> boxplot[<span class="string">&#x27;bodies&#x27;</span>]:</span><br><span class="line">        pc.set_facecolor(<span class="string">&#x27;lightblue&#x27;</span>)  <span class="comment"># 设置填充颜色</span></span><br><span class="line">        pc.set_edgecolor(<span class="string">&#x27;lightblue&#x27;</span>)  <span class="comment"># 设置边缘线颜色</span></span><br><span class="line">        pc.set_alpha(<span class="number">0.5</span>)  <span class="comment"># 设置透明度</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 设置其他线条颜色</span></span><br><span class="line">    boxplot[<span class="string">&#x27;cmedians&#x27;</span>].set_color(<span class="string">&#x27;black&#x27;</span>)  <span class="comment"># 设置中位数线颜色</span></span><br><span class="line">    boxplot[<span class="string">&#x27;cmins&#x27;</span>].set_color(<span class="string">&#x27;black&#x27;</span>)  <span class="comment"># 设置小提琴下届线颜色</span></span><br><span class="line">    boxplot[<span class="string">&#x27;cmaxes&#x27;</span>].set_color(<span class="string">&#x27;black&#x27;</span>)  <span class="comment"># 设置小提琴上届线颜色</span></span><br><span class="line">    boxplot[<span class="string">&#x27;cbars&#x27;</span>].set_color(<span class="string">&#x27;black&#x27;</span>)  <span class="comment"># 设置小提琴竖线颜色</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># y轴范围</span></span><br><span class="line">    ax.set_xlim(<span class="number">0</span>, <span class="number">2</span>)</span><br><span class="line">    ax.set_ylim(<span class="number">10</span>, <span class="number">30</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># X轴标记</span></span><br><span class="line">    ax.set_xticks([<span class="number">1</span>])</span><br><span class="line">    ax.set_xticklabels(labels)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 在第一组数据上标记点</span></span><br><span class="line">    ax.scatter(<span class="number">1</span>, key_point_value, color=<span class="string">&#x27;red&#x27;</span>, s=<span class="number">50</span>, zorder=<span class="number">5</span>, marker=<span class="string">&#x27;o&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 添加网格</span></span><br><span class="line">    ax.grid(<span class="literal">True</span>, which=<span class="string">&#x27;both&#x27;</span>, linestyle=<span class="string">&#x27;-&#x27;</span>, linewidth=<span class="number">0.5</span>, alpha=<span class="number">0.5</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 设置主刻度和次刻度的位置和格式</span></span><br><span class="line">    ax.yaxis.set_major_locator(ticker.MultipleLocator(<span class="number">5</span>))  <span class="comment"># 主刻度间隔为5</span></span><br><span class="line">    ax.xaxis.set_minor_locator(ticker.MultipleLocator(<span class="number">1</span>))  <span class="comment"># 次刻度间隔为1</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 分别设置 x 轴和 y 轴的刻度标签大小</span></span><br><span class="line">    ax.tick_params(axis=<span class="string">&#x27;x&#x27;</span>, labelsize=<span class="number">7</span>)  <span class="comment"># 设置 x 轴刻度标签大小</span></span><br><span class="line">    ax.tick_params(axis=<span class="string">&#x27;y&#x27;</span>, labelsize=<span class="number">8</span>)  <span class="comment"># 设置 y 轴刻度标签大小</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 设置刻度长度和宽度方向</span></span><br><span class="line">    ax.tick_params(axis=<span class="string">&#x27;x&#x27;</span>, which=<span class="string">&#x27;major&#x27;</span>, length=<span class="number">4</span>, width=<span class="number">1</span>, direction=<span class="string">&#x27;in&#x27;</span>)</span><br><span class="line">    ax.tick_params(axis=<span class="string">&#x27;x&#x27;</span>, which=<span class="string">&#x27;minor&#x27;</span>, length=<span class="number">3</span>, width=<span class="number">1</span>, direction=<span class="string">&#x27;in&#x27;</span>)</span><br><span class="line">    ax.tick_params(axis=<span class="string">&#x27;y&#x27;</span>, which=<span class="string">&#x27;major&#x27;</span>, length=<span class="number">4</span>, width=<span class="number">1</span>, direction=<span class="string">&#x27;in&#x27;</span>)</span><br><span class="line">    ax.tick_params(axis=<span class="string">&#x27;y&#x27;</span>, which=<span class="string">&#x27;minor&#x27;</span>, length=<span class="number">3</span>, width=<span class="number">1</span>, direction=<span class="string">&#x27;in&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 设置坐标轴线条样式</span></span><br><span class="line">    ax.spines[<span class="string">&#x27;bottom&#x27;</span>].set_linewidth(<span class="number">1</span>)  <span class="comment"># 底部轴线宽度</span></span><br><span class="line">    ax.spines[<span class="string">&#x27;left&#x27;</span>].set_linewidth(<span class="number">1</span>)    <span class="comment"># 左侧轴线宽度</span></span><br><span class="line">    ax.spines[<span class="string">&#x27;top&#x27;</span>].set_linewidth(<span class="number">1</span>)     <span class="comment"># 顶部轴线宽度</span></span><br><span class="line">    ax.spines[<span class="string">&#x27;right&#x27;</span>].set_linewidth(<span class="number">1</span>)   <span class="comment"># 右侧轴线宽度</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 坐标轴标题</span></span><br><span class="line">    ax.set_ylabel(<span class="string">&#x27;POR(%)&#x27;</span>, fontsize=<span class="number">10</span>, fontname=<span class="string">&#x27;Times New Roman&#x27;</span>, fontweight=<span class="string">&#x27;bold&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    plt.tight_layout()</span><br><span class="line">    <span class="keyword">return</span> plt</span><br><span class="line"></span><br><span class="line"><span class="comment"># 小提琴图</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">xiaotiqintu_one_K</span>(<span class="params">file_path: <span class="built_in">str</span>,</span></span><br><span class="line"><span class="params">                        img_name:  <span class="built_in">str</span>,</span></span><br><span class="line"><span class="params">                        key_point_value: <span class="built_in">float</span></span></span><br><span class="line"><span class="params">                        </span>):</span><br><span class="line">    df = pd.read_csv(file_path, header=<span class="literal">None</span>, names=[<span class="string">&#x27;img_name&#x27;</span>, <span class="string">&#x27;por&#x27;</span>, <span class="string">&#x27;K&#x27;</span>])</span><br><span class="line">    df[<span class="string">&#x27;K&#x27;</span>] = pd.to_numeric(df[<span class="string">&#x27;K&#x27;</span>], errors=<span class="string">&#x27;coerce&#x27;</span>)</span><br><span class="line">    K = df[<span class="string">&#x27;K&#x27;</span>].dropna()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 创建图形和坐标轴 1in=2.54 figsize=(宽度, 高度) 5 , 7</span></span><br><span class="line">    fig, ax = plt.subplots(figsize=(<span class="number">3</span>, <span class="number">2.7</span>), dpi=<span class="number">300</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 设置全局字体为 Times New Roman</span></span><br><span class="line">    plt.rcParams[<span class="string">&#x27;font.family&#x27;</span>] = <span class="string">&#x27;serif&#x27;</span></span><br><span class="line">    plt.rcParams[<span class="string">&#x27;font.serif&#x27;</span>] = [<span class="string">&#x27;Times New Roman&#x27;</span>] + plt.rcParams[<span class="string">&#x27;font.serif&#x27;</span>]</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 基础框体</span></span><br><span class="line">    data = [K]</span><br><span class="line">    labels = [img_name]</span><br><span class="line">    boxplot = ax.violinplot(data, showmeans=<span class="literal">False</span>, showmedians=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 设置填充区域颜色</span></span><br><span class="line">    <span class="keyword">for</span> pc <span class="keyword">in</span> boxplot[<span class="string">&#x27;bodies&#x27;</span>]:</span><br><span class="line">        pc.set_facecolor(<span class="string">&#x27;lightgreen&#x27;</span>)  <span class="comment"># 设置填充颜色</span></span><br><span class="line">        pc.set_edgecolor(<span class="string">&#x27;lightgreen&#x27;</span>)  <span class="comment"># 设置边缘线颜色</span></span><br><span class="line">        pc.set_alpha(<span class="number">0.5</span>)  <span class="comment"># 设置透明度</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 设置其他线条颜色</span></span><br><span class="line">    boxplot[<span class="string">&#x27;cmedians&#x27;</span>].set_color(<span class="string">&#x27;black&#x27;</span>)  <span class="comment"># 设置中位数线颜色</span></span><br><span class="line">    boxplot[<span class="string">&#x27;cmins&#x27;</span>].set_color(<span class="string">&#x27;black&#x27;</span>)  <span class="comment"># 设置小提琴下届线颜色</span></span><br><span class="line">    boxplot[<span class="string">&#x27;cmaxes&#x27;</span>].set_color(<span class="string">&#x27;black&#x27;</span>)  <span class="comment"># 设置小提琴上届线颜色</span></span><br><span class="line">    boxplot[<span class="string">&#x27;cbars&#x27;</span>].set_color(<span class="string">&#x27;black&#x27;</span>)  <span class="comment"># 设置小提琴竖线颜色</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># X轴标记</span></span><br><span class="line">    ax.set_xlim(<span class="number">0</span>, <span class="number">2</span>)</span><br><span class="line">    ax.set_xticks([<span class="number">1</span>])</span><br><span class="line">    ax.set_xticklabels(labels)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 设置为对数y轴</span></span><br><span class="line">    ax.set_yscale(<span class="string">&#x27;log&#x27;</span>)</span><br><span class="line">    <span class="comment"># 取消 y 轴的科学计数法</span></span><br><span class="line">    formatter = ScalarFormatter(useOffset=<span class="literal">False</span>, useMathText=<span class="literal">False</span>)</span><br><span class="line">    ax.yaxis.set_major_formatter(formatter)</span><br><span class="line">    <span class="comment"># 设置坐标轴范围</span></span><br><span class="line">    ax.set_ylim(<span class="number">1</span>, <span class="number">1000</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 在第一组数据上标记点</span></span><br><span class="line">    ax.scatter(<span class="number">1</span>, key_point_value, color=<span class="string">&#x27;red&#x27;</span>, s=<span class="number">50</span>, zorder=<span class="number">5</span>, marker=<span class="string">&#x27;o&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 添加网格</span></span><br><span class="line">    ax.grid(<span class="literal">True</span>, which=<span class="string">&#x27;both&#x27;</span>, linestyle=<span class="string">&#x27;-&#x27;</span>, linewidth=<span class="number">0.5</span>, alpha=<span class="number">0.5</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 设置主刻度和次刻度的位置和格式</span></span><br><span class="line">    <span class="comment">#ax.yaxis.set_major_locator(ticker.MultipleLocator(5))  # 主刻度间隔为5</span></span><br><span class="line">    ax.xaxis.set_minor_locator(ticker.MultipleLocator(<span class="number">1</span>))  <span class="comment"># 次刻度间隔为1</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 分别设置 x 轴和 y 轴的刻度标签大小</span></span><br><span class="line">    ax.tick_params(axis=<span class="string">&#x27;x&#x27;</span>, labelsize=<span class="number">7</span>)  <span class="comment"># 设置 x 轴刻度标签大小</span></span><br><span class="line">    ax.tick_params(axis=<span class="string">&#x27;y&#x27;</span>, labelsize=<span class="number">8</span>)  <span class="comment"># 设置 y 轴刻度标签大小</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 设置刻度长度和宽度方向</span></span><br><span class="line">    ax.tick_params(axis=<span class="string">&#x27;x&#x27;</span>, which=<span class="string">&#x27;major&#x27;</span>, length=<span class="number">4</span>, width=<span class="number">1</span>, direction=<span class="string">&#x27;in&#x27;</span>)</span><br><span class="line">    ax.tick_params(axis=<span class="string">&#x27;x&#x27;</span>, which=<span class="string">&#x27;minor&#x27;</span>, length=<span class="number">3</span>, width=<span class="number">1</span>, direction=<span class="string">&#x27;in&#x27;</span>)</span><br><span class="line">    ax.tick_params(axis=<span class="string">&#x27;y&#x27;</span>, which=<span class="string">&#x27;major&#x27;</span>, length=<span class="number">4</span>, width=<span class="number">1</span>, direction=<span class="string">&#x27;in&#x27;</span>)</span><br><span class="line">    ax.tick_params(axis=<span class="string">&#x27;y&#x27;</span>, which=<span class="string">&#x27;minor&#x27;</span>, length=<span class="number">3</span>, width=<span class="number">1</span>, direction=<span class="string">&#x27;in&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 设置坐标轴线条样式</span></span><br><span class="line">    ax.spines[<span class="string">&#x27;bottom&#x27;</span>].set_linewidth(<span class="number">1</span>)  <span class="comment"># 底部轴线宽度</span></span><br><span class="line">    ax.spines[<span class="string">&#x27;left&#x27;</span>].set_linewidth(<span class="number">1</span>)    <span class="comment"># 左侧轴线宽度</span></span><br><span class="line">    ax.spines[<span class="string">&#x27;top&#x27;</span>].set_linewidth(<span class="number">1</span>)     <span class="comment"># 顶部轴线宽度</span></span><br><span class="line">    ax.spines[<span class="string">&#x27;right&#x27;</span>].set_linewidth(<span class="number">1</span>)   <span class="comment"># 右侧轴线宽度</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 坐标轴标题</span></span><br><span class="line">    ax.set_ylabel(<span class="string">&#x27;Permeability(mD)&#x27;</span>, fontsize=<span class="number">10</span>, fontname=<span class="string">&#x27;Times New Roman&#x27;</span>, fontweight=<span class="string">&#x27;bold&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    plt.tight_layout()</span><br><span class="line">    <span class="keyword">return</span> plt</span><br></pre></td></tr></table></figure><img src="/2025/03/06/Python%E7%A7%91%E5%AD%A6%E7%BB%98%E5%9B%BE/%E5%B0%8F%E6%8F%90%E7%90%B4%E5%9B%BE-1.png" class="" title="小提琴图-1"><img src="/2025/03/06/Python%E7%A7%91%E5%AD%A6%E7%BB%98%E5%9B%BE/%E5%B0%8F%E6%8F%90%E7%90%B4%E5%9B%BE-2.png" class="" title="小提琴图-2">]]></content>
    
    
    <summary type="html">科研利器</summary>
    
    
    
    <category term="AvizoUsersGuide" scheme="http://hibiscidai.com/categories/AvizoUsersGuide/"/>
    
    
    <category term="Python" scheme="http://hibiscidai.com/tags/Python/"/>
    
    <category term="科研利器" scheme="http://hibiscidai.com/tags/%E7%A7%91%E7%A0%94%E5%88%A9%E5%99%A8/"/>
    
  </entry>
  
  <entry>
    <title>AVIZO自动化</title>
    <link href="http://hibiscidai.com/2024/09/19/AVIZO%E8%87%AA%E5%8A%A8%E5%8C%96/"/>
    <id>http://hibiscidai.com/2024/09/19/AVIZO%E8%87%AA%E5%8A%A8%E5%8C%96/</id>
    <published>2024-09-19T06:00:00.000Z</published>
    <updated>2025-02-27T14:45:11.362Z</updated>
    
    <content type="html"><![CDATA[<img src="/2024/09/19/AVIZO%E8%87%AA%E5%8A%A8%E5%8C%96/AVIZO%E8%87%AA%E5%8A%A8%E5%8C%96.png" class="" title="AVIZO自动化"><p>AVIZO自动化</p><span id="more"></span><h1 id="AVIZO自动化"><a href="#AVIZO自动化" class="headerlink" title="AVIZO自动化"></a>AVIZO自动化</h1><p>第9章《自动化、自定义和扩展》主要讲解了如何使用Avizo的自动化、自定义和扩展功能。以下是详细介绍：</p><p>9.1 模板项目</p><p>模板项目用于简化对相似数据集的重复任务处理。用户可以将原始项目保存为模板，以便在相同类型的数据上重复使用。模板项目可以通过右键菜单或“项目 &gt; 创建对象”子菜单加载和执行。模板项目为自动化重复操作提供了便捷的途径。</p><p>9.2 Avizo启动<br>这一节描述了Avizo的启动选项，包括：</p><p>命令行选项：可用于配置Avizo启动时的行为，例如日志记录、禁用图形界面等。<br>环境变量：用户可以通过环境变量设置临时目录、启用或禁用特定功能（例如3D立体视图）。<br>用户定义的启动脚本：可以通过编写用户定义的启动脚本（如Avizo.init）定制Avizo的行为，包含注册文件格式、模块和编辑器等。</p><p>9.3 脚本编写</p><p>这一节介绍了如何使用脚本来控制Avizo，实现自动化和自定义任务。Avizo的脚本基于Tcl语言，用户可以通过编写Tcl脚本来操控Avizo的大部分功能，包括：</p><p>命令替换：使用括号[]执行命令并返回结果。<br>控制结构：支持if-else条件判断、for循环、while循环等控制结构。<br>用户自定义过程：使用proc定义新函数或过程，支持灵活参数列表和局部变量。<br>列表和字符串操作：Tcl中的所有内容都是通过列表构建的，提供了多个操作列表的命令。</p><p>9.4 使用MATLAB与Avizo集成</p><p>Avizo提供了与MATLAB的集成模块，允许用户从Avizo传递数据到MATLAB进行复杂计算，并将结果返回到Avizo中。通过这种方式，用户可以在Avizo中执行MATLAB脚本、调用用户自定义的MATLAB函数、以及使用字段结构等。</p><p>总的来说，第9章提供了Avizo的高级功能，允许用户通过模板、脚本编写和MATLAB集成来自动化和扩展工作流程 。</p><h2 id="9-1-模板项目"><a href="#9-1-模板项目" class="headerlink" title="9.1 模板项目"></a>9.1 模板项目</h2><p>这一节描述了如何使用模板项目。</p><h3 id="9-1-1-模板项目说明"><a href="#9-1-1-模板项目说明" class="headerlink" title="9.1.1 模板项目说明"></a>9.1.1 模板项目说明</h3><p>模板项目可以用于简化对一组相似数据的重复任务处理。模板项目是原始项目的副本，可以在相同类型的其他数据上重新应用。</p><h4 id="9-1-1-1-如何保存模板项目"><a href="#9-1-1-1-如何保存模板项目" class="headerlink" title="9.1.1.1 如何保存模板项目"></a>9.1.1.1 如何保存模板项目</h4><p>要创建模板项目，请从文件菜单中选择“另存项目为模板”（Save Project As Template）。这时会弹出一个输入选择对话框，列出所有可能的模板输入（当前的所有数据对象）。模板输入代表在执行模板时必须提供的数据集。您可以更改每个所选模板输入的标签。由于该标签会在模板执行期间显示出来，因此标签应当通用且有意义。默认标签是原始数据对象的名称。注意：未使用的数据对象会默认被过滤，但您可以通过选择“包含未使用的数据”（Include unused data）选项将其包含在模板项目中。</p><p>如果模板只包含一个输入，对话框会询问您是否希望将模板与该类型的数据关联。如果点击“确定”，则该模板会在右键菜单中的模板子菜单下（Templates submenu）对所有相同数据类型的对象可用。</p><p>最后，将弹出文件对话框以命名输出文件。文件名也是模板的名称，即将显示在模板菜单中的名称。内置的模板项目存储在“share/templates”文件夹中，但您可能没有足够的权限在该目录中创建新文件。</p><img src="/2024/09/19/AVIZO%E8%87%AA%E5%8A%A8%E5%8C%96/Figure9.1.png" class="" title="Figure 9.1: The template project save dialog."><img src="/2024/09/19/AVIZO%E8%87%AA%E5%8A%A8%E5%8C%96/Figure9.2.png" class="" title="Figure 9.2: Data Type association is possible if template has only one input."><p>您可以将自定义模板保存在任何目录中。每次启动 Avizo 时，它们都会自动重新加载。</p><h4 id="9-1-1-2-如何使用模板项目"><a href="#9-1-1-2-如何使用模板项目" class="headerlink" title="9.1.1.2 如何使用模板项目"></a>9.1.1.2 如何使用模板项目</h4><p>内置的模板项目和已知的用户自定义模板项目会在Avizo启动时自动加载。加载模板并不意味着实例化模板项目。模板项目仅在用户请求时创建，例如通过“项目 &gt; 创建对象…”菜单。一个例外是：如果用户通过“打开数据”对话框加载模板文件，则模板资源会被加载并执行。</p><p>如果模板与某种数据类型相关联，您可以使用该类型的数据对象的右键菜单创建实例。在这种情况下，将立即使用所选数据对象创建模板。</p><p>对于其他模板，您可以从“项目 &gt; 创建对象…”菜单的模板子菜单中创建实例。模板也可能出现在宏按钮列表中。在这种情况下，模板执行时将出现以下对话框：</p><img src="/2024/09/19/AVIZO%E8%87%AA%E5%8A%A8%E5%8C%96/Figure9.3.png" class="" title="Figure 9.3: The template project run dialog."><p>每个模板输入都会显示其模板输入名称和一个组合框，用于选择将用于该输入的数据集。每个组合框中的候选数据根据其数据类型进行过滤。您可以通过取消选中“检查输入类型”选项来禁用此过滤并显示项目视图中的所有数据。如果没有适合的数据对象，组合框将为空。您还可以随时选择“&lt;加载文件…&gt;”项，显示文件打开对话框并选择数据文件。</p><p>对于色彩映射的特殊处理：默认情况下，项目视图中已存在的色彩映射会按原样重新使用。例如，模板项目中的对象可能会受到范围变化的影响。您还可以选择不与现有对象共享色彩映射，方法是选择“独立色彩映射”选项。</p><h2 id="9-2-Avizo-启动"><a href="#9-2-Avizo-启动" class="headerlink" title="9.2 Avizo 启动"></a>9.2 Avizo 启动</h2><p>这一节描述了一些与 Avizo 启动相关的选项，包括：</p><ul><li>命令行选项</li><li>环境变量</li><li>Avizo 启动脚本</li></ul><h3 id="9-2-1-命令行选项"><a href="#9-2-1-命令行选项" class="headerlink" title="9.2.1 命令行选项"></a>9.2.1 命令行选项</h3><p>本节介绍 Avizo 支持的命令行选项。通常，在 Unix 系统上，Avizo 是通过位于 bin 子目录中的启动脚本启动的。这个脚本通常链接到 /usr/local/bin/Avizo 或类似位置。用户也可以定义一个指向 bin/start 的 Avizo 别名。</p><p>在 Windows 系统上，Avizo 通常通过开始菜单或桌面图标启动。不过，用户也可以直接调用 bin/arch-Win64VC10-Optimize/Avizo.exe 来启动。在这种情况下，支持与 Unix 系统相同的命令行选项。</p><p>Avizo 的语法如下：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Avizo [options] [files ...]</span><br></pre></td></tr></table></figure><p>命令行中指定的数据文件将自动加载。除了数据文件外，还可以指定脚本文件。这些脚本将在程序启动时执行。</p><p>支持的选项如下：</p><ul><li>help </li></ul><p>打印命令行选项的简要说明。</p><ul><li>version</li></ul><p>打印 Avizo 的版本信息。</p><ul><li>no stencils</li></ul><p>指示 Avizo 不在其 3D 图形窗口中请求模板缓冲区。此选项可用于在某些低端 PC 图形板上利用硬件加速。</p><ul><li>no overlays</li></ul><p>指示 Avizo 不在其 3D 图形窗口中使用叠加平面。如果在远程显示上重定向 Avizo 时遇到问题，可以使用此选项。</p><ul><li>no gui</li></ul><p>启动 Avizo 而不打开任何窗口。此选项对于批处理模式下执行脚本很有用。</p><ul><li>logfile filename</li></ul><p>将控制台窗口中打印的所有消息也写入指定的日志文件。此选项尤其适用于与 -no gui 选项结合使用。</p><ul><li>depth number</li></ul><p>此选项仅在 Linux 系统上支持。它指定首选的深度缓冲区深度。Linux 系统上的默认值为 16 位。</p><ul><li>style={windows | motif | cde} </li></ul><p>此选项设置 Avizo 的 Qt 用户界面的显示样式。</p><ul><li>debug</li></ul><p>此选项仅适用于开发者版本。它会导致本地包以调试版本执行。默认情况下将使用优化代码。</p><ul><li>cmd command [  - host hostname ] [ - port port] </li></ul><p>向正在运行的 Avizo 应用程序发送 Tcl 命令。可以选择指定主机名和端口号。在 Avizo 控制台窗口中键入 app -listen 后，才能接收命令。</p><ul><li>clusterdaemon</li></ul><p>以 VR 守护程序模式启动，适用于集群从节点（Avizo XScreen 扩展）。这可能会被服务替代。有关更多信息，请参阅在线文档。</p><ul><li>tclcmd command</li></ul><p>在启动应用程序时执行 Tcl 命令。</p><ul><li>edition { LiteEdition | AvizoEdition }</li></ul><p>在特定版本下启动 Avizo。</p><h3 id="9-2-2-环境变量"><a href="#9-2-2-环境变量" class="headerlink" title="9.2.2 环境变量"></a>9.2.2 环境变量</h3><p>执行 Avizo 不需要特别的环境设置。在 Unix 系统上，某些环境变量（如共享库路径或 AVIZO_ROOT 目录）会由 Avizo 启动脚本自动设置。用户还可以设置其他环境变量来控制某些功能，这些变量列举如下。在 Unix 系统上，可以使用 setenv（适用于 csh 或 tcsh）或 export（适用于 sh、bash 或 ksh）来设置环境变量。在 Windows 上，可以在系统属性对话框中定义环境变量（Microsoft Windows）。</p><ul><li>AVIZO_DATADIR</li></ul><p>一个数据目录路径。此目录将用作文件对话框的默认目录。请注意，为了快速访问多个目录，您可以使用操作系统功能（例如在文件对话框中添加收藏夹位置列表），或者使用包含快捷方式或指向其他目录的链接的目录。</p><ul><li>AVIZO_TEXMEM</li></ul><p>指定以兆字节为单位的纹理内存量。如果未设置此变量，将应用一些启发式算法来确定系统上可用的纹理内存量。然而，这些启发式算法可能并不总是得出正确的值。在这种情况下，可以使用此变量来提高体积渲染模块的性能。</p><ul><li>AVIZO_MULTISAMPLE</li></ul><p>在高端图形系统上，默认使用多采样视觉。这种方式可以实现高效的场景抗锯齿。如果您希望禁用此功能，请将环境变量 AVIZO_MULTISAMPLE 设置为 0。请注意，在其他系统上，特别是在 PC 上，抗锯齿无法通过应用程序控制，而是必须直接在图形驱动程序中激活。</p><ul><li>AVIZO_NO_LICENSE_MESSAGE</li></ul><p>默认情况下，当您的 Avizo 许可证即将到期时，Avizo 会向控制台发出警告消息。这使您可以及时采取行动，防止在许可证到期时意外中断 Avizo 的使用。要禁用这些消息，请将此变量设置为 1。</p><ul><li>AVIZO_NO_OVERLAYS</li></ul><p>如果设置此变量，Avizo 将不会在其 3D 图形窗口中使用叠加平面。通过 -no overlays 命令行选项可以获得相同的效果。如果在远程显示上重定向 Avizo 时遇到问题，或者您的 X 服务器不支持叠加视觉，可以关闭叠加。</p><ul><li>AVIZO_NO_SPLASH_SCREEN</li></ul><p>如果设置此变量，Avizo 在初始化时不会显示启动画面。</p><ul><li>AVIZO_LOCAL</li></ul><p>指定包含用户定义模块的本地 Avizo 目录。此目录中的 IO 例程或模块将替代主 Avizo 目录中定义的例程或模块。此环境变量将覆盖开发向导中设置的本地 Avizo 目录（有关详细信息，请参阅 Avizo 程序员指南）。</p><ul><li>AVIZO_SMALLFONT</li></ul><p>仅适用于 Unix 系统。如果设置了此变量，即使屏幕分辨率为 1280x1024 或更高，所有在属性区中显示的端口也将使用小字体。默认情况下，小字体只会在较低分辨率的情况下使用。</p><ul><li>AVIZO_XSHM</li></ul><p>仅适用于 Unix 系统。如果您希望在 Avizo 的分割编辑器中禁止使用 X 共享内存扩展，请将此变量设置为 0。</p><ul><li>AVIZO_SPACEMOUSE</li></ul><p>如果 Avizo 发现连接了 Spacemouse（详见 <a href="http://www.3dconnexion.com">http://www.3dconnexion.com</a> ），Spacemouse 支持将自动启用。如果驱动程序已安装，则控制台窗口中会打印一条消息。通过 Spacemouse，您可以在 3D 查看器窗口中导航。支持两种模式：旋转模式和飞行模式。可以通过按下 Spacemouse 按钮 1 或 2 来切换两种模式。更多配置选项可能在 Avizo.init 文件中可用。<br>3Dconnexion Spacemouse 限制：</p><ul><li>Mac OS X 不支持 Spacemouse。</li><li>Avizo 和 AvizoClue 应用程序会识别 Spacemouse。</li><li>尚未完全支持六自由度运动。</li><li>Spacemouse 只能控制第一个查看器。</li><li>在旋转模式下，无法平移相机或上下移动。</li><li>在飞行模式下，无法绕物体旋转或上下移动。</li><li><p>默认情况下，按钮 1 用于打开菜单，必须重新配置为“按钮 1”功能。</p></li><li><p>AVIZO STEREO ON DEFAULT</p></li></ul><p>如果设置了此变量，则默认情况下 3D 查看器将以 OpenGL 原始立体模式打开。<br>这样，可以避免从单声道切换到立体模式时出现的屏幕闪烁。目前，该变量仅在 Unix 系统上受支持。</p><ul><li>TMPDIR</li></ul><p>此变量指定应将临时数据存储在哪个目录中。如果未设置，则此类数据将在 /tmp 下创建。此外，此变量由 Avizo 的作业队列解释。</p><h3 id="9-2-3-用户自定义启动脚本"><a href="#9-2-3-用户自定义启动脚本" class="headerlink" title="9.2.3 用户自定义启动脚本"></a>9.2.3 用户自定义启动脚本</h3><p>Avizo 可以通过提供用户自定义的启动脚本进行某些定制。默认的启动脚本名为 Avizo.init，位于 Avizo 安装目录的 share/resources/Avizo 子目录中。每次程序启动时，都会读取此脚本。此启动脚本的功能包括注册文件格式、模块和编辑器，以及加载默认的颜色映射。</p><p>如果在当前工作目录中找到名为 Avizo.init 的文件，则会读取该文件而不是默认的启动脚本。如果没有找到该文件，在 Unix 系统上会检查用户的主目录中是否存在名为 .Avizo 的启动脚本。下面是一个用户定义启动脚本的示例：</p><figure class="highlight tcl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 执行默认启动脚本</span></span><br><span class="line"><span class="keyword">source</span> <span class="variable">$AVIZO_ROOT</span>/share/resources/Avizo/Avizo.init <span class="number">0</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置均匀的黑色背景</span></span><br><span class="line">viewer <span class="number">0</span> setBackgroundMode <span class="number">0</span></span><br><span class="line">viewer <span class="number">0</span> setBackgroundColor black</span><br><span class="line"></span><br><span class="line"><span class="comment"># 为帮助浏览器选择非默认字体大小</span></span><br><span class="line">help setFontSize <span class="number">12</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 通过按 [F3] 键恢复摄像机设置</span></span><br><span class="line"><span class="keyword">proc</span><span class="title"> onKeyF3</span> &#123; &#125; &#123;</span><br><span class="line">    viewer setCameraOrientation <span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">3.14159</span></span><br><span class="line">    viewer setCameraPosition <span class="number">0</span> <span class="number">0</span> <span class="number">-2.50585</span></span><br><span class="line">    viewer setCameraFocalDistance <span class="number">2.50585</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>在此示例中，首先执行系统的默认启动脚本，以确保所有 Avizo 对象被正确注册。接着进行一些特定的设置，最后为功能键 [F3] 定义了一个快捷键过程。您也可以为其他功能键定义此类过程。此外，还可以定义类似 onKeyShiftF3 或 onKeyCtrlF3 的过程。这些过程在按下功能键同时按住 [SHIFT] 或 [CTRL] 键时执行。</p><h2 id="9-3-脚本编写"><a href="#9-3-脚本编写" class="headerlink" title="9.3 脚本编写"></a>9.3 脚本编写</h2><p>本节描述如何在 Avizo 中使用脚本功能。</p><h3 id="9-3-1-脚本编写介绍"><a href="#9-3-1-脚本编写介绍" class="headerlink" title="9.3.1 脚本编写介绍"></a>9.3.1 脚本编写介绍</h3><p>本章专为高级 Avizo 用户而写。如果您不知道什么是脚本编写，那么很可能不需要本章中描述的功能。</p><p>除了通过图形用户界面的交互控制之外，大多数 Avizo 功能也可以通过特定的命令访问。这允许您自动化某些流程，创建用于管理日常任务或演示的脚本。Avizo 的脚本命令基于 Tcl（工具命令语言）。这意味着您可以使用 Tcl 编写带有 Avizo 特定扩展的命令脚本。</p><p>可以在 Avizo 的控制台窗口中键入命令，如第 8.1.13 节中所述。直接在控制台窗口中输入的命令将立即执行。或者，也可以将命令写入文本文件，然后作为整体执行。</p><p>本章内容如下：</p><p>9.3.2 Tcl 简介 提供了 Tcl 脚本语言的简短介绍。本节与 Avizo 相关性不大。</p><p>9.3.3 Avizo 脚本接口 解释了与脚本编写相关的 Avizo 特定命令和概念。包括全局命令参考。</p><p>9.3.5 Avizo 脚本文件 解释了编写和执行脚本文件的不同方法，包括脚本对象、资源文件和功能键绑定的 Tcl 过程的参考。</p><p>9.3.6 配置弹出菜单 描述了如何使用脚本命令配置对象的弹出菜单，并如何创建执行脚本的新条目。</p><p>9.3.7 注册拾取回调 描述了如何将脚本回调附加到对象或查看器中，并在用户拾取事件时调用它们。</p><p>9.3.8 Tcl 文件读取器 解释了如何注册用 Tcl 实现的自定义文件读取器。</p><h3 id="9-3-2-Tcl简介"><a href="#9-3-2-Tcl简介" class="headerlink" title="9.3.2 Tcl简介"></a>9.3.2 Tcl简介</h3><p>本章简要介绍Tcl脚本语言。如果你已经熟悉Tcl，你可以跳过本节。然而，请注意，输出到Avizo控制台时，应该使用echo命令，而不是puts命令。</p><p>本章并不打算涵盖Tcl语言的所有细节。要了解Tcl语言的完整文档或参考手册，请参阅John K. Ousterhout撰写的《Tcl and the Tk Toolkit》。许多其他关于Tcl的书籍也涵盖了Tk GUI工具包，但请注意，Tk在Avizo中并未使用。</p><p>你也可以在互联网上找到Tcl文档和参考手册，例如在<a href="http://www.scriptics.com">http://www.scriptics.com</a> ，或者通过搜索引擎查找”Tcl教程”或”Tcl文档”。</p><p>当你在Avizo控制台中键入Tcl命令时，命令会在按下回车键后立即执行。使用Avizo控制台提供的自动补全和历史功能，参见第8.1.13节（控制台窗口）。</p><h4 id="9-3-2-1-Tcl列表、命令和注释"><a href="#9-3-2-1-Tcl列表、命令和注释" class="headerlink" title="9.3.2.1 Tcl列表、命令和注释"></a>9.3.2.1 Tcl列表、命令和注释</h4><p>首先，请注意Tcl是区分大小写的：set和Set并不相同。</p><p>Tcl命令是由空格分隔的单词列表。第一个单词代表命令名称，后续的单词被视为该命令的参数。例如，尝试输入Avizo特定的命令echo，该命令将所有参数打印到Avizo控制台。尝试键入：</p><figure class="highlight tcl"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">echo Hello World</span><br></pre></td></tr></table></figure><p>这将输出字符串”Hello World”。注意，Tcl命令可以用分号（;）或换行符分隔。如果你想连续执行两个echo命令，可以这样：</p><figure class="highlight tcl"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">echo Hello World ; echo Hello World2</span><br></pre></td></tr></table></figure><p>或者这样：</p><figure class="highlight tcl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">echo Hello World</span><br><span class="line">echo Hello World2</span><br></pre></td></tr></table></figure><p>除了命令，你还可以在Tcl代码中插入注释。注释以 # 字符开头，并以换行符结束：</p><figure class="highlight tcl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 这是一个注释</span></span><br><span class="line">echo Hello World</span><br></pre></td></tr></table></figure><h4 id="9-3-2-2-Tcl变量"><a href="#9-3-2-2-Tcl变量" class="headerlink" title="9.3.2.2 Tcl变量"></a>9.3.2.2 Tcl变量</h4><p>Tcl中可以使用变量。变量表示某个特定的状态或值。使用Tcl代码，可以查询、定义和修改占位符的值。要定义一个变量，可以使用命令：</p><figure class="highlight tcl"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">set</span> name value</span><br></pre></td></tr></table></figure><p>例如：</p><figure class="highlight tcl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">set</span> i <span class="number">1</span></span><br><span class="line"><span class="keyword">set</span> myVar foobar</span><br></pre></td></tr></table></figure><p>请注意，在Tcl中，内部所有变量都是字符串类型。因为set命令要求一个作为变量值的参数，所以你必须对包含空格的值加引号：</p><figure class="highlight tcl"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">set</span> Output <span class="string">&quot;Hello World&quot;</span></span><br></pre></td></tr></table></figure><p>或者：</p><figure class="highlight tcl"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">set</span> Output &#123;Hello World&#125;</span><br></pre></td></tr></table></figure><p>要替换变量名为varname的值，需要在变量名前加上$符号。表达式$varname将被替换为变量的值。在上面的定义之后：</p><figure class="highlight tcl"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">echo <span class="variable">$Output</span></span><br></pre></td></tr></table></figure><p>将会在控制台窗口中打印：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Hello World</span><br></pre></td></tr></table></figure><p>同时，</p><figure class="highlight tcl"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">echo <span class="string">&quot;$i.) $Output&quot;</span></span><br></pre></td></tr></table></figure><p>将输出<code>1.) Hello World</code>。注意，对于使用双引号 “ 括起的字符串，会执行变量替换，但对于使用大括号{}括起的字符串，则不会进行替换。大括号内甚至允许换行符。然而，在Avizo控制台中不可能输入多行命令。</p><h4 id="9-3-2-3-Tcl命令替换"><a href="#9-3-2-3-Tcl命令替换" class="headerlink" title="9.3.2.3 Tcl命令替换"></a>9.3.2.3 Tcl命令替换</h4><p>在Tcl中进行数学计算时，可以使用<code>expr</code>命令，该命令将评估其参数并返回表达式的值。例如：</p><figure class="highlight tcl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">expr</span> <span class="number">5</span> / ( <span class="number">7</span> + <span class="number">3</span>)</span><br><span class="line"><span class="keyword">expr</span> <span class="variable">$i</span> + <span class="number">1</span></span><br></pre></td></tr></table></figure><p>为了将像 expr 这样的命令的结果用于后续命令，必须使用 Tcl 中一个重要的机制：命令替换。命令替换由方括号 [] 表示。任何用方括号括起来的列表都会首先作为一个单独的命令执行，[…] 构造将被命令的结果替换。这类似于 Unix 命令 shell 中的反引号构造 …。例如，为了将变量 i 的值增加 1，可以使用：</p><figure class="highlight tcl"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">set</span> i [<span class="keyword">expr</span> <span class="variable">$i</span> + <span class="number">1</span>]</span><br></pre></td></tr></table></figure><p>当然，命令表达式可以任意嵌套。执行顺序总是从最内层的括号对到最外层的括号对：</p><figure class="highlight tcl"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">echo [<span class="keyword">expr</span> <span class="number">5</span> * [<span class="keyword">expr</span> <span class="number">7</span> + [<span class="keyword">expr</span> <span class="number">3</span> + <span class="number">3</span>]]]</span><br></pre></td></tr></table></figure><h4 id="9-3-2-4-Tcl-控制结构"><a href="#9-3-2-4-Tcl-控制结构" class="headerlink" title="9.3.2.4 Tcl 控制结构"></a>9.3.2.4 Tcl 控制结构</h4><p>另一个重要的语言元素是 if-else 结构、for 循环和 while 循环。这些结构通常是多行结构，因此不适合在 Avizo 控制台中方便地输入。如果您想尝试下面的示例，可以使用您选择的文本编辑器将它们写入文件，如 C:\test.txt，然后通过输入以下命令执行该文件：</p><figure class="highlight tcl"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">source</span> C:\test.txt</span><br></pre></td></tr></table></figure><p>首先介绍 if-then 机制。它用于在某个表达式求值为 “true” 时执行一些代码（意思是值不为 0）：</p><figure class="highlight tcl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">set</span> a <span class="number">7</span></span><br><span class="line"><span class="keyword">set</span> b <span class="number">8</span></span><br><span class="line"><span class="keyword">if</span> &#123;<span class="variable">$a</span> &lt; <span class="variable">$b</span>&#125; &#123;</span><br><span class="line">    echo <span class="string">&quot;$a is smaller than $b&quot;</span></span><br><span class="line">&#125; elseif &#123;<span class="variable">$a</span> == <span class="variable">$b</span>&#125; &#123;</span><br><span class="line">    echo <span class="string">&quot;$a equals $b&quot;</span></span><br><span class="line">&#125; else &#123;</span><br><span class="line">    echo <span class="string">&quot;$a is greater than $b&quot;</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>elseif 和 else 部分是可选的。可以使用多个 elseif 部分，但只能有一个 if 和一个 else 部分。</p><p>另一个重要结构是条件循环。像 if 命令一样，它基于检查条件表达式。与 if 不同的是，条件代码会多次执行，只要表达式求值为 true：</p><figure class="highlight tcl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> &#123;<span class="keyword">set</span> i <span class="number">1</span>&#125; &#123;<span class="variable">$i</span> &lt; <span class="number">100</span>&#125; &#123;<span class="keyword">set</span> i [<span class="keyword">expr</span> <span class="variable">$i</span>*<span class="number">2</span>]&#125; &#123;</span><br><span class="line">    echo <span class="variable">$i</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>实际上，这段代码等同于：</p><figure class="highlight tcl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">set</span> i <span class="number">1</span></span><br><span class="line"><span class="keyword">while</span> &#123;<span class="variable">$i</span> &lt; <span class="number">100</span>&#125; &#123;</span><br><span class="line">    echo <span class="variable">$i</span></span><br><span class="line">    <span class="keyword">set</span> i [<span class="keyword">expr</span> <span class="variable">$i</span> * <span class="number">2</span>]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>两个循环都会产生输出 1、2、4、8、16、32、64。<br>如果要对列表的所有元素执行循环，还有另一个非常方便的命令：</p><figure class="highlight tcl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">foreach</span> x &#123;<span class="number">1</span> <span class="number">2</span> <span class="number">4</span> <span class="number">8</span> <span class="number">16</span> <span class="number">32</span> <span class="number">64</span>&#125; &#123;</span><br><span class="line">echo <span class="variable">$x</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这将生成与上一个示例相同的输出。请注意，括号中的表达式是以空格分隔的单词列表。</p><h4 id="9-3-2-5-用户自定义的Tcl过程"><a href="#9-3-2-5-用户自定义的Tcl过程" class="headerlink" title="9.3.2.5 用户自定义的Tcl过程"></a>9.3.2.5 用户自定义的Tcl过程</h4><p>在Tcl中，使用 proc 命令来定义一个新的函数或过程。proc 需要两个参数：一个参数名称列表和要执行的Tcl代码。一旦定义了一个过程，它就可以像任何其他Tcl命令一样使用：</p><figure class="highlight tcl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">proc</span><span class="title"> computeAverageA</span> &#123;a b&#125; &#123;</span><br><span class="line">    <span class="keyword">return</span> [<span class="keyword">expr</span> (<span class="variable">$a</span>+<span class="variable">$b</span>)/<span class="number">2.0</span>]</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">proc</span><span class="title"> computeAverageB</span> &#123;a b c&#125; &#123;</span><br><span class="line">    <span class="keyword">return</span> [<span class="keyword">expr</span> (<span class="variable">$a</span>+<span class="variable">$b</span>+<span class="variable">$c</span>)/<span class="number">3.0</span>]</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">echo <span class="string">&quot;average of 2 and 3: [computeAverageA 2 3]&quot;</span></span><br><span class="line">echo <span class="string">&quot;average of 2,3,4: [computeAverageB 2 3 4]&quot;</span></span><br></pre></td></tr></table></figure><p>在这个例子中，参数列表定义了可以在过程体内使用的局部变量的名称（例如 $a）。return 命令用于定义过程的结果。这个结果是通过方括号 [] 进行命令替换时使用的值。</p><p>如果想定义一个具有可变数量参数的过程，必须使用特殊参数名称 args。如果参数列表中只包含这个词，新的命令将接受任意数量的参数，并且这些参数会作为一个列表传递给名为 args 的变量：</p><figure class="highlight tcl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">proc</span><span class="title"> computeAverage</span> args &#123;</span><br><span class="line">    <span class="keyword">set</span> result <span class="number">0</span></span><br><span class="line">    <span class="keyword">foreach</span> x <span class="variable">$args</span> &#123;</span><br><span class="line">        <span class="keyword">set</span> result [<span class="keyword">expr</span> <span class="variable">$result</span> + <span class="variable">$x</span>]</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> [<span class="keyword">expr</span> <span class="variable">$result</span> / [<span class="keyword">llength</span> <span class="variable">$args</span>]]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>在这个例子中，llength 命令返回 args 列表中包含的元素数量。</p><p>注意，过程内定义的变量 result 具有局部作用域，这意味着它在过程体外是未知的。此外，全局变量的值在过程内也是未知的，除非使用 global 关键字声明该全局变量：</p><figure class="highlight tcl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">set</span> x <span class="number">3</span></span><br><span class="line"><span class="keyword">proc</span><span class="title"> printX</span> &#123;&#125; &#123;</span><br><span class="line">    <span class="keyword">global</span> x</span><br><span class="line">    echo <span class="string">&quot;x的值是 $x&quot;</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>关于过程还有很多内容，例如参数传递、在过程外部上下文中执行命令等。请参阅Tcl参考书以获取这些高级主题。</p><h4 id="9-3-2-6-列表和字符串操作"><a href="#9-3-2-6-列表和字符串操作" class="headerlink" title="9.3.2.6 列表和字符串操作"></a>9.3.2.6 列表和字符串操作</h4><p>最后，在这简短的Tcl介绍结束时，我们回到列表的概念。基本上Tcl中的一切都是通过列表构造的，因此了解最重要的列表操作命令以及理解一些微妙的细节是非常重要的。</p><p>下面是一个示例，展示了如何获取一个输入的数字列表并构造一个输出列表，其中每个元素的值是输入列表中相应元素的两倍：</p><figure class="highlight tcl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">set</span> input [<span class="keyword">list</span> <span class="number">1</span> <span class="number">2</span> <span class="number">3</span> <span class="number">4</span> <span class="number">5</span>]</span><br><span class="line"><span class="keyword">set</span> output [<span class="keyword">list</span>]</span><br><span class="line"><span class="keyword">foreach</span> element <span class="variable">$input</span> &#123;</span><br><span class="line">    <span class="keyword">lappend</span> output [<span class="keyword">expr</span> <span class="variable">$element</span> * <span class="number">2</span>]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>你可以将列表看作是用空格分隔列表元素的简单字符串。这意味着可以不用列表命令来实现与前面例子相同的结果：</p><figure class="highlight tcl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">set</span> input <span class="string">&quot;1 2 3 4 5&quot;</span></span><br><span class="line"><span class="keyword">set</span> output <span class="string">&quot;&quot;</span></span><br><span class="line"><span class="keyword">foreach</span> element <span class="variable">$input</span> &#123;</span><br><span class="line">    <span class="keyword">append</span> output [<span class="keyword">expr</span> <span class="variable">$element</span> * <span class="number">2</span>] <span class="string">&quot; &quot;</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>append命令类似于lappend，但它只是在现有字符串的末尾添加字符串。当你开始嵌套列表时，列表操作变得更加复杂。嵌套列表用嵌套的大括号表示，例如：</p><figure class="highlight tcl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">set</span> input &#123;<span class="number">1</span> <span class="number">2</span> &#123;<span class="number">3</span> <span class="number">4</span> <span class="number">5</span> &#123;<span class="number">6</span> <span class="number">7</span>&#125; <span class="number">8</span> &#125; <span class="number">9</span>&#125;</span><br><span class="line"><span class="keyword">foreach</span> x <span class="variable">$input</span> &#123;</span><br><span class="line">    echo <span class="variable">$x</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>此命令的结果将是：</p><figure class="highlight tcl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">1</span></span><br><span class="line"><span class="number">2</span></span><br><span class="line"><span class="number">3</span> <span class="number">4</span> <span class="number">5</span> &#123;<span class="number">6</span> <span class="number">7</span>&#125; <span class="number">8</span></span><br><span class="line"><span class="number">9</span></span><br></pre></td></tr></table></figure><p>请注意，当构造列表时，Tcl会自动引用不是单个词的字符串。以下是一个示例：</p><figure class="highlight tcl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">set</span> i [<span class="keyword">list</span> <span class="number">1</span> <span class="number">2</span> <span class="number">3</span>]</span><br><span class="line"><span class="keyword">lappend</span> i <span class="string">&quot;4 5 6&quot;</span></span><br><span class="line">echo <span class="variable">$i</span></span><br></pre></td></tr></table></figure><p>将输出：</p><figure class="highlight tcl"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">1</span> <span class="number">2</span> <span class="number">3</span> &#123;<span class="number">4</span> <span class="number">5</span> <span class="number">6</span>&#125;</span><br></pre></td></tr></table></figure><p>你可以使用lindex命令来访问列表的单个元素。lindex接受两个参数：列表和所需元素的索引号，索引从0开始：</p><figure class="highlight tcl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">set</span> i [<span class="keyword">list</span> a b c d e]</span><br><span class="line">echo [<span class="keyword">lindex</span> <span class="variable">$i</span> <span class="number">2</span>]</span><br></pre></td></tr></table></figure><p>将输出结果为 c：</p><h3 id="9-3-3-Avizo-脚本接口"><a href="#9-3-3-Avizo-脚本接口" class="headerlink" title="9.3.3 Avizo 脚本接口"></a>9.3.3 Avizo 脚本接口</h3><p>尽管 Tcl 语言本身并不是面向对象的，Avizo 的脚本接口是面向对象的。Avizo 项目视图中的每个对象都有一个与之关联的命令。此外，还有几个与 Avizo 中的全局对象（如查看器或 Avizo 主窗口）相关的全局命令。</p><p>与项目视图中的对象关联的命令（例如，“Ortho Slice”模块或“Isosurface”模块）仅在该对象存在时才存在。这些命令与项目视图中显示的对象名称相同。通常，特定对象的脚本接口包含许多不同的功能。Avizo 对象相关命令的通用语法是：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&lt;object-name&gt; &lt;command-word&gt; &lt;optional-arguments&gt; ...</span><br></pre></td></tr></table></figure><p>例如，如果存在一个名为“Global Axes”的对象（从 Avizo 菜单中选择 View/Axis），那么你可以使用类似以下的命令：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&quot;GlobalAxes&quot; deselect</span><br><span class="line">&quot;GlobalAxes&quot; select</span><br><span class="line">&quot;GlobalAxes&quot; setIconPosition 100 100</span><br></pre></td></tr></table></figure><p>注意：模块名称使用驼峰命名法。命令中可能出现这三个词：“Global Axes”、“GlobalAxes”或 GlobalAxes。</p><p>请记住使用 Avizo 控制台提供的自动补全和历史功能（参见第 8.1.13 节“控制台窗口”），以节省打字时间。</p><p>如果你已经使用过 Avizo，你可能注意到 Avizo 模块的参数和行为是通过其端口控制的。选择模块时，端口提供了用户界面来更改其值。所有端口也可以通过命令接口控制。其通用语法是：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&lt;object-name&gt; &lt;port-name&gt; &lt;port-command&gt; &lt;optional-arguments&gt; ...</span><br></pre></td></tr></table></figure><p>例如，对于“Global Axes”，你可以输入：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&quot;GlobalAxes&quot; options setValue 1 1</span><br><span class="line">&quot;GlobalAxes&quot; thickness setValue 1.5</span><br><span class="line">&quot;GlobalAxes&quot; fire</span><br></pre></td></tr></table></figure><p>当你输入这些命令时，你会注意到用户界面中的值会立即更改。然而，模块的计算方法在显式调用 fire 命令之前不会被调用。这允许你先为多个端口设置值，而无需在每个命令之后重新计算。然而请注意，一些模块在连接新输入对象时会自动重置其某些端口。在这种情况下，你可能需要在为每个端口设置值后调用 fire。</p><p>通常，端口名称与图形用户界面中显示的文本标签相同，除了删除了空格并且命令名称以小写字母开头。要找出特定模块的所有端口名称，请使用以下命令：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&lt;object-name&gt; allPorts</span><br></pre></td></tr></table></figure><p>几乎所有端口都提供 setValue 和 getValue 命令。当然，参数数量和语法取决于端口。</p><p>对象相关命令类型<code>&lt;object-name&gt; &lt;port-name&gt; setValue ...</code>构成了典型 Avizo 脚本的 90% 以上。然而，除了端口命令外，许多 Avizo 对象还提供其他特定命令。特定模块的命令接口在用户参考指南中有详细描述。当选择模块时，单击属性区域中的“?”按钮可以快速找到相应页面。</p><p>作为快速帮助，输入对象名称而不加任何选项将显示该对象可用的所有命令。请注意，这也会显示未记录、未发布和实验性的命令。为了获取有关特定模块或端口命令的更多信息，你可以将其输入控制台窗口而不加任何参数，然后按 F1 键。这将打开帮助浏览器，显示命令的描述。</p><p>Avizo 对象是类层次结构的一部分。与 C++ 编程接口类似，脚本命令也可以由派生类从其基类继承。这意味着像轴对象这样的特定对象，除了其自己的特定命令外，还提供其基类中的所有命令。模块文档中提供了指向基类命令的链接。</p><h4 id="9-3-3-1-预定义变量"><a href="#9-3-3-1-预定义变量" class="headerlink" title="9.3.3.1 预定义变量"></a>9.3.3.1 预定义变量</h4><p>在Avizo Tcl中存在一些预定义变量，它们具有特殊的含义。这些变量包括：</p><ul><li><p>AVIZO ROOT: Avizo安装目录。</p></li><li><p>AVIZO LOCAL: 个人Avizo开发目录（仅限Avizo XPand扩展）。</p></li><li><p>SCRIPTFILE: 当前正在执行的Tcl脚本文件。</p></li><li><p>SCRIPTDIR: 当前正在执行的脚本所在的目录。</p></li><li><p>hideNewModules: 如果设置为1，初始创建的新模块图标将被隐藏。请谨慎设置此变量，并在严格必要时使用。为了避免意外地持续隐藏创建的模块（例如在脚本中断的情况下），应在使用后立即恢复此变量。</p></li></ul><h4 id="9-3-3-2-对象命令"><a href="#9-3-3-2-对象命令" class="headerlink" title="9.3.3.2 对象命令"></a>9.3.3.2 对象命令</h4><p>Avizo模块和数据对象的基本命令接口在用户指南的参考部分的”对象”章节中进行了描述。对象命令的基本语法如下：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&lt;object&gt; &lt;command&gt; &lt;arguments&gt; ...</span><br></pre></td></tr></table></figure><p>其中，<code>&lt;object&gt;</code> 是指对象的名称，<code>&lt;command&gt;</code> 表示要执行的命令。每个模块或数据对象可能定义自己的一组命令，除了其基类定义的命令之外。在”对象”章节中描述的命令由所有模块和数据对象提供。</p><p>全局命令将在下一节中介绍。</p><h3 id="9-3-4-全局命令"><a href="#9-3-4-全局命令" class="headerlink" title="9.3.4 全局命令"></a>9.3.4 全局命令</h3><p>本节列出了Avizo特定的全局Tcl命令。这些命令中的一些与Avizo中的某些全局对象相关联，如控制台窗口、主窗口或查看器窗口。其他命令如load或echo则不属于此类。以下命令分为不同的子部分：</p><p>• viewer command options (viewer)<br>• main window command options (theMain)<br>• console command options (theMsg)<br>• common commands for top-level windows<br>• progress bar command options (workArea)<br>• application command options (app)<br>• other global commands</p><ul><li>查看器命令选项（viewer）</li><li>主窗口命令选项（theMain）</li><li>控制台命令选项（theMsg）</li><li>顶级窗口的通用命令</li><li>进度条命令选项（workArea）</li><li>应用程序命令选项（app）</li><li>其他全局命令</li></ul><h4 id="9-3-4-1-视图命令选项"><a href="#9-3-4-1-视图命令选项" class="headerlink" title="9.3.4.1 视图命令选项"></a>9.3.4.1 视图命令选项</h4><p>可以在控制台窗口中输入对视图的命令。语法为：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">viewer [&lt;number&gt;] <span class="built_in">command</span></span><br></pre></td></tr></table></figure><p>其中，<code>&lt;number&gt;</code> 指定要操作的视图。数值 0 表示主视图，可省略以方便操作。</p><h5 id="命令："><a href="#命令：" class="headerlink" title="命令："></a>命令：</h5><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">viewer [&lt;number&gt;] snapshot [-offscreen [&lt;width&gt; &lt;height&gt;]] [-stereo] [-alpha] [-tiled &lt;nx&gt; &lt;ny&gt;] &lt;filename&gt; [filename2]</span><br></pre></td></tr></table></figure><p>此命令截取当前场景的快照，并将其保存为指定的文件名。图像格式由文件名的扩展名自动决定。支持的格式列表包括：TIFF (.tif, .tiff)、SGI-RGB (.rgb, .sgi, .bw)、JPEG (.jpg, .jpeg)、PNM (.pgm, .ppm)、BMP (.bmp)、PNG (.png) 和 EPS (.eps)。如果没有提供视图编号，将从所有视图中截取快照，前提是从“视图”菜单中选择了2个或4个视图布局。</p><p>如果指定了 <code>-offscreen</code> 选项，将使用最大尺寸为 2048x2048 的屏幕外渲染。在这种情况下，即使是视图 0，也需要指定视图编号。如果没有明确指定宽度和高度，图像的尺寸将为当前视图的大小。</p><p><strong>注意</strong>： 如果视图中有多个可见的透明对象，并且想使用屏幕外渲染，请将透明度模式设置为“Blend Delayed”，并在拍摄快照之前检查所有对象是否正确渲染。</p><p>如果使用了 <code>-stereo</code> 选项，将创建立体模式图像。在这种情况下，filename2 文件可用于指定保存立体图像第二个视图的文件。</p><p>如果使用了 <code>-alpha</code> 选项，将创建具有透明背景的快照图像。</p><p>如果使用了 <code>-tiled nx ny</code> 选项，将使用 nx 和 ny 指定的拼贴渲染进行渲染，在水平和垂直方向上各渲染nx和ny个拼贴。</p><p><code>viewer [&lt;number&gt;] setPosition &lt;x&gt; &lt;y&gt;</code><br>（仅限顶级模式）设置视图窗口相对于屏幕左上角的位置。如果在同一窗口中显示了多个视图，则设置顶级窗口的位置。</p><p><code>viewer [&lt;number&gt;] getPosition</code><br>返回视图窗口的位置。如果同一窗口中显示了多个视图，则返回顶级窗口的位置。</p><p><code>viewer [&lt;number&gt;] setSize &lt;width&gt; &lt;height&gt;</code><br>（仅限顶级模式）设置视图窗口的大小。宽度和高度指定的是实际的图形区域大小。窗口的大小可能会稍大一些，因为还包括视图装饰和窗口框架。</p><p><strong>注意</strong>：当视图未按请求的大小调整时，控制台会打印警告消息。设置新大小时，可能出现以下情况导致视图未能按请求大小调整：</p><ul><li>视图在顶级窗口中，且给定的大小太小（例如：10x10）。</li><li>视图不在顶级窗口中，且主窗口无法调整为更小的尺寸（例如，Mac上的统一标题和工具栏或具有最小宽度的停靠窗口阻止了主窗口调整大小）。</li></ul><p><code>viewer [&lt;number&gt;] getSize</code><br>返回不带装饰和窗口框架的视图窗口大小。</p><p><code>viewer [&lt;number&gt;] setCamera &lt;camera-string&gt;</code><br>恢复所有相机设置。相机字符串应为 getCamera 命令的输出。</p><p><code>viewer [&lt;number&gt;] getCamera</code><br>此命令返回当前的相机设置，即位置、方向、焦距、类型和高度角（用于透视相机）或高度（用于正交相机）。这些值以 Avizo 命令的形式返回，可以执行这些命令以恢复相机设置。完整的命令字符串也可以传递给 setCamera 一次执行。</p><p><code>viewer [&lt;number&gt;] setCameraPosition &lt;x&gt; &lt;y&gt; &lt;z&gt;</code><br>定义相机在世界坐标中的位置。</p><p><code>viewer [&lt;number&gt;] getCameraPosition</code><br>返回相机在世界坐标中的位置。</p><p><code>viewer [&lt;number&gt;] setCameraOrientation &lt;x&gt; &lt;y&gt; &lt;z&gt; &lt;a&gt;</code><br>定义相机的方向。默认情况下，相机朝负z方向看，y轴向上。任何其他方向可以作为相对于默认方向的旋转来指定。旋转由一个旋转轴 x y z 以及旋转角度 a（以弧度为单位）指定。</p><p><code>viewer [&lt;number&gt;] getCameraOrientation</code><br>以与 setCameraOrientation 相同的格式返回当前相机的方向。</p><p><code>viewer [&lt;number&gt;] setCameraFocalDistance &lt;value&gt;</code><br>定义相机的焦距。焦距用于计算在交互查看模式下场景旋转的中心。</p><p><code>viewer [&lt;number&gt;] getCameraFocalDistance</code><br>返回当前相机的焦距。</p><p><code>viewer [&lt;number&gt;] setCameraHeightAngle &lt;degrees&gt;</code><br>以角度设置透视相机的高度角。减小角度会使视野变小，从而“放大”效果，类似于远摄镜头。如果不专门想改变相机的视野，通常更好的方法是将相机移得更近来放大对象。这条命令对正交相机无效。</p><p><code>viewer [&lt;number&gt;] getCameraHeightAngle</code><br>返回透视相机的高度角。</p><p><code>viewer [&lt;number&gt;] setCameraHeight &lt;height&gt;</code><br>设置正交相机视图体积的高度。此命令对透视相机无效。</p><p><code>viewer [&lt;number&gt;] getCameraHeight</code><br>返回正交相机的高度。</p><p><code>viewer [&lt;number&gt;] setCameraType &lt;perspective|orthographic&gt;</code><br>设置相机的类型，参数为透视（perspective）或正交（orthographic）。</p><p><code>viewer [&lt;number&gt;] getCameraType</code><br>返回当前相机的类型。</p><p><code>viewer [&lt;number&gt;] setTransparencyType &lt;type&gt;</code><br>此命令定义透明对象渲染策略。类型参数是介于0到8之间的数字，分别对应以下透明度模式：Screen Door、Add、Add Delayed、Add Sorted、Blend、Blend Delayed、Blend Sorted、Sorted Layers 和 Sorted Layers Delayed。建议使用模式8以获得最准确的结果，默认使用模式6。</p><p><code>viewer [&lt;number&gt;] getTransparencyType</code><br>返回当前使用的透明度模式。</p><p><code>viewer [&lt;number&gt;] setSortedLayersNumPasses &lt;value&gt;</code><br>当透明度模式为Sorted Layers或Sorted Layers Delayed时，此命令设置渲染的通过次数。通常，4次通过（默认值）能给出良好的效果。</p><p><code>viewer [&lt;number&gt;] getSortedLayersNumPasses</code><br>返回使用的渲染通过次数。</p><p><code>viewer [&lt;number&gt;] setBackgroundColor &lt;r&gt; &lt;g&gt; &lt;b&gt;</code><br>设置背景颜色，颜色值可以用RGB整数值（0到255）或小数（0.0到1.0）表示，也可以直接使用文本（如”white”）。</p><p><code>viewer [&lt;number&gt;] getBackgroundColor</code><br>返回主背景颜色，以RGB三元组（0到1之间的值）表示。</p><p><code>viewer [&lt;number&gt;] setBackgroundColor2 &lt;r&gt; &lt;g&gt; &lt;b&gt;</code><br>设置次背景颜色，次背景颜色用于非均匀背景模式。</p><p><code>viewer [&lt;number&gt;] getBackgroundColor2</code><br>返回次背景颜色，以RGB三元组（0到1之间的值）表示。</p><p><code>viewer setBackgroundMode &lt;mode&gt;</code><br>允许指定不同的背景模式。如果 mode 设置为 0，将显示均匀的背景。mode 1 表示渐变背景。mode 2 会显示棋盘格模式，这有助于理解透明对象的形状。最后，mode 3 在背景中绘制通过 setBackgroundImage 预定义的图像。</p><p><code>viewer getBackgroundMode</code><br>返回当前的背景模式。</p><p><code>viewer setBackgroundImage &lt;imagefile&gt; [&lt;imagefile2&gt;] [-stereo]</code><br>此命令允许在查看器背景中放置任意光栅图像。图像不得大于查看器窗口，否则会被裁剪。将通过文件扩展名自动检测图像文件格式，支持的格式与 snapshot 命令相同，除了 EPS 格式外。如果指定了第二个图像文件，并且使用的是立体渲染模式，则此文件将用作右眼图像。如果指定了 -stereo 选项且只有一个图像文件，则假设该文件包含左右眼的组合视图，并将自动分离这些视图。</p><p><code>viewer getBackgroundImage</code><br>返回通过 setBackgroundImage 定义的最后一个背景图像文件的文件名。如果指定了一对立体图像，则返回两个文件名。如果 setBackgroundImage 使用了 -stereo 选项，则也会返回该选项。</p><p><code>viewer [&lt;number&gt;] setAutoRedraw &lt;state&gt;</code><br>如果 state 为 0，则自动重绘模式关闭。在这种情况下，查看器窗口中的图像不会更新，除非发送 redraw 命令。如果 state 为 1，自动重绘模式再次开启。在脚本中，临时禁用自动重绘模式可能会很有用。</p><p><code>viewer [&lt;number&gt;] isAutoRedraw</code><br>返回自动重绘模式是否开启的状态。</p><p><code>viewer [&lt;number&gt;] redraw</code><br>此命令强制当前场景重新绘制。如果自动重绘模式已禁用，则只需要进行明确的重绘。</p><p><code>viewer [&lt;number&gt;] rotate &lt;degrees&gt; [x|y|z|m|u|v]</code><br>绕轴旋转相机。通过第二个参数指定轴，以下选项可用：x、y、z、m、u、v。</p><p>• x: the x-axis (1,0,0)<br>• y: the y-axis (0,1,0<br>• z: the z-axis (0,0,1)<br>• m: the most vertical axis of x, y, or z<br>• u: the viewer’s up direction<br>• v: the view direction</p><p>最后一个选项的作用与用户界面的旋转按钮相同。在大多数情况下，m 选项最合适。为了向后兼容，默认值为 u。</p><p><code>viewer [&lt;number&gt;] setDecoration &lt;state&gt;</code><br>此命令已废弃。</p><p><code>viewer [&lt;number&gt;] saveScene [-b] [-r] [-z] &lt;filename&gt;</code><br>将查看器中显示的所有几何体保存为 Open Inventor 3D 图形格式文件。请注意：由于许多 Avizo 模块使用了自定义的 Open Inventor 节点，场景通常无法在外部程序（如 ivview）中正确显示。可用的选项如下：</p><p>-b: 以二进制格式保存 Open Inventor 文件。<br>-r: 保存查看器中显示的几何体以及其他属性。<br>-z: 将 Open Inventor 文件保存为压缩格式（使用 zip 压缩）。</p><p><code>viewer [&lt;number&gt;] viewAll</code><br>重置相机，使整个场景可见。此方法会自动在查看器中显示第一个对象时调用。</p><p><code>viewer [&lt;number&gt;] show</code><br>打开指定的查看器，并确保查看器窗口位于屏幕上的所有其他窗口之上。</p><p><code>viewer [&lt;number&gt;] hide</code><br>关闭指定的查看器。</p><p><code>viewer [&lt;number&gt;] isVisible</code><br>此命令显示指定的查看器是否可见。</p><p><code>viewer [&lt;number&gt;] fogRange &lt;min&gt; &lt;max&gt;</code><br>设置雾效的衰减范围，该范围可通过视图菜单引入查看器场景。默认范围为 [0, 1]。范围内的值对应于场景点距相机的距离，其中离相机最近的点的值为 0，最远的点的值为 1。限制衰减范围意味着衰减将在指定最小值达到时开始，并在指定最大值达到时达到最大。由于雾效的最大衰减与不可见性相同，因此所有超过最大值的点将显示为背景。</p><p><code>viewer [&lt;number&gt;] setVideoFormat pal|ntsc</code><br>设置视图窗口的尺寸为 PAL 601 或 NTSC 601 分辨率，即 720x576 像素或 720x486 像素。当前装饰设置将被考虑在内。</p><p><code>viewer [&lt;number&gt;] setVideoFrame &lt;state&gt;</code><br>如果 state 为 1，则在查看器的覆盖平面中显示一个帧。这一帧显示了视频播放器上安全显示图像的区域。设置为 0 则关闭此帧。注意：在覆盖平面中显示的对象不会通过 snapshot 命令保存到文件中。</p><p><code>viewer [&lt;number&gt;] getViewerSpinAnimation</code><br>如果查看器旋转动画已启用，返回 1，否则返回 0。</p><p><code>viewer [&lt;number&gt;] setViewerSpinAnimation &lt;state&gt;</code><br>如果 state 为 1，启用查看器旋转动画。否则，传递 0 作为状态将关闭查看器旋转动画。注意：查看器旋转动画的状态会保存为首选项，因此重启 Avizo 后仍保持不变。</p><p><code>viewer [&lt;number&gt;] setViewing &lt;state&gt;</code><br>开启或关闭查看器的查看状态。如果 state 为 1，查看器进入查看模式；如果为 0，关闭查看模式。</p><p>设置查看器的查看状态。如果 state 为 0，查看器切换到交互模式；如果为 1，则切换到查看模式。</p><p><code>viewer [&lt;number&gt;] getViewing</code><br>返回当前查看状态：0 表示交互模式，1 表示查看模式。</p><p><code>viewer [&lt;number&gt;] linkViewers [&lt;ID&gt;...]</code><br>此命令用于将多个查看器链接在一起。它的操作与相应的 GUI 操作一致。</p><p><code>viewer [&lt;number&gt;] unlinkViewers [&lt;ID&gt;...] [all]</code><br>此命令用于取消已链接的查看器。</p><h4 id="9-3-4-2-主窗口命令选项"><a href="#9-3-4-2-主窗口命令选项" class="headerlink" title="9.3.4.2 主窗口命令选项"></a>9.3.4.2 主窗口命令选项</h4><p>命令 theMain 允许你访问并控制 Avizo 的主窗口。除了下列列出的特定命令选项外，所有在 9.3.4.4 节（顶层窗口的通用命令）中列出的子命令也可以使用。</p><h5 id="命令：-1"><a href="#命令：-1" class="headerlink" title="命令："></a>命令：</h5><p><code>theMain snapshot filename</code><br>创建并保存主窗口的快照图像。图像文件的格式由文件名扩展名决定。任何 Avizo 支持的标准图像文件格式都可以使用，例如 .jpg、.tif、.png 或 .bmp。</p><p><code>theMain setViewerTogglesOnIcons &#123;0|1&#125;</code><br>启用或禁用 Avizo 项目视图中对象图标上的橙色查看器切换。</p><p><code>theMain ignoreShow [0|1]</code><br>启用或禁用特殊用途的 “no show” 标志。如果设置了该标志，后续的 mainWindow show 命令将被忽略。这对于在 Avizo XScreen 扩展环境中运行标准 Avizo 脚本非常有用。如果不带参数调用该命令，则仅返回标志的当前值。</p><p><code>theMain showConsole [0|1]</code><br>启用或禁用 Avizo 中控制台窗口的显示。</p><h5 id="9-3-4-3-控制台命令选项"><a href="#9-3-4-3-控制台命令选项" class="headerlink" title="9.3.4.3 控制台命令选项"></a>9.3.4.3 控制台命令选项</h5><p>命令 theMsg 允许您访问和控制 Avizo 控制台窗口。除了下列的特定命令选项外，9.3.4.4 节（顶层窗口的通用命令）中列出的所有子命令也可以使用。</p><p>命令：</p><p><code>theMsg error &lt;message&gt; [&lt;btn0-text&gt;] [&lt;btn1-text&gt;] [&lt;btn2-text&gt;]</code><br>弹出一个带有指定消息的错误对话框。该对话框可以配置多达三个不同的按钮。命令会阻塞，直到用户按下按钮。返回按下按钮的 ID。</p><p><code>theMsg warning &lt;message&gt; [&lt;btn0-text&gt;] [&lt;btn1-text&gt;] [&lt;btn2-text&gt;]</code><br>弹出一个带有指定消息的警告对话框。对话框可以配置多达三个不同的按钮。命令会阻塞，直到用户按下按钮。返回按下按钮的 ID。</p><p><code>theMsg question &lt;message&gt; [&lt;btn0-text&gt;] [&lt;btn1-text&gt;] [&lt;btn2-text&gt;]</code><br>弹出一个带有指定消息的问题对话框。该对话框可以配置多达三个不同的按钮。命令会阻塞，直到用户按下按钮。返回按下按钮的 ID。</p><p><code>theMsg overwrite &lt;filename&gt;</code><br>弹出一个对话框，询问用户是否可以覆盖指定的文件。如果用户点击“确定”，则返回 1，否则返回 0。</p><h4 id="9-3-4-4-顶层窗口的通用命令"><a href="#9-3-4-4-顶层窗口的通用命令" class="headerlink" title="9.3.4.4 顶层窗口的通用命令"></a>9.3.4.4 顶层窗口的通用命令</h4><p>这些命令适用于所有打开独立顶层窗口的 Avizo 对象，特别是 Avizo 主窗口（theMain）、控制台窗口（theMsg）和查看器窗口（viewer 0）。例如，您可以使用相应的全局命令和 setPosition 或 getPosition 来设置或获取这些窗口的位置。</p><h5 id="命令：-2"><a href="#命令：-2" class="headerlink" title="命令："></a>命令：</h5><ul><li><p><code>getFrameGeometry</code><br>返回窗口的位置和大小，包括窗口框架。共返回四个数字。前两个数字表示窗口框架左上角相对于桌面左上角的位置，后两个数字表示窗口的大小（像素）。</p></li><li><p><code>getGeometry</code><br>返回窗口的位置和大小，不包括窗口框架。共返回四个数字。前两个数字表示窗口左上角相对于桌面左上角的位置，后两个数字表示窗口的大小（像素）。</p></li><li><p><code>getPosition</code><br>返回窗口左上角的位置，包括窗口框架。此结果与 getFrameGeometry 返回的前两个数字相同。</p></li><li><p><code>getRelativeGeometry</code><br>返回窗口的位置和大小，包括窗口框架，以相对坐标表示。桌面的大小为 (1,1)。窗口的位置和大小以 0 到 1 之间的小数表示。</p></li><li><p><code>getSize</code><br>返回窗口的大小，不包括窗口框架。此结果与 getGeometry 返回的后两个数字相同。</p></li><li><p><code>hide</code><br>隐藏窗口。</p></li><li><p><code>setCaption &lt;text&gt;</code><br>设置显示在窗口框架中的窗口标题。</p></li><li><p><code>setFrameGeometry &lt;x y width height&gt;</code><br>设置窗口的位置和大小，包括窗口框架。需要指定四个数字，即 x 和 y 位置、窗口宽度和高度。</p></li><li><p><code>setGeometry &lt;x y width height&gt;</code><br>设置窗口的位置和大小，不包括窗口框架。需要指定四个数字，即 x 和 y 位置、窗口宽度和高度。</p></li><li><p><code>setPosition &lt;x y&gt;</code><br>设置窗口的左上角位置，包括窗口框架。需要指定两个数字，即 x 和 y 坐标。</p></li><li><p><code>setRelativeGeometry &lt;x y width height&gt;</code><br>以相对桌面大小的比例设置窗口的位置和大小，包括窗口框架。输入值应该在 0 到 1 之间。</p></li><li><p><code>setSize &lt;width height&gt;</code><br>设置窗口的大小，不包括窗口框架。需要指定两个数字，即窗口的宽度和高度。</p></li><li><p><code>show</code><br>显示窗口。</p></li><li><p><code>showMinimized</code><br>使窗口在图标状态下可见。</p></li><li><p><code>showMaximized</code><br>使窗口在最大化状态下可见</p></li></ul><h4 id="9-3-4-5-进度条命令选项"><a href="#9-3-4-5-进度条命令选项" class="headerlink" title="9.3.4.5 进度条命令选项"></a>9.3.4.5 进度条命令选项</h4><p>workArea 命令允许你访问位于Avizo主窗口底部的进度条。你可以打印信息或检查是否按下了停止按钮。</p><h5 id="命令"><a href="#命令" class="headerlink" title="命令"></a>命令</h5><ul><li><p><code>workArea setProgressInfo &lt;text&gt;</code><br>设置要显示在进度条中的信息文本。该文本可用于描述某些计算期间的状态。</p></li><li><p><code>workArea setProgressValue &lt;value&gt;</code><br>设置进度条的值。该参数必须是0到1之间的浮点数。例如，值0.8表示当前任务已经完成了80%。</p></li><li><p><code>workArea startWorking [&lt;message&gt;]</code><br>激活停止按钮。调用此命令后，Avizo的停止按钮变为活动状态。在脚本中，可以通过调用workArea wasInterrupted来检查是否按下了停止按钮。当停止按钮处于活动状态时，除非在脚本中调用workArea stopWorking，否则无法与其他任何小部件进行交互。因此，不应直接在控制台窗口中输入此命令，而应仅在脚本文件或Tcl过程（procedure）中使用它。</p></li><li><p><code>workArea stopWorking</code><br>停用停止按钮。当通过workArea startWorking启动的计算任务完成或用户按下停止按钮时，调用此命令。该命令还会恢复调用startWorking之前显示的进度信息文本。</p></li><li><p><code>workArea wasInterrupted</code><br>检查用户是否按下了停止按钮。此命令应仅在workArea startWorking和workArea stopWorking之间使用。如果有多个嵌套计算任务且用户按下了停止按钮，那么在到达第一级之前，后续所有对wasInterrupted的调用都将返回true。</p></li></ul><h4 id="9-3-4-6-应用程序命令选项"><a href="#9-3-4-6-应用程序命令选项" class="headerlink" title="9.3.4.6 应用程序命令选项"></a>9.3.4.6 应用程序命令选项</h4><p>app 命令提供了与Avizo本身相关的几个选项，而不是特定于某个对象或组件。</p><h5 id="命令-1"><a href="#命令-1" class="headerlink" title="命令"></a>命令</h5><ul><li><p><code>app version</code><br>返回当前的Avizo版本。</p></li><li><p><code>app uname</code><br>返回简化的操作系统名称。</p></li><li><p><code>app arch</code><br>返回Avizo的架构字符串，例如arch-Win32VC8-Optimize、arch-LinuxAMD64-Optimize。</p></li><li><p><code>app hostid</code><br>返回创建Avizo许可证密钥所需的主机ID。</p></li><li><p><code>app listen [port]</code><br>打开一个套接字，Tcl命令可以通过该套接字发送。可以选择性地指定TCP/IP端口。<br>警告： 这可能会创建安全漏洞。除非在防火墙后且您明确知道自己在做什么，否则请勿使用此功能。</p></li><li><p><code>app close</code><br>关闭Avizo Tcl端口。</p></li><li><p><code>app port</code><br>返回Avizo Tcl端口号。如果套接字未打开，则返回-1。</p></li><li><p><code>app send &lt;command&gt; [&lt;host&gt; [&lt;port&gt;]]</code><br>将Tcl命令发送到监听的Avizo实例。如果未指定主机或端口，则Avizo实例会将命令发送给自己。</p></li><li><p><code>app opengl</code><br>检索有关所用 OpenGL 驱动程序的信息，包括版本号和支持的扩展。如果报告渲染问题，这些信息可以发送到热线。</p></li><li><p><code>app cluster</code><br>返回当前节点状态，如果某个集群模式处于活动状态，则该状态可以是“主”或“从”，否则，则简单地为“单个”。</p></li><li><p><code>app memTotal [-k | -m | -g]</code><br>返回系统的物理内存（以字节为单位）。可选开关 -k、-m、-g 分别将输出转换为千字节、兆字节或千兆字节。</p></li><li><p><code>app memAvail [-k | -m | -g]</code><br>返回系统的可用内存（以字节为单位）。可选开关 -k、-m、-g 分别将输出转换为千字节、兆字节或千兆字节。请注意，根据操作系统的不同，输出可能与其他工具报告的输出不同。</p></li></ul><h4 id="9-3-4-7-其他全局命令"><a href="#9-3-4-7-其他全局命令" class="headerlink" title="9.3.4.7 其他全局命令"></a>9.3.4.7 其他全局命令</h4><h5 id="命令-2"><a href="#命令-2" class="headerlink" title="命令"></a>命令</h5><ul><li><p><code>addTimeout msec procedure [arg]</code><br>安排在 msec 毫秒后调用 Tcl 过程。如果指定了 arg，它将作为参数传递给该过程。指定的过程只会被调用一次。如果需要，您可以在超时过程中再次安排它。例如：addTimeout 10000 echo {10 seconds are over.}</p></li><li><p><code>all [-selected | -visible | -hidden] [type]</code><br>返回当前在项目视图中的所有 Avizo 对象的列表。如果指定了 type，则只返回具有该 C++ 类类型（或派生对象）的对象。搜索可以分别限于已选择的、可见的或隐藏的对象。例如：all -hidden HxColormap.</p></li><li><p><code>aminfo [-a outfile|-b outfile] Avizo-File</code><br>如果只使用文件名作为参数，此命令将打开必须是 Avizo 数据格式的文件并打印头信息。如果使用 -a 或 -b 选项，则指定为参数的输出文件 outfile 将分别以 ASCII (-a) 或二进制 (-b) 格式写入。因此，aminfo 可用于将二进制 Avizo 数据转换为 ASCII，反之亦然。</p></li><li><p><code>clear</code><br>清除控制台窗口。</p></li><li><p><code>create class name [instance name]</code><br>创建 Avizo 对象（如模块或数据对象）的实例。返回实例名称。请注意，数据对象通常不是通过这种方式创建的，而是通过从文件加载它们。例如：create HxOrthoSlice MySlice.</p></li><li><p><code>dso options</code><br>控制动态库（“动态共享对象”）的加载。提供以下选项：</p></li></ul><p><code>addPath path ...</code>: 添加路径到加载动态库时搜索的目录列表中。<br><code>verbose &#123;0|1&#125;</code>: 开启或关闭与动态库相关的调试信息。<br><code>open &lt;package&gt;</code>: 尝试加载指定的动态库。只需指定包名，例如 hxfield。此名称将自动转换为平台相关的名称，例如 Linux 上的 libhxfield.so 或 Windows 上的 hxfield.dll。<br><code>unloadPackage &lt;package&gt;</code>: 卸载（如果可能）指定的动态库。<br><code>execute &lt;package&gt; &lt;function&gt;</code>: 执行在指定动态库中定义的函数。</p><ul><li><p><code>echo args</code><br>将其参数打印到 Avizo 控制台。请使用此命令，而不是原生的 Tcl 命令 puts，后者会打印到标准输出。</p></li><li><p><code>help arguments</code><br>不带参数时，打开 Avizo 帮助浏览器。</p></li><li><p><code>httpd [port]</code><br>启动内置的HTTP服务器。HTTP服务器将交付任何请求的文档。如果请求的文档以“.hx”结尾，Avizo将不会交付它，而是将其作为Tcl脚本执行。这可以用于从网页浏览器控制Avizo。<strong>警告：</strong>该命令可能会产生安全漏洞，除非你在防火墙后且清楚自己在做什么，否则不要使用此功能。</p></li><li><p><code>limit &#123;datasize | stacksize | coredumpsize&#125; size</code><br>更改进程限制。仅适用于Unix平台。使用“unlimited”作为无限制的大小。大小必须以字节为单位指定。或者，你可以使用1000k表示1000千字节或1m表示1兆字节。</p></li><li><p><code>load [fileformat] options files</code><br>从一个或多个文件中加载数据。可以选择指定文件格式以覆盖Avizo的自动文件格式识别。文件格式使用与在Avizo文件对话框中的文件格式组合框中显示的标签相同。使用全局命令fileFormats可以获得Avizo支持的所有文件格式列表。可以使用FTP或HTTP协议读取远程文件。</p></li></ul><p>其他选项包括：</p><ul><li><code>browse</code>：显示打开数据窗口。</li><li><code>avizoscript</code>：打开Avizo脚本文件。</li><li><code>avizo</code>：Avizo的本地通用文件格式。用于加载许多不同的数据对象，如在规则或四面体网格上定义的字段、分割结果、颜色映射或顶点集（如地标）。</li><li><code>dataOnly</code>：阻止导入器创建显示模块，适用于hx文件。</li></ul><p>继续翻译如下：</p><ul><li><code>load [fileformat] options files</code></li></ul><p>从一个或多个文件中加载数据。可以选择指定文件格式以覆盖Avizo的自动文件格式识别。文件格式使用与在Avizo文件对话框中的文件格式组合框中显示的标签相同。使用全局命令fileFormats可以获得Avizo支持的所有文件格式列表。可以使用FTP或HTTP协议读取远程文件。</p><p>其他选项包括：</p><ul><li>browse：显示打开数据窗口。</li><li>avizoscript：打开Avizo脚本文件。</li><li>avizo：Avizo的本地通用文件格式。用于加载许多不同的数据对象，如在规则或四面体网格上定义的字段、分割结果、颜色映射或顶点集（如地标）。</li><li>dataOnly：阻止导入器创建显示模块，适用于hx文件。</li></ul><p>Options for raw data:<br>load -raw FileName Endianess IndexOrder<br>DataType nDataVar dimX dimY dimZ<br>xMin xMax yMin yMax zMin zMax</p><p>Options for DICOM data:</p><ul><li><p>nodialog: option prevent the Dicom dialog box from being shown.</p></li><li><p><code>mem</code><br>Prints out some memory statistics.</p></li><li><p><code>quit</code><br>Immediately quits Avizo.</p></li><li><p><code>remove fobjectname | -all | -selectedg</code><br>Removes objects from Project View.<br>• objectname: the specified Avizo object.<br>• -all: all objects.<br>• -selected: selected objects.</p></li></ul><p>从项目视图中删除对象。<br>• objectname：指定的 Avizo 对象。<br>• -all：所有对象。<br>• -selected：选定对象。</p><ul><li><p><code>removeTimeout procedure [arg]</code><br>Unschedules a Tcl procedure previously scheduled with addTimeout.<br>取消先前使用 addTimeout 安排的 Tcl 过程。</p></li><li><p><code>rename objectname newname</code><br>Changes instance name of an object. Identical to objectname setLabel newname, except that it<br>returns 1 if successful, and nothing if unsuccessful.<br>更改对象的实例名称。与 objectname setLabel newname 相同，不同之处在于如果成功则返回 1，如果不成功则不返回任何内容。</p></li><li><p><code>sleep sec</code><br>Waits for sec seconds. Avizo will not process events in that time.<br>等待 sec 秒。Avizo 将不会在这段时间内处理事件。</p></li><li><p><code>source filename</code><br>Loads and executes Tcl commands from the specified file. If the script file contains the extension<br>.hx, the load command may be used as well.<br>从指定文件加载并执行 Tcl 命令。如果脚本文件包含扩展名 .hx，也可以使用加载命令。</p></li><li><p><code>system command</code><br>Executes an external program. Do not use this unless you know what you are doing.<br>执行外部程序。除非您知道自己在做什么，否则不要使用此功能。</p></li><li><p><code>saveProject</code><br>Saves current project. If the project is not previously saved, then the project will be saved in the<br>Avizo root dir as Untitled.hx.<br>保存当前项目。如果之前未保存该项目，则该项目将作为 Untitled.hx 保存在 Avizo 根目录中。</p></li><li><p><code>saveProjectAs [-forceAutoSave | -packAndGo] arg</code><br>A copy of the current project will be saved as arg in Avizo root dir.(e.g., saveProjectAs<br>myProject). When using a path, a full path needs to be specified and a .hx extension needs to be<br>added on the project name (e.g., saveProjectAs c:/work/myProject.hx). Optionally, a<br>forceAutoSave parameter can be specified to force auto saving of modified data without displaying<br>a warning dialog. If parameter packAndGo is specified, in the same folder where the project file<br>is saved, a new folder will be created and it will contain all data necessary for loading the saved<br>project. Note: If a file exists it will not be overwritten.<br>当前项目的副本将作为 arg 保存在 Avizo 根目录中。（例如，saveProjectAs<br>myProject）。使用路径时，需要指定完整路径，并在项目名称上添加 .hx 扩展名（例如，saveProjectAs c:/work/myProject.hx）。或者，可以指定 forceAutoSave 参数以强制自动保存修改后的数据而不显示警告对话框。如果指定了参数 packAndGo，则在保存项目文件的同一文件夹中，将创建一个新文件夹，其中包含加载已保存项目所需的所有数据。注意：如果文件存在，则不会覆盖它。</p></li><li><p><code>theObjectPool setSelectionOrder ffirst objectg fsecond objectg...</code><br>This command reorders the selection so that it matches the given object order. Selected objects not contained inside this list will be moved at the end of the selection (their relative order will not be<br>changed though).<br>此命令将重新排列所选内容，使其与给定的对象顺序相匹配。不包含在此列表中的所选对象将移动到所选内容的末尾（但它们的相对顺序不会改变）。</p></li><li><p><code>thePreferences [save | load] filename</code><br>This command saves or loads preferences to/from the file specified as filename.<br>此命令将首选项保存到指定为文件名的文件中，或从指定为文件名的文件中加载首选项。</p></li><li><p><code>theProperties [show | hide]</code><br>This command shows or hides the Properties panel in Avizo.<br>此命令显示或隐藏 Avizo 中的属性面板。</p></li><li><p><code>theProjectView [show | hide]</code><br>This command shows or hides the Project View panel in Avizo.<br>此命令显示或隐藏 Avizo 中的项目视图面板。</p></li><li><p><code>fileFormats</code><br>Shows all file formats which can be used in Avizo.<br>显示可在 Avizo 中使用的所有文件格式。</p></li></ul><h3 id="9-3-5-Avizo-脚本文件"><a href="#9-3-5-Avizo-脚本文件" class="headerlink" title="9.3.5 Avizo 脚本文件"></a>9.3.5 Avizo 脚本文件</h3><p>值得注意的是，一个 Avizo 项目本质上就是一个 Tcl 脚本，它能够重新生成当前的 Avizo 状态。因此，通常可以通过交互式地创建一个 Avizo 项目，将其保存为“保存项目”，并使用它作为脚本编写的起点。</p><p>在 Avizo 中执行 Tcl 命令的最简单方式是在 Avizo 控制台窗口中输入命令。然而，对于像循环或过程这样的多行结构，使用这种方式并不实用。在这种情况下，建议将 Tcl 代码写入文件，并通过 source 文件名 命令执行该文件。你还可以在一个文件中使用 source 命令以包含另一个文件的内容。</p><p>另一种方法是使用 load 文件名 命令或通过文件菜单中的“打开项目…”选项并使用文件浏览器加载文件。不过，要让 Avizo 识别该文件格式，文件名必须以 .hx 结尾，或者文件内容必须以以下标题行开头：</p><figure class="highlight tcl"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Avizo Script</span></span><br></pre></td></tr></table></figure><p>在 Avizo 启动时，有一些 Tcl 文件会被自动加载。启动时，程序会查找当前目录或主目录中的 .Avizo 文件（详见 9.2.3 节，启动脚本）。如果没有找到这样的用户自定义启动脚本，默认的初始化脚本 Avizo.init 将从 $AVIZO_LOCAL/share/resources/Avizo 或 $AVIZO_ROOT/share/resources/Avizo 目录加载。该脚本随后会读取所有 .rc 文件，这些文件用于注册模块和数据类型。因此，用户可以通过简单地向该目录添加新的 .rc 文件或修改 Avizo.init 文件来自定义 Avizo 的启动行为。</p><p>另一种执行 Tcl 代码的方式是定义与功能键相关联的过程。如果存在名为 onKeyF2、onKeyF3、…、onKeyShiftF2、…、onKeyCtrlF2、… 等的预定义过程，当相应的键在 Avizo 主窗口、控制台窗口或查看器窗口中按下时，这些过程将被自动调用。要定义这些过程，可以将其写入一个文件并使用 source 加载，或者将其写入 Avizo.init 或某个 .rc 文件中。例如：</p><figure class="highlight tcl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">proc</span><span class="title"> onKeyF2</span> &#123; &#125; &#123;</span><br><span class="line">  echo <span class="string">&quot;Key F2 was hit&quot;</span></span><br><span class="line">  viewer <span class="number">0</span> viewAll</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>注意：<br>某些功能键已保留给 Avizo 特定的操作。例如，[F1] 永远用于帮助，[F2] 在项目视图或树视图中用于对象重命名。</p><p>最后，Tcl 脚本也可以在 GUI 中表示并与用户界面结合使用。在 Avizo 中，这被称为脚本模块。</p><h3 id="9-3-6-配置弹出菜单"><a href="#9-3-6-配置弹出菜单" class="headerlink" title="9.3.6 配置弹出菜单"></a>9.3.6 配置弹出菜单</h3><p>在 Avizo 中，所有可以附加到数据对象的模块都会列在对象的弹出菜单中，该菜单通过右键单击对象图标激活。对于某些应用来说，在创建新模块后使用 Tcl 命令自定义这些模块是有意义的。有时还需要在对象的弹出菜单中添加新条目，以执行特定的脚本。本节将介绍如何通过修改 Avizo 资源文件或创建新文件来实现这些目标。</p><p>Avizo 的资源文件位于目录 $AVIZO_ROOT/share/resources 中，其中 $AVIZO_ROOT 表示 Avizo 的安装目录。资源文件实际上是普通的脚本文件，只是使用 .rc 作为后缀。当 Avizo 启动时，资源目录中的所有资源文件都会被读取。在资源文件中，可以使用特殊的 Tcl 命令注册模块、编辑器和 IO 例程。注册一个模块意味着指定它在弹出菜单中的名称，它可以附加的对象类型，模块所在的共享库或 DLL 的名称，等等。例如，Multi-Thresholding 模块通过以下命令在文件 hxlattice.rc 中注册：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">module -name &quot;Multi-Thresholding&quot; \</span><br><span class="line">-check &#123; ![$PRIMARY hasInterface HxLabelLattice3] &amp;&amp;</span><br><span class="line"><span class="meta prompt_">([$</span><span class="language-bash">PRIMARY primType]&lt;3 || [<span class="variable">$PRIMARY</span> primType]==7 || [<span class="variable">$PRIMARY</span> primType]==8) &#125; \</span></span><br><span class="line"><span class="language-bash">-primary <span class="string">&quot;HxUniformScalarField3 HxStackedScalarField3&quot;</span> \</span></span><br><span class="line"><span class="language-bash">-category <span class="string">&quot;&#123;Image Segmentation&#125;&quot;</span> \</span></span><br><span class="line"><span class="language-bash">-class <span class="string">&quot;HxLabelVoxel&quot;</span> \</span></span><br><span class="line"><span class="language-bash">-dso <span class="string">&quot;libhxlattice.so&quot;</span></span></span><br></pre></td></tr></table></figure><p>该命令的不同选项具有以下含义：</p><ul><li>选项 -name 指定模块的名称或标签，它将显示在弹出菜单中。</li><li>选项 -primary 表示该模块可以附加到类型为 HxUniformScalarField3 或 HxStackedScalarField3 的数据对象上。这意味着 Multi-Thresholding 只会包含在这些对象的弹出菜单中。</li><li>选项 -check 指定一个附加的 Tcl 表达式，该表达式在菜单弹出之前会被执行。如果表达式失败，模块将从菜单中删除。对于 Multi-Thresholding 模块，它会检查输入对象是否提供了 HxLabelLattice3 接口，即输入是否是一个标签场。尽管标签图像可以被视为 3D 图像，但对其进行阈值分割是没有意义的。因此，Multi-Thresholding 仅对原始 3D 图像提供，而不适用于标签场。还会检查输入的原始数据类型（有符号/无符号整数、浮点、短整型等）。这里，Multi-Thresholding 模块不支持浮点或双精度标签图像输入。</li><li>选项 -category 表示 Multi-Thresholding 应该出现在主弹出菜单的 “Image Segmentation” 子菜单中。如果模块不应出现在子菜单中，而是直接在弹出菜单中显示，则应使用类别 Main。</li><li>选项 -class 指定模块的内部类名称。对象的内部类名称可以使用命令 getTypeId 检索。正是这个类名称必须用于上述的 -primary 选项，而不是通过 -name 定义的对象标签。</li><li>最后，选项 -package 指定定义该模块的包（共享库或 DLL）。</li></ul><p>除了这些标准选项，还可以使用额外的 -proc 选项指定在创建模块后执行的额外 Tcl 命令。例如，假设你在一个医疗项目中，需要识别头部 CT 图像中的立体定位标记。此时，可以在弹出菜单中添加一个 Multi-Thresholding 模块的自定义版本，并预定义适当的材质名称和阈值。可以通过在 $AVIZO_ROOT/share/resources 目录中添加一个新资源文件，或者直接在 hxlattice.rc 文件中添加以下命令来实现：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">module -name &quot;Stereotaxy&quot; \</span><br><span class="line">-primary &quot;HxUniformScalarField3 HxStackedScalarField3&quot; \</span><br><span class="line">-check &#123; ![$PRIMARY hasInterface HxLabelLattice3] &#125; \</span><br><span class="line">-category &quot;&#123;Image Segmentation&#125;&quot; \</span><br><span class="line">-class &quot;HxLabelVoxel&quot; \</span><br><span class="line">-package &quot;hxlattice&quot; \</span><br><span class="line">-proc &#123; $this regions setValue &quot;Exterior Bone Markers&quot;; \</span><br><span class="line"><span class="meta prompt_">$</span><span class="language-bash">this fire; \</span></span><br><span class="line"><span class="language-bash"><span class="variable">$this</span> boundary01 setValue 150; \</span></span><br><span class="line"><span class="language-bash"><span class="variable">$this</span> boundary12 setvalue 300 &#125;</span></span><br></pre></td></tr></table></figure><p>上述 Tcl 代码中的变量 $this 指的是新创建的模块，即 Multi-Thresholding 模块。注意，这些命令是在模块连接到弹出菜单的源对象之前执行的。某些模块在连接到新的输入对象时会进行一些特殊的初始化，这些初始化可能会覆盖使用自定义 -proc 选项通过 Tcl 命令设置的值。在这种情况下，可以通过以下命令显式连接模块到输入对象：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$</span><span class="language-bash">this data connect <span class="variable">$PRIMARY</span>;</span></span><br><span class="line"><span class="meta prompt_">$</span><span class="language-bash">this fire;</span></span><br></pre></td></tr></table></figure><p>其中 Tcl 变量 $PRIMARY 指的是输入对象。同样，该变量也用于上述 -check 选项中定义的 Tcl 表达式。</p><p>除了基于现有模块创建自定义弹出菜单条目外，还可以定义完全新的条目，这些条目只执行 Tcl 命令。例如，我们可以在每个 Avizo 对象的弹出菜单中添加一个新的子菜单“编辑”，并在此处放入通常包含在 Avizo 主窗口的“编辑”菜单中的“隐藏”、“删除”和“复制”命令。这可以通过以下方式实现：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">module -name &quot;Remove&quot; \</span><br><span class="line">    -primary &quot;HxObject&quot; \</span><br><span class="line">    -proc &#123; remove $PRIMARY &#125; \</span><br><span class="line">    -category &quot;Edit&quot;</span><br><span class="line">module -name &quot;Hide&quot; \</span><br><span class="line">    -primary &quot;HxObject&quot; \</span><br><span class="line">    -proc &#123; $PRIMARY hideIcon &#125; \</span><br><span class="line">    -category &quot;Edit&quot;</span><br><span class="line">module -name &quot;Duplicate&quot; \</span><br><span class="line">    -primary &quot;HxData&quot; \</span><br><span class="line">    -proc &#123; $PRIMARY duplicate &#125; \</span><br><span class="line">    -category &quot;Edit</span><br></pre></td></tr></table></figure><p>当然，也可以使用 <code>-proc</code> 命令执行普通的 Avizo 脚本，甚至 Avizo 脚本对象。</p><h3 id="9-3-7-注册点击回调函数"><a href="#9-3-7-注册点击回调函数" class="headerlink" title="9.3.7 注册点击回调函数"></a>9.3.7 注册点击回调函数</h3><p>点击回调函数是附加到模块或查看器上的 Tcl 过程。当点击事件发生在目标上时，会调用该回调函数。可以通过在模块或查看器上使用 Tcl 命令 setPickCallback 来注册此类回调：</p><figure class="highlight tcl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&lt;module&gt; setPickCallback &lt;<span class="keyword">proc</span>&gt; [&lt;EventType&gt;]<span class="title"></span></span><br><span class="line"><span class="title">viewer</span> &lt;n&gt;<span class="title"> setPickCallback</span> &lt;<span class="keyword">proc</span>&gt; [&lt;EventType&gt;]</span><br></pre></td></tr></table></figure><p>每个模块或查看器只能附加一个回调。为了分离回调，只需调用注册命令而不带参数：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&lt;module&gt; setPickCallback</span><br><span class="line">viewer &lt;n&gt; setPickCallback</span><br></pre></td></tr></table></figure><p>可选的 <code>&lt;EventType&gt;</code> 参数用于指定触发回调的事件类型。其他事件将被忽略。该参数可以取以下值：</p><ul><li>MouseButtonPress, MouseButtonRelease（任意鼠标按钮）</li><li>VRButtonPress, VRButtonRelease（任意3D按钮）</li><li>MouseButton1Press, MouseButton1Release 等（特定的鼠标按钮）</li><li>VRButton0Press, VRButton0Release 等（特定的3D按钮）</li></ul><p>默认值为 MouseButton1Press。</p><p>实际的回调过程 <code>&lt;proc&gt;</code> 预期接收一个参数，该参数被解释为一个关联数组，并编码所有点击信息。定义的元素如下：</p><ul><li>object：被点击几何体所属的 Avizo 对象的名称</li><li>x：被点击点的 x 坐标</li><li>y：被点击点的 y 坐标</li><li>z：被点击点的 z 坐标</li><li>idx：被点击元素的索引</li><li>stateBefore：事件发生之前的修饰符状态</li><li>stateAfter：事件发生之后的修饰符状态</li></ul><p>回调过程应返回 0，如果未处理点击事件，这样其他回调过程可以被调用。以下是一个示例：</p><figure class="highlight tcl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">proc</span><span class="title"> pickCallback</span> arg &#123;</span><br><span class="line">    <span class="keyword">array</span> <span class="keyword">set</span> a <span class="variable">$arg</span></span><br><span class="line">    echo <span class="string">&quot;$a(object) : picked element $a(idx)&quot;</span></span><br><span class="line">    <span class="keyword">return</span> <span class="number">1</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>请注意，任何模块都可以向该参数数组添加特定信息。所有元素可以通过以下方式显示：</p><figure class="highlight tcl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">proc</span><span class="title"> pickCallback</span> arg &#123;</span><br><span class="line">    echo <span class="string">&quot;arg = &#123; $arg &#125;&quot;</span></span><br><span class="line">    <span class="keyword">return</span> <span class="number">1</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>因此，一些 Avizo 模块会追加额外的数据：</p><ul><li>Vertex View：idx 是被点击的点索引</li><li>Point Cloud View：idx 是被点击的点索引</li><li>Line Set View：idx 是被点击的线索引，pt0 和 pt1 是被点击段的两个点</li><li>Surface View：idx 是被点击的三角形索引</li><li>Hexa/Tetra Grid View：idx 是被点击的三角形索引，tetra0 和 tetra1 是相邻的四面体</li><li>Grid Boundary：idx 是被点击的三角形索引，originalIdx 是网格中的索引，tetra0 和 tetra1 是相邻的四面体</li></ul><h3 id="9-3-8-文件读取器在Tcl中"><a href="#9-3-8-文件读取器在Tcl中" class="headerlink" title="9.3.8 文件读取器在Tcl中"></a>9.3.8 文件读取器在Tcl中</h3><p>本节介绍如何注册一个由Tcl实现的自定义文件读取器。</p><p>首先，需要在全局作用域中声明Tcl读取器函数。该函数必须接受一个文件列表作为输入参数，并返回成功读取的文件数量。</p><figure class="highlight tcl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">proc</span><span class="title"> myReaderInTcl</span> &#123;args&#125; &#123;</span><br><span class="line">    echo <span class="string">&quot;myReaderInTcl $args&quot;</span></span><br><span class="line"><span class="comment">    # 其他相关处理</span></span><br><span class="line">    <span class="keyword">return</span> <span class="number">1</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>接着，必须使用以下模板将Tcl读取器函数注册到目标文件格式声明中：</p><figure class="highlight tcl"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">dataFile -name <span class="string">&quot;MyFormat&quot;</span> ... -<span class="keyword">package</span> hxcore -<span class="keyword">load</span> hxReadByTcl -loadArgs <span class="string">&quot;-cmd myReaderInTcl&quot;</span></span><br></pre></td></tr></table></figure><p>使用 -loadArgs 来指定自定义的Tcl读取器函数。参数 -package hxcore -load hxReadByTcl 需按原样填写，不做修改。这些参数用于设置内部包装器，该包装器将调用Tcl解释器。</p><p>可以在Tcl脚本中声明自定义读取器，或将其包含在一个资源文件中，在应用程序启动时加载。</p><h2 id="9-4-使用-MATLAB-与-Avizo"><a href="#9-4-使用-MATLAB-与-Avizo" class="headerlink" title="9.4 使用 MATLAB 与 Avizo"></a>9.4 使用 MATLAB 与 Avizo</h2><p>本节介绍如何在 Avizo 中使用 MATLAB 脚本。</p><h3 id="9-4-1-使用-MATLAB-脚本"><a href="#9-4-1-使用-MATLAB-脚本" class="headerlink" title="9.4.1 使用 MATLAB 脚本"></a>9.4.1 使用 MATLAB 脚本</h3><p>在本教程中，您将学习如何通过使用 MATLAB 计算模块（The MathWorks, Inc.）将复杂的计算集成到 Avizo 中。</p><p>为了使用 MATLAB 计算模块，MATLAB 必须正确安装在您的计算机上。此外，为了使该模块能够与 MATLAB 计算引擎建立连接，您可能需要注册 MATLAB 引擎（在 Windows 上），并根据您的系统设置环境变量以包含 MATLAB 库或程序在搜索路径中。请参阅 MATLAB 计算模块的文档以了解安装细节和限制。</p><p>本教程，作为在线文档提供，涵盖了以下主题，通过各种示例进行讲解：</p><ul><li>加载和执行 MATLAB 脚本。</li><li>在 Avizo 和 MATLAB 之间传递各种数据类型，并将数据导出回 Avizo。</li><li>使用字段结构。</li><li>使用时间滑块控制脚本变量。</li><li>从脚本中调用用户自定义的 MATLAB 函数。</li><li>你可以通过这些步骤来学习如何将 MATLAB 的复杂计算功能与 Avizo 集成，从而执行更加精确和复杂的数据处理任务。</li></ul><h1 id="Python-Scripting"><a href="#Python-Scripting" class="headerlink" title="Python Scripting"></a>Python Scripting</h1><p><a href="https://www.thermofisher.cn/cn/zh/home/electron-microscopy/products/software-em-3d-vis/3d-visualization-analysis-software/python-scripting.html">Amira-Avizo Software and PerGeos Software Python Integration</a></p><p><a href="https://www.youtube.com/watch?v=tUlZFJj-aYs">Amira-Avizo Software | Introduction to Python scripting</a></p><p><a href="D:\Program Files\Avizo-2019.1\share\doc\python\html\index.html">Thermo Fisher Python API documentation</a></p><h2 id="11-6-Python-脚本编写"><a href="#11-6-Python-脚本编写" class="headerlink" title="11.6 Python 脚本编写"></a>11.6 Python 脚本编写</h2><p>本节描述了如何在Avizo中使用Python脚本。</p><h3 id="11-6-1-Python-文档"><a href="#11-6-1-Python-文档" class="headerlink" title="11.6.1 Python 文档"></a>11.6.1 Python 文档</h3><p>本章按如下方式组织：</p><p>11.6.1.1 Python 简介<br>11.6.1.2 内嵌 Python 的使用<br>11.6.1.3 常见的全局命令<br>11.6.1.4 模块管理<br>11.6.1.5 脚本对象<br>11.6.1.6 Python 环境和包管理器<br>11.6.1.7 Python 包列表<br>Avizo Python API 文档可以在此处查看。</p><blockquote><p>安装文件’\share\doc\python\html\index.html’</p></blockquote><h4 id="11-6-1-1-Python-简介"><a href="#11-6-1-1-Python-简介" class="headerlink" title="11.6.1.1 Python 简介"></a>11.6.1.1 Python 简介</h4><p>什么是Python</p><p>Python是一种高级的、面向对象的、解释型语言，首次实现于1989年。<br>(<a href="https://www.python.org/dev/peps/pep-0020/">https://www.python.org/dev/peps/pep-0020/</a>)</p><p>• Beautiful is better than ugly<br>• Explicit is better than implicit<br>• Simple is better than complex<br>• Complex is better than complicated<br>• Readability counts</p><ul><li>美比丑好</li><li>明确比隐含好</li><li>简单比复杂好</li><li>复杂比难懂好</li><li>可读性很重要</li><li>包含的内容</li></ul><p>Avizo 使用 Python 3.5.2。关于如何使用Python 3.X的详细信息可以在以下链接找到：<br><a href="https://docs.python.org/3.5/tutorial/index.html">https://docs.python.org/3.5/tutorial/index.html</a> 。许多包都已包含在Python的安装中（参见此处的Python包列表）。Numpy 和 Scipy 是此安装中包含的两个最流行的Python包。</p><p>Numpy 是用于处理多维数组的扩展，它允许元素操作、比较、逻辑操作、统计等。Numpy数组在C中实现，计算速度更快。更多信息请参见：<a href="http://www.numpy.org/">http://www.numpy.org/</a> 。</p><p>Scipy 是一个提供科学计算工具的扩展，例如插值、积分、图像处理、线性代数、信号处理和统计。更多信息请参见：<a href="http://www.scipy.org/">http://www.scipy.org/</a> 。</p><p>从 Python 2 迁移到 Python 3</p><p>Python 2 和 Python 3 之间存在一些兼容性问题。关于迁移到Python 3的官方文档可以在这里找到：<br><a href="https://docs.python.org/3.5/howto/pyporting.html">https://docs.python.org/3.5/howto/pyporting.html</a> 。</p><h5 id="11-6-1-1-1-使用-Python"><a href="#11-6-1-1-1-使用-Python" class="headerlink" title="11.6.1.1.1 使用 Python"></a>11.6.1.1.1 使用 Python</h5><p>本节并不旨在涵盖Python语言的所有应用和细节。要了解更多关于Python、Scipy和Numpy的信息，请参阅前一节中的链接。要了解Python如何与Avizo交互，请继续阅读第11.6.1.2节《内嵌Python的使用》。</p><h6 id="Python控制台"><a href="#Python控制台" class="headerlink" title="Python控制台"></a>Python控制台</h6><p>可以通过 Windows &gt; Consoles 访问控制台。控制台面板具有带有多个不同工具的标签界面。控制台充当Python解释器，因此任何编写的命令在按Enter键后将立即执行。执行后将显示赋值或返回值。</p><img src="/2024/09/19/AVIZO%E8%87%AA%E5%8A%A8%E5%8C%96/Figure11.4.png" class="" title="Figure 11.4: Accessing the Consoles"><img src="/2024/09/19/AVIZO%E8%87%AA%E5%8A%A8%E5%8C%96/Figure11.5.png" class="" title="Figure 11.5: Main Python Console Interface"><img src="/2024/09/19/AVIZO%E8%87%AA%E5%8A%A8%E5%8C%96/Figure11.6.png" class="" title="Figure 11.6: Python Script Object Console Interface"><p>从左到右图标：</p><ul><li>删除此内容：删除此解释器中显示的所有内容</li><li>删除 Pythonic 对象：这会从 Avizo 的工作区中删除控制台内创建的所有 Python 对象</li><li>重定向所有输出：这会将所有解释器的所有输出推送到主控制台</li><li>重定向此输出：这会将所有当前控制台的输出推送到主控制台</li></ul><p>控制台充当 Python 解释器，因此按下 Enter 后将立即执行任何书面命令。执行后将显示赋值或返回值。</p><h6 id="常用快捷键和命令"><a href="#常用快捷键和命令" class="headerlink" title="常用快捷键和命令"></a>常用快捷键和命令</h6><ul><li><p><code>TAB</code><br>在控制台没有编写任何内容时，按下TAB键会自动补全以下命令 hx_project.get(module)，该命令将为对象创建一个Python句柄。当控制台中有文本时，TAB键将尝试从可用方法、属性和模块列表中自动补全当前字符串。选中的项目会被补全。</p></li><li><p><code>UP</code> or <code>DOWN</code><br>这些按钮可以循环浏览您最近的历史记录。UP按钮可以检索上一个命令，而DOWN按钮可以检索后续命令。</p></li></ul><h5 id="11-6-1-1-2-关于Python的注意事项"><a href="#11-6-1-1-2-关于Python的注意事项" class="headerlink" title="11.6.1.1.2 关于Python的注意事项"></a>11.6.1.1.2 关于Python的注意事项</h5><h6 id="软件包"><a href="#软件包" class="headerlink" title="软件包"></a>软件包</h6><p>Python是一种面向对象的语言，这意味着代码通常会被分解为类，在实例化时变量和方法可以被对象继承。</p><p>这种方式可以避免重复编写经常使用的功能。关于Python面向对象编程（OOP）的更多信息，可以在以下链接中找到：<a href="http://www.tutorialspoint.com/python/python_classes_objects.htm">Python类和对象教程</a>。</p><p>软件包是类、方法和变量的集合，可以被导入到Python的命名空间中。例如，如果用户想要计算sin(π/2)，首先需要将Numpy软件包导入命名空间：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt;<span class="keyword">import</span> numpy</span><br></pre></td></tr></table></figure><p>Numpy软件包包含一个sin(x)方法，可以用于计算sin(π/2)：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt;numpy.sin(<span class="number">3.1415</span>/<span class="number">2</span>)</span><br><span class="line"><span class="number">0.99999999892691405</span></span><br></pre></td></tr></table></figure><p>Numpy已经包含了一个全局变量π，可以通过以下方式访问：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt;numpy.pi</span><br><span class="line"><span class="number">3.141592653589793</span></span><br><span class="line">&gt;&gt;&gt;numpy.sin(numpy.pi/<span class="number">2</span>)</span><br><span class="line"><span class="number">1.0</span></span><br></pre></td></tr></table></figure><p>导入软件包时，可以将其赋值给变量以简化代码：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt;<span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">&gt;&gt;&gt;np.sin(np.pi/<span class="number">2</span>)</span><br><span class="line"><span class="number">1.0</span></span><br></pre></td></tr></table></figure><h6 id="语法"><a href="#语法" class="headerlink" title="语法"></a>语法</h6><p>Python支持多种不同的对象类型：</p><div class="table-container"><table><thead><tr><th style="text-align:center">类型</th><th style="text-align:center">描述</th><th style="text-align:center">示例</th></tr></thead><tbody><tr><td style="text-align:center">Number</td><td style="text-align:center">Integers, floats, complex, booleans</td><td style="text-align:center">1, 1.05, 3j+2, 3&gt;2 is True</td></tr><tr><td style="text-align:center">String List</td><td style="text-align:center">Sequence of characters Container to group items that can be changed</td><td style="text-align:center">“String of charaters” [1, 5, “Dragon”, 948.5]</td></tr><tr><td style="text-align:center">Tuple</td><td style="text-align:center">Container to group items that cannot be changed</td><td style="text-align:center">(948.5, “Dragon”, 5, 1)</td></tr><tr><td style="text-align:center">Dictionary</td><td style="text-align:center">Associated arrays with unique keys</td><td style="text-align:center">{‘a’:99, ’b’:’red’, ’c’:’balloons’}</td></tr><tr><td style="text-align:center">Array</td><td style="text-align:center">Vectorized numeric array optimized for C</td><td style="text-align:center">numpy.ones ((10,5))</td></tr></tbody></table></div><p>有些类型通过特定的字符标识。例如，单引号或双引号用于创建字符串：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt;a = <span class="string">&#x27;这是一个字符串。&#x27;</span></span><br><span class="line">&gt;&gt;&gt;b = <span class="string">&quot;这也是一个字符串。&quot;</span></span><br></pre></td></tr></table></figure><p>列表通过方括号进行赋值：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt;c = [<span class="number">1</span>, <span class="number">5</span>, <span class="string">&quot;Dragon&quot;</span>, <span class="number">948.5</span>]</span><br></pre></td></tr></table></figure><p>对象之间可以使用标准语法进行操作：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">+  加法        ==  相等</span><br><span class="line">-  减法        !=  不相等</span><br><span class="line">*  乘法        &gt;  大于</span><br><span class="line">/  除法        &lt;  小于</span><br><span class="line">** 指数运算    &lt;= 小于或等于</span><br><span class="line"><span class="meta prompt_">% </span><span class="language-bash"> 取余数      &gt;= 大于或等于</span></span><br></pre></td></tr></table></figure><p>某些关键词是保留用于全局变量或执行特定功能的。应尽量避免将这些关键词作为变量使用：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">and</span>, <span class="keyword">as</span>, <span class="keyword">assert</span>, <span class="keyword">break</span>, <span class="keyword">class</span>, <span class="keyword">continue</span>, <span class="keyword">def</span>, <span class="keyword">del</span>, <span class="keyword">elif</span>, <span class="keyword">else</span>, <span class="keyword">except</span>, <span class="built_in">exec</span>, <span class="keyword">finally</span>, <span class="keyword">for</span>, <span class="keyword">from</span>, <span class="keyword">global</span>, <span class="keyword">if</span>, <span class="keyword">import</span>, <span class="keyword">in</span>, <span class="keyword">is</span>, <span class="keyword">lambda</span>, <span class="keyword">not</span>, <span class="keyword">or</span>, <span class="keyword">pass</span>, <span class="built_in">print</span>, <span class="keyword">raise</span>, <span class="keyword">return</span>, <span class="keyword">try</span>, <span class="keyword">while</span>, <span class="keyword">with</span>, <span class="keyword">yield</span></span><br></pre></td></tr></table></figure><p>关于Python语法和对象类型的更深入的讨论可以在官方教程中找到：<a href="https://docs.python.org/3.5/tutorial/index.html">Python官方教程</a>。</p><h4 id="11-6-1-2-嵌入式Python的使用"><a href="#11-6-1-2-嵌入式Python的使用" class="headerlink" title="11.6.1.2 嵌入式Python的使用"></a>11.6.1.2 嵌入式Python的使用</h4><h5 id="11-6-1-2-1-概述"><a href="#11-6-1-2-1-概述" class="headerlink" title="11.6.1.2.1 概述"></a>11.6.1.2.1 概述</h5><p>与TCL类似，Python已通过Pythonic API在Avizo中实现。Avizo的特定命令允许你访问模块中包含的信息和功能。通过Python与Avizo进行交互有两种主要方式。第一种方式是通过Python控制台，它与TCL控制台分离，这是一个解释器。控制台的基本功能，如Tab自动补全，已经在第11.6.1.1节“Python简介”中描述。</p><p>第二种方式是通过脚本模块在Avizo中使用Python。Python脚本模块允许你继承预定义的PyScriptObject类的属性，然后覆盖这些属性，以创建与Avizo集成的扩展。脚本模块的行为类似于Avizo中的常规模块，并可以通过资源文件伴随出现在对象弹出菜单中。资源文件仍然必须用TCL编写。PyScriptObject类中包含以下四种方法，供你方便使用：</p><ul><li><code>__init__()</code>：构造函数方法，可以包含在项目视图中创建脚本对象时运行的代码。</li><li><code>update()</code>：可以调用update方法来更新脚本对象在属性面板中的GUI。</li><li><code>compute()</code>：通常包含主要代码的compute方法应在需要进行计算时调用。</li><li><code>__del__()</code>：这个析构函数方法可以包含帮助在删除模块时清理命名空间的代码。</li></ul><h5 id="11-6-1-2-2-示例：与模块交互"><a href="#11-6-1-2-2-示例：与模块交互" class="headerlink" title="11.6.1.2.2 示例：与模块交互"></a>11.6.1.2.2 示例：与模块交互</h5><p>以下是如何通过控制台与项目视图中的模块交互的一个示例，通过创建一个正交切片并更改其属性：</p><p>1、确保在工作区显示Python控制台。</p><p>2、打开 <code>$AVIZO_ROOT/data/tutorials/chocolate-bar.am</code>。</p><ul><li>如果启用了自动视图，将会自动创建一个正交切片。删除它。</li></ul><p>3、要创建正交切片，请在<code>HxProject</code>类中访问<code>create()</code>方法。<code>create()</code>方法要求我们传递我们要创建的对象的类型ID作为字符串参数。</p><ul><li>如果你不确定对象的类型ID，可以在GUI中创建对象，然后使用TCL控制台中的<code>&lt; module &gt;</code> getTypeId命令来了解其类型。</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>hx_project.create(<span class="string">&#x27;HxOrthoSlice&#x27;</span>)</span><br></pre></td></tr></table></figure><p>4、现在我们需要将正交切片连接到 <code>chocolate-bar.am</code>，但首先我们会使用 get() 方法将正交切片分配给变量，以便以后更容易访问。我们也会对 <code>chocolate-bar.am</code> 执行相同操作：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt;ortho = hx_project.get(<span class="string">&#x27;Ortho Slice&#x27;</span>)</span><br><span class="line">&gt;&gt;&gt;input_data = hx_project.get(<span class="string">&#x27;chocolate-bar.am&#x27;</span>)</span><br></pre></td></tr></table></figure><p>5、为了将正交切片连接到 <code>chocolate-bar.am</code>，我们需要查看如何访问正交切片的 Data 端口。通过在控制台中打印 <code>portnames</code> 命令的结果，展示可供交互的端口列表：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt;ortho.portnames</span><br><span class="line">[<span class="string">&#x27;data&#x27;</span>, <span class="string">&#x27;origin&#x27;</span>, <span class="string">&#x27;normal&#x27;</span>, <span class="string">&#x27;frameSettings&#x27;</span>, ...]</span><br></pre></td></tr></table></figure><p>6、从 <code>portnames</code> 命令可以看到 <code>data</code> 端口可能对应于正交切片属性中显示的”Data数据”连接。使用 <code>ports</code> 层级中的 <code>connect()</code> 方法将 <code>chocolate-bar.am</code> 连接到这个端口，然后使用 <code>fire()</code> 方法应用更改：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt;ortho.ports.data.connect(input_data)</span><br><span class="line">&gt;&gt;&gt;ortho.fire()</span><br></pre></td></tr></table></figure><p>7、我们还可以通过设置 sliceNumber 端口的值来更改切片位置：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt;ortho.ports.sliceNumber.value = <span class="number">100</span></span><br><span class="line">&gt;&gt;&gt;ortho.fire()</span><br></pre></td></tr></table></figure><p>8、尝试正交切片中的其他端口，查看是否可以更改切片方向和色彩图。要访问这些端口的帮助，可以将 access 命令传递给 help() 方法：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt;<span class="built_in">help</span>(ortho.ports.sliceOrientation)</span><br></pre></td></tr></table></figure><p>9、通过将它们传递给 help() 方法，进一步了解可供操作的方法和类：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt;<span class="built_in">help</span>(ortho.fire)</span><br></pre></td></tr></table></figure><h5 id="11-6-1-2-3-示例：开发脚本"><a href="#11-6-1-2-3-示例：开发脚本" class="headerlink" title="11.6.1.2.3 示例：开发脚本"></a>11.6.1.2.3 示例：开发脚本</h5><p>在本示例中，我们将编写一个简单的脚本来计算数据集边界框的总体积。该脚本可以直接在Avizo的Python控制台中输入，也可以在文本编辑器中输入命令，然后将其复制到Python控制台执行。</p><p>1、加载 <code>$AVIZO_ROOT/data/tutorials/chocolate-bar.am</code>。</p><p>2、将 <code>chocolate-bar.am</code> 分配给一个变量，以便在后续代码中快速引用。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt;data = hx_project.get(<span class="string">&#x27;chocolate-bar.am&#x27;</span>)</span><br></pre></td></tr></table></figure><p>3、创建一个边界框并将其附加到 <code>chocolate-bar.am</code> 上。</p><ul><li>你可以在创建时直接将边界框分配给一个变量，而不是在单独的命令中创建它后再使用 get() 方法获取。</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt;bbox = hx_project.create(<span class="string">&#x27;HxBoundingBox&#x27;</span>)</span><br><span class="line">&gt;&gt;&gt;bbox.ports.data.connect(data)</span><br><span class="line">&gt;&gt;&gt;bbox.fire()</span><br></pre></td></tr></table></figure><p>4、检索边界框在 X、Y 和 Z 方向的范围，以计算其体积。已经存在一个可以使用的边界框命令，该命令以元组的形式存储这些信息，定义为 <code>((xmin, ymin, zmin), (xmax, ymax, zmax))</code>。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt;<span class="built_in">type</span>(data.bounding_box)</span><br><span class="line">&lt;<span class="keyword">class</span> <span class="string">&#x27;tuple&#x27;</span>&gt;</span><br><span class="line">&gt;&gt;&gt;data.bounding_box</span><br><span class="line">((<span class="number">0.0</span>, <span class="number">0.0</span>, <span class="number">0.0</span>),</span><br><span class="line">(<span class="number">0.02807999961078167</span>,</span><br><span class="line"><span class="number">0.020880000665783882</span>,</span><br><span class="line"><span class="number">0.035280000418424606</span>))</span><br></pre></td></tr></table></figure><p>5、Python还可以很容易地从这个两列表元组中提取两个变量。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt;min_bounds, max_bounds = data.bounding_box</span><br></pre></td></tr></table></figure><p>6、使用方括号 <code>[ ]</code> 访问最小和最大边界列表中的每个索引，并将这些信息插入公式中，以计算框的体积。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt;x_extent = max_bounds[<span class="number">0</span>] - min_bounds[<span class="number">0</span>]</span><br><span class="line">&gt;&gt;&gt;y_extent = max_bounds[<span class="number">1</span>] - min_bounds[<span class="number">1</span>]</span><br><span class="line">&gt;&gt;&gt;z_extent = max_bounds[<span class="number">2</span>] - min_bounds[<span class="number">2</span>]</span><br><span class="line">&gt;&gt;&gt;volume = x_extent * y_extent * z_extent</span><br></pre></td></tr></table></figure><p>7、最后，以精确的格式将信息打印到控制台。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt;<span class="built_in">print</span>(<span class="string">&#x27;The volume of %s is %.g.&#x27;</span> % (data.name, volume))</span><br></pre></td></tr></table></figure><h5 id="11-6-1-2-4-示例：创建一个函数"><a href="#11-6-1-2-4-示例：创建一个函数" class="headerlink" title="11.6.1.2.4 示例：创建一个函数"></a>11.6.1.2.4 示例：创建一个函数</h5><p>在本例中，我们将边界框体积计算器封装到一个函数中，该函数接受输入数据作为参数，并将答案返回到控制台。关于函数和Python语法的一些注意事项：</p><ul><li>如果你在Avizo控制台中直接执行，请按<code>SHIFT+ENTER</code>键以输入一个换行符，而不执行代码。</li><li>Python要求在函数体内保持一致的缩进。最佳实践是将代码体缩进四个空格（而不是Tab键）。</li><li>Avizo中的Python控制台不会为用户自动缩进行，用户必须自行控制缩进。</li></ul><p>1、加载 <code>$AVIZO_ROOT/data/tutorials/chocolate-bar.am</code><br>2、使用<code>def</code>关键字定义一个名为<code>bbVol</code>的函数，该函数接受单个输入数据集作为参数。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">def</span> <span class="title function_">bbVol</span>(<span class="params">data_arg</span>):  <span class="comment"># 记住这里要按SHIFT+ENTER键！</span></span><br><span class="line">...</span><br></pre></td></tr></table></figure><p>3、解释器中会显示省略号，表示它正在等待更多代码输入。在此时手动输入四个空格，然后像之前一样，将最小和最大边界框列表赋给变量。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">... </span>min_bounds, max_bounds = data_arg.bounding_box</span><br></pre></td></tr></table></figure><p>4、按下<code>SHIFT+ENTER</code>键以创建新行，再次输入四个空格，然后继续执行体积计算器的其余部分。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">... </span>x_extent = max_bounds[<span class="number">0</span>] - min_bounds[<span class="number">0</span>]</span><br><span class="line"><span class="meta">... </span>y_extent = max_bounds[<span class="number">1</span>] - min_bounds[<span class="number">1</span>]</span><br><span class="line"><span class="meta">... </span>z_extent = max_bounds[<span class="number">2</span>] - min_bounds[<span class="number">2</span>]</span><br><span class="line"><span class="meta">... </span>volume = x_extent * y_extent * z_extent</span><br></pre></td></tr></table></figure><p>5、最后，添加一个<code>return</code>语句将<code>volume</code>变量返回到控制台。这允许你将计算结果设置为一个变量。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">... </span><span class="keyword">return</span> volume</span><br></pre></td></tr></table></figure><p>6、通过按<code>ENTER</code>键执行函数定义，然后使用<code>chocolate-bar.am</code>测试代码。测试将计算结果分配给变量的能力。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>bbVol(hx_project.get(<span class="string">&#x27;chocolate-bar.am&#x27;</span>))</span><br><span class="line">The volume of chocolate-bar.am is2e-05。</span><br><span class="line"><span class="number">2e-05</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>chocolatebar_volume = bbVol(hx_project.get(<span class="string">&#x27;chocolate-bar.am&#x27;</span>))</span><br></pre></td></tr></table></figure><h4 id="11-6-1-3-常用全局命令"><a href="#11-6-1-3-常用全局命令" class="headerlink" title="11.6.1.3 常用全局命令"></a>11.6.1.3 常用全局命令</h4><p>在 Avizo 的 Python 环境中，有两个主要的函数可以帮助用户探索 Python 的结构。<br><code>dir()</code> 函数允许用户查看给定对象可用的属性和方法的列表。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt;ortho = hx_project.get(<span class="string">&#x27;Ortho Slice&#x27;</span>)</span><br><span class="line">&gt;&gt;&gt;<span class="built_in">dir</span>(ortho)</span><br><span class="line">[<span class="string">&#x27;__class__&#x27;</span>, <span class="string">&#x27;__delattr__&#x27;</span>, <span class="string">&#x27;__dir__&#x27;</span>, <span class="string">&#x27;__doc__&#x27;</span>, <span class="string">&#x27;__eq__&#x27;</span>, <span class="string">&#x27;__format__&#x27;</span>, <span class="string">&#x27;__ge__&#x27;</span>, <span class="string">&#x27;__getattribute__&#x27;</span>, <span class="string">&#x27;__gt__&#x27;</span>, <span class="string">&#x27;__hash__&#x27;</span>, <span class="string">&#x27;__init__&#x27;</span>, <span class="string">&#x27;__le__&#x27;</span>, <span class="string">&#x27;__lt__&#x27;</span>, <span class="string">&#x27;__ne__&#x27;</span>, <span class="string">&#x27;__new__&#x27;</span>, <span class="string">&#x27;__pyx_vtable__&#x27;</span>, <span class="string">&#x27;__reduce__&#x27;</span>, <span class="string">&#x27;__reduce_ex__&#x27;</span>, <span class="string">&#x27;__repr__&#x27;</span>, <span class="string">&#x27;__setattr__&#x27;</span>, <span class="string">&#x27;__sizeof__&#x27;</span>, <span class="string">&#x27;__str__&#x27;</span>, <span class="string">&#x27;__subclasshook__&#x27;</span>, <span class="string">&#x27;_cpp_classname&#x27;</span>, <span class="string">&#x27;_cpp_package&#x27;</span>, <span class="string">&#x27;_tcl_interp&#x27;</span>, <span class="string">&#x27;all_interfaces&#x27;</span>, <span class="string">&#x27;can_be_renamed&#x27;</span>, <span class="string">&#x27;clip_geometry&#x27;</span>, <span class="string">&#x27;compute&#x27;</span>, <span class="string">&#x27;create_doc_file&#x27;</span>, <span class="string">&#x27;create_port_snaps&#x27;</span>, <span class="string">&#x27;downstream_connections&#x27;</span>, <span class="string">&#x27;duplicate&#x27;</span>, <span class="string">&#x27;execute&#x27;</span>, <span class="string">&#x27;fire&#x27;</span>, <span class="string">&#x27;get_all_interface_names&#x27;</span>, <span class="string">&#x27;icon_color&#x27;</span>, <span class="string">&#x27;icon_position&#x27;</span>, <span class="string">&#x27;icon_visible&#x27;</span>, <span class="string">&#x27;is_geometry_clipped&#x27;</span>, <span class="string">&#x27;is_same_object&#x27;</span>, <span class="string">&#x27;name&#x27;</span>, <span class="string">&#x27;need_saving&#x27;</span>, <span class="string">&#x27;portnames&#x27;</span>, <span class="string">&#x27;ports&#x27;</span>, <span class="string">&#x27;removable&#x27;</span>, <span class="string">&#x27;selected&#x27;</span>, <span class="string">&#x27;unclip_geometry&#x27;</span>, <span class="string">&#x27;update&#x27;</span>, <span class="string">&#x27;viewer_mask&#x27;</span>]</span><br></pre></td></tr></table></figure><p>这些信息也可以在你开始输入命令时通过下拉列表显示。</p><img src="/2024/09/19/AVIZO%E8%87%AA%E5%8A%A8%E5%8C%96/Figure11.7.png" class="" title="Figure 11.7: Pulldown List of Commands"><p><code>help()</code> 函数提供了有关属性和方法的详细信息及其使用的示例。<br><code>help()</code> 的输出还包含有关相关父类的信息。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt;<span class="built_in">help</span>(ortho)</span><br><span class="line">Help on HxPlanarModBase <span class="built_in">object</span>:</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">HxPlanarModBase</span>(<span class="title class_ inherited__">HxModule</span>)</span><br><span class="line">| This <span class="keyword">is</span> the first <span class="keyword">class</span> <span class="title class_">of</span> HxBase hierarchy which represents items that can be added to the project view.</span><br><span class="line">|</span><br><span class="line">| Method resolution order:</span><br><span class="line">| HxPlanarModBase</span><br><span class="line">| HxModule</span><br><span class="line">| HxObject</span><br><span class="line">| HxBase</span><br><span class="line">| McInterface</span><br><span class="line">| builtins.<span class="built_in">object</span></span><br><span class="line">|</span><br><span class="line">| Methods defined here:</span><br><span class="line">...</span><br><span class="line">...</span><br><span class="line">...</span><br><span class="line">| all_interfaces</span><br><span class="line">| Attribute that contains <span class="built_in">all</span> admissible interfaces <span class="keyword">as</span> sub-members.</span><br><span class="line">|</span><br><span class="line">| Examples</span><br><span class="line">| --------</span><br><span class="line">|</span><br><span class="line">| Retrieve an ‘HxBase‘ interface on an orthoslice:</span><br><span class="line">|</span><br><span class="line">| &gt;&gt;&gt; ortho = hx_project.create(’HxOrthoSlice’)</span><br><span class="line">| &gt;&gt;&gt; base = ortho.all_interfaces.HxBase</span><br></pre></td></tr></table></figure><p>下方列出了一些更具体的全局命令：</p><ul><li><code>print()</code> 是 Python 的原生命令，用于在 Avizo 中的 Python 控制台输出结果。</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt;x = <span class="number">3</span></span><br><span class="line">&gt;&gt;&gt;y = <span class="number">2</span></span><br><span class="line">&gt;&gt;&gt;<span class="built_in">print</span>(<span class="string">&#x27;The sum of %i + %i is %i.&#x27;</span> % (x,y,x+y))</span><br><span class="line">The <span class="built_in">sum</span> of <span class="number">3</span> + <span class="number">2</span> <span class="keyword">is</span> <span class="number">5.</span></span><br></pre></td></tr></table></figure><ul><li><code>import</code> 是 Python 的原生命令，用于通过加载额外的包来扩展 Python 的功能。</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt;x = <span class="number">3</span></span><br><span class="line">&gt;&gt;&gt;y = <span class="number">2</span></span><br><span class="line">&gt;&gt;&gt;<span class="keyword">import</span> numpy</span><br><span class="line">&gt;&gt;&gt;numpy.add(x,y)</span><br><span class="line"><span class="number">5</span></span><br></pre></td></tr></table></figure><p>一些用于与项目视图交互的有用全局函数包含在 <code>hx_project</code> 方法中。</p><div class="table-container"><table><thead><tr><th style="text-align:center">方法</th><th style="text-align:center">描述</th></tr></thead><tbody><tr><td style="text-align:center">hx_project.create()</td><td style="text-align:center">创建某个 Avizo 类的实例并将其添加到项目视图中</td></tr><tr><td style="text-align:center">hx_project.remove()</td><td style="text-align:center">从项目视图中删除对象</td></tr><tr><td style="text-align:center">hx_project.add()</td><td style="text-align:center">将对象添加到项目视图中</td></tr><tr><td style="text-align:center">hx_project.load()</td><td style="text-align:center">当指定了文件名时加载定义格式的数据</td></tr></tbody></table></div><p><code>hx_paths</code> 方法还提供了包含目录路径的变量。</p><div class="table-container"><table><thead><tr><th style="text-align:center">变量</th><th style="text-align:center">描述</th></tr></thead><tbody><tr><td style="text-align:center">hx_paths.install.dir</td><td style="text-align:center">安装目录，也称为 &lt;$AVIZO_ROOT&gt;</td></tr><tr><td style="text-align:center">hx_paths.tutorials.dir</td><td style="text-align:center">教程数据目录</td></tr><tr><td style="text-align:center">hx_paths.python_modules.dir</td><td style="text-align:center">包含额外包的 Python 模块目录</td></tr><tr><td style="text-align:center">hx_paths.python_script_objects.dir</td><td style="text-align:center">包含用户创建的自定义 Python 脚本的 Python 脚本对象目录</td></tr><tr><td style="text-align:center">hx_paths.executable_dir</td><td style="text-align:center">包含 Avizo.exe 的目录</td></tr></tbody></table></div><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt;hx_paths.install_dir</span><br><span class="line"><span class="string">&#x27;C:/Program Files/&lt;INSTALL DIR&gt;&#x27;</span></span><br><span class="line">&gt;&gt;&gt;hx_paths.tutorials_dir</span><br><span class="line"><span class="string">&#x27;C:/Program Files/&lt;INSTALL DIR&gt;/data/tutorials&#x27;</span></span><br><span class="line">&gt;&gt;&gt;hx_paths.python_modules_dir</span><br><span class="line"><span class="string">&#x27;C:/Program Files/&lt;INSTALL DIR&gt;/share/python_modules&#x27;</span></span><br><span class="line">&gt;&gt;&gt;hx_paths.python_script_objects_dir</span><br><span class="line"><span class="string">&#x27;C:/Program Files/&lt;INSTALL DIR&gt;/share/python_script_objects&#x27;</span></span><br><span class="line">&gt;&gt;&gt;hx_paths.executable_dir</span><br><span class="line"><span class="string">&#x27;C:\\Program Files\\&lt;INSTALL DIR&gt;\\bin\\arch-Win64VC12-Optimize\\Avizo.exe&#x27;</span></span><br></pre></td></tr></table></figure><h4 id="11-6-1-4-模块管理"><a href="#11-6-1-4-模块管理" class="headerlink" title="11.6.1.4 模块管理"></a>11.6.1.4 模块管理</h4><p>一个包含许多代码片段的完整参考手册，解释了如何配置所有端口和模块，可以从Python参考帮助菜单项中访问。</p><h5 id="11-6-1-4-1-模块属性"><a href="#11-6-1-4-1-模块属性" class="headerlink" title="11.6.1.4.1 模块属性"></a>11.6.1.4.1 模块属性</h5><h6 id="什么是属性"><a href="#什么是属性" class="headerlink" title="什么是属性"></a>什么是属性</h6><p>属性是类中包含的数据字段。有些属性可能是只读的。</p><h6 id="常见属性列表"><a href="#常见属性列表" class="headerlink" title="常见属性列表"></a>常见属性列表</h6><p>这里的变量 “a” 指的是你的对象的 Python 句柄。</p><p><code>a.name</code>:<br>这是一个字符串属性，指的是你的 Avizo 对象的名称。可以分配一个字符串来更改对象的显示名称。</p><p><code>a.portnames</code>:<br>这是一个只读列表，包含属于 Avizo 对象的所有端口名称。</p><p><code>a.viewer_mask</code>:<br>这是一个整数属性，触发视图中的可见性。有16个配置，可以从 [0, 15] 中设置。如果使用了该范围之外的数字，该数字将在执行模16操作后评估。</p><p><code>a.bounding_box</code>:<br>这存储了一对元组，描述对象的空间维度。可以以 ((xmin, ymin, zmin), (xmax, ymax, zmax)) 的格式分配新的维度。</p><p><code>a.downstream_connections[x]</code>:<br>这存储了一个只读序列，显示引用它的所有对象。每个连接都分配了一个整数索引 “x”。要从指针中找到对象的名称，可以使用命令 a.downstream_connections[x].get_owner().name</p><p><code>a.range</code>:<br>这存储了一个只读的元组，显示数据的强度范围，格式为 (min, max)。</p><p><code>a.transform</code>:<br>这存储了一个显示 4x4 转换矩阵的元组。可以分配一个新的转换矩阵。</p><h6 id="11-6-1-4-2-模块方法"><a href="#11-6-1-4-2-模块方法" class="headerlink" title="11.6.1.4.2 模块方法"></a>11.6.1.4.2 模块方法</h6><h6 id="什么是方法"><a href="#什么是方法" class="headerlink" title="什么是方法"></a>什么是方法</h6><p>方法是类中包含的函数。许多方法不需要参数。</p><h6 id="常见方法列表"><a href="#常见方法列表" class="headerlink" title="常见方法列表"></a>常见方法列表</h6><p>这里的变量 “a” 指的是你的对象的 Python 句柄。</p><p><code>a.compute()</code>:<br>如果 a.ports.doIt.was_hit = True，则此方法执行对象的计算。这模拟了在条件允许时单击应用按钮。</p><p><code>a.update()</code>:<br>此方法更新对象 GUI 的属性窗口。</p><p><code>a.fire()</code>:<br>此方法调用 a.update() 和 a.compute()。</p><p><code>a.execute()</code>:<br>此方法结合了上述所有方法，模拟了单击应用按钮并刷新 GUI。</p><p><code>a.get_array()</code>:<br>此方法访问对象的 NumPy 数组。访问该数组将阻止对象删除。</p><p><code>a.set_array(...)</code>:<br>此方法将 NumPy 数组分配给对象。数组的所有权不会传递，因此未来对数组的更改不会传播，除非重新分配。</p><h4 id="11-6-1-5-脚本对象"><a href="#11-6-1-5-脚本对象" class="headerlink" title="11.6.1.5 脚本对象"></a>11.6.1.5 脚本对象</h4><h5 id="11-6-1-5-1-什么是-Python-脚本对象"><a href="#11-6-1-5-1-什么是-Python-脚本对象" class="headerlink" title="11.6.1.5.1 什么是 Python 脚本对象"></a>11.6.1.5.1 什么是 Python 脚本对象</h5><p>Python 脚本对象是一个计算模块，其行为在继承自 PyScriptObject 的 Python 类中进行硬编码。Python 脚本对象对于创建自定义工具非常有用，其功能可通过与 Avizo 计算模块相同的方式访问。</p><h6 id="脚本结构"><a href="#脚本结构" class="headerlink" title="脚本结构"></a>脚本结构</h6><p>当你将 Python 脚本对象定义为类时，以下类方法非常有用，但并不要求必须这样定义。任何脚本都会像在控制台中输入的那样运行。变量 self 指代其类的标识。</p><p><code>def init(self)</code>:<br>此方法在对象创建时调用。在此处定义脚本结构并设置 GUI 是非常有用的。</p><p><code>def del(self)</code>:<br>此方法在对象重新启动或删除时调用。这是清理连接的好地方。</p><p><code>def update(self)</code>:<br>当 GUI 需要刷新时调用此方法。</p><p><code>def compute(self)</code>:<br>当单击“应用”时调用此方法。</p><p>注意：Python 脚本对象的执行是在单独的 Python 解释器上完成的，并且有自己的 Python 控制台。但是，请注意，在某些特殊情况下，例如来自 PyQt 插槽的消息打印，流式传输可能会重定向到主 Python 解释器。</p><h6 id="创建端口"><a href="#创建端口" class="headerlink" title="创建端口"></a>创建端口</h6><p>用户通过端口与对象进行交互。端口可以通过简单的分配进行初始化，它们属于 <code>HxPort</code> 类。以下是一些有用的端口：</p><p><code>HxConnection</code><br>此端口类允许用户连接模块。模块的类型也可以限制。</p><p><code>HxPortFilename</code><br>此端口类允许用户加载或保存文件。端口的功能由 mode 属性定义。文件名可以以文本形式输入或通过文件浏览器访问。</p><p><code>HxPortIntSlider</code><br>此端口类包含一个可以通过滑动比例访问的整数值范围。此端口用于定义“Ortho Slice”模块的切片编号。</p><p><code>HxPortDoIt</code><br>此端口类控制自动刷新框，并处理应用按钮。</p><p><code>HxPortInfo</code><br>此端口类用于为用户提供说明、备注或警告。文本可以在模块属性中找到。</p><h6 id="Bounding-Box-脚本示例"><a href="#Bounding-Box-脚本示例" class="headerlink" title="Bounding Box 脚本示例"></a>Bounding Box 脚本示例</h6><p>在本例中，我们将 Bounding Box 体积计算器（在“嵌入式 Python 使用”一章中描述）封装成一个脚本模块，可以通过对象弹出菜单加载到 Avizo GUI 中。</p><p>1、打开文本编辑器并创建一个新文件，结构如下。将对象命名为 <code>BoundingBoxVolume</code>。</p><ul><li>你也可以从 <code>$AVIZO_ROOT/share/python_script_objects/PythonScriptObjectTemplate.pyscro</code> 模板开始。</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">BoundingBoxVolume</span>(<span class="title class_ inherited__">PyScriptObject</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="comment"># 这里是初始化代码</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">update</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="comment"># 这里是更新代码</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">compute</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="comment"># 这里是计算代码</span></span><br></pre></td></tr></table></figure><p>2、脚本对象需要能够连接到数据对象，以便知道需要计算体积的 Bounding Box。默认情况下，Python 脚本对象从 <code>PyScriptObject</code> 类继承数据连接。确保它在<code>__init__()</code> 方法中可见。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">    self.data.visible = <span class="literal">True</span></span><br></pre></td></tr></table></figure><p>3、在此示例中，使用 pass 关键字跳过 update() 方法中的 GUI 更新，因为没有需要更新的端口。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">update</span>(<span class="params">self</span>):</span><br><span class="line">    <span class="keyword">pass</span></span><br></pre></td></tr></table></figure><p>4、在 <code>compute()</code> 方法中，我们希望在没有数据对象连接到脚本模块时停止体积计算。添加一个 <code>if</code> 语句检查数据连接是否为空。如果数据连接为空，使用 <code>return</code> 语句退出 <code>compute()</code> 方法。</p><ul><li>Python 使用 None 关键字来简化此操作（即：<code>if &lt;expression&gt; is None</code>）</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">compute</span>(<span class="params">self</span>):</span><br><span class="line">    <span class="comment"># 检查是否连接了输入数据</span></span><br><span class="line">    <span class="keyword">if</span> self.<span class="built_in">input</span>.source() <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">        <span class="keyword">return</span></span><br></pre></td></tr></table></figure><p>5、最后，如果逻辑检查失败，因为已连接数据对象，请使用 <code>bbVol</code> 脚本计算体积。使用 <code>source()</code> 方法获取已连接数据对象的名称。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">compute</span>(<span class="params">self</span>):</span><br><span class="line">    <span class="comment"># 检查是否连接了输入数据</span></span><br><span class="line">    <span class="keyword">if</span> self.<span class="built_in">input</span>.source() <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">        <span class="keyword">return</span></span><br><span class="line"></span><br><span class="line">    data = self.<span class="built_in">input</span>.source()</span><br><span class="line">    min_bounds, max_bounds = data.bounding_box</span><br><span class="line">    x_extent = max_bounds[<span class="number">0</span>] - min_bounds[<span class="number">0</span>]</span><br><span class="line">    y_extent = max_bounds[<span class="number">1</span>] - min_bounds[<span class="number">1</span>]</span><br><span class="line">    z_extent = max_bounds[<span class="number">2</span>] - min_bounds[<span class="number">2</span>]</span><br><span class="line">    volume = x_extent * y_extent * z_extent</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;The volume of %s is %.g.&#x27;</span> % (data.name, volume))</span><br></pre></td></tr></table></figure><p>6、完成模块后，在 TCL 中创建一个资源文件，以便在对象弹出菜单中将此模块显示为所有数据对象的选项。</p><ul><li>有关创建资源文件的更多信息，请参考配置弹出菜单部分。</li><li>资源文件可在 <code>$AVIZO_ROOT/share/resources/PythonBoundingBoxVolume.rc</code> 中找到。</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">module -name <span class="string">&quot;Bounding Box Volume&quot;</span> \</span><br><span class="line">-primary <span class="string">&quot;HxUniformScalarField3&quot;</span> \</span><br><span class="line">-package <span class="string">&quot;py_core&quot;</span> \</span><br><span class="line">-category <span class="string">&quot;&#123;Measure And Analyze&#125;&quot;</span> \</span><br><span class="line">-proc &#123;</span><br><span class="line">    <span class="built_in">set</span> this [[create HxPythonScriptObject] \</span><br><span class="line">    setLabel <span class="string">&quot;Bounding Box Volume&quot;</span>]</span><br><span class="line">    <span class="string">&quot;$this&quot;</span> startStop hideMaskIncrease</span><br><span class="line">    <span class="string">&quot;$this&quot;</span> filename hideMaskIncrease</span><br><span class="line">    <span class="string">&quot;$this&quot;</span> filename setValue \</span><br><span class="line">    &lt;PRODUCT_PATH&gt;/share/python_script_objects/PythonBoundingBoxVolume.pyscro</span><br><span class="line">    <span class="string">&quot;$this&quot;</span> startStop hit <span class="number">0</span></span><br><span class="line">    <span class="string">&quot;$this&quot;</span> fire</span><br><span class="line">    <span class="keyword">if</span> &#123; [exists $PRIMARY] &#125; &#123;</span><br><span class="line">        $this data connect $PRIMARY</span><br><span class="line">        $this fire</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h5 id="11-6-1-5-2-资源文件"><a href="#11-6-1-5-2-资源文件" class="headerlink" title="11.6.1.5.2 资源文件"></a>11.6.1.5.2 资源文件</h5><p>资源文件是一个在 Avizo 启动过程中读取和执行的 TCL 脚本。你可以配置一个资源文件，使你的 Python 脚本对象出现在下拉菜单中或作为宏按钮。资源文件位于 <code>$AVIZO_ROOT/share/resources</code> 目录中。</p><h6 id="结构化下拉菜单资源文件"><a href="#结构化下拉菜单资源文件" class="headerlink" title="结构化下拉菜单资源文件"></a>结构化下拉菜单资源文件</h6><p>脚本以 TCL 命令 <code>&lt;module&gt;</code> 开始，后跟一个简单案例的以下标志。在下例中，<code>$PRIMARY</code> 是指你最初右键单击的对象。</p><p><code>-name</code><br>这是菜单中模块的名称。</p><p><code>-package</code><br>这定义了对象的包。</p><p><code>-primary</code><br>这限制了脚本出现时所需的数据类型。</p><p><code>-category</code><br>这定义了脚本在菜单中出现的文件夹。</p><p><code>-proc</code><br>这是资源文件的主体部分，指定 .pyscro 文件的加载位置以及如何将脚本连接到你最初右键单击的对象。</p><h6 id="结构化宏资源文件"><a href="#结构化宏资源文件" class="headerlink" title="结构化宏资源文件"></a>结构化宏资源文件</h6><p>脚本以 TCL 命令 <code>&lt;macroButton&gt;</code> 开始，后跟一个简单案例的以下标志。</p><p><code>-add</code><br>这为按钮创建了一个名称。</p><p><code>-color</code><br>这控制按钮的颜色。</p><p><code>-proc</code><br>这是资源文件的主体部分，指定 <code>.pyscro</code> 文件的加载位置或过程的运行。</p><h4 id="11-6-1-6-Python-环境和包管理器"><a href="#11-6-1-6-Python-环境和包管理器" class="headerlink" title="11.6.1.6 Python 环境和包管理器"></a>11.6.1.6 Python 环境和包管理器</h4><h5 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h5><p>本节解释了如何在 Windows 的命令提示符或 Linux/Mac 的终端中列出、安装或更新 Avizo 的新 Python 包。包管理器允许用户创建多个自包含的 Python 环境，每个环境都有自己的 Python 可执行文件（例如 Windows 上的 python.exe）和一组包。每个自包含环境都可以在 Avizo 中使用。</p><h5 id="描述"><a href="#描述" class="headerlink" title="描述"></a>描述</h5><p><code>EDM(Enthought Deployment Manager)</code>包管理器可用于安装、删除或升级在两个存储库中提供的 Python 包：</p><p>• official ThermoScientific/3dSoftware<br>• enthought/free</p><p>此工具应用于查找可用的 Python 包并安装新包。它允许查看、更新和删除已安装的包。此外，它还允许恢复到以前的状态，并恢复到 Avizo 的原始 Python 环境。</p><h5 id="如何安装和配置-EDM"><a href="#如何安装和配置-EDM" class="headerlink" title="如何安装和配置 EDM"></a>如何安装和配置 EDM</h5><p>注意：EDM 安装程序可能需要重新启动你的计算机。</p><p>EDM 安装程序可以从 Enthought 网站获取：<a href="https://www.enthought.com/product/enthought-deployment-manager/">https://www.enthought.com/product/enthought-deployment-manager/</a></p><p>安装程序会将 EDM（例如，Windows 上的 edm.bat）提取到默认文件夹中（例如，Windows 上的 C:\Enthought\edm）。</p><p>要创建一个名为 hxEnv 的新 Python 环境，在 Windows 的命令提示符（转到 EDM 安装目录）和 Linux/Mac 的终端中执行以下命令行（使用与正确架构对应的 .json 文件）：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">edm envs <span class="keyword">import</span> -f $AVIZO_ROOT/python/bundles/3dSoftware_win64.json hxEnv</span><br></pre></td></tr></table></figure><p>如果此命令失败（例如，出现以下错误消息：“The packages repository ‘ThermoScientific/3dSoftware’ does not exist or is not available under your subscription. Check your repositories settings”），则配置文件 $HOME/.edm.yaml 可能不完整或缺失。打开 $HOME 文件夹（$HOME 环境变量包含用户主目录的绝对路径）并搜索 .edm.yaml 文件。如果它存在，请删除并重新启动 Avizo，它应会重新创建此文件。如果文件仍然缺失，请联系支持人员。</p><p>新创建的 Python 环境存储在 <code>$HOME\.edm\envs\hxEnv</code> 中。</p><p>要在 Avizo 中使用名为 hxEnv 的新 Python 环境，你需要将环境变量 <code>HX_FORCE_PYTHON_PATH</code> 设置为 <code>$HOME/.edm/envs/hxEnv</code>。</p><p>可以通过以下命令获取可用环境的列表：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">edm environments <span class="built_in">list</span></span><br></pre></td></tr></table></figure><h5 id="如何搜索和安装包"><a href="#如何搜索和安装包" class="headerlink" title="如何搜索和安装包"></a>如何搜索和安装包</h5><p>首先，按如下方式搜索所需的包：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">edm search &lt;package_name&gt; -e hxEnv</span><br></pre></td></tr></table></figure><p>如果该包可用，按如下方式安装：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">edm install &lt;package_name&gt; -e hxEnv</span><br></pre></td></tr></table></figure><h5 id="如何列出当前安装的包"><a href="#如何列出当前安装的包" class="headerlink" title="如何列出当前安装的包"></a>如何列出当前安装的包</h5><p>要列出 Avizo 中当前安装的所有包，请输入：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">edm <span class="built_in">list</span> -e hxEnv</span><br></pre></td></tr></table></figure><h5 id="如何重新初始化-Avizo-包"><a href="#如何重新初始化-Avizo-包" class="headerlink" title="如何重新初始化 Avizo 包"></a>如何重新初始化 Avizo 包</h5><p>要将 Python 包重新初始化到其原始状态，请使用 .json 文件创建一个新环境，或取消设置 <code>HX_FORCE_PYTHON_PATH</code> 环境变量。取消设置该变量将使 Avizo 使用其嵌入版本。</p><p>如果 Python 分发版因在 Avizo 中安装了不受支持的包而变得无法使用，这可能非常有用。</p><p>要显示所有可用选项，请使用以下命令：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">edm <span class="built_in">help</span></span><br></pre></td></tr></table></figure><h4 id="11-6-1-7-Python-包列表"><a href="#11-6-1-7-Python-包列表" class="headerlink" title="11.6.1.7 Python 包列表"></a>11.6.1.7 Python 包列表</h4><p>以下是 Thermo Scientific Python 中已经包含的包列表：</p><p>alabaster 0.7.10-1<br>appdirs 1.4.3-1<br>babel 2.4.0-2<br>backports.abc 0.5-1<br>backports abc remove 0.4-2<br>certifi 2017.7.27.1-1<br>chardet 3.0.4-1<br>colorama 0.3.7-1<br>configobj 5.0.6-2<br>cycler 0.10.0-1<br>cython 0.25.2-1<br>decorator 4.1.2-1<br>distribute remove 1.0.0-4<br>docutils 0.13.1-1<br>h5py 2.7.0-2<br>idna 2.5-1<br>imagesize 0.7.1-1<br>intel runtime 15.0.6.285-2<br>jdcal 1.2-1<br>jinja2 2.9.6-1<br>lxml 3.7.3-2<br>markupsafe 0.23-2<br>matplotlib 2.0.0-5<br>mkl 2017.0.3-1<br>networkx 1.11-7<br>nose 1.3.7-3<br>numexpr 2.6.2-3<br>numpy 1.13.3-3<br>numpydoc 0.6.0-4<br>opencv 3.2.0-3<br>openpyxl 2.4.1-2<br>packaging 16.8-2<br>pandas 0.20.3-3<br>patsy 0.4.1-4<br>pillow 4.0.0-1<br>pip 10.0.1-1<br>py 1.4.34-1<br>pydicom 0.9.9-1<br>pygments 2.2.0-1<br>pyparsing 2.2.0-1<br>pyqt5 5.8.2-3<br>pytables 3.3.0-5<br>pytest 3.1.2-1<br>python dateutil 2.6.0-1<br>pytz 2017.3-1<br>pywavelets 0.5.2-2<br>requests 2.18.4-1<br>scikit learn 0.19.1-2<br>scikits.image 0.13.0-5<br>scipy 1.0.0-2<br>seaborn 0.8.1-2<br>setuptools 38.2.5-1<br>singledispatch 3.4.0.3-1<br>sip 4.19.2-2<br>six 1.10.0-1<br>snowballstemmer 1.2.1-1<br>sphinx 1.5.5-5<br>sphinx rtd theme 0.2.4-1<br>ssl match hostname 3.5.0.1-1<br>statsmodels 0.8.0-4<br>tornado 4.4.2-3<br>urllib3 1.22-1<br>xlwt 1.2.0-1</p><h3 id="11-6-2-Python-教程"><a href="#11-6-2-Python-教程" class="headerlink" title="11.6.2 Python 教程"></a>11.6.2 Python 教程</h3><h4 id="11-6-2-1-Python-教程-在-Avizo-中使用-Python-生态系统中的工具"><a href="#11-6-2-1-Python-教程-在-Avizo-中使用-Python-生态系统中的工具" class="headerlink" title="11.6.2.1 Python 教程 - 在 Avizo 中使用 Python 生态系统中的工具"></a>11.6.2.1 Python 教程 - 在 Avizo 中使用 Python 生态系统中的工具</h4><p>将 Python 集成到 Avizo 中的一个优点是，可以使用 Python 工具扩展 Avizo 的功能。这种扩展允许编写封装 Python 函数的脚本对象，以使它们在 Avizo 的图形用户界面中作为模块可用。这些 Python 工具随后可以通过标准的 Avizo 端口进行控制。</p><p>本教程演示如何将 Scipy 中的快速傅里叶变换 (FFT) 作为 Avizo 中使用的 FFT 的替代方案进行集成。您可以按照逐步说明操作，或者查看 <code>$AVIZO_ROOT/share/python_script_objects</code> 目录中的相关文件（ScipyFFT.pyscro 和 ScipyFFT.rc）。</p><p>从 <code>$AVIZO_ROOT/share/python_script_objects</code> 目录中复制 <code>PythonScriptObjectTemplate.pyscro</code> 文件到您选择的位置，并将其重命名为 <code>ScipyFFT.pyscro</code>。</p><p>1、用文本编辑器打开该文件，并通过更改第一行给新模块命名：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">ScipyFFT</span>(<span class="title class_ inherited__">PyScriptObject</span>):</span><br></pre></td></tr></table></figure><p>2、在初始化函数中，将使用默认数据输入端口进行模块的数据连接，并定义允许的连接类型：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">self.data.valid_types = [<span class="string">&#x27;HxUniformScalarField3&#x27;</span>]</span><br></pre></td></tr></table></figure><p>3、最终的初始化函数定义如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">    self.data.valid_types = [<span class="string">&#x27;HxUniformScalarField3&#x27;</span>]</span><br><span class="line">    <span class="comment"># 创建一个“应用”按钮。</span></span><br><span class="line">    self.do_it = HxPortDoIt(self, <span class="string">&#x27;apply&#x27;</span>, <span class="string">&#x27;Apply&#x27;</span>)</span><br></pre></td></tr></table></figure><p>4、保持 update 函数不变：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">update</span>(<span class="params">self</span>):</span><br><span class="line">    <span class="keyword">pass</span></span><br></pre></td></tr></table></figure><p>5、FFT 的计算将在 compute 函数中完成。检查是否点击了<code>Apply</code>按钮以及是否选择了输入数据集后，从 Python 中导入几个包。在本例中，我们需要从 scipy 导入 fftpack、从 numpy 导入一些数学函数，以及 time 包来测量执行时间：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> scipy <span class="keyword">import</span> fftpack</span><br><span class="line"><span class="keyword">import</span> numpy</span><br><span class="line"><span class="keyword">import</span> time</span><br></pre></td></tr></table></figure><p>6、计算的第一步是创建一个变量来存储 FFT 计算的结果作为 3D 均匀标量场。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">result = hx_project.create(<span class="string">&#x27;HxUniformScalarField3&#x27;</span>)</span><br></pre></td></tr></table></figure><p>7、要测量执行时间，首先需要在计算开始时获取时间戳：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">start_time = time.time()</span><br></pre></td></tr></table></figure><p>8、为输入数据创建一个 Python 变量：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">input</span> = self.data.source()</span><br></pre></td></tr></table></figure><p>9、要计算输入数据的 FFT 绝对值，执行以下三条命令：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 计算离散傅里叶变换</span></span><br><span class="line">F1 = fftpack.fftn(<span class="built_in">input</span>.get_array())</span><br><span class="line"></span><br><span class="line"><span class="comment"># 将零频率分量移至频谱中心</span></span><br><span class="line">F2 = fftpack.fftshift(F1)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 获取所有系数的幅值</span></span><br><span class="line">F3 = numpy.<span class="built_in">abs</span>(F2)</span><br></pre></td></tr></table></figure><p>10、计算完成后，将结果数组分配给您之前创建的 result 变量：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">result.set_array(F3)</span><br></pre></td></tr></table></figure><p>11、输出 FFT 的总执行时间：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(<span class="string">&quot;--- %s seconds ---&quot;</span> % (time.time() - start_time))</span><br></pre></td></tr></table></figure><p>12、整个 compute 函数应如下所示：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">compute</span>(<span class="params">self</span>):</span><br><span class="line">    <span class="comment"># 检查是否已触碰模块的应用按钮</span></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> self.do_it.was_hit:</span><br><span class="line">        <span class="keyword">return</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 检查输入数据是否连接到有效对象</span></span><br><span class="line">    <span class="keyword">if</span> self.data.source() <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">        <span class="keyword">return</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 导入用于执行 FFT 的 scipy 包</span></span><br><span class="line">    <span class="keyword">from</span> scipy <span class="keyword">import</span> fftpack</span><br><span class="line">    <span class="keyword">import</span> numpy</span><br><span class="line">    <span class="keyword">import</span> time</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 创建输出字段</span></span><br><span class="line">    result = hx_project.create(<span class="string">&#x27;HxUniformScalarField3&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    start_time = time.time()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 检索输入数据</span></span><br><span class="line">    <span class="built_in">input</span> = self.data.source()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 计算离散傅里叶变换</span></span><br><span class="line">    F1 = fftpack.fftn(<span class="built_in">input</span>.get_array())</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 将零频率分量移至频谱中心</span></span><br><span class="line">    F2 = fftpack.fftshift(F1)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 获取所有系数的幅值</span></span><br><span class="line">    F3 = numpy.<span class="built_in">abs</span>(F2)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 将结果 numpy 数组赋值给输出标量场</span></span><br><span class="line">    result.set_array(F3)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 在控制台显示计算时间</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;--- %s seconds ---&quot;</span> % (time.time() - start_time))</span><br></pre></td></tr></table></figure><p>13、为了让此模块在 Avizo 的图形用户界面中可用，您还需要编写一个资源文件。用文本编辑器创建一个新文件，并将其保存为 ScipyFFT.rc。资源文件通常以注释行开头：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#############################################################</span></span><br><span class="line"><span class="comment"># .rc for pyscro Scipy FFT</span></span><br><span class="line"><span class="comment">#############################################################</span></span><br></pre></td></tr></table></figure><p>14、为模块命名：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">module -name <span class="string">&quot;Scipy FFT&quot;</span> \</span><br></pre></td></tr></table></figure><p>15、指定希望将其附加到的数据类型：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">-primary <span class="string">&quot;HxUniformScalarField3&quot;</span> \</span><br></pre></td></tr></table></figure><p>16、将其声明为 Python 脚本对象：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">-package <span class="string">&quot;py_core&quot;</span> \</span><br></pre></td></tr></table></figure><p>17、下一行定义了它将出现在 Avizo 对象弹出菜单中的位置：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">-category <span class="string">&quot;&#123;Python Scripts&#125;&quot;</span> \</span><br></pre></td></tr></table></figure><p>18、运行几个 TCL 命令以在 Avizo 的图形用户界面中初始化模块。第一个命令将创建脚本对象并为模块设置标签：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">-proc &#123;</span><br><span class="line"><span class="built_in">set</span> this [[create HxPythonScriptObject] setLabel <span class="string">&quot;Python FFT&quot;</span>]</span><br></pre></td></tr></table></figure><p>19、设置文件名以找到该模块的 Python 脚本位置，其中 <code>&lt;PRODUCT_PATH&gt;</code> 是 <code>$AVIZO_ROOT</code>:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&quot;$this&quot;</span> startStop hideMaskIncrease</span><br><span class="line"><span class="string">&quot;$this&quot;</span> filename hideMaskIncrease</span><br><span class="line"><span class="string">&quot;$this&quot;</span> filename setValue \</span><br><span class="line">&lt;PRODUCT_PATH&gt;/share/python_script_objects/ScipyFFT.pyscro</span><br></pre></td></tr></table></figure><p>20、脚本将运行以使更改生效：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&quot;$this&quot;</span> startStop hit <span class="number">0</span></span><br><span class="line"><span class="string">&quot;$this&quot;</span> fire</span><br></pre></td></tr></table></figure><p>21、将数据集连接到您右键单击以创建模块的默认输入数据端口：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> &#123; [exists $PRIMARY] &#125; &#123;</span><br><span class="line">    $this data connect $PRIMARY</span><br><span class="line">    $this fire</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>22、完整的资源文件应如下所示，其中 <code>&lt;PRODUCT_PATH&gt;</code> 是 <code>$AVIZO_ROOT</code>:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#############################################################</span></span><br><span class="line"><span class="comment"># .rc for pyscro Scipy FFT</span></span><br><span class="line"><span class="comment">#############################################################</span></span><br><span class="line">module -name <span class="string">&quot;Scipy FFT&quot;</span> \</span><br><span class="line">-primary <span class="string">&quot;HxUniformScalarField3&quot;</span> \</span><br><span class="line">-package <span class="string">&quot;py_core&quot;</span> \</span><br><span class="line">-category <span class="string">&quot;&#123;Python Scripts&#125;&quot;</span> \</span><br><span class="line">-proc &#123;</span><br><span class="line">    <span class="built_in">set</span> this [[create HxPythonScriptObject] setLabel <span class="string">&quot;Python FFT&quot;</span>]</span><br><span class="line">    <span class="string">&quot;$this&quot;</span> startStop hideMaskIncrease</span><br><span class="line">    <span class="string">&quot;$this&quot;</span> filename hideMaskIncrease</span><br><span class="line">    <span class="string">&quot;$this&quot;</span> filename setValue \</span><br><span class="line">    &lt;PRODUCT_PATH&gt;/share/python_script_objects/ScipyFFT.pyscro</span><br><span class="line">    <span class="string">&quot;$this&quot;</span> startStop hit <span class="number">0</span></span><br><span class="line">    <span class="string">&quot;$this&quot;</span> fire</span><br><span class="line">    <span class="keyword">if</span> &#123; [exists $PRIMARY] &#125; &#123;</span><br><span class="line">        $this data connect $PRIMARY</span><br><span class="line">        $this fire</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>23、要使此 Python 脚本对象在 Avizo 中可用，需要将这两个文件（覆盖现有文件）复制到 <code>$AVIZO_ROOT/share/python_script_objects/</code>，并在修改资源文件后重新启动 Avizo。 如果要重复使用内嵌的 Python FFT 示例，请编辑 <code>$AVIZO_ROOT/share/python_script_objects/ScipyFFT.rc</code> 文件，并将 -category 值从 “None” 改为 “{Python Scripts}”。</p><p>24、要测试此模块，请执行以下操作：</p><p>（1）启动 Avizo。</p><p>（2）加载 <code>$AVIZO_ROOT/data/tutorials/chocolate-bar.am</code>。</p><p>（3）右键单击数据对象，并从对象弹出菜单中选择 <code>Python Scripts/Scipy</code> FFT。</p><p>（4）单击<code>Apply</code>，并且具有结果 FFT 的新数据对象将在项目视图中显示。</p><p>11.7 使用 MATLAB 与 Avizo</p><p>本节描述了如何在 Avizo 中使用 MATLAB 脚本。</p><h3 id="11-7-1-使用-MATLAB-脚本"><a href="#11-7-1-使用-MATLAB-脚本" class="headerlink" title="11.7.1 使用 MATLAB 脚本"></a>11.7.1 使用 MATLAB 脚本</h3><p>在本教程中，您将学习如何通过 Calculus MATLAB 模块在 Avizo 中使用 MATLAB（The MathWorks, Inc.）进行复杂计算。</p><p>为了使用 Calculus MATLAB 模块，必须在您的计算机上正确安装 MATLAB。此外，为了允许此模块与 MATLAB 计算引擎建立连接，您可能需要注册 MATLAB 引擎（在 Windows 上），并根据您的系统设置环境变量以包括 MATLAB 库或程序的搜索路径。请参阅 Calculus MATLAB 模块的文档以了解安装详情和限制。</p><p>本教程在在线文档中提供，通过各种示例涵盖以下主题：</p><ul><li>加载和执行 MATLAB 脚本。</li><li>将各种数据类型从 Avizo 传递给 MATLAB 并导出它们。</li><li>使用字段结构。</li><li>使用时间滑块控制脚本变量。</li><li>从脚本调用用户自定义的 MATLAB 函数。</li></ul><h1 id="Thermo-Fisher-Python-API-documentation"><a href="#Thermo-Fisher-Python-API-documentation" class="headerlink" title="Thermo Fisher Python API documentation"></a>Thermo Fisher Python API documentation</h1><h2 id="Object-handling-classes"><a href="#Object-handling-classes" class="headerlink" title="Object handling classes"></a>Object handling classes</h2><h3 id="hx-core-HxObjectFactory"><a href="#hx-core-HxObjectFactory" class="headerlink" title="hx.core.HxObjectFactory"></a>hx.core.HxObjectFactory</h3><p>这是一个类，用于在Python中实例化所有模块并加载所有数据。该类的所有实例是可互换的，已经实例化的一个实例被命名为 <code>hx_object_factory</code>。</p><h4 id="create-classname"><a href="#create-classname" class="headerlink" title="create(classname)"></a>create(classname)</h4><p>此函数用于创建一个模块。</p><h5 id="参数"><a href="#参数" class="headerlink" title="参数:"></a>参数:</h5><ul><li><code>classname</code> : str<br>字符串，表示要实例化的类名。</li></ul><h5 id="返回"><a href="#返回" class="headerlink" title="返回:"></a>返回:</h5><ul><li><code>HxBase</code><br>返回最接近派生自 <code>HxBase</code> 的实例。</li></ul><h5 id="示例"><a href="#示例" class="headerlink" title="示例:"></a>示例:</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>my_var = hx_object_factory.create(<span class="string">&#x27;HxOrthoSlice&#x27;</span>)</span><br></pre></td></tr></table></figure><h4 id="get-obj-name"><a href="#get-obj-name" class="headerlink" title="get(obj_name)"></a>get(obj_name)</h4><p>此函数尝试通过名称找到一个模块或数据。</p><h5 id="参数-1"><a href="#参数-1" class="headerlink" title="参数:"></a>参数:</h5><ul><li><code>obj_name</code> : str<br>表示要查找的模块或数据的名称属性（它对应于 <code>HxBase.name</code> 属性）。</li></ul><h5 id="返回-1"><a href="#返回-1" class="headerlink" title="返回:"></a>返回:</h5><ul><li><code>HxBase</code><br>返回与名称匹配的 <code>HxBase</code> 派生实例。</li></ul><h5 id="Raises"><a href="#Raises" class="headerlink" title="Raises:"></a>Raises:</h5><ul><li><code>KeyError</code><br>如果找不到名为 <code>obj_name</code> 的模块，则引发此异常。</li></ul><h5 id="示例-1"><a href="#示例-1" class="headerlink" title="示例:"></a>示例:</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>my_var = hx_object_factory.get(<span class="string">&#x27;Ortho Slice&#x27;</span>)</span><br></pre></td></tr></table></figure><h4 id="load-filename"><a href="#load-filename" class="headerlink" title="load(filename)"></a>load(filename)</h4><p>此函数用于加载数据。</p><h5 id="参数-2"><a href="#参数-2" class="headerlink" title="参数:"></a>参数:</h5><ul><li><code>filename</code> : str<br>表示要加载的文件。</li></ul><h5 id="返回-2"><a href="#返回-2" class="headerlink" title="返回:"></a>返回:</h5><ul><li><code>HxBase 或 list[HxBase]</code><br>如果文件名对应的模块为一个，返回 <code>HxData</code> 的派生实例；如果文件名对应多个模块，返回一个 <code>HxBase</code> 的列表。</li></ul><h5 id="Raises-1"><a href="#Raises-1" class="headerlink" title="Raises:"></a>Raises:</h5><ul><li><code>KeyError</code></li><li><code>RuntimeError</code></li></ul><h5 id="示例-2"><a href="#示例-2" class="headerlink" title="示例:"></a>示例:</h5><p>此示例说明如何加载文件。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>my_var = hx_object_factory.load(hx_paths.tutorials_dir + <span class="string">&#x27;/chocolate-bar.am&#x27;</span>)</span><br></pre></td></tr></table></figure><h3 id="hx-core-HxProject"><a href="#hx-core-HxProject" class="headerlink" title="hx.core.HxProject"></a>hx.core.HxProject</h3><p>这是一个类，用于通过添加或删除对象与项目视图（也称为对象池）进行交互。该类的所有实例是可互换的，实例之一被称为 <code>hx_project</code>。</p><h4 id="add-obj"><a href="#add-obj" class="headerlink" title="add(obj)"></a>add(obj)</h4><p>将 <code>obj</code> 添加到项目视图中。</p><h5 id="参数-3"><a href="#参数-3" class="headerlink" title="参数:"></a>参数:</h5><ul><li><code>obj</code> : HxObject<br>必须添加到项目视图的对象。</li></ul><h5 id="示例-3"><a href="#示例-3" class="headerlink" title="示例:"></a>示例:</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>ortho = hx_object_factory.create(<span class="string">&#x27;HxOrthoSlice&#x27;</span>)  </span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>hx_project.add(ortho)<span class="string">&#x27;</span></span><br></pre></td></tr></table></figure><h4 id="create-classname-1"><a href="#create-classname-1" class="headerlink" title="create(classname)"></a>create(classname)</h4><p>创建一个 <code>classname</code> 类型的对象并将其添加到项目视图中。</p><h5 id="参数-4"><a href="#参数-4" class="headerlink" title="参数:"></a>参数:</h5><ul><li><code>classname</code> : str<br>表示要实例化的类的字符串。</li></ul><h5 id="返回-3"><a href="#返回-3" class="headerlink" title="返回:"></a>返回:</h5><ul><li><code>HxBase</code><br>返回最接近派生自 <code>HxBase</code> 的实例。</li></ul><h5 id="Notes"><a href="#Notes" class="headerlink" title="Notes"></a>Notes</h5><p>The following code:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>some_obj = hx_project.create(<span class="string">&#x27;HxOrthoSlice&#x27;</span>)</span><br></pre></td></tr></table></figure><p>is equivalent to:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>some_obj = hx_object_factory.create(<span class="string">&#x27;HxOrthoSlice&#x27;</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>hx_project.add(some_obj)</span><br></pre></td></tr></table></figure><h5 id="示例-4"><a href="#示例-4" class="headerlink" title="示例:"></a>示例:</h5><p>创建正交切片并将其添加到项目视图：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>some_obj = hx_project.create(<span class="string">&#x27;HxOrthoSlice&#x27;</span>)<span class="string">&#x27;</span></span><br></pre></td></tr></table></figure><h4 id="get-obj-name-1"><a href="#get-obj-name-1" class="headerlink" title="get(obj_name)"></a>get(obj_name)</h4><p>根据名称从项目视图中检索对象。</p><h5 id="参数-5"><a href="#参数-5" class="headerlink" title="参数:"></a>参数:</h5><ul><li><code>obj_name</code> : str<br>要检索的对象名称。</li></ul><h5 id="Raises-2"><a href="#Raises-2" class="headerlink" title="Raises:"></a>Raises:</h5><ul><li><code>KeyError</code><br>如果在项目视图中找不到名为 <code>obj_name</code> 的对象，则引发此异常。</li></ul><h5 id="示例-5"><a href="#示例-5" class="headerlink" title="示例:"></a>示例:</h5><p>我们创建一个 Ortho Slice，给它命名，将它添加到项目视图并通过其名称进行查询：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>ortho = hx_object_factory.create(<span class="string">&#x27;HxOrthoSlice&#x27;</span>)  </span><br><span class="line">ortho.name = <span class="string">&quot;MyNewName&quot;</span>  </span><br><span class="line">hx_project.add(ortho)  </span><br><span class="line">ortho2 = hx_project.get(<span class="string">&quot;MyNewName&quot;</span>)<span class="string">&#x27;</span></span><br></pre></td></tr></table></figure><p>请注意，在这种情况下，ortho 和 ortho2 代表应用程序中的同一个对象：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">print</span>(ortho.is_same_object(ortho2))</span><br><span class="line"><span class="literal">True</span></span><br></pre></td></tr></table></figure><h4 id="load-filename-1"><a href="#load-filename-1" class="headerlink" title="load(filename)"></a>load(filename)</h4><p>加载指定文件并将其添加到项目视图中。</p><h5 id="参数-6"><a href="#参数-6" class="headerlink" title="参数:"></a>参数:</h5><ul><li><code>filename</code> : str<br>表示要加载的文件。</li></ul><h5 id="返回-4"><a href="#返回-4" class="headerlink" title="返回:"></a>返回:</h5><ul><li><code>HxBase</code><br>返回最接近派生自 <code>HxData</code> 的实例。</li></ul><h5 id="Notes-1"><a href="#Notes-1" class="headerlink" title="Notes"></a>Notes</h5><p>The following code:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>some_obj = hx_project.load(hx_paths.tutorials_dir + <span class="string">&#x27;/chocolate-bar.am&#x27;</span>)</span><br></pre></td></tr></table></figure><p>is equivalent to:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>some_obj = hx_object_factory.load(hx_paths.tutorials_dir + <span class="string">&#x27;/chocolate-bar.am&#x27;</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>hx_project.add(some_obj)</span><br></pre></td></tr></table></figure><h5 id="示例-6"><a href="#示例-6" class="headerlink" title="示例:"></a>示例:</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>some_obj = hx_project.load(hx_paths.tutorials_dir + <span class="string">&#x27;/chocolate-bar.am&#x27;</span>)<span class="string">&#x27;</span></span><br></pre></td></tr></table></figure><h4 id="remove-obj"><a href="#remove-obj" class="headerlink" title="remove(obj)"></a>remove(obj)</h4><p>从项目视图中移除 <code>obj</code>。</p><h5 id="参数-7"><a href="#参数-7" class="headerlink" title="参数:"></a>参数:</h5><ul><li><code>obj</code> : HxObject<br>要从项目视图中删除的对象。</li></ul><h5 id="Raises-3"><a href="#Raises-3" class="headerlink" title="Raises:"></a>Raises:</h5><ul><li><code>KeyError</code><br>如果 <code>obj</code> 不在项目视图中，则引发此异常。</li></ul><h5 id="示例-7"><a href="#示例-7" class="headerlink" title="示例:"></a>示例:</h5><p>我们使用object_factory创建一个正交切片，将其添加到项目视图，然后将其从项目视图中删除：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>ortho = hx_object_factory.create(<span class="string">&#x27;HxOrthoSlice&#x27;</span>)  </span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>hx_project.add(ortho)  </span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>hx_project.remove(ortho)<span class="string">&#x27;</span></span><br></pre></td></tr></table></figure><h4 id="remove-all"><a href="#remove-all" class="headerlink" title="remove_all()"></a>remove_all()</h4><p>从项目视图中移除所有对象（仅移除可移除的对象）。</p><h5 id="示例-8"><a href="#示例-8" class="headerlink" title="示例:"></a>示例:</h5><p>从项目视图中删除所有对象。（只有可移动的对象才会被删除。）</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>hx_project.remove_all()<span class="string">&#x27;</span></span><br></pre></td></tr></table></figure><h2 id="Path-management"><a href="#Path-management" class="headerlink" title="Path management"></a>Path management</h2><h3 id="hx-core-HxPaths"><a href="#hx-core-HxPaths" class="headerlink" title="hx.core.HxPaths"></a>hx.core.HxPaths</h3><p>这是一个类，用于检索与产品路径相关的信息。该类的一个实例称为 <code>hx_paths</code>。</p><h4 id="appdata-dir"><a href="#appdata-dir" class="headerlink" title="appdata_dir"></a>appdata_dir</h4><p>与产品的 <code>appdata</code> 目录绑定的只读属性。</p><h4 id="executable-dir"><a href="#executable-dir" class="headerlink" title="executable_dir"></a>executable_dir</h4><p>与产品的可执行目录绑定的只读属性。</p><h4 id="home-dir"><a href="#home-dir" class="headerlink" title="home_dir"></a>home_dir</h4><p>与产品的主目录绑定的只读属性。</p><h4 id="install-data-dir"><a href="#install-data-dir" class="headerlink" title="install_data_dir"></a>install_data_dir</h4><p>与产品的数据目录绑定的只读属性。</p><h4 id="install-dir"><a href="#install-dir" class="headerlink" title="install_dir"></a>install_dir</h4><p>与产品的安装目录绑定的只读属性。</p><h4 id="python-modules-dir"><a href="#python-modules-dir" class="headerlink" title="python_modules_dir"></a>python_modules_dir</h4><p>与产品的 Python 模块目录绑定的只读属性。</p><h4 id="python-script-objects-dir"><a href="#python-script-objects-dir" class="headerlink" title="python_script_objects_dir"></a>python_script_objects_dir</h4><p>与产品的 Python 脚本对象目录绑定的只读属性。</p><h4 id="python-share-dir"><a href="#python-share-dir" class="headerlink" title="python_share_dir"></a>python_share_dir</h4><p>与产品的 <code>share</code> 目录绑定的只读属性。</p><h4 id="tutorials-dir"><a href="#tutorials-dir" class="headerlink" title="tutorials_dir"></a>tutorials_dir</h4><p>与产品的教程目录绑定的只读属性。</p><h2 id="Messaging-utilities"><a href="#Messaging-utilities" class="headerlink" title="Messaging utilities"></a>Messaging utilities</h2><h3 id="hx-core-HxMessage"><a href="#hx-core-HxMessage" class="headerlink" title="hx.core.HxMessage"></a>hx.core.HxMessage</h3><p>此界面用于弹出模式对话框。（例如错误、警告、信息、文件覆盖、问题）。</p><p>这些简单对话框（消息框）已实现“不再显示此消息”功能。使用此功能，用户可以禁用显示某些消息。此外，用户还可以通过“首选项”面板恢复已禁用的消息框。在消息框中使用此功能时，将创建消息框的唯一密钥，并将该密钥与用户单击的按钮索引一起保存到设置中。默认情况下，所有消息框均禁用此功能，如果我们想启用此功能，则必须传递其他参数。</p><p>该类的一个实例称为 <code>hx_message</code>。</p><h4 id="confirmations-message-button0-text-button1-text"><a href="#confirmations-message-button0-text-button1-text" class="headerlink" title="confirmations(message, button0_text, button1_text)"></a>confirmations(message, button0_text, button1_text)</h4><p>确认对话框，使用方法与 <code>question()</code> 相同。</p><h5 id="参数-8"><a href="#参数-8" class="headerlink" title="参数:"></a>参数:</h5><ul><li><code>message</code> : str<br>要在消息框中显示的消息。</li><li><code>button0_text</code> : str<br>按钮0的标签。</li><li><code>button1_text</code> : str<br>按钮1的标签。</li><li><code>do_not_show_again_key</code> : str, optional<br>如果此参数不为空，将添加“不要再显示此消息”的复选框，用户勾选后可防止再次显示该消息。该字符串值将作为识别消息的键。</li></ul><h5 id="返回-5"><a href="#返回-5" class="headerlink" title="返回:"></a>返回:</h5><ul><li><code>int</code><br>返回值指示用户按下了哪个按钮。</li></ul><h5 id="示例-9"><a href="#示例-9" class="headerlink" title="示例:"></a>示例:</h5><p>显示一个简单的确认消息框：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="string">&#x27;ret = hx_message.confirmations(&quot;Computation may be very long. Do you want to continue ?&quot;, &quot;Yes&quot;, &quot;No&quot;)  </span></span><br><span class="line"><span class="string">&gt;&gt;&gt; if ret == 0:  </span></span><br><span class="line"><span class="string">&gt;&gt;&gt;     print(&quot;Execute your computation code.&quot;)&#x27;</span></span><br></pre></td></tr></table></figure><h4 id="error-message-button0-text-””-button1-text-””-button2-text-””-default-button-index-1-escape-button-index-1"><a href="#error-message-button0-text-””-button1-text-””-button2-text-””-default-button-index-1-escape-button-index-1" class="headerlink" title="error(message, button0_text=””, button1_text=””, button2_text=””, default_button_index=-1, escape_button_index=-1)"></a>error(message, button0_text=””, button1_text=””, button2_text=””, default_button_index=-1, escape_button_index=-1)</h4><p>弹出一个模态对话框，显示用户定义的错误消息。</p><h5 id="参数-9"><a href="#参数-9" class="headerlink" title="参数:"></a>参数:</h5><ul><li><code>message</code> : str<br>要在消息框中显示的消息。</li><li><code>button0_text</code> : str, optional<br>按钮0的标签。如果为空，则显示“关闭”。</li><li><code>button1_text</code> : str, optional<br>按钮1的标签。</li><li><code>button2_text</code> : str, optional<br>按钮2的标签。</li><li><code>default_button_index</code> : int, optional<br>默认按钮的索引（0-2）。</li><li><code>escape_button_index</code> : int, optional<br>逃生按钮的索引。</li></ul><h5 id="返回-6"><a href="#返回-6" class="headerlink" title="返回:"></a>返回:</h5><ul><li><code>int</code><br>返回值指示用户按下了哪个按钮。</li></ul><h5 id="示例-10"><a href="#示例-10" class="headerlink" title="示例:"></a>示例:</h5><p>显示一个简单的消息框错误：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>hx_message.error(<span class="string">&quot;Could not locate specified file.&quot;</span>)</span><br></pre></td></tr></table></figure><h4 id="info-message-do-not-show-again-key-””"><a href="#info-message-do-not-show-again-key-””" class="headerlink" title="info(message, do_not_show_again_key=””)"></a>info(message, do_not_show_again_key=””)</h4><p>与错误、警告和问题对话框不同，信息对话框始终只有一个按钮，标有“关闭”。</p><h5 id="参数-10"><a href="#参数-10" class="headerlink" title="参数:"></a>参数:</h5><ul><li><code>message</code> : str<br>要在消息框中显示的消息。</li><li><code>do_not_show_again_key</code> : str, optional<br>如果此参数不为空，将添加“不要再显示此消息”的复选框。</li></ul><h5 id="返回-7"><a href="#返回-7" class="headerlink" title="返回:"></a>返回:</h5><ul><li><code>int</code><br>返回0。</li></ul><h5 id="示例-11"><a href="#示例-11" class="headerlink" title="示例:"></a>示例:</h5><p>显示一个简单的信息消息框：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>hx_message.info(<span class="string">&quot;Computation was a success!&quot;</span>)</span><br></pre></td></tr></table></figure><h4 id="overwrite-filename"><a href="#overwrite-filename" class="headerlink" title="overwrite(filename)"></a>overwrite(filename)</h4><p>将会弹出一个模式对话框，提示指定的文件已经存在。用户可以选择覆盖或取消。如果选择覆盖，该方法将返回 True。否则，该方法将返回 False。不会检查指定的文件是否确实已经存在。</p><h5 id="参数-11"><a href="#参数-11" class="headerlink" title="参数:"></a>参数:</h5><ul><li><code>filename</code> : str<br>已存在的文件名。</li></ul><h5 id="返回-8"><a href="#返回-8" class="headerlink" title="返回:"></a>返回:</h5><ul><li><code>bool</code><br>如果用户选择覆盖返回 <code>True</code>，否则返回 <code>False</code>。</li></ul><h4 id="question-message-button0-text-button1-text-button2-text-””-default-button-index-1-escape-button-index-1-do-not-show-again-key-””"><a href="#question-message-button0-text-button1-text-button2-text-””-default-button-index-1-escape-button-index-1-do-not-show-again-key-””" class="headerlink" title="question(message, button0_text, button1_text, button2_text=””, default_button_index=-1, escape_button_index=-1, do_not_show_again_key=””)"></a>question(message, button0_text, button1_text, button2_text=””, default_button_index=-1, escape_button_index=-1, do_not_show_again_key=””)</h4><p>问题对话框，使用方法与 <code>error()</code> 相同。</p><h5 id="参数-12"><a href="#参数-12" class="headerlink" title="参数:"></a>参数:</h5><ul><li><code>message</code> : str<br>要在消息框中显示的问题。</li><li><code>button0_text</code> : str<br>按钮0的标签。</li><li><code>button1_text</code> : str<br>按钮1的标签。</li><li><code>button2_text</code> : str, optional<br>按钮2的标签。</li><li><code>default_button_index</code> : int, optional<br>默认按钮的索引（0-2）。</li><li><code>escape_button_index</code> : int, optional<br>逃生按钮的索引。</li><li><code>do_not_show_again_key</code> : str, optional<br>如果此参数不为空，将添加“不要再显示此消息”的复选框。</li></ul><h5 id="返回-9"><a href="#返回-9" class="headerlink" title="返回:"></a>返回:</h5><ul><li><code>int</code><br>返回值指示用户按下了哪个按钮。</li></ul><h5 id="示例-12"><a href="#示例-12" class="headerlink" title="示例:"></a>示例:</h5><p>显示一个简单的消息框问题：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>ret = hx_message.question(<span class="string">&quot;Specified file seems corrupted. Do you want to load the data anyway ?&quot;</span>, <span class="string">&quot;Yes&quot;</span>, <span class="string">&quot;No&quot;</span>)  </span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">if</span> ret == <span class="number">0</span>:  </span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>    <span class="built_in">print</span>(<span class="string">&quot;Abort image loading...&quot;</span>)</span><br></pre></td></tr></table></figure><h4 id="warning-message-button0-text-””-button1-text-””-button2-text-””-default-button-index-1-escape-button-index-1-do-not-show-again-key-””"><a href="#warning-message-button0-text-””-button1-text-””-button2-text-””-default-button-index-1-escape-button-index-1-do-not-show-again-key-””" class="headerlink" title="warning(message, button0_text=””, button1_text=””, button2_text=””, default_button_index=-1, escape_button_index=-1, do_not_show_again_key=””)"></a>warning(message, button0_text=””, button1_text=””, button2_text=””, default_button_index=-1, escape_button_index=-1, do_not_show_again_key=””)</h4><p>警告对话框，使用方法与 <code>error()</code> 相同。</p><h5 id="参数-13"><a href="#参数-13" class="headerlink" title="参数:"></a>参数:</h5><ul><li><code>message</code> : str<br>要在消息框中显示的警告消息。</li><li><code>button0_text</code> : str, optional<br>按钮0的标签。</li><li><code>button1_text</code> : str, optional<br>按钮1的标签。</li><li><code>button2_text</code> : str, optional<br>按钮2的标签。</li><li><code>default_button_index</code> : int, optional<br>默认按钮的索引（0-2）。</li><li><code>escape_button_index</code> : int, optional<br>逃生按钮的索引。</li><li><code>do_not_show_again_key</code> : str, optional<br>如果此参数不为空，将添加“不要再显示此消息”的复选框。</li></ul><h5 id="返回-10"><a href="#返回-10" class="headerlink" title="返回:"></a>返回:</h5><ul><li><code>int</code><br>返回值指示用户按下了哪个按钮。</li></ul><h5 id="示例-13"><a href="#示例-13" class="headerlink" title="示例:"></a>示例:</h5><p>显示一个简单的消息框警告：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>hx_message.warning(<span class="string">&quot;Imported file does not have the expected size.&quot;</span>)</span><br></pre></td></tr></table></figure><h2 id="Hierarchy-of-objects"><a href="#Hierarchy-of-objects" class="headerlink" title="Hierarchy of objects"></a>Hierarchy of objects</h2><h3 id="hx-core-McInterface"><a href="#hx-core-McInterface" class="headerlink" title="hx.core.McInterface"></a>hx.core.McInterface</h3><p>McInterface 是所有接口的基类，包括 HxBase 层次结构。此类是抽象基类。</p><h4 id="属性"><a href="#属性" class="headerlink" title="属性"></a>属性</h4><h5 id="all-interfaces"><a href="#all-interfaces" class="headerlink" title="all_interfaces"></a>all_interfaces</h5><p>包含所有允许的接口作为子成员的属性。</p><h5 id="示例-14"><a href="#示例-14" class="headerlink" title="示例"></a>示例</h5><p>检索正交切片 (HxOrthoSlice) 的 HxBase 接口：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>ortho = hx_project.create(<span class="string">&#x27;HxOrthoSlice&#x27;</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>base = ortho.all_interfaces.HxBase</span><br></pre></td></tr></table></figure></p><h4 id="方法"><a href="#方法" class="headerlink" title="方法"></a>方法</h4><h5 id="get-all-interface-names"><a href="#get-all-interface-names" class="headerlink" title="get_all_interface_names()"></a>get_all_interface_names()</h5><p>返回支持的所有接口名称的列表。</p><h5 id="返回-11"><a href="#返回-11" class="headerlink" title="返回:"></a>返回:</h5><ul><li>list of strings<br>返回对象支持的所有接口名称的列表。</li></ul><h5 id="示例-15"><a href="#示例-15" class="headerlink" title="示例"></a>示例</h5><p>打印正交切片支持的所有接口：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>ortho = hx_project.create(<span class="string">&#x27;HxOrthoSlice&#x27;</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">print</span>(ortho.get_all_interface_names())</span><br><span class="line">[<span class="string">&#x27;HxPlanarModBase&#x27;</span>, <span class="string">&#x27;HxModule&#x27;</span>, <span class="string">&#x27;HxObject&#x27;</span>, <span class="string">&#x27;HxBase&#x27;</span>]</span><br></pre></td></tr></table></figure></p><h3 id="hx-core-HxBase"><a href="#hx-core-HxBase" class="headerlink" title="hx.core.HxBase"></a>hx.core.HxBase</h3><p>文档太长，暂不翻译</p><h1 id="python-avizo代码测试"><a href="#python-avizo代码测试" class="headerlink" title="python+avizo代码测试"></a>python+avizo代码测试</h1><h2 id="代码创建方法"><a href="#代码创建方法" class="headerlink" title="代码创建方法"></a>代码创建方法</h2><p>在python控制台中调用 <code>Segmentation Editor</code> 很难实现，对于pyhon接口，只可以在project中实现的算法，可以采用API去调用。</p><p>对于某个具体的方法，可以鼠标放在方法栏上，然后悬停后显示方法名。</p><img src="/2024/09/19/AVIZO%E8%87%AA%E5%8A%A8%E5%8C%96/%E9%98%88%E5%80%BC%E5%88%86%E5%89%B2-1.png" class="" title="阈值分割-1"><p>例如<code>Image Curvature</code>方法，在API中对应的接口就是<code>curvature2d/curvature3d</code></p><p>对于<code>curvature</code>方法不熟悉，可以在控制台直接输出。</p><ul><li>curvature3d</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hx_object_factory.create(<span class="string">&#x27;curvature3d&#x27;</span>)</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">Python handle of type: &#x27;HxCompModule&#x27;</span><br><span class="line">Kernel item name     : &#x27;Image Curvature 3D&#x27;</span><br><span class="line">Kernel item type     : &#x27;HxQuant2GenericModule&#x27;</span><br><span class="line">All ports            :</span><br><span class="line">    &#x27;interpretation&#x27;: &#x27;HxPortRadioBox&#x27;</span><br><span class="line">    &#x27;outputLocation&#x27;: &#x27;HxPortMultiMenu&#x27;</span><br><span class="line">    &#x27;doIt&#x27;: &#x27;HxPortDoIt&#x27;</span><br><span class="line">    &#x27;inputImage&#x27;: &#x27;HxConnection&#x27;</span><br><span class="line">    &#x27;inputImageMask&#x27;: &#x27;HxConnection&#x27;</span><br><span class="line">    &#x27;standardDeviation&#x27;: &#x27;HxPortFloatTextN&#x27;</span><br></pre></td></tr></table></figure><ul><li>curvature2d</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hx_object_factory.create(<span class="string">&#x27;curvature2d&#x27;</span>)</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">Python handle of type: &#x27;HxCompModule&#x27;</span><br><span class="line">Kernel item name     : &#x27;Image Curvature 2&#x27;</span><br><span class="line">Kernel item type     : &#x27;HxQuant2GenericModule&#x27;</span><br><span class="line">All ports            :</span><br><span class="line">    &#x27;interpretation&#x27;: &#x27;HxPortRadioBox&#x27;</span><br><span class="line">    &#x27;outputLocation&#x27;: &#x27;HxPortMultiMenu&#x27;</span><br><span class="line">    &#x27;doIt&#x27;: &#x27;HxPortDoIt&#x27;</span><br><span class="line">    &#x27;inputImage&#x27;: &#x27;HxConnection&#x27;</span><br><span class="line">    &#x27;inputImageMask&#x27;: &#x27;HxConnection&#x27;</span><br><span class="line">    &#x27;standardDeviation&#x27;: &#x27;HxPortFloatTextN&#x27;</span><br></pre></td></tr></table></figure><ul><li>图形化界面可以看到，使用以下创建方式</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hx_project.create(<span class="string">&#x27;curvature3d&#x27;</span>)</span><br></pre></td></tr></table></figure><h2 id="helloworld"><a href="#helloworld" class="headerlink" title="helloworld"></a>helloworld</h2><p>在Avizo的Main Python Console调用并执行脚本</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">exec</span>(<span class="built_in">open</span>(<span class="string">&#x27;F://PYCharmWorkSpace//DigitalCoreFeatureExtraction//avizo//avizo_helloworld.py&#x27;</span>).read())</span><br></pre></td></tr></table></figure><h2 id="读取文件并进行切片显示"><a href="#读取文件并进行切片显示" class="headerlink" title="读取文件并进行切片显示"></a>读取文件并进行切片显示</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">dataLoaded = hx_project.load(<span class="string">&#x27;E:/digitalrock/eleven_sandstones_dataset/1_Berea/Berea_2d25um_binary_1-0_test.tif&#x27;</span>)</span><br><span class="line"></span><br><span class="line">ortho_slice = hx_project.create(<span class="string">&#x27;HxOrthoSlice&#x27;</span>)</span><br><span class="line"></span><br><span class="line">ortho_slice.ports.data.connect(dataLoaded)</span><br><span class="line"></span><br><span class="line">ortho_slice.fire()</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">exec</span>(<span class="built_in">open</span>(<span class="string">&#x27;F://PYCharmWorkSpace//DigitalCoreFeatureExtraction//avizo//avizo_read_test.py&#x27;</span>).read())</span><br></pre></td></tr></table></figure><h2 id="阈值分割"><a href="#阈值分割" class="headerlink" title="阈值分割"></a>阈值分割</h2><h3 id="avizo中Image-Segmentation方法"><a href="#avizo中Image-Segmentation方法" class="headerlink" title="avizo中Image Segmentation方法"></a>avizo中Image Segmentation方法</h3><img src="/2024/09/19/AVIZO%E8%87%AA%E5%8A%A8%E5%8C%96/ImageSegmentation-1.png" class="" title="ImageSegmentation-1"><ul><li>2D-Histogram Segmentation</li></ul><p>使用2D直方图分割脚本模块，您可以以半自动的方式对由两个或多个阶段组成的CT或MR灰度图像数据进行分割。</p><p>考虑多相材料，如教程数据 chocolate-bar.am，即气缸盖样品的 CT 扫描。有许多离散相，但直方图显示不同相的峰值重叠。在这种情况下，基于强度对图像进行阈值处理将失败，因为任何阈值都会导致某些像素被错误分配。<br>这里使用的方法称为 2D 直方图分割，依赖于梯度幅度与图像强度直方图。<br>此分割过程包括两个主要步骤：将一些体素初步分类为两个或多个相，然后是扩展步骤，在该步骤中扩展该分类，以便所有体素都被标记。<br>分类：对于此例程，体素的初始分类是基于这些体素的强度及其梯度幅度执行的。此例程的输入是 3D 体积的强度图。从该输入计算梯度幅度。计算梯度幅度后，将向用户显示显示梯度幅度与图像强度的 2D 散点图。用户将使用此图来确定初始分类（这在使用直方图初始化分类中进行了描述）。<br>扩展：扩展由标记种子分水岭变换计算（参见分水岭算法原理）。分水岭变换需要两个输入，一组种子标记和一个景观函数。种子标记将由分类确定（参见解释直方图），梯度幅度将用于景观函数。<br>2D 直方图分割的 6 个步骤：<br>步骤 1 - 计算梯度幅度以开始 - 请参阅计算梯度幅度中的详细信息：<br>选择精确计算梯度幅度或更快近似梯度幅度。<br>点击下一步：计算梯度幅度以继续。<br>步骤 2 - 绘制直方图，请参阅解释直方图中的详细信息：<br>点击下一步：绘制直方图以继续。<br>步骤 3 - 绘制窗口 - 请参阅使用直方图初始化分类中的详细信息：<br>如果您使用鼠标拖动绘图窗口，并且希望将其重置为原始大小和位置，则只需拖动属性面板上的伽马校正滑块即可。<br>使用伽马校正在 2D 直方图上可视化峰值。使用绘图窗口顶部的绘图工具直接在绘图上绘制窗口。通常，您需要选择梯度幅度非常低的区域（峰值靠近 x 轴）。<br>点击下一步：计算种子以继续下一步。<br>步骤 4 - 查看种子标签：<br>使用权重因子更新视图以显示灰度数据、种子标签图像或两个数据集的加权融合。<br>使用隐藏/显示直方图按钮切换直方图的显示，以便更轻松地在查看器中查看结果。使用切片编号调整正在显示的切片索引平面。如果您对从所选窗口计算出的种子不满意，请点击“删除最后一个窗口”以逐个删除窗口（按添加时的相反顺序）。然后您可以绘制新窗口。绘制新窗口后，请点击“重新计算种子”。您可以反复进行，直到对种子满意为止。<br>点击“下一步：应用分水岭”继续（请参阅“使用分水岭扩展”中的详细信息）<br>步骤 5 - 确认分水岭结果：<br>如果结果不令人满意，请绘制新区域，然后点击“上一步：重新计算种子”重新应用分水岭。<br>点击“下一步”继续执行最后一步，这是可选的。<br>步骤 6 - [可选] 删除通道：<br>如果分配的标签之一对应于空白空间，您可以选择从标签图像中删除该标签。<br>完成后，您应该删除此模块。</p><ul><li>Watershed Segmentation</li></ul><p>此模块通过对高梯度幅值应用分水岭来对不同相进行精确分割。<br>指定要分割的相数后，单击“跳过”按钮并按照说明进行操作。<br>要执行的操作包括：<br>指定相数。如果仅指定一个相，则将从指定相的侵蚀负片内部计算假标签。因此，分水岭计算期间指定相的扩散受到侵蚀的限制。<br>计算 3D 梯度幅值。内部使用 Avizo gradient_canny3d。或者，可以通过将梯度幅值标量场连接到 portGradient 来设置梯度幅值。<br>阈值梯度蒙版。使用滑块对梯度蒙版进行阈值设置，即定义无法设置标记的区域。<br>为相指定每个标记。可以使用最小和最大阈值滑块设置每个标记，也可以通过 portPhase 将相标记指定为二进制图像来设置每个标记。<br>应用分水岭计算。Avizo 分水岭算法根据先前设置的标记执行，以梯度幅度作为高度图像。<br>可视化最终阶段。颜色清洗模块连接到切片，同时提供阶段分割和原始数据可视化。</p><ul><li>Adaptive Thresholding</li></ul><p>该模块通过应用相对于滑动窗口的平均强度自动适应的阈值来执行二值化。<br>对于每个像素，根据其局部平均强度计算局部阈值。然后使用可以乘法或加法的模型应用此阈值。<br>保留的像素是那些根据比较标准“大于或等于”或“小于或等于”阈值的像素。</p><ul><li>Auto Thresholding</li></ul><p>自动阈值高是模块自动阈值的配置之一。有关其他配置，请参阅端口类型。<br>此模块计算灰度图像上的自动阈值，即将图像分成 2 个像素类。有四种分类方法：熵、因式分解、矩和 IsoData。计算出的阈值显示在表格面板中。</p><ul><li>Feature Adaptive Thresholding</li></ul><p>二值化将灰度图像转换为二进制图像。当灰度图像中的相关信息对应于特定的灰度间隔时，使用此方法。在二进制图像中，感兴趣的像素设置为 1，其他所有像素（背景）设置为 0。<br>此模块计算灰度图像的阈值，给定与原始图像的预分割相对应的标签图像。用户不是为阈值提供两个固定值，而是选择两个代表性度量（例如，直方图的第 10 和第 90 个百分位数）。每个标签的最小和最大阈值都是动态计算的，并对它们进行单独的阈值处理。</p><ul><li>Hysteresis Thresholding</li></ul><p>二值化将灰度图像转换为二进制图像。当灰度图像中的相关信息对应于特定的灰度间隔时，使用此方法。在二进制图像中，感兴趣的像素设置为 1，其他所有像素（背景）设置为 0。<br>滞后阈值使用滞后环来提供更连接的阈值结果。</p><ul><li>Interactive Thresholding</li></ul><p>此工具允许以交互方式选择阈值。当前选择显示为所连接正交视图的每个视图上的叠加层。<br>按“应用”按钮创建二进制图像。将创建一个新字段，该字段对于阈值间隔内的每个值均为 1，对于所有其他字段值均为 0。</p><ul><li>Interactive Top-Hat</li></ul><p>Top-Hat 分割从给定图像中提取小元素和细节。它检测对应于谷值或窄峰的暗区或白区。</p><p>有两种类型的 Top-Hat 变换：</p><p>黑色 Top-Hat：它被定义为使用给定大小的内核闭合的立方体与输入图像之间的差异。内核越小，Top-Hat 图像中的元素越小。阈值允许选择 Top-Hat 结果中较暗的元素，即所选谷值的深度。参见图 1。</p><p>白色 Top-Hat：它被定义为输入图像与其开口立方体之间的差异（使用给定大小的内核）。阈值允许选择 Top-Hat 结果中较亮的元素。</p><ul><li>Local Thresholding</li></ul><p>该模块提供算法，将图像堆栈二分分割为前景和背景对象。模块的输出是标签图像。如果需要在缓慢变化的背景之前分割多个小对象，则该算法效果最佳。<br>一些阈值算法需要大量主内存才能运行（Niblack、Oberlaender、Mardia-Hainsworth）。浮点分辨率缓冲区将根据输入图像大小进行分配。</p><ul><li>Threshold by Criterion</li></ul><p>按标准阈值对图像进行阈值处理。如果计算结果为真，则输出像素将设置为 1，否则设置为 0。</p><h3 id="是否需要阈值分割"><a href="#是否需要阈值分割" class="headerlink" title="是否需要阈值分割"></a>是否需要阈值分割</h3><img src="/2024/09/19/AVIZO%E8%87%AA%E5%8A%A8%E5%8C%96/ImageSegmentation-2.png" class="" title="ImageSegmentation-2"><p>相同的数据体，计算曲率的过程相同<br>上面执行材料划分<br>下面不执行材料划分<br>数据执行结果相同<br>因为孔隙为1，骨架为0。</p><h2 id="曲率计算及分析"><a href="#曲率计算及分析" class="headerlink" title="曲率计算及分析"></a>曲率计算及分析</h2><h3 id="Image-Curvature"><a href="#Image-Curvature" class="headerlink" title="Image Curvature"></a>Image Curvature</h3><p>从本地加载一张tif图片，然后调用curvature方法</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">data = hx_project.load(<span class="string">&#x27;E:/digitalrock/eleven_sandstones_dataset/1_Berea/Berea_2d25um_binary_1-0_test.tif&#x27;</span>)</span><br><span class="line"></span><br><span class="line">curvature3d = hx_project.create(<span class="string">&#x27;curvature3d&#x27;</span>)</span><br><span class="line"></span><br><span class="line">curvature3d.ports.inputImage.connect(data)</span><br><span class="line"></span><br><span class="line">curvature3d.ports.doIt.was_hit = <span class="literal">True</span></span><br><span class="line">curvature3d.compute()</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(curvature3d.results[<span class="number">0</span>].name)</span><br></pre></td></tr></table></figure><p><code>fire()</code> → 如果这是一个计算模块并且其端口 doIt 已被触碰或者自动刷新已被激活，则此方法将触发对对象上的 update() 的调用，并最终触发 compute() 的调用。<br><code>execute()</code> → 此方法将模拟点击此对象的属性区域下的绿色应用按钮，并对此对象执行<code>fire()</code>。<br><code>compute()</code> → 执行计算。</p><p>现在我们通过触发端口doIt来调用计算：<code>curvature3d.ports.doIt.was_hit = True</code></p><p>执行</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">exec</span>(<span class="built_in">open</span>(<span class="string">&#x27;F://PYCharmWorkSpace//DigitalCoreFeatureExtraction//avizo//avizo_test.py&#x27;</span>).read())</span><br></pre></td></tr></table></figure><h3 id="Image-Statistics"><a href="#Image-Statistics" class="headerlink" title="Image Statistics"></a>Image Statistics</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hx_project.create(<span class="string">&#x27;statistics&#x27;</span>)</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">Python handle of type: &#x27;HxCompModule&#x27;</span><br><span class="line">Kernel item name     : &#x27;Image Statistics&#x27;</span><br><span class="line">Kernel item type     : &#x27;HxQuant2GenericModule&#x27;</span><br><span class="line">All ports            :</span><br><span class="line">    &#x27;Type&#x27;: &#x27;HxPortModuleSwitch&#x27;</span><br><span class="line">    &#x27;interpretation&#x27;: &#x27;HxPortRadioBox&#x27;</span><br><span class="line">    &#x27;outputLocation&#x27;: &#x27;HxPortMultiMenu&#x27;</span><br><span class="line">    &#x27;doIt&#x27;: &#x27;HxPortDoIt&#x27;</span><br><span class="line">    &#x27;inputImage&#x27;: &#x27;HxConnection&#x27;</span><br><span class="line">    &#x27;rangeMode&#x27;: &#x27;HxPortMultiMenu&#x27;</span><br><span class="line">    &#x27;inputRange&#x27;: &#x27;HxPortIntTextN&#x27;</span><br></pre></td></tr></table></figure><h3 id="Image-Curvature-Image-Statistics"><a href="#Image-Curvature-Image-Statistics" class="headerlink" title="Image Curvature + Image Statistics"></a>Image Curvature + Image Statistics</h3><ul><li>接收到处理结果</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">result1 = curvature3d.results[<span class="number">0</span>]</span><br><span class="line">result2 = curvature3d.results[<span class="number">1</span>]</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(result1.portnames)</span><br><span class="line"><span class="built_in">print</span>(result2.portnames)</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[&#x27;master&#x27;, &#x27;histogramInfo&#x27;, &#x27;sharedColormap&#x27;, &#x27;preview&#x27;]</span><br><span class="line">[&#x27;master&#x27;, &#x27;histogramInfo&#x27;, &#x27;sharedColormap&#x27;, &#x27;preview&#x27;]</span><br></pre></td></tr></table></figure><ul><li>处理结果运行分析</li></ul><p>对两个曲率进行统计</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">imagestatic1 = hx_project.create(<span class="string">&#x27;statistics&#x27;</span>)</span><br><span class="line">imagestatic2 = hx_project.create(<span class="string">&#x27;statistics&#x27;</span>)</span><br><span class="line"></span><br><span class="line">imagestatic1.ports.inputImage.connect(result1)</span><br><span class="line">imagestatic2.ports.inputImage.connect(result2)</span><br><span class="line"></span><br><span class="line">imagestatic1.ports.doIt.was_hit = <span class="literal">True</span></span><br><span class="line">imagestatic2.ports.doIt.was_hit = <span class="literal">True</span></span><br><span class="line"></span><br><span class="line">imagestatic1.compute()</span><br><span class="line">imagestatic2.compute()</span><br></pre></td></tr></table></figure><ul><li>接收到统计结果</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">staticresult1 = imagestatic1.results[<span class="number">0</span>]</span><br><span class="line">staticresult12 = imagestatic2.results[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(staticresult1.portnames)</span><br><span class="line"><span class="built_in">print</span>(staticresult12.portnames)</span><br><span class="line"></span><br><span class="line">staticresult1.method</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[&#x27;master&#x27;, &#x27;table&#x27;, &#x27;DataClass&#x27;]</span><br><span class="line">[&#x27;master&#x27;, &#x27;table&#x27;, &#x27;DataClass&#x27;]</span><br></pre></td></tr></table></figure><h3 id="读取表格"><a href="#读取表格" class="headerlink" title="读取表格"></a>读取表格</h3><p>参看API中<code>hx.core.HxSpreadSheetInterface</code></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">ssi = staticresult1.all_interfaces.HxSpreadSheetInterface</span><br><span class="line"><span class="built_in">print</span>(ssi.tables[<span class="number">0</span>].columns[<span class="number">1</span>].name)<span class="comment"># NbPixels</span></span><br><span class="line"><span class="built_in">print</span>(ssi.tables[<span class="number">0</span>].columns[<span class="number">5</span>].name)<span class="comment"># Mean</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(ssi.tables[<span class="number">0</span>].items[<span class="number">0</span>,<span class="number">5</span>])</span><br><span class="line"><span class="built_in">print</span>(ssi.tables[<span class="number">0</span>].row[<span class="number">0</span>].items[<span class="number">1</span>])</span><br></pre></td></tr></table></figure><h2 id="阈值分割计算曲率案例"><a href="#阈值分割计算曲率案例" class="headerlink" title="阈值分割计算曲率案例"></a>阈值分割计算曲率案例</h2><h3 id="2D"><a href="#2D" class="headerlink" title="2D"></a>2D</h3><p>1、加载图像<br>2、计算曲率<br>3、曲率结果处理</p><ul><li>2D图片加载弹窗问题</li></ul><p>暂时无法解决，获取不到对话框，只可以认为用鼠标连点器点击</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> skimage.io <span class="keyword">import</span> imread_collection</span><br><span class="line"></span><br><span class="line">hx_project.remove_all()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">imgfloder_src = [<span class="string">&#x27;E:/digitalrock/eleven_sandstones_dataset/1_Berea/Berea_2d25um_binary_tif_1-0_test/&#x27;</span>]</span><br><span class="line"></span><br><span class="line">img_suffix = <span class="string">&#x27;*.tif&#x27;</span></span><br><span class="line"></span><br><span class="line">pixel_size = <span class="number">2.25e-6</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> imgfloder_src:</span><br><span class="line">    imgfloder_seq = imread_collection(i + img_suffix)</span><br><span class="line">    <span class="comment">#print(imgfloder_seq)</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> imgfloder_seq.files:</span><br><span class="line">        img_name = j.split(<span class="string">&#x27;\\&#x27;</span>)[-<span class="number">1</span>]</span><br><span class="line">        filepath = i + img_name</span><br><span class="line">        <span class="comment">#print(filepath)</span></span><br><span class="line">        data = hx_project.load(filepath)</span><br><span class="line">        curvaturemodel = hx_project.create(<span class="string">&#x27;curvature2d&#x27;</span>)</span><br><span class="line">        curvaturemodel.ports.inputImage.connect(data)</span><br><span class="line">        curvaturemodel.ports.doIt.was_hit = <span class="literal">True</span></span><br><span class="line">        curvaturemodel.compute()</span><br><span class="line"></span><br><span class="line">        gasscurvature = curvaturemodel.results[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">        gasscurvaturestatistics = hx_project.create(<span class="string">&#x27;statistics&#x27;</span>)</span><br><span class="line">        gasscurvaturestatistics.ports.inputImage.connect(gasscurvature)</span><br><span class="line">        gasscurvaturestatistics.ports.doIt.was_hit = <span class="literal">True</span></span><br><span class="line">        gasscurvaturestatistics.execute()</span><br><span class="line">        gasscurvaturestatisticsresult = gasscurvaturestatistics.results[<span class="number">0</span>]</span><br><span class="line">        ssi1 = gasscurvaturestatisticsresult.all_interfaces.HxSpreadSheetInterface</span><br><span class="line">        <span class="built_in">print</span>(img_name + <span class="string">&quot;  &quot;</span> + <span class="string">&quot;&#123;:.4e&#125;&quot;</span>.<span class="built_in">format</span>((ssi1.tables[<span class="number">0</span>].items[<span class="number">0</span>, <span class="number">5</span>]) / pixel_size))  <span class="comment"># m-1</span></span><br><span class="line">        hx_project.remove_all()</span><br></pre></td></tr></table></figure><h3 id="3D-单个"><a href="#3D-单个" class="headerlink" title="3D-单个"></a>3D-单个</h3><p>1、加载图像<br>2、计算曲率<br>3、曲率结果处理</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 加载数据</span></span><br><span class="line">data = hx_project.load(<span class="string">&#x27;E:/digitalrock/eleven_sandstones_dataset/1_Berea/Berea_2d25um_binary_1-0_test.tif&#x27;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建3维曲率计算模块</span></span><br><span class="line">curvaturemodel = hx_project.create(<span class="string">&#x27;curvature3d&#x27;</span>)</span><br><span class="line"><span class="comment"># 设置曲率计算模块输入</span></span><br><span class="line">curvaturemodel.ports.inputImage.connect(data)</span><br><span class="line"><span class="comment"># 设置曲率计算方法打开doIt</span></span><br><span class="line">curvaturemodel.ports.doIt.was_hit = <span class="literal">True</span></span><br><span class="line"><span class="comment"># 执行计算</span></span><br><span class="line">curvaturemodel.compute()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 高斯曲率计算结果</span></span><br><span class="line">gasscurvature = curvaturemodel.results[<span class="number">0</span>]</span><br><span class="line"><span class="comment"># 平均曲率计算结果</span></span><br><span class="line">avgcurvature = curvaturemodel.results[<span class="number">1</span>]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建高斯曲率统计模块</span></span><br><span class="line">gasscurvaturestatistics = hx_project.create(<span class="string">&#x27;statistics&#x27;</span>)</span><br><span class="line"><span class="comment"># 设置高斯曲率计算模块输入</span></span><br><span class="line">gasscurvaturestatistics.ports.inputImage.connect(gasscurvature)</span><br><span class="line"><span class="comment"># 设置高斯曲率统计模块打开doIt</span></span><br><span class="line">gasscurvaturestatistics.ports.doIt.was_hit = <span class="literal">True</span></span><br><span class="line"><span class="comment"># 执行高斯曲率统计计算</span></span><br><span class="line">gasscurvaturestatistics.execute()</span><br><span class="line"><span class="comment"># 高斯曲率统计结果</span></span><br><span class="line">gasscurvaturestatisticsresult = gasscurvaturestatistics.results[<span class="number">0</span>]</span><br><span class="line"><span class="comment"># 查看高斯曲率整体均值</span></span><br><span class="line">ssi1 = gasscurvaturestatisticsresult.all_interfaces.HxSpreadSheetInterface</span><br><span class="line"><span class="built_in">print</span>(ssi1.tables[<span class="number">0</span>].items[<span class="number">0</span>, <span class="number">5</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建平均曲率统计模块</span></span><br><span class="line">avgcurvaturestatistics = hx_project.create(<span class="string">&#x27;statistics&#x27;</span>)</span><br><span class="line"><span class="comment"># 设置平均曲率计算模块输入</span></span><br><span class="line">avgcurvaturestatistics.ports.inputImage.connect(avgcurvature)</span><br><span class="line"><span class="comment"># 设置平均曲率统计模块打开doIt</span></span><br><span class="line">avgcurvaturestatistics.ports.doIt.was_hit = <span class="literal">True</span></span><br><span class="line"><span class="comment"># 执行平均曲率统计计算</span></span><br><span class="line">avgcurvaturestatistics.execute()</span><br><span class="line"><span class="comment"># 平均曲率统计结果</span></span><br><span class="line">avgcurvaturestatisticsresult = avgcurvaturestatistics.results[<span class="number">0</span>]</span><br><span class="line"><span class="comment"># 查看平均曲率整体均值</span></span><br><span class="line">ssi2 = avgcurvaturestatisticsresult.all_interfaces.HxSpreadSheetInterface</span><br><span class="line"><span class="built_in">print</span>(ssi2.tables[<span class="number">0</span>].items[<span class="number">0</span>,<span class="number">5</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># exec(open(&#x27;F://PYCharmWorkSpace//DigitalCoreFeatureExtraction//curvature//curvature_avizo_3d_test1.py&#x27;).read())</span></span><br></pre></td></tr></table></figure><p>执行：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">exec</span>(<span class="built_in">open</span>(<span class="string">&#x27;F://PYCharmWorkSpace//DigitalCoreFeatureExtraction//curvature//curvature_avizo_3d_test1.py&#x27;</span>).read())</span><br></pre></td></tr></table></figure><p>结果：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">0.04535578936338425</span><br><span class="line">-0.028369586914777756</span><br></pre></td></tr></table></figure>]]></content>
    
    
    <summary type="html">AVIZO自动化</summary>
    
    
    
    <category term="AvizoUsersGuide" scheme="http://hibiscidai.com/categories/AvizoUsersGuide/"/>
    
    
    <category term="Avizo" scheme="http://hibiscidai.com/tags/Avizo/"/>
    
    <category term="石油地质" scheme="http://hibiscidai.com/tags/%E7%9F%B3%E6%B2%B9%E5%9C%B0%E8%B4%A8/"/>
    
    <category term="数字岩心" scheme="http://hibiscidai.com/tags/%E6%95%B0%E5%AD%97%E5%B2%A9%E5%BF%83/"/>
    
  </entry>
  
  <entry>
    <title>AVIZO曲率计算</title>
    <link href="http://hibiscidai.com/2024/09/03/AVIZO%E6%9B%B2%E7%8E%87%E8%AE%A1%E7%AE%97/"/>
    <id>http://hibiscidai.com/2024/09/03/AVIZO%E6%9B%B2%E7%8E%87%E8%AE%A1%E7%AE%97/</id>
    <published>2024-09-03T05:30:00.000Z</published>
    <updated>2025-03-06T10:34:19.210Z</updated>
    
    <content type="html"><![CDATA[<img src="/2024/09/03/AVIZO%E6%9B%B2%E7%8E%87%E8%AE%A1%E7%AE%97/AVIZO%E6%9B%B2%E7%8E%87%E8%AE%A1%E7%AE%97.png" class="" title="AVIZO曲率计算"><p>AVIZO曲率计算</p><span id="more"></span><h1 id="AVIZO曲率计算"><a href="#AVIZO曲率计算" class="headerlink" title="AVIZO曲率计算"></a>AVIZO曲率计算</h1><p>参考视频教程：</p><p><a href="https://www.bilibili.com/video/BV1aY4y1E7dE/?spm_id_from=333.880.my_history.page.click&amp;vd_source=e29d2e4b12ca5d1c1091b9265d56c53d"> 通过分形维数和表面曲率衡量样品的粗糙度</a></p><p><a href="https://www.bilibili.com/video/BV1nW4y1q7E7/?spm_id_from=333.999.0.0&amp;vd_source=e29d2e4b12ca5d1c1091b9265d56c53d">Avizo中利用auto refresh功能半自动化进行REV（体元表征）</a></p><h1 id="计算流程"><a href="#计算流程" class="headerlink" title="计算流程"></a>计算流程</h1><p>原始数据<br>↓<br>数据体分割提取<br>↓<br>分割后感兴趣的区域（孔隙）<br>↓<br>生成表面网格<br>↓<br>曲率计算</p><img src="/2024/09/03/AVIZO%E6%9B%B2%E7%8E%87%E8%AE%A1%E7%AE%97/AVIZO%E6%9B%B2%E7%8E%87%E8%AE%A1%E7%AE%97_1.png" class="" title="AVIZO曲率计算_1"><img src="/2024/09/03/AVIZO%E6%9B%B2%E7%8E%87%E8%AE%A1%E7%AE%97/AVIZO%E6%9B%B2%E7%8E%87%E8%AE%A1%E7%AE%97_2.png" class="" title="AVIZO曲率计算_2"><img src="/2024/09/03/AVIZO%E6%9B%B2%E7%8E%87%E8%AE%A1%E7%AE%97/AVIZO%E6%9B%B2%E7%8E%87%E8%AE%A1%E7%AE%97_3.png" class="" title="AVIZO曲率计算_3"><img src="/2024/09/03/AVIZO%E6%9B%B2%E7%8E%87%E8%AE%A1%E7%AE%97/AVIZO%E6%9B%B2%E7%8E%87%E8%AE%A1%E7%AE%97_4.png" class="" title="AVIZO曲率计算_4"><p>如果要实现批量计算需要写脚本代码实现</p><h1 id="Image-Curvature-3D-原理"><a href="#Image-Curvature-3D-原理" class="headerlink" title="Image Curvature 3D-原理"></a>Image Curvature 3D-原理</h1><p>3维会生成两个曲率：<br>第一个默认是高斯<br>第二个默认是平均</p><p>2维生成一个曲率→高斯</p><img src="/2024/09/03/AVIZO%E6%9B%B2%E7%8E%87%E8%AE%A1%E7%AE%97/AVIZO%E6%9B%B2%E7%8E%87%E8%AE%A1%E7%AE%97_6.png" class="" title="AVIZO曲率计算_6"><img src="/2024/09/03/AVIZO%E6%9B%B2%E7%8E%87%E8%AE%A1%E7%AE%97/AVIZO%E6%9B%B2%E7%8E%87%E8%AE%A1%E7%AE%97_7.png" class="" title="AVIZO曲率计算_7"><h2 id="Description"><a href="#Description" class="headerlink" title="Description:"></a>Description:</h2><p>This module computes for each voxel of an input image local texture curvature. Computed curvature(s) takes voxel size into account.<br>More informations on these algorithms can be found in:</p><p>该模块计算输入图像中每个体素的局部纹理曲率。计算出的曲率考虑了体素的大小。<br>有关这些算法的更多信息，请参见：</p><p>该模块接收两个或多个输入数据对象（例如两个表面或两个四面体网格），并通过线性插值计算输出对象。插值过程可以在线性插值顶点位置的同时插值附加到表面或网格上的数据字段。</p><ul><li>On Curvature Estimation of ISO Surfaces in 3D Gray-Value Images and the Computation of Shape Descriptors, Bernd Rieger, Frederik J. Timmermans, Lucas J. van Vliet and Piet W. Verbeek, IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE, VOL. 26, NO. 8, AUGUST 2004.</li></ul><p>This module compute local gray level 2D curvature in image. For each pixel, the curvature parameter K is linked to radius of curvature R by formula:<br>该模块计算图像中的局部灰度二维曲率。对于每个像素，曲率参数 K 与曲率半径 R 的关系如下：</p><script type="math/tex; mode=display">k = \frac{1}{R}</script><img src="/2024/09/03/AVIZO%E6%9B%B2%E7%8E%87%E8%AE%A1%E7%AE%97/AVIZO%E6%9B%B2%E7%8E%87%E8%AE%A1%E7%AE%97_8.png" class="" title="AVIZO曲率计算_8"><p>This module computes local gray level 3D curvatures in image. Each voxel is then associated with two principal curvatures:  Kmax and Kmin. The Kmax stands for maximal local curvature whereas  stands for minimal curvature.</p><p>此模块计算图像中的局部灰度 3D 曲率。每个体素随后与两个主曲率相关联：Kmax 和 Kmin。Kmax 代表最大局部曲率，而 Kmin 代表最小曲率。</p><img src="/2024/09/03/AVIZO%E6%9B%B2%E7%8E%87%E8%AE%A1%E7%AE%97/AVIZO%E6%9B%B2%E7%8E%87%E8%AE%A1%E7%AE%97_5.png" class="" title="AVIZO曲率计算_5"><p>Two important indicators can be extracted from these values:<br>从这些数值中可以提取两个重要指标：</p><p>Gaussian curvature: </p><script type="math/tex; mode=display">K = K_{max} × K_{min}</script><p>Mean curvature:</p><script type="math/tex; mode=display">K = \frac{1}{2} (K_{max} + K_{min})</script><p>Gaussian curvature can be used to characterize local surface comportment:</p><ul><li>If Gaussian curvature is positive, both principal curvatures have same sign and local surface will be dome like (which mean that it is locally lying on one side of its tangent plane. In this case, a positive curvature stand for convex surface whereas a negative value stand for a concave surface.</li><li>If Gaussian curvature is negative, principal curvatures have opposite signs and local surface will be saddle shaped (see Figure 1).</li><li>If Gaussian curvature is null, surface will be locally parabolic like. If Kmax = 0, surface profil will locally be valley like. If Kmin = 0, surface profil will locally be crest like.<br>See also: Flow Inpainting.</li></ul><p>高斯曲率可用于表征局部表面行为：</p><ul><li>如果高斯曲率为正，则两个主曲率具有相同的符号，局部表面将呈圆顶状（这意味着它局部位于其切平面的一侧。在这种情况下，正曲率代表凸面，而负值代表凹面。</li><li>如果高斯曲率为负，则主曲率具有相反的符号，局部表面将呈马鞍形（见上图 ）。</li><li>如果高斯曲率为零，则表面将局部呈抛物线状。如果Kmax = 0 ，表面轮廓将局部呈山谷状。如果 Kmin = 0 ，表面轮廓将局部呈波峰状。<br>另请参阅：流修复。</li></ul><h2 id="Connections"><a href="#Connections" class="headerlink" title="Connections:"></a>Connections:</h2><h3 id="Input-Image-required-输入图像-必需"><a href="#Input-Image-required-输入图像-必需" class="headerlink" title="Input Image [required] 输入图像 [必需]"></a>Input Image [required] 输入图像 [必需]</h3><p>The image to be analyzed. Supported types include: grayscale image (Uniform Scalar Field), binary (Uniform Label Field with 2 labels) and label (Uniform Label Field) images.</p><p>要分析的图像。支持的类型包括：灰度图像（统一标量场）、二进制（具有 2 个标签的统一标签场）和标签（统一标签场）图像。</p><h3 id="Input-Image-Mask-optional-输入图像蒙版-可选"><a href="#Input-Image-Mask-optional-输入图像蒙版-可选" class="headerlink" title="Input Image Mask [optional] 输入图像蒙版 [可选]"></a>Input Image Mask [optional] 输入图像蒙版 [可选]</h3><p>The masking image. Supported types include: binary images (Uniform Label Field with 2 labels).</p><p>蒙版图像。支持的类型包括：二进制图像（具有 2 个标签的统一标签场）。</p><h2 id="Ports"><a href="#Ports" class="headerlink" title="Ports:"></a>Ports:</h2><h3 id="Interpretation-解释"><a href="#Interpretation-解释" class="headerlink" title="Interpretation 解释"></a>Interpretation 解释</h3><p>This port specifies whether the input will be interpreted as a 3D volume or a stack of 2D images for processing.<br>“3D”: the module configuration is set to 3D. The image will be processed as a whole in 3D.<br>“XY planes”: the module configuration is set to 2D. The image will be processed slice per slice.</p><p>此端口指定输入是否将被解释为 3D 体积或 2D 图像堆栈以供处理。<br>“3D”：模块配置设置为 3D。图像将以 3D 形式整体处理。<br>“XY 平面”：模块配置设置为 2D。图像将逐片处理。</p><h3 id="Standard-Deviation"><a href="#Standard-Deviation" class="headerlink" title="Standard Deviation"></a>Standard Deviation</h3><p>This port defines the standard deviation used for Gaussian smoothing of image Tensor.<br>该端口定义用于图像张量高斯平滑的标准偏差。</p><h1 id="Curvature-Integrals-原理"><a href="#Curvature-Integrals-原理" class="headerlink" title="Curvature Integrals -原理"></a>Curvature Integrals -原理</h1><h2 id="Description-1"><a href="#Description-1" class="headerlink" title="Description:"></a>Description:</h2><p>For an introduction, see section Analysis.<br>有关介绍，请参阅分析部分。</p><p>This module computes the integral of mean curvature and integral of total curvature of objects in a binary image. Intuitively, “curvature” is the amount by which a geometric object deviates from being “flat”.<br>此模块计算二值图像中物体的平均曲率积分和总曲率积分。直观地说，“曲率”是几何物体偏离“平面”的量。</p><p>This module computes a local measure. It is obtained as the sum of measures in local 2x2x2 neighborhoods (a cube), for 13 planes associated with different normal directions and hitting three or four vertices of the cells (in the cubical lattice).<br>此模块计算局部测量值。它是局部 2x2x2 邻域（立方体）中测量值的总和，针对与不同法线方向相关的 13 个平面，并击中立方体格子中的三个或四个顶点。</p><p>In the case of very elongated objects (needles or fibers) the integral of mean curvature M can be used to measure the length L of the object: L= M / π<br>对于非常细长的物体（针或纤维），平均曲率积分 M 可用于测量物体的长度 L：L= M / π</p><p>For convex object, the integral of mean curvature M is (up to a constant) equivalent to the mean diameter, i.e.<br>对于凸物体，平均曲率积分 M（最多一个常数）等于平均直径，即</p><script type="math/tex; mode=display">M = 2 \pi d where d = \frac{1}{13} (\sum^1_{i=0} 3 d_i)</script><p>The Euler number and the Integral of Total Curvature carry the same information about the object. They differ by the constant factor 4π. If we consider a set X of the 3-dimensional space and X（X） being its Euler number then the integral total curvature of X will be: K(X) = 4πX(X)<br>欧拉数和总曲率积分都包含相同的物体信息，它们相差一个常数因子 4π。如果我们考虑三维空间中的集合 X，X（X）是它的欧拉数，那么 X 的积分总曲率将是：K(X) = 4πX(X)</p><p>See Also: Euler Number</p><p>For more information on Integral Curvatures you can refer to</p><ul><li>C .Lang, J. Ohser, R.Hilfer (1999) On the Analysis of Spatial Binary Images</li></ul><p>See also: Area 3D, Euler Number 3D, Fractal Dimension, Moments of Inertia 3D, Volume Fraction.</p><h2 id="Connections-1"><a href="#Connections-1" class="headerlink" title="Connections:"></a>Connections:</h2><p>Input Image [required]<br>The image to be analyzed. Supported types include: binary images (Uniform Label Field with 2 labels).<br>需要分析的图像。支持的类型包括：二值图像（具有 2 个标签的统一标签字段）。</p><h2 id="Ports-1"><a href="#Ports-1" class="headerlink" title="Ports:"></a>Ports:</h2><p>Interpretation </p><p>This port specifies whether the input will be interpreted as a 3D volume or a stack of 2D images for processing. The port is grayed out if alternate interpretation is not available.<br>此端口指定输入是否将被解释为 3D 体积或 2D 图像堆栈以供处理。如果没有其他解释，则端口将变灰。</p><h1 id="curvature-原理"><a href="#curvature-原理" class="headerlink" title="curvature-原理"></a>curvature-原理</h1><p>需要生成表面</p><h2 id="Description-2"><a href="#Description-2" class="headerlink" title="Description:"></a>Description:</h2><p>This module computes curvature information for a discrete triangular surface of type Surface.<br>该模块计算表面类型的离散三角表面的曲率信息。</p><p>Either the maximum principal curvature value, the reciprocal curvature value, or the direction of maximum principal curvature can be computed. The algorithm works by approximating the surface locally by a quadric form. The eigenvalues and eigenvectors of the quadric form correspond to the principal curvature values and to the directions of principal curvature. Note that the algorithm does not produce meaningful results near locations where the input surface is not topologically flat, i.e., where it has non-manifold structure.</p><p>可以计算最大主曲率值、倒数曲率值或最大主曲率方向。该算法通过用二次型局部近似表面来工作。二次型的特征值和特征向量对应于主曲率值和主曲率方向。请注意，该算法在输入表面不是拓扑平坦的位置附近（即具有非流形结构的位置）不会产生有意义的结果。</p><p>Press the Apply button to start the computation.</p><p>按下“应用”按钮开始计算。</p><h2 id="Connections-2"><a href="#Connections-2" class="headerlink" title="Connections:"></a>Connections:</h2><p>Data [required]<br>The surface for which curvature information should be computed.</p><p>数据 [必需]<br>应计算曲率信息的表面。</p><h2 id="Ports-2"><a href="#Ports-2" class="headerlink" title="Ports:"></a>Ports:</h2><h3 id="Method"><a href="#Method" class="headerlink" title="Method"></a>Method</h3><img src="/2024/09/03/AVIZO%E6%9B%B2%E7%8E%87%E8%AE%A1%E7%AE%97/%E6%9B%B2%E7%8E%87%E8%AE%A1%E7%AE%97%E5%8E%9F%E7%90%86_1.png" class="" title="曲率计算原理_1"><p>Radio box allowing the user to select between two different computational algorithms. Choice on triangles produces a surface field with curvature values or curvature vectors being defined on the surface’s triangles. Alternatively, by selecting on vertices a surface field with data being defined on the vertices can be generated.</p><p>单选框允许用户在两种不同的计算算法之间进行选择。选择三角形<code>on triangles</code>会产生一个表面场，其曲率值或曲率向量在表面的三角形上定义。或者，选择顶点<code>on vertices</code>可以生成一个表面场，其数据在顶点上定义。</p><h3 id="Parameters"><a href="#Parameters" class="headerlink" title="Parameters"></a>Parameters</h3><img src="/2024/09/03/AVIZO%E6%9B%B2%E7%8E%87%E8%AE%A1%E7%AE%97/%E6%9B%B2%E7%8E%87%E8%AE%A1%E7%AE%97%E5%8E%9F%E7%90%86_2.png" class="" title="曲率计算原理_2"><p>The first input, denoted nLayers, determines which triangles are considered to be neighbors of a given triangle and which points are considered to be neighbors of a given point. If the value of this input is 1, then only triangles sharing a common edge with a given triangle are considered to be neighbors of this triangle and only points directly connected to a given point are considered to be neighbors of this point. For larger values of nLayers successively larger neighborhoods are taken into account.</p><p>第一个输入表示为 nLayers，它确定哪些三角形被视为给定三角形的邻居，哪些点被视为给定点的邻居。如果此输入的值为 1，则只有与给定三角形共享公共边的三角形才被视为此三角形的邻居，只有直接连接到给定点的点才被视为此点的邻居。对于较大的 nLayers 值，会依次考虑较大的邻域。</p><p>The second input, denoted nAverage, determines how many times the initial curvature values computed for a triangle or for a point are being averaged with the curvature values of direct (first-order) neighbor triangles or points. The larger the value of nAverage the smoother the curvature data being obtained. Note that averaging only applies to the scalar curvature values, not to the directional curvature vectors which are computed when port output is set to max direction.</p><p>第二个输入表示为 nAverage，它决定了为三角形或点计算的初始曲率值与直接（一阶）相邻三角形或点的曲率值取平均值的次数。nAverage 的值越大，获得的曲率数据越平滑。请注意，平均仅适用于标量曲率值，而不适用于当端口输出设置为最大方向时计算的方向曲率向量。</p><h3 id="Output"><a href="#Output" class="headerlink" title="Output"></a>Output</h3><img src="/2024/09/03/AVIZO%E6%9B%B2%E7%8E%87%E8%AE%A1%E7%AE%97/%E6%9B%B2%E7%8E%87%E8%AE%A1%E7%AE%97%E5%8E%9F%E7%90%86_3.png" class="" title="曲率计算原理_3"><p>This menu controls the output of the curvature module.<br>此菜单控制曲率模块的输出。</p><h4 id="Max-curvature"><a href="#Max-curvature" class="headerlink" title="Max curvature"></a><code>Max curvature</code></h4><p>a surface scalar field is generated containing the maximal principal curvature of a triangle or of a point.<br>生成一个包含三角形或点的最大主曲率的表面标量场。</p><h4 id="1-Max-curvature"><a href="#1-Max-curvature" class="headerlink" title="1/Max curvature"></a><code>1/Max curvature</code></h4><p>the curvature values are inverted. In this case, the output values have the dimension of a length, indicating the radius of a sphere locally fitting the surface.</p><p>曲率值被反转。在这种情况下，输出值具有长度维度，表示局部拟合表面的球体的半径。</p><h4 id="Mean-curvature"><a href="#Mean-curvature" class="headerlink" title="Mean curvature"></a><code>Mean curvature</code></h4><p>is similar to Max curvature. Here, however, the mean value of the two principal curvature values is computed. This quantity will be negative in strictly concave regions and positive in strictly convex regions. It can be zero in regions where a positive and negative principal curvature cancel each other.<br>与最大曲率类似。不过，这里计算的是两个主曲率值的平均值。这个量在严格凹陷区域为负，在严格凸陷区域为正。在正负主曲率相互抵消的区域，它可以为零。</p><h4 id="1-Mean-curvature"><a href="#1-Mean-curvature" class="headerlink" title="1/Mean curvature"></a><code>1/Mean curvature</code></h4><p>the mean curvature values are inverted.<br>平均曲率值被反转。</p><h4 id="Gauss-curvature"><a href="#Gauss-curvature" class="headerlink" title="Gauss curvature"></a><code>Gauss curvature</code></h4><p>is the product of the two principal curvatures. It is negative in surface areas with hyperbolic geometry (convex-concave, like near saddle points) and positive in areas with elliptic geometry (strictly convex or strictly concave).<br>是两个主曲率的乘积。在具有双曲几何（凸凹，如鞍点附近）的表面区域，它是负值；在具有椭圆几何（严格凸或严格凹）的区域，它是正值。</p><h4 id="1-Gauss-curvature"><a href="#1-Gauss-curvature" class="headerlink" title="1/Gauss curvature"></a><code>1/Gauss curvature</code></h4><p>Gauss curvature values are inverted.<br>高斯曲率值被反转。</p><h4 id="Both-curvature-values"><a href="#Both-curvature-values" class="headerlink" title="Both curvature values"></a><code>Both curvature values</code></h4><p>returns the two principal curvature values as a surface complex scalar field that should be interpreted as a field of pairs of scalar values (use Arithmetic to retrieve each value).<br>将两个主曲率值作为表面复标量场返回，该标量场应解释为标量值对的场（使用算术来检索每个值）。</p><h4 id="Both-1-curvature-values"><a href="#Both-1-curvature-values" class="headerlink" title="Both 1/curvature values"></a><code>Both 1/curvature values</code></h4><p>returns the inverted two principal curvature values.<br>返回两个主曲率值的倒数。</p><h4 id="Max-curvature-vector"><a href="#Max-curvature-vector" class="headerlink" title="Max curvature vector"></a><code>Max curvature vector</code></h4><p>a surface vector field is computed indicating the direction of maximum principal curvature. The length of a directional vector is equal to the corresponding curvature value.<br>计算一个表面矢量场来指示最大主曲率的方向。方向矢量的长度等于相应的曲率值。</p><h4 id="Both-curvature-vector"><a href="#Both-curvature-vector" class="headerlink" title="Both curvature vector"></a><code>Both curvature vector</code></h4><p>a surface complex vector field (that should be interpreted as a field of pairs of vectors) is computed indicating the direction of the two principal curvatures. The length of a directional vector is equal to the corresponding curvature value.<br>计算表面复矢量场（应理解为矢量对的场），指示两个主曲率的方向。方向矢量的长度等于相应的曲率值。</p><h4 id="Shape-index"><a href="#Shape-index" class="headerlink" title="Shape index"></a><code>Shape index</code></h4><p>computes the surface scalar field which values are equal to<br>计算表面标量场，其值等于</p><script type="math/tex; mode=display">\frac{2}{\pi} atan \frac{C_1 + C_2}{C_1 - C_2}</script><p>where <script type="math/tex">C_1</script> and <script type="math/tex">C_2</script> are the two principal curvatures.<br>其中 <script type="math/tex">C_1</script> 和 <script type="math/tex">C_2</script> 是两个主曲率。</p><h4 id="Curvedness"><a href="#Curvedness" class="headerlink" title="Curvedness"></a><code>Curvedness</code></h4><p>computes the surface scalar field which values are equal to<br>计算表面标量场，其值等于</p><script type="math/tex; mode=display">\frac{1}{2} \sqrt{C_1^2 + C_2^2}</script><p>where <script type="math/tex">C_1</script> and <script type="math/tex">C_2</script> are the two principal curvatures.<br>其中 <script type="math/tex">C_1</script> 和 <script type="math/tex">C_2</script> 是两个主曲率。</p>]]></content>
    
    
    <summary type="html">AVIZO曲率计算</summary>
    
    
    
    <category term="AvizoUsersGuide" scheme="http://hibiscidai.com/categories/AvizoUsersGuide/"/>
    
    
    <category term="Avizo" scheme="http://hibiscidai.com/tags/Avizo/"/>
    
    <category term="石油地质" scheme="http://hibiscidai.com/tags/%E7%9F%B3%E6%B2%B9%E5%9C%B0%E8%B4%A8/"/>
    
    <category term="数字岩心" scheme="http://hibiscidai.com/tags/%E6%95%B0%E5%AD%97%E5%B2%A9%E5%BF%83/"/>
    
  </entry>
  
  <entry>
    <title>AVIZO二值化数据导出</title>
    <link href="http://hibiscidai.com/2024/08/30/AVIZO%E4%BA%8C%E5%80%BC%E5%8C%96%E6%95%B0%E6%8D%AE%E5%AF%BC%E5%87%BA/"/>
    <id>http://hibiscidai.com/2024/08/30/AVIZO%E4%BA%8C%E5%80%BC%E5%8C%96%E6%95%B0%E6%8D%AE%E5%AF%BC%E5%87%BA/</id>
    <published>2024-08-30T05:50:00.000Z</published>
    <updated>2025-02-27T14:44:41.503Z</updated>
    
    <content type="html"><![CDATA[<img src="/2024/08/30/AVIZO%E4%BA%8C%E5%80%BC%E5%8C%96%E6%95%B0%E6%8D%AE%E5%AF%BC%E5%87%BA/AVIZO%E4%BA%8C%E5%80%BC%E5%8C%96%E6%95%B0%E6%8D%AE%E5%AF%BC%E5%87%BA.png" class="" title="AVIZO二值化数据导出"><p>AVIZO二值化数据导出</p><span id="more"></span><h1 id="AVIZO二值化数据导出"><a href="#AVIZO二值化数据导出" class="headerlink" title="AVIZO二值化数据导出"></a>AVIZO二值化数据导出</h1><p>万老师b站的视频教程：</p><p><a href="https://www.bilibili.com/video/BV1Le4y197rh/?spm_id_from=333.999.0.0&amp;vd_source=e29d2e4b12ca5d1c1091b9265d56c53d">Avizo中如何导出可直接浏览的二值化数据结果</a></p><p>样例数据：</p><p>11SANDSTONS，十一块贝瑞砂岩数字岩心数据。</p><p>数据说明<code>Berea_2d25um_binary.raw</code></p><p>导入格式：</p><img src="/2024/08/30/AVIZO%E4%BA%8C%E5%80%BC%E5%8C%96%E6%95%B0%E6%8D%AE%E5%AF%BC%E5%87%BA/AVIZO%E4%BA%8C%E5%80%BC%E5%8C%96%E6%95%B0%E6%8D%AE%E5%AF%BC%E5%87%BA-0.png" class="" title="AVIZO二值化数据导出-0"><img src="/2024/08/30/AVIZO%E4%BA%8C%E5%80%BC%E5%8C%96%E6%95%B0%E6%8D%AE%E5%AF%BC%E5%87%BA/AVIZO%E4%BA%8C%E5%80%BC%E5%8C%96%E6%95%B0%E6%8D%AE%E5%AF%BC%E5%87%BA-1.png" class="" title="AVIZO二值化数据导出-1"><p>骨架1，孔隙0。</p><p>导出为tif</p><img src="/2024/08/30/AVIZO%E4%BA%8C%E5%80%BC%E5%8C%96%E6%95%B0%E6%8D%AE%E5%AF%BC%E5%87%BA/AVIZO%E4%BA%8C%E5%80%BC%E5%8C%96%E6%95%B0%E6%8D%AE%E5%AF%BC%E5%87%BA-2.png" class="" title="AVIZO二值化数据导出-2"><img src="/2024/08/30/AVIZO%E4%BA%8C%E5%80%BC%E5%8C%96%E6%95%B0%E6%8D%AE%E5%AF%BC%E5%87%BA/AVIZO%E4%BA%8C%E5%80%BC%E5%8C%96%E6%95%B0%E6%8D%AE%E5%AF%BC%E5%87%BA-3.png" class="" title="AVIZO二值化数据导出-3"><p>系统会自动导出每一个切片为一个个单张的二值化图像，后缀为tif</p><img src="/2024/08/30/AVIZO%E4%BA%8C%E5%80%BC%E5%8C%96%E6%95%B0%E6%8D%AE%E5%AF%BC%E5%87%BA/AVIZO%E4%BA%8C%E5%80%BC%E5%8C%96%E6%95%B0%E6%8D%AE%E5%AF%BC%E5%87%BA-4.png" class="" title="AVIZO二值化数据导出-4"><p>但是用本地图片查看器打开之后是一片黑</p><img src="/2024/08/30/AVIZO%E4%BA%8C%E5%80%BC%E5%8C%96%E6%95%B0%E6%8D%AE%E5%AF%BC%E5%87%BA/AVIZO%E4%BA%8C%E5%80%BC%E5%8C%96%E6%95%B0%E6%8D%AE%E5%AF%BC%E5%87%BA-5.png" class="" title="AVIZO二值化数据导出-5"><p>查看图片属性</p><img src="/2024/08/30/AVIZO%E4%BA%8C%E5%80%BC%E5%8C%96%E6%95%B0%E6%8D%AE%E5%AF%BC%E5%87%BA/AVIZO%E4%BA%8C%E5%80%BC%E5%8C%96%E6%95%B0%E6%8D%AE%E5%AF%BC%E5%87%BA-6.png" class="" title="AVIZO二值化数据导出-6"><p>原因是图片查看器是0-255显示，但是0-1二值图没有办法显示。</p><p>这种图可以用于训练，或者导入专用的图片查看器可以查看。</p><p>但是不方便认为查看。</p><p>解决思路：</p><p>骨架1，孔隙0。→骨架255，孔隙0。将数值放大。</p><p>操作方法：</p><p>原始数据→Arithmetic→输入A×255→输出保存即可</p><img src="/2024/08/30/AVIZO%E4%BA%8C%E5%80%BC%E5%8C%96%E6%95%B0%E6%8D%AE%E5%AF%BC%E5%87%BA/AVIZO%E4%BA%8C%E5%80%BC%E5%8C%96%E6%95%B0%E6%8D%AE%E5%AF%BC%E5%87%BA-7.png" class="" title="AVIZO二值化数据导出-7"><img src="/2024/08/30/AVIZO%E4%BA%8C%E5%80%BC%E5%8C%96%E6%95%B0%E6%8D%AE%E5%AF%BC%E5%87%BA/AVIZO%E4%BA%8C%E5%80%BC%E5%8C%96%E6%95%B0%E6%8D%AE%E5%AF%BC%E5%87%BA-8.png" class="" title="AVIZO二值化数据导出-8"><img src="/2024/08/30/AVIZO%E4%BA%8C%E5%80%BC%E5%8C%96%E6%95%B0%E6%8D%AE%E5%AF%BC%E5%87%BA/AVIZO%E4%BA%8C%E5%80%BC%E5%8C%96%E6%95%B0%E6%8D%AE%E5%AF%BC%E5%87%BA-9.png" class="" title="AVIZO二值化数据导出-9"><p>重新导出后，可以在本地看到数据，方便人预览。</p><p>对于porespy要求的数据格式：</p><p>骨架0，孔隙1。</p><p>需要进行的操作</p><p>骨架1，孔隙0。→骨架0，孔隙1。</p><p>步骤：</p><p>孔隙0，骨架1<br>A × 255<br>孔隙0，骨架255<br>255 - A<br>孔隙255，骨架0<br>A / 255<br>孔隙1，骨架0</p><p>经过多次运算后实现孔隙骨架数值取反。</p><p>直接使用NOT会出现问题，区间会变成254-255。</p>]]></content>
    
    
    <summary type="html">AVIZO二值化数据导出</summary>
    
    
    
    <category term="AvizoUsersGuide" scheme="http://hibiscidai.com/categories/AvizoUsersGuide/"/>
    
    
    <category term="Avizo" scheme="http://hibiscidai.com/tags/Avizo/"/>
    
    <category term="石油地质" scheme="http://hibiscidai.com/tags/%E7%9F%B3%E6%B2%B9%E5%9C%B0%E8%B4%A8/"/>
    
    <category term="数字岩心" scheme="http://hibiscidai.com/tags/%E6%95%B0%E5%AD%97%E5%B2%A9%E5%BF%83/"/>
    
  </entry>
  
  <entry>
    <title>内网穿透</title>
    <link href="http://hibiscidai.com/2024/08/21/%E5%86%85%E7%BD%91%E7%A9%BF%E9%80%8F/"/>
    <id>http://hibiscidai.com/2024/08/21/%E5%86%85%E7%BD%91%E7%A9%BF%E9%80%8F/</id>
    <published>2024-08-21T13:01:18.000Z</published>
    <updated>2025-02-27T14:44:14.169Z</updated>
    
    <content type="html"><![CDATA[<img src="/2024/08/21/%E5%86%85%E7%BD%91%E7%A9%BF%E9%80%8F/%E5%86%85%E7%BD%91%E7%A9%BF%E9%80%8F.png" class="" title="内网穿透"><p>内网穿透</p><span id="more"></span><h1 id="内网穿透"><a href="#内网穿透" class="headerlink" title="内网穿透"></a>内网穿透</h1><p>内网穿透，简单地说就是内网的数据让外网可以获取，可以映射到公共网络上，这样就可以在公共网络上访问内网的数据。 内网是不能被外网直接访问的，只能通过一些中转技术，如DingTalk Design CLI、花生壳、Natap 等工具，让内网“假装”成外网，就是内网穿透。</p><h1 id="花生壳"><a href="#花生壳" class="headerlink" title="花生壳"></a>花生壳</h1><p>国内老牌内网映射品牌，有较成熟的<br>可以做域名映射等。</p><blockquote><p>工具使用简单，流量烧钱，成熟品牌，价格较贵。</p></blockquote><p><a href="https://hsk.oray.com/">花生壳官网</a><br><a href="https://console.hsk.oray.com/home">花生壳控制台</a></p><h1 id="FRP"><a href="#FRP" class="headerlink" title="FRP"></a>FRP</h1><p>frp 是一款高性能的反向代理应用，专注于内网穿透。它支持多种协议，包括 TCP、UDP、HTTP、HTTPS 等，并且具备 P2P 通信功能。使用 frp，您可以安全、便捷地将内网服务暴露到公网，通过拥有公网 IP 的节点进行中转。</p><p><a href="https://github.com/fatedier/frp">github.com/fatedier/frp</a><br><a href="https://github.com/fatedier/frp/releases">下载地址</a><br><a href="https://gofrp.org/zh-cn/">FRP说明文档</a></p><h1 id="樱花内网穿透-自用"><a href="#樱花内网穿透-自用" class="headerlink" title="樱花内网穿透-自用"></a>樱花内网穿透-自用</h1><p><a href="https://www.natfrp.com/">SAKURA FRP</a></p><p>目前发现比较便宜的二次开发FRP</p><h1 id="Padavan固件路由器内网穿透"><a href="#Padavan固件路由器内网穿透" class="headerlink" title="Padavan固件路由器内网穿透"></a>Padavan固件路由器内网穿透</h1><h2 id="使用花生壳内网版"><a href="#使用花生壳内网版" class="headerlink" title="使用花生壳内网版"></a>使用花生壳内网版</h2><img src="/2024/08/21/%E5%86%85%E7%BD%91%E7%A9%BF%E9%80%8F/%E8%8A%B1%E7%94%9F%E5%A3%B3%E5%86%85%E7%BD%91%E7%89%88-1.png" class="" title="花生壳内网版-1"><p>点击开，需要等一会才可以读取到目前设备的SN。</p><p>然后去花生壳官网。</p><img src="/2024/08/21/%E5%86%85%E7%BD%91%E7%A9%BF%E9%80%8F/%E8%8A%B1%E7%94%9F%E5%A3%B3%E5%86%85%E7%BD%91%E7%89%88-2.png" class="" title="花生壳内网版-2"><p>然后购买服务就额可以了。</p><p>有6块的新人券，但是速度和流量进行了限制，可以用作偶尔的登录页面管理，可以采用。</p><p>博主到此为止没有尝试（太贵了）。</p><h2 id="使用FRP"><a href="#使用FRP" class="headerlink" title="使用FRP"></a>使用FRP</h2><img src="/2024/08/21/%E5%86%85%E7%BD%91%E7%A9%BF%E9%80%8F/FRP-1.png" class="" title="FRP-1"><p>目前发现版本BUG，指定版本不太好用。</p><p>可以用来当做服务器，但是使用第三方服务的时候不通。</p><p>默认参数文件位置：<code>/etc/storage/frp_script.sh</code></p><p>贴默认启动参数：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash">!/bin/bash</span></span><br><span class="line">export PATH=&#x27;/etc/storage/bin:/tmp/script:/etc/storage/script:/opt/usr/sbin:/opt/usr/bin:/opt/sbin:/opt/bin:/usr/local/sbin:/usr/sbin:/usr/bin:/sbin:/bin&#x27;</span><br><span class="line">export LD_LIBRARY_PATH=/lib:/opt/lib</span><br><span class="line">killall frpc frps</span><br><span class="line">rm -f /dev/null ; mknod /dev/null c 1 3 ; chmod 666 /dev/null;</span><br><span class="line">mkdir -p /tmp/frp</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">启动frp功能后会运行以下脚本</span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">frp项目地址教程: https://github.com/fatedier/frp/blob/master/README_zh.md</span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">请自行修改 token 用于对客户端连接进行身份验证</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">IP查询： http://119.29.29.29/d?dn=github.com</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">cat &gt; &quot;/tmp/frp/myfrpc.ini&quot; &lt;&lt;-\EOF</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">==========客户端配置：==========</span></span><br><span class="line">[common]</span><br><span class="line">server_addr = xxx</span><br><span class="line">server_port = xxx</span><br><span class="line">token = xxx</span><br><span class="line">tls_enable = true</span><br><span class="line">pool_count = 1</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">log_file = /dev/null</span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">log_level = info</span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">log_max_days = 3</span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">[web]</span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">remote_port = 6000</span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">服务端开放的端口</span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">remote_port = 6000</span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"><span class="built_in">type</span> = tcp</span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">local_ip = xxx</span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">local_port = 80</span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">subdomain = <span class="built_in">test</span></span></span><br><span class="line"></span><br><span class="line">[***]</span><br><span class="line">type = http</span><br><span class="line">local_ip = xxx</span><br><span class="line">local_port = 80</span><br><span class="line">subdomain = test</span><br><span class="line">use_compression = true</span><br><span class="line"></span><br><span class="line">[nas] 我的nas</span><br><span class="line">type = tcp</span><br><span class="line">local_ip = xxx</span><br><span class="line">local_port = 5000</span><br><span class="line">remote_port = 5000</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">host_header_rewrite = 实际你内网访问的域名，可以供公网的域名不一致，如果一致可以不写</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">====================</span></span><br><span class="line">EOF</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">请手动配置【外部网络 (WAN) - 端口转发 (UPnP)】开启 WAN 外网端口</span></span><br><span class="line">cat &gt; &quot;/tmp/frp/myfrps.ini&quot; &lt;&lt;-\EOF</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">==========服务端配置：==========</span></span><br><span class="line">[common]</span><br><span class="line">bind_port = 7000</span><br><span class="line">dashboard_port = 7500</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">dashboard 用户名密码，默认都为 admin</span></span><br><span class="line">dashboard_user = admin</span><br><span class="line">dashboard_pwd = admin</span><br><span class="line">vhost_http_port = 88</span><br><span class="line">token =</span><br><span class="line">subdomain_host = frps.com</span><br><span class="line">max_pool_count = 50</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">log_file = /dev/null</span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">log_level = info</span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">log_max_days = 3</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">====================</span></span><br><span class="line">EOF</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">启动：</span></span><br><span class="line">frpc_enable=`nvram get frpc_enable`</span><br><span class="line">frpc_enable=$&#123;frpc_enable:-&quot;0&quot;&#125;</span><br><span class="line">frps_enable=`nvram get frps_enable`</span><br><span class="line">frps_enable=$&#123;frps_enable:-&quot;0&quot;&#125;</span><br><span class="line">if [ &quot;$frpc_enable&quot; = &quot;1&quot; ] ; then</span><br><span class="line">    frpc -c /tmp/frp/myfrpc.ini 2&gt;&amp;1 &amp;</span><br><span class="line">fi</span><br><span class="line">if [ &quot;$frps_enable&quot; = &quot;1&quot; ] ; then</span><br><span class="line">    frps -c /tmp/frp/myfrps.ini 2&gt;&amp;1 &amp;</span><br><span class="line">fi</span><br></pre></td></tr></table></figure><h2 id="使用第三方FRP-樱花内网为例"><a href="#使用第三方FRP-樱花内网为例" class="headerlink" title="使用第三方FRP-樱花内网为例"></a>使用第三方FRP-樱花内网为例</h2><h3 id="开启路由器ssh登录"><a href="#开启路由器ssh登录" class="headerlink" title="开启路由器ssh登录"></a>开启路由器ssh登录</h3><img src="/2024/08/21/%E5%86%85%E7%BD%91%E7%A9%BF%E9%80%8F/%E5%BC%80%E5%90%AF%E8%B7%AF%E7%94%B1%E5%99%A8ssh%E7%99%BB%E5%BD%95-1.png" class="" title="开启路由器ssh登录-1"><p>注意开启ssh后，设置路由器端口转发设置。</p><p>外部网络（WAN）→端口转发，注意打开端口。</p><h3 id="检查路由器处理器"><a href="#检查路由器处理器" class="headerlink" title="检查路由器处理器"></a>检查路由器处理器</h3><p>使用ssh登录到路由器后台</p><p>确认处理器架构</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">uname -m</span><br></pre></td></tr></table></figure><div class="table-container"><table><thead><tr><th style="text-align:center">输出</th><th style="text-align:center">架构</th></tr></thead><tbody><tr><td style="text-align:center">i386,i686</td><td style="text-align:center">i386</td></tr><tr><td style="text-align:center">x86_64</td><td style="text-align:center">amd64</td></tr><tr><td style="text-align:center">arm,armel</td><td style="text-align:center">arm_garbage</td></tr><tr><td style="text-align:center">armv71,armhf</td><td style="text-align:center">armv7</td></tr><tr><td style="text-align:center">aarch64,armv81</td><td style="text-align:center">arm64</td></tr><tr><td style="text-align:center">mips</td><td style="text-align:center">mips</td></tr><tr><td style="text-align:center">mips64</td><td style="text-align:center">mips64</td></tr></tbody></table></div><p>小米3路由器→mips</p><p>确认处理器字节序：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">一般来说只需要使用这条命令:</span></span><br><span class="line">echo -n I | hexdump -o | awk &#x27;&#123;print substr($2,6,1); exit&#125;&#x27;</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">如果上面的命令报错，请尝试这条:</span></span><br><span class="line">echo -n I | od -to2 | awk &#x27;&#123;print substr($2,6,1); exit&#125;&#x27;</span><br><span class="line">````</span><br><span class="line"></span><br><span class="line">| 输出 | 架构 |</span><br><span class="line">| :-: | :-: |</span><br><span class="line">| 0 | mips/mips64 |</span><br><span class="line">| 1 | mipsle/mips64le |</span><br><span class="line"></span><br><span class="line">这一步指的是小端还是大端，可以直接查询路由器制造商或者百度。</span><br><span class="line"></span><br><span class="line">小米3路由器→小端</span><br><span class="line"></span><br><span class="line">所以最终确定的是`mipsle`</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"><span class="comment">## 下载及上传适合系统的frp包</span></span></span><br><span class="line"></span><br><span class="line">前往[natfrp-download](https://www.natfrp.com/tunnel/download)下载</span><br><span class="line"></span><br><span class="line">{% asset_img 下载及上传适合系统的frp包-1.png 下载及上传适合系统的frp包-1 %}</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">&gt;</span><span class="language-bash">注意Padavan系统不同于常规的linux，不能使用weget方式下载软件包，还需要打开文件传输软件进行上传。</span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">&gt;</span><span class="language-bash">Padavan的系统（或者说目前刷路由器，非软路由，可用的系统里）大部分目录都是重启即丢失的。</span></span><br><span class="line"><span class="meta prompt_">&gt;</span><span class="language-bash">frp添加到/etc/storage目录下，并且烧录，使其重启可用。</span></span><br><span class="line"></span><br><span class="line">更改下载后的文件名字变为`frpc`</span><br><span class="line"></span><br><span class="line">上传至`/etc/storge/bin`中</span><br><span class="line"></span><br><span class="line">注意修改文件权限为755</span><br><span class="line"></span><br><span class="line">在该文件夹下运行</span><br><span class="line"></span><br><span class="line">```shell</span><br><span class="line">frpc -v</span><br></pre></td></tr></table></figure><p>查看软件版本</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">0.51.0-sakura-8</span><br></pre></td></tr></table></figure><h3 id="FRP服务器配置"><a href="#FRP服务器配置" class="headerlink" title="FRP服务器配置"></a>FRP服务器配置</h3><img src="/2024/08/21/%E5%86%85%E7%BD%91%E7%A9%BF%E9%80%8F/FRP%E6%9C%8D%E5%8A%A1%E5%99%A8%E9%85%8D%E7%BD%AE-1.png" class="" title="FRP服务器配置-1"><p>本地ip填写要转发的设备，我选的是NAS做登录页面测试转发。</p><p>访问密码随机生成。</p><img src="/2024/08/21/%E5%86%85%E7%BD%91%E7%A9%BF%E9%80%8F/FRP%E6%9C%8D%E5%8A%A1%E5%99%A8%E9%85%8D%E7%BD%AE-2.png" class="" title="FRP服务器配置-2"><p>对于FRP的配置，如果是上游原生的FRP软件，会根据对应的版本进行生成配置。生成的配置需要手动去调配，就比如Padavan系统内置的FRP，需要手动配置。</p><p>樱花第三方的包有一键配置功能，例如点击某个隧道的配置。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">frpc -f wdnmdtoken666666:12345 &amp;</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash"> &amp;放在后台运行</span></span><br></pre></td></tr></table></figure><p>使用 启动参数 启动 frpc，只需要在启动参数中加上半角逗号 , 分隔的其他隧道 ID 即可，例如：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">frpc -f &lt;访问密钥&gt;:&lt;隧道ID 1&gt;[,隧道ID 2[,隧道ID 3...]]</span><br><span class="line">frpc -f wdnmdtoken666666:114514,114515,114516</span><br></pre></td></tr></table></figure><p>此时回到路由器的ssh，执行命令，开启frpc。</p><p>然后会提示隧道启动成功，这时候可以通过提供的域名端口进行访问测试。</p><blockquote><p>注意路由器报打开端口转发。</p></blockquote><p>对于已经建立并且成功的隧道，官网前方灰色按钮会变绿。</p><p>对于http链接，第一次访问还需要认证。</p><img src="/2024/08/21/%E5%86%85%E7%BD%91%E7%A9%BF%E9%80%8F/FRP%E6%9C%8D%E5%8A%A1%E5%99%A8%E9%85%8D%E7%BD%AE-3.png" class="" title="FRP服务器配置-3"><p>可以授权固定ip访问该隧道。</p><blockquote><p>到这一步已经跑通了所有流程。</p></blockquote><p>还可以运行</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">frpc -w</span><br></pre></td></tr></table></figure><p>使用秘钥登录后可以直接进行</p><h3 id="路由配置"><a href="#路由配置" class="headerlink" title="路由配置"></a>路由配置</h3><h4 id="第三方配置"><a href="#第三方配置" class="headerlink" title="第三方配置"></a>第三方配置</h4><p>由于Padavan系统的特殊性，关键目录以外的目录均为 tmpfs ，可以理解为是把数据暂存在内存上。因此在/etc/storage目录里所做的修改，如果没有执行保存脚本，就并没有真正的写入 Rom 里，重启之后文件还会丢失。</p><p>完成上述测试后，确定没有问题，可以进行烧录。</p><p>选择“保存/etc/storage/内容到闪存”的提交。</p><p>重启路由器，检查文件是否还在</p><p>设置开机自启</p><p>高级设置→自定义设置→脚本→在路由器启动后执行</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash">启动樱花FRP</span></span><br><span class="line">/etc/storage/frpc -f xxx:xxx &amp;</span><br></pre></td></tr></table></figure><p>查询所有服务</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">systemctl list-units --all &quot;frpc@*&quot;</span><br></pre></td></tr></table></figure><blockquote><p>开机自启没有采用</p></blockquote><h4 id="使用自带FRP"><a href="#使用自带FRP" class="headerlink" title="使用自带FRP"></a>使用自带FRP</h4><p>检查版本 贴配置就行</p><p>最终Padavan0.6.0</p><h3 id="FRP客户端配置"><a href="#FRP客户端配置" class="headerlink" title="FRP客户端配置"></a>FRP客户端配置</h3><p>查看隧道日志：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">journalctl -u &lt;Unit名称&gt;</span><br><span class="line">journalctl -u frpc@wdnmdtoken666666:12345</span><br></pre></td></tr></table></figure><p>如果当前窗口无法显示所有日志，可以用 ↑、↓ 方向键滚动，输入大写的 G 跳转动到日志底部，输入 q 退出日志查看。</p><p>参考链接</p><p><a href="https://www.right.com.cn/forum/thread-5560332-1-1.html">如何正确配置Padavan老毛子frp的frp_script客户端</a><br><a href="https://sixdian.com/post/openwrt-padavan-frp/">OpenWrt、Padavan 下 frp 服务和客户端的配置</a><br><a href="https://sparkle.im/post/padavan%E8%87%AA%E5%B7%B1%E5%A2%9E%E5%8A%A0frp%E5%B9%B6%E6%8E%92%E9%99%A4%E6%95%85%E9%9A%9C">Padavan自己增加frp并排除故障</a></p><h1 id="Unbutu内网穿透"><a href="#Unbutu内网穿透" class="headerlink" title="Unbutu内网穿透"></a>Unbutu内网穿透</h1><h2 id="安装FRP客户端"><a href="#安装FRP客户端" class="headerlink" title="安装FRP客户端"></a>安装FRP客户端</h2><p>宝塔面板内置</p><h2 id="设置开机自启动"><a href="#设置开机自启动" class="headerlink" title="设置开机自启动"></a>设置开机自启动</h2><p>设置宝塔开机启动</p><p>设置开机自启：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">systemctl &lt;enable|disable&gt; &lt;Unit名称&gt;</span><br><span class="line">systemctl status &lt;Unit名称&gt;</span><br><span class="line"></span><br><span class="line">systemctl enable frpc@wdnmdtoken666666:12345</span><br><span class="line">systemctl status frpc@wdnmdtoken666666:12345</span><br><span class="line"></span><br><span class="line">systemctl enable frpc@tf7be1xpwaxpugip67ddu59eifs433fn:17294766</span><br></pre></td></tr></table></figure><h2 id="配置文件"><a href="#配置文件" class="headerlink" title="配置文件"></a>配置文件</h2><p>同上</p><h1 id="宝塔内网穿透"><a href="#宝塔内网穿透" class="headerlink" title="宝塔内网穿透"></a>宝塔内网穿透</h1><p>使用第三方插件安装</p><p>安装FRPs</p><p>后台7500可以看到连接数</p><p>然后在别的机器上使用FRPc即可</p><p>也有win端，可以实现本地端口的公网映射</p><p>如果使用的是阿里云或者腾讯云的服务器</p><p>流量包月模式可以不收费</p><p>第三方的穿透服务会收费</p><h1 id="备注"><a href="#备注" class="headerlink" title="备注"></a>备注</h1><p>ONVIF转发因为涉及到http所以只能发请求，但是没有回应就不行。</p><p>对于视频流可以利用rtsp承载，带账号密码的输入，就可以持续的穿透转发。</p>]]></content>
    
    
    <summary type="html">内网穿透</summary>
    
    
    
    <category term="计算机网络" scheme="http://hibiscidai.com/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"/>
    
    
    <category term="路由器" scheme="http://hibiscidai.com/tags/%E8%B7%AF%E7%94%B1%E5%99%A8/"/>
    
    <category term="Linux" scheme="http://hibiscidai.com/tags/Linux/"/>
    
    <category term="内网穿透" scheme="http://hibiscidai.com/tags/%E5%86%85%E7%BD%91%E7%A9%BF%E9%80%8F/"/>
    
  </entry>
  
  <entry>
    <title>PyTorch-26H-7</title>
    <link href="http://hibiscidai.com/2024/08/20/PyTorch-26H-7/"/>
    <id>http://hibiscidai.com/2024/08/20/PyTorch-26H-7/</id>
    <published>2024-08-20T12:00:00.000Z</published>
    <updated>2024-08-22T14:17:05.000Z</updated>
    
    <content type="html"><![CDATA[<img src="/2024/08/20/PyTorch-26H-7/PyTorch-26H-7.png" class="" title="PyTorch-26H-7"><p>PyTorch-26H-7</p><span id="more"></span><h1 id="PyTorch-26H-7"><a href="#PyTorch-26H-7" class="headerlink" title="PyTorch-26H-7"></a>PyTorch-26H-7</h1><p>主页：<a href="https://www.freecodecamp.org/news/learn-pytorch-for-deep-learning-in-day/">https://www.freecodecamp.org/news/learn-pytorch-for-deep-learning-in-day/</a></p><p>youtub：<a href="https://youtu.be/V_xro1bcAuA">https://youtu.be/V_xro1bcAuA</a></p><p>github：<a href="https://github.com/mrdbourke/pytorch-deep-learning">https://github.com/mrdbourke/pytorch-deep-learning</a></p><p>Learn PyTorch for Deep Learning: Zero to Mastery book：<a href="https://www.learnpytorch.io/">https://www.learnpytorch.io/</a></p><p>PyTorch documentation：<a href="https://pytorch.org/docs/stable/index.html">https://pytorch.org/docs/stable/index.html</a></p>]]></content>
    
    
    <summary type="html">PyTorch-26H-7</summary>
    
    
    
    <category term="PyTorch" scheme="http://hibiscidai.com/categories/PyTorch/"/>
    
    
    <category term="学习笔记" scheme="http://hibiscidai.com/tags/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
    <category term="PyTorch" scheme="http://hibiscidai.com/tags/PyTorch/"/>
    
  </entry>
  
  <entry>
    <title>PyTorch-26H-6</title>
    <link href="http://hibiscidai.com/2024/08/19/PyTorch-26H-6/"/>
    <id>http://hibiscidai.com/2024/08/19/PyTorch-26H-6/</id>
    <published>2024-08-19T12:00:00.000Z</published>
    <updated>2024-11-30T07:10:39.000Z</updated>
    
    <content type="html"><![CDATA[<img src="/2024/08/19/PyTorch-26H-6/PyTorch-26H-6.png" class="" title="PyTorch-26H-6"><p>PyTorch-26H-6</p><span id="more"></span><h1 id="PyTorch-26H-6"><a href="#PyTorch-26H-6" class="headerlink" title="PyTorch-26H-6"></a>PyTorch-26H-6</h1><p>主页：<a href="https://www.freecodecamp.org/news/learn-pytorch-for-deep-learning-in-day/">https://www.freecodecamp.org/news/learn-pytorch-for-deep-learning-in-day/</a></p><p>youtub：<a href="https://youtu.be/V_xro1bcAuA">https://youtu.be/V_xro1bcAuA</a></p><p>github：<a href="https://github.com/mrdbourke/pytorch-deep-learning">https://github.com/mrdbourke/pytorch-deep-learning</a></p><p>Learn PyTorch for Deep Learning: Zero to Mastery book：<a href="https://www.learnpytorch.io/">https://www.learnpytorch.io/</a></p><p>PyTorch documentation：<a href="https://pytorch.org/docs/stable/index.html">https://pytorch.org/docs/stable/index.html</a></p><p>本节回答以下问题：“如何将我的笔记本代码转换为 Python 脚本？”</p><p>为此，我们将把 上一节 自定义数据集 的笔记本中最有用的代码单元转换为一系列 Python 脚本，并保存到名为的目录中<code>going_modular</code>。</p><h1 id="What-is-going-modular-什么是模块化"><a href="#What-is-going-modular-什么是模块化" class="headerlink" title="What is going modular? 什么是模块化?"></a>What is going modular? 什么是模块化?</h1><p>模块化涉及将笔记本代码（来自 Jupyter Notebook 或 Google Colab 笔记本）转换为一系列提供类似功能的不同 Python 脚本。</p><p>例如，我们可以将笔记本代码从一系列单元格转换为以下 Python 文件：</p><ul><li><code>data_setup.py</code>： 如果需要，可以准备并下载数据的文件。</li><li><code>engine.py</code>：包含各种训练功能的文件。</li><li><code>model_builder.py</code>或者<code>model.py</code>：一个用于创建 PyTorch 模型的文件。</li><li><code>train.py</code>：一个利用所有其他文件并训练目标 PyTorch 模型的文件。</li><li><code>utils.py</code>：专用于实用功能的文件。</li></ul><blockquote><p>注意：上述文件的命名和布局取决于您的用例和代码要求。Python 脚本与单个笔记本单元一样通用，这意味着您可以为几乎任何类型的功能创建一个脚本。</p></blockquote><h1 id="Why-would-you-want-to-go-modular-为何要采用模块化？"><a href="#Why-would-you-want-to-go-modular-为何要采用模块化？" class="headerlink" title="Why would you want to go modular? 为何要采用模块化？"></a>Why would you want to go modular? 为何要采用模块化？</h1><p>笔记本非常适合快速迭代探索和运行实验。</p><p>然而，对于更大规模的项目，您可能会发现 Python 脚本更具可重复性且更易于运行。</p><p>尽管这是一个有争议的话题，但像<a href="https://netflixtechblog.com/notebook-innovation-591ee3221233">Netflix 这样的公司已经展示了他们如何使用笔记本编写生产代码</a>。</p><p>生产代码是运行以向某人或某物提供服务的代码。</p><p>例如，如果有一个在线运行的应用程序，其他人可以访问和使用，则运行该应用程序的代码被视为生产代码。</p><p>像 fast.ai <a href="https://github.com/fastai/nbdev"><code>nb-dev</code></a>（笔记本开发的缩写）这样的库，能够使用 Jupyter Notebooks 编写整个 Python 库（包括文档）。</p><h2 id="Pros-and-cons-of-notebooks-vs-Python-scripts-笔记本与-Python-脚本的优缺点"><a href="#Pros-and-cons-of-notebooks-vs-Python-scripts-笔记本与-Python-脚本的优缺点" class="headerlink" title="Pros and cons of notebooks vs Python scripts 笔记本与 Python 脚本的优缺点"></a>Pros and cons of notebooks vs Python scripts 笔记本与 Python 脚本的优缺点</h2><div class="table-container"><table><thead><tr><th style="text-align:center"></th><th style="text-align:center">优点</th><th style="text-align:center">缺点</th></tr></thead><tbody><tr><td style="text-align:center">Notebooks</td><td style="text-align:center">易于实验/入门</td><td style="text-align:center">版本控制可能很困难</td></tr><tr><td style="text-align:center"></td><td style="text-align:center">易于分享（例如 Google Colab 笔记本的链接）</td><td style="text-align:center">难以仅使用特定部件</td></tr><tr><td style="text-align:center"></td><td style="text-align:center">非常直观</td><td style="text-align:center">文本和图形可能会妨碍代码</td></tr><tr><td style="text-align:center">Python 脚本</td><td style="text-align:center">可以将代码打包在一起（节省在不同的笔记本中重写类似代码的麻烦）</td><td style="text-align:center">实验并不直观（通常必须运行整个脚本而不是一个单元格）</td></tr><tr><td style="text-align:center"></td><td style="text-align:center">可以使用 git 进行版本控制</td><td style="text-align:center"></td></tr><tr><td style="text-align:center"></td><td style="text-align:center">许多开源项目使用脚本</td><td style="text-align:center"></td></tr><tr><td style="text-align:center"></td><td style="text-align:center">较大的项目可以在云供应商上运行（对笔记本的支持不太多）</td></tr></tbody></table></div><h2 id="My-workflow-工作流程"><a href="#My-workflow-工作流程" class="headerlink" title="My workflow 工作流程"></a>My workflow 工作流程</h2><p>通常在 Jupyter/Google Colab 笔记本中启动机器学习项目，以便快速进行实验和可视化。</p><p>然后，当我完成一些工作时，我会将最有用的代码片段移到 Python 脚本中。</p><img src="/2024/08/19/PyTorch-26H-6/PyTorch-26H-6-1.png" class="" title="PyTorch-26H-6-1"><p>编写机器学习代码有许多可能的工作流程。有些人喜欢从脚本开始，而其他人（比如我）则喜欢从笔记本开始，然后再转到脚本。</p><h2 id="PyTorch-in-the-wild-PyTorch-的应用"><a href="#PyTorch-in-the-wild-PyTorch-的应用" class="headerlink" title="PyTorch in the wild PyTorch 的应用"></a>PyTorch in the wild PyTorch 的应用</h2><p>有许多基于 PyTorch 的 ML 项目的代码存储库都有关于如何以 Python 脚本的形式运行 PyTorch 代码的说明。</p><p>例如，可能会被指示在终端/命令行中运行如下代码来训练模型：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python train.py --model MODEL_NAME --batch_size BATCH_SIZE --lr LEARNING_RATE --num_epochs NUM_EPOCHS</span><br></pre></td></tr></table></figure><img src="/2024/08/19/PyTorch-26H-6/PyTorch-26H-6-2.png" class="" title="PyTorch-26H-6-2"><p><code>train.py</code>在命令行上运行具有各种超参数设置的 PyTorch脚本。</p><p>在这种情况下，<code>train.py</code>目标 Python 脚本可能包含训练 PyTorch 模型的函数。</p><p>并且<code>--model</code>、<code>--batch_size</code>、<code>--lr</code>和<code>--num_epochs</code>被称为参数标志。</p><p>您可以将它们设置为您喜欢的任何值，如果它们兼容<code>train.py</code>，它们就会起作用，如果不兼容，它们就会出错。</p><p>例如，假设我们想要使用笔记本 04 训练我们的 TinyVGG 模型 10 个时期，批量大小为 32，学习率为 0.001：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python train.py --model tinyvgg --batch_size 32 --lr 0.001 --num_epochs 10</span><br></pre></td></tr></table></figure><p><code>train.py</code>您可以根据需要在脚本中设置任意数量的这些参数标志。</p><p>用于训练最先进的计算机视觉模型的 PyTorch 博客文章采用了这种风格。</p><h1 id="What-we’re-going-to-cover"><a href="#What-we’re-going-to-cover" class="headerlink" title="What we’re going to cover"></a>What we’re going to cover</h1><p>本节的主要概念是：将有用的笔记本代码单元转换为可重复使用的 Python 文件。</p><p>这样做可以节省我们一遍又一遍编写相同代码的时间。</p><p>此部分有两个笔记本：</p><ul><li>走向模块化：第 1 部分（单元模式） ——此笔记本作为传统的 Jupyter Notebook/Google Colab 笔记本运行，是笔记本 04的浓缩版。</li><li>走向模块化：第 2 部分（脚本模式） ——这个笔记本与第 1 部分相同，但增加了将每个主要部分转换为 Python 脚本的功能，例如<code>data_setup.py</code>和<code>train.py</code>。</li></ul><p>本文档中的文本重点介绍代码单元 05. 走向模块化：第 2 部分（脚本模式），即<code>%%writefile ...</code>位于顶部的代码单元。</p><h2 id="Why-two-parts"><a href="#Why-two-parts" class="headerlink" title="Why two parts?"></a>Why two parts?</h2><p>因为有时学习某事物的最好方法是观察它与其他事物的不同之处。</p><p>如果你并排运行每个笔记本，你会看到它们的不同之处，这就是关键的学习内容所在。</p><img src="/2024/08/19/PyTorch-26H-6/PyTorch-26H-6-3.png" class="" title="PyTorch-26H-6-3"><h2 id="What-we’re-working-towards"><a href="#What-we’re-working-towards" class="headerlink" title="What we’re working towards"></a>What we’re working towards</h2><ul><li>使用命令行中的一行代码即可训练我们在笔记本 04（Food Vision Mini）中构建的模型：python train.py。</li><li>可重用 Python 脚本的目录结构，例如：</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">going_modular/</span><br><span class="line">├── going_modular/</span><br><span class="line">│   ├── data_setup.py</span><br><span class="line">│   ├── engine.py</span><br><span class="line">│   ├── model_builder.py</span><br><span class="line">│   ├── train.py</span><br><span class="line">│   └── utils.py</span><br><span class="line">├── models/</span><br><span class="line">│   ├── 05_going_modular_cell_mode_tinyvgg_model.pth</span><br><span class="line">│   └── 05_going_modular_script_mode_tinyvgg_model.pth</span><br><span class="line">└── data/</span><br><span class="line">    └── pizza_steak_sushi/</span><br><span class="line">        ├── train/</span><br><span class="line">        │   ├── pizza/</span><br><span class="line">        │   │   ├── image01.jpeg</span><br><span class="line">        │   │   └── ...</span><br><span class="line">        │   ├── steak/</span><br><span class="line">        │   └── sushi/</span><br><span class="line">        └── test/</span><br><span class="line">            ├── pizza/</span><br><span class="line">            ├── steak/</span><br><span class="line">            └── sushi/</span><br></pre></td></tr></table></figure><h2 id="Things-to-note"><a href="#Things-to-note" class="headerlink" title="Things to note"></a>Things to note</h2><ul><li><strong>文档字符串</strong>- 编写可重复且易于理解的代码非常重要。考虑到这一点，我们将放入脚本中的每个函数/类都是根据 Google 的<a href="https://google.github.io/styleguide/pyguide.html#383-functions-and-methods">Python 文档字符串样式</a>创建的。</li><li><strong>在脚本顶部导入</strong>——由于我们要创建的所有 Python 脚本都可以被视为一个小程序，因此所有脚本都需要在脚本开始时导入它们的输入模块，例如：</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Import modules required for train.py</span></span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> data_setup, engine, model_builder, utils</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> transforms</span><br></pre></td></tr></table></figure><h1 id="0-Cell-mode-vs-script-mode-单元格模式与脚本模式"><a href="#0-Cell-mode-vs-script-mode-单元格模式与脚本模式" class="headerlink" title="0. Cell mode vs. script mode 单元格模式与脚本模式"></a>0. Cell mode vs. script mode 单元格模式与脚本模式</h1><p>单元格模式笔记本，例如<a href="https://github.com/mrdbourke/pytorch-deep-learning/blob/main/going_modular/05_pytorch_going_modular_cell_mode.ipynb">05. 走向模块化第 1 部分（单元格模式）</a>是一个正常运行的笔记本，笔记本中的每个单元格都是代码或 markdown。</p><p>脚本模式笔记本（例如<a href="https://github.com/mrdbourke/pytorch-deep-learning/blob/main/going_modular/05_pytorch_going_modular_script_mode.ipynb">05. Going Modular Part 2（脚本模式））</a>与单元格模式笔记本非常相似，但是，许多代码单元格可以转换为 Python 脚本。</p><blockquote><p>注意：您不需要通过笔记本创建 Python 脚本，您可以直接通过 IDE（集成开发环境）创建它们，例如VS Code。将脚本模式笔记本作为本节的一部分只是为了演示从笔记本到 Python 脚本的一种方法。</p></blockquote><h1 id="1-Get-data-获取数据"><a href="#1-Get-data-获取数据" class="headerlink" title="1. Get data 获取数据"></a>1. Get data 获取数据</h1><p><a href="https://www.learnpytorch.io/04_pytorch_custom_datasets/#1-get-data">获取 05 个笔记本中每个笔记本的数据的方式与获取04 个笔记本</a>中的数据的方式相同。</p><p>通过 Python 的模块调用 GitHub<code>requests</code>下载<code>.zip</code>文件并解压。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">import</span> zipfile</span><br><span class="line"><span class="keyword">from</span> pathlib <span class="keyword">import</span> Path</span><br><span class="line"></span><br><span class="line"><span class="comment"># Setup path to data folder</span></span><br><span class="line">data_path = Path(<span class="string">&quot;data/&quot;</span>)</span><br><span class="line">image_path = data_path / <span class="string">&quot;pizza_steak_sushi&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># If the image folder doesn&#x27;t exist, download it and prepare it... </span></span><br><span class="line"><span class="keyword">if</span> image_path.is_dir():</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;<span class="subst">&#123;image_path&#125;</span> directory exists.&quot;</span>)</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;Did not find <span class="subst">&#123;image_path&#125;</span> directory, creating one...&quot;</span>)</span><br><span class="line">    image_path.mkdir(parents=<span class="literal">True</span>, exist_ok=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Download pizza, steak, sushi data</span></span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(data_path / <span class="string">&quot;pizza_steak_sushi.zip&quot;</span>, <span class="string">&quot;wb&quot;</span>) <span class="keyword">as</span> f:</span><br><span class="line">    request = requests.get(<span class="string">&quot;https://github.com/mrdbourke/pytorch-deep-learning/raw/main/data/pizza_steak_sushi.zip&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Downloading pizza, steak, sushi data...&quot;</span>)</span><br><span class="line">    f.write(request.content)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Unzip pizza, steak, sushi data</span></span><br><span class="line"><span class="keyword">with</span> zipfile.ZipFile(data_path / <span class="string">&quot;pizza_steak_sushi.zip&quot;</span>, <span class="string">&quot;r&quot;</span>) <span class="keyword">as</span> zip_ref:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Unzipping pizza, steak, sushi data...&quot;</span>) </span><br><span class="line">    zip_ref.extractall(image_path)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Remove zip file</span></span><br><span class="line">os.remove(data_path / <span class="string">&quot;pizza_steak_sushi.zip&quot;</span>)</span><br></pre></td></tr></table></figure><p>这样就会产生一个名为 <code>data</code> 的文件，其中包含另一个名为的目录，<code>pizza_steak_sushi</code>其中包含标准图像分类格式的披萨、牛排和寿司图像。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">data/</span><br><span class="line">└── pizza_steak_sushi/</span><br><span class="line">    ├── train/</span><br><span class="line">    │   ├── pizza/</span><br><span class="line">    │   │   ├── train_image01.jpeg</span><br><span class="line">    │   │   ├── test_image02.jpeg</span><br><span class="line">    │   │   └── ...</span><br><span class="line">    │   ├── steak/</span><br><span class="line">    │   │   └── ...</span><br><span class="line">    │   └── sushi/</span><br><span class="line">    │       └── ...</span><br><span class="line">    └── test/</span><br><span class="line">        ├── pizza/</span><br><span class="line">        │   ├── test_image01.jpeg</span><br><span class="line">        │   └── test_image02.jpeg</span><br><span class="line">        ├── steak/</span><br><span class="line">        └── sushi/</span><br></pre></td></tr></table></figure><h1 id="2-Create-Datasets-and-DataLoaders-data-setup-py-创建数据集和数据加载器（data-setup-py）"><a href="#2-Create-Datasets-and-DataLoaders-data-setup-py-创建数据集和数据加载器（data-setup-py）" class="headerlink" title="2. Create Datasets and DataLoaders (data_setup.py) 创建数据集和数据加载器（data_setup.py）"></a>2. Create Datasets and DataLoaders (data_setup.py) 创建数据集和数据加载器（data_setup.py）</h1><p>一旦我们获得了数据，我们就可以将其转换为 <code>PyTorchDataset</code> 的和 <code>DataLoader</code>（一个用于训练数据，一个用于测试数据）。</p><p>我们将有用 <code>Dataset</code> 和 <code>DataLoader</code> 创建的代码转换为一个名为的函数<code>create_dataloaders()</code>。</p><p>我们使用以下行将其写入文件<code>%%writefile going_modular/data_setup.py</code>。</p><p><code>data_setup.py</code></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br></pre></td><td class="code"><pre><span class="line">%%writefile going_modular/data_setup.py</span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">Contains functionality for creating PyTorch DataLoaders for </span></span><br><span class="line"><span class="string">image classification data.</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> datasets, transforms</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> DataLoader</span><br><span class="line"></span><br><span class="line">NUM_WORKERS = os.cpu_count()</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">create_dataloaders</span>(<span class="params"></span></span><br><span class="line"><span class="params">    train_dir: <span class="built_in">str</span>, </span></span><br><span class="line"><span class="params">    test_dir: <span class="built_in">str</span>, </span></span><br><span class="line"><span class="params">    transform: transforms.Compose, </span></span><br><span class="line"><span class="params">    batch_size: <span class="built_in">int</span>, </span></span><br><span class="line"><span class="params">    num_workers: <span class="built_in">int</span>=NUM_WORKERS</span></span><br><span class="line"><span class="params"></span>):</span><br><span class="line">  <span class="string">&quot;&quot;&quot;Creates training and testing DataLoaders.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">  Takes in a training directory and testing directory path and turns</span></span><br><span class="line"><span class="string">  them into PyTorch Datasets and then into PyTorch DataLoaders.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">  Args:</span></span><br><span class="line"><span class="string">    train_dir: Path to training directory.</span></span><br><span class="line"><span class="string">    test_dir: Path to testing directory.</span></span><br><span class="line"><span class="string">    transform: torchvision transforms to perform on training and testing data.</span></span><br><span class="line"><span class="string">    batch_size: Number of samples per batch in each of the DataLoaders.</span></span><br><span class="line"><span class="string">    num_workers: An integer for number of workers per DataLoader.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">  Returns:</span></span><br><span class="line"><span class="string">    A tuple of (train_dataloader, test_dataloader, class_names).</span></span><br><span class="line"><span class="string">    Where class_names is a list of the target classes.</span></span><br><span class="line"><span class="string">    Example usage:</span></span><br><span class="line"><span class="string">      train_dataloader, test_dataloader, class_names = \</span></span><br><span class="line"><span class="string">        = create_dataloaders(train_dir=path/to/train_dir,</span></span><br><span class="line"><span class="string">                             test_dir=path/to/test_dir,</span></span><br><span class="line"><span class="string">                             transform=some_transform,</span></span><br><span class="line"><span class="string">                             batch_size=32,</span></span><br><span class="line"><span class="string">                             num_workers=4)</span></span><br><span class="line"><span class="string">  &quot;&quot;&quot;</span></span><br><span class="line">  <span class="comment"># Use ImageFolder to create dataset(s)</span></span><br><span class="line">  train_data = datasets.ImageFolder(train_dir, transform=transform)</span><br><span class="line">  test_data = datasets.ImageFolder(test_dir, transform=transform)</span><br><span class="line"></span><br><span class="line">  <span class="comment"># Get class names</span></span><br><span class="line">  class_names = train_data.classes</span><br><span class="line"></span><br><span class="line">  <span class="comment"># Turn images into data loaders</span></span><br><span class="line">  train_dataloader = DataLoader(</span><br><span class="line">      train_data,</span><br><span class="line">      batch_size=batch_size,</span><br><span class="line">      shuffle=<span class="literal">True</span>,</span><br><span class="line">      num_workers=num_workers,</span><br><span class="line">      pin_memory=<span class="literal">True</span>,</span><br><span class="line">  )</span><br><span class="line">  test_dataloader = DataLoader(</span><br><span class="line">      test_data,</span><br><span class="line">      batch_size=batch_size,</span><br><span class="line">      shuffle=<span class="literal">False</span>, <span class="comment"># don&#x27;t need to shuffle test data</span></span><br><span class="line">      num_workers=num_workers,</span><br><span class="line">      pin_memory=<span class="literal">True</span>,</span><br><span class="line">  )</span><br><span class="line"></span><br><span class="line">  <span class="keyword">return</span> train_dataloader, test_dataloader, class_names</span><br></pre></td></tr></table></figure><p>如果我们想要制作 <code>DataLoader</code>，我们现在可以使用其中的函数，<code>data_setup.py</code>如下所示：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Import data_setup.py</span></span><br><span class="line"><span class="keyword">from</span> going_modular <span class="keyword">import</span> data_setup</span><br><span class="line"></span><br><span class="line"><span class="comment"># Create train/test dataloader and get class names as a list</span></span><br><span class="line">train_dataloader, test_dataloader, class_names = data_setup.create_dataloaders(...)</span><br></pre></td></tr></table></figure><h1 id="3-Making-a-model-model-builder-py-制作模型（model-builder-py）"><a href="#3-Making-a-model-model-builder-py-制作模型（model-builder-py）" class="headerlink" title="3. Making a model (model_builder.py)制作模型（model_builder.py）"></a>3. Making a model (model_builder.py)制作模型（model_builder.py）</h1><p>在过去的几本笔记本（笔记本 03 和笔记本 04）中，我们已经构建了 TinyVGG 模型几次。</p><p>因此将模型放入其文件中以便我们可以反复重复使用它是很有意义的。</p><p>我们将<code>TinyVGG()</code>模型类放入脚本中，如下所示<code>%%writefile going_modular/model_builder.py</code>：</p><p><code>model_builder.py</code></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br></pre></td><td class="code"><pre><span class="line">%%writefile going_modular/model_builder.py</span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">Contains PyTorch model code to instantiate a TinyVGG model.</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn </span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">TinyVGG</span>(nn.Module):</span><br><span class="line">  <span class="string">&quot;&quot;&quot;Creates the TinyVGG architecture.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">  Replicates the TinyVGG architecture from the CNN explainer website in PyTorch.</span></span><br><span class="line"><span class="string">  See the original architecture here: https://poloclub.github.io/cnn-explainer/</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">  Args:</span></span><br><span class="line"><span class="string">    input_shape: An integer indicating number of input channels.</span></span><br><span class="line"><span class="string">    hidden_units: An integer indicating number of hidden units between layers.</span></span><br><span class="line"><span class="string">    output_shape: An integer indicating number of output units.</span></span><br><span class="line"><span class="string">  &quot;&quot;&quot;</span></span><br><span class="line">  <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, input_shape: <span class="built_in">int</span>, hidden_units: <span class="built_in">int</span>, output_shape: <span class="built_in">int</span></span>) -&gt; <span class="literal">None</span>:</span><br><span class="line">      <span class="built_in">super</span>().__init__()</span><br><span class="line">      self.conv_block_1 = nn.Sequential(</span><br><span class="line">          nn.Conv2d(in_channels=input_shape, </span><br><span class="line">                    out_channels=hidden_units, </span><br><span class="line">                    kernel_size=<span class="number">3</span>, </span><br><span class="line">                    stride=<span class="number">1</span>, </span><br><span class="line">                    padding=<span class="number">0</span>),  </span><br><span class="line">          nn.ReLU(),</span><br><span class="line">          nn.Conv2d(in_channels=hidden_units, </span><br><span class="line">                    out_channels=hidden_units,</span><br><span class="line">                    kernel_size=<span class="number">3</span>,</span><br><span class="line">                    stride=<span class="number">1</span>,</span><br><span class="line">                    padding=<span class="number">0</span>),</span><br><span class="line">          nn.ReLU(),</span><br><span class="line">          nn.MaxPool2d(kernel_size=<span class="number">2</span>,</span><br><span class="line">                        stride=<span class="number">2</span>)</span><br><span class="line">      )</span><br><span class="line">      self.conv_block_2 = nn.Sequential(</span><br><span class="line">          nn.Conv2d(hidden_units, hidden_units, kernel_size=<span class="number">3</span>, padding=<span class="number">0</span>),</span><br><span class="line">          nn.ReLU(),</span><br><span class="line">          nn.Conv2d(hidden_units, hidden_units, kernel_size=<span class="number">3</span>, padding=<span class="number">0</span>),</span><br><span class="line">          nn.ReLU(),</span><br><span class="line">          nn.MaxPool2d(<span class="number">2</span>)</span><br><span class="line">      )</span><br><span class="line">      self.classifier = nn.Sequential(</span><br><span class="line">          nn.Flatten(),</span><br><span class="line">          <span class="comment"># Where did this in_features shape come from? </span></span><br><span class="line">          <span class="comment"># It&#x27;s because each layer of our network compresses and changes the shape of our inputs data.</span></span><br><span class="line">          nn.Linear(in_features=hidden_units*<span class="number">13</span>*<span class="number">13</span>,</span><br><span class="line">                    out_features=output_shape)</span><br><span class="line">      )</span><br><span class="line"></span><br><span class="line">  <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x: torch.Tensor</span>):</span><br><span class="line">      x = self.conv_block_1(x)</span><br><span class="line">      x = self.conv_block_2(x)</span><br><span class="line">      x = self.classifier(x)</span><br><span class="line">      <span class="keyword">return</span> x</span><br><span class="line">      <span class="comment"># return self.classifier(self.conv_block_2(self.conv_block_1(x))) # &lt;- leverage the benefits of operator fusion</span></span><br></pre></td></tr></table></figure><p>现在，我们不用每次都从头开始编写 TinyVGG 模型，而是可以使用以下方法导入它：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="comment"># Import model_builder.py</span></span><br><span class="line"><span class="keyword">from</span> going_modular <span class="keyword">import</span> model_builder</span><br><span class="line">device = <span class="string">&quot;cuda&quot;</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&quot;cpu&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Instantiate an instance of the model from the &quot;model_builder.py&quot; script</span></span><br><span class="line">torch.manual_seed(<span class="number">42</span>)</span><br><span class="line">model = model_builder.TinyVGG(input_shape=<span class="number">3</span>,</span><br><span class="line">                              hidden_units=<span class="number">10</span>, </span><br><span class="line">                              output_shape=<span class="built_in">len</span>(class_names)).to(device)</span><br></pre></td></tr></table></figure><h1 id="4-Creating-train-step-and-test-step-functions-and-train-to-combine-them-创建train-step-和test-step-函数并将train-它们组合起来"><a href="#4-Creating-train-step-and-test-step-functions-and-train-to-combine-them-创建train-step-和test-step-函数并将train-它们组合起来" class="headerlink" title="4. Creating train_step() and test_step() functions and train() to combine them 创建train_step()和test_step()函数并将train()它们组合起来"></a>4. Creating train_step() and test_step() functions and train() to combine them 创建train_step()和test_step()函数并将train()它们组合起来</h1><p><a href="https://www.learnpytorch.io/04_pytorch_custom_datasets/#75-create-train-test-loop-functions">我们在笔记本 04</a>中写了几个训练函数：</p><ul><li><code>train_step()</code> - 接受一个模型、一个 <code>DataLoader</code>、一个损失函数和一个优化器，并在 <code>DataLoader</code> 上训练模型。</li><li><code>test_step()</code> - 接受一个模型、一个 <code>DataLoader</code> 和一个损失函数，并在 <code>DataLoader</code> 上评估模型。</li><li><code>train()</code> - 在给定的周期数内同时执行 1. 和 2.，并返回结果字典。</li></ul><p>由于这些将成为我们模型训练的引擎，我们可以将它们全部放入一个 Python 脚本中，<code>engine.py</code>并使用以下行进行调用<code>%%writefile going_modular/engine.py</code>：</p><p><code>engine.py</code><br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br></pre></td><td class="code"><pre><span class="line">%%writefile going_modular/engine.py</span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">Contains functions for training and testing a PyTorch model.</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> tqdm.auto <span class="keyword">import</span> tqdm</span><br><span class="line"><span class="keyword">from</span> typing <span class="keyword">import</span> <span class="type">Dict</span>, <span class="type">List</span>, <span class="type">Tuple</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">train_step</span>(<span class="params">model: torch.nn.Module, </span></span><br><span class="line"><span class="params">               dataloader: torch.utils.data.DataLoader, </span></span><br><span class="line"><span class="params">               loss_fn: torch.nn.Module, </span></span><br><span class="line"><span class="params">               optimizer: torch.optim.Optimizer,</span></span><br><span class="line"><span class="params">               device: torch.device</span>) -&gt; <span class="type">Tuple</span>[<span class="built_in">float</span>, <span class="built_in">float</span>]:</span><br><span class="line">  <span class="string">&quot;&quot;&quot;Trains a PyTorch model for a single epoch.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">  Turns a target PyTorch model to training mode and then</span></span><br><span class="line"><span class="string">  runs through all of the required training steps (forward</span></span><br><span class="line"><span class="string">  pass, loss calculation, optimizer step).</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">  Args:</span></span><br><span class="line"><span class="string">    model: A PyTorch model to be trained.</span></span><br><span class="line"><span class="string">    dataloader: A DataLoader instance for the model to be trained on.</span></span><br><span class="line"><span class="string">    loss_fn: A PyTorch loss function to minimize.</span></span><br><span class="line"><span class="string">    optimizer: A PyTorch optimizer to help minimize the loss function.</span></span><br><span class="line"><span class="string">    device: A target device to compute on (e.g. &quot;cuda&quot; or &quot;cpu&quot;).</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">  Returns:</span></span><br><span class="line"><span class="string">    A tuple of training loss and training accuracy metrics.</span></span><br><span class="line"><span class="string">    In the form (train_loss, train_accuracy). For example:</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    (0.1112, 0.8743)</span></span><br><span class="line"><span class="string">  &quot;&quot;&quot;</span></span><br><span class="line">  <span class="comment"># Put model in train mode</span></span><br><span class="line">  model.train()</span><br><span class="line"></span><br><span class="line">  <span class="comment"># Setup train loss and train accuracy values</span></span><br><span class="line">  train_loss, train_acc = <span class="number">0</span>, <span class="number">0</span></span><br><span class="line"></span><br><span class="line">  <span class="comment"># Loop through data loader data batches</span></span><br><span class="line">  <span class="keyword">for</span> batch, (X, y) <span class="keyword">in</span> <span class="built_in">enumerate</span>(dataloader):</span><br><span class="line">      <span class="comment"># Send data to target device</span></span><br><span class="line">      X, y = X.to(device), y.to(device)</span><br><span class="line"></span><br><span class="line">      <span class="comment"># 1. Forward pass</span></span><br><span class="line">      y_pred = model(X)</span><br><span class="line"></span><br><span class="line">      <span class="comment"># 2. Calculate  and accumulate loss</span></span><br><span class="line">      loss = loss_fn(y_pred, y)</span><br><span class="line">      train_loss += loss.item() </span><br><span class="line"></span><br><span class="line">      <span class="comment"># 3. Optimizer zero grad</span></span><br><span class="line">      optimizer.zero_grad()</span><br><span class="line"></span><br><span class="line">      <span class="comment"># 4. Loss backward</span></span><br><span class="line">      loss.backward()</span><br><span class="line"></span><br><span class="line">      <span class="comment"># 5. Optimizer step</span></span><br><span class="line">      optimizer.step()</span><br><span class="line"></span><br><span class="line">      <span class="comment"># Calculate and accumulate accuracy metric across all batches</span></span><br><span class="line">      y_pred_class = torch.argmax(torch.softmax(y_pred, dim=<span class="number">1</span>), dim=<span class="number">1</span>)</span><br><span class="line">      train_acc += (y_pred_class == y).<span class="built_in">sum</span>().item()/<span class="built_in">len</span>(y_pred)</span><br><span class="line"></span><br><span class="line">  <span class="comment"># Adjust metrics to get average loss and accuracy per batch </span></span><br><span class="line">  train_loss = train_loss / <span class="built_in">len</span>(dataloader)</span><br><span class="line">  train_acc = train_acc / <span class="built_in">len</span>(dataloader)</span><br><span class="line">  <span class="keyword">return</span> train_loss, train_acc</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">test_step</span>(<span class="params">model: torch.nn.Module, </span></span><br><span class="line"><span class="params">              dataloader: torch.utils.data.DataLoader, </span></span><br><span class="line"><span class="params">              loss_fn: torch.nn.Module,</span></span><br><span class="line"><span class="params">              device: torch.device</span>) -&gt; <span class="type">Tuple</span>[<span class="built_in">float</span>, <span class="built_in">float</span>]:</span><br><span class="line">  <span class="string">&quot;&quot;&quot;Tests a PyTorch model for a single epoch.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">  Turns a target PyTorch model to &quot;eval&quot; mode and then performs</span></span><br><span class="line"><span class="string">  a forward pass on a testing dataset.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">  Args:</span></span><br><span class="line"><span class="string">    model: A PyTorch model to be tested.</span></span><br><span class="line"><span class="string">    dataloader: A DataLoader instance for the model to be tested on.</span></span><br><span class="line"><span class="string">    loss_fn: A PyTorch loss function to calculate loss on the test data.</span></span><br><span class="line"><span class="string">    device: A target device to compute on (e.g. &quot;cuda&quot; or &quot;cpu&quot;).</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">  Returns:</span></span><br><span class="line"><span class="string">    A tuple of testing loss and testing accuracy metrics.</span></span><br><span class="line"><span class="string">    In the form (test_loss, test_accuracy). For example:</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    (0.0223, 0.8985)</span></span><br><span class="line"><span class="string">  &quot;&quot;&quot;</span></span><br><span class="line">  <span class="comment"># Put model in eval mode</span></span><br><span class="line">  model.<span class="built_in">eval</span>() </span><br><span class="line"></span><br><span class="line">  <span class="comment"># Setup test loss and test accuracy values</span></span><br><span class="line">  test_loss, test_acc = <span class="number">0</span>, <span class="number">0</span></span><br><span class="line"></span><br><span class="line">  <span class="comment"># Turn on inference context manager</span></span><br><span class="line">  <span class="keyword">with</span> torch.inference_mode():</span><br><span class="line">      <span class="comment"># Loop through DataLoader batches</span></span><br><span class="line">      <span class="keyword">for</span> batch, (X, y) <span class="keyword">in</span> <span class="built_in">enumerate</span>(dataloader):</span><br><span class="line">          <span class="comment"># Send data to target device</span></span><br><span class="line">          X, y = X.to(device), y.to(device)</span><br><span class="line"></span><br><span class="line">          <span class="comment"># 1. Forward pass</span></span><br><span class="line">          test_pred_logits = model(X)</span><br><span class="line"></span><br><span class="line">          <span class="comment"># 2. Calculate and accumulate loss</span></span><br><span class="line">          loss = loss_fn(test_pred_logits, y)</span><br><span class="line">          test_loss += loss.item()</span><br><span class="line"></span><br><span class="line">          <span class="comment"># Calculate and accumulate accuracy</span></span><br><span class="line">          test_pred_labels = test_pred_logits.argmax(dim=<span class="number">1</span>)</span><br><span class="line">          test_acc += ((test_pred_labels == y).<span class="built_in">sum</span>().item()/<span class="built_in">len</span>(test_pred_labels))</span><br><span class="line"></span><br><span class="line">  <span class="comment"># Adjust metrics to get average loss and accuracy per batch </span></span><br><span class="line">  test_loss = test_loss / <span class="built_in">len</span>(dataloader)</span><br><span class="line">  test_acc = test_acc / <span class="built_in">len</span>(dataloader)</span><br><span class="line">  <span class="keyword">return</span> test_loss, test_acc</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">train</span>(<span class="params">model: torch.nn.Module, </span></span><br><span class="line"><span class="params">          train_dataloader: torch.utils.data.DataLoader, </span></span><br><span class="line"><span class="params">          test_dataloader: torch.utils.data.DataLoader, </span></span><br><span class="line"><span class="params">          optimizer: torch.optim.Optimizer,</span></span><br><span class="line"><span class="params">          loss_fn: torch.nn.Module,</span></span><br><span class="line"><span class="params">          epochs: <span class="built_in">int</span>,</span></span><br><span class="line"><span class="params">          device: torch.device</span>) -&gt; <span class="type">Dict</span>[<span class="built_in">str</span>, <span class="type">List</span>]:</span><br><span class="line">  <span class="string">&quot;&quot;&quot;Trains and tests a PyTorch model.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">  Passes a target PyTorch models through train_step() and test_step()</span></span><br><span class="line"><span class="string">  functions for a number of epochs, training and testing the model</span></span><br><span class="line"><span class="string">  in the same epoch loop.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">  Calculates, prints and stores evaluation metrics throughout.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">  Args:</span></span><br><span class="line"><span class="string">    model: A PyTorch model to be trained and tested.</span></span><br><span class="line"><span class="string">    train_dataloader: A DataLoader instance for the model to be trained on.</span></span><br><span class="line"><span class="string">    test_dataloader: A DataLoader instance for the model to be tested on.</span></span><br><span class="line"><span class="string">    optimizer: A PyTorch optimizer to help minimize the loss function.</span></span><br><span class="line"><span class="string">    loss_fn: A PyTorch loss function to calculate loss on both datasets.</span></span><br><span class="line"><span class="string">    epochs: An integer indicating how many epochs to train for.</span></span><br><span class="line"><span class="string">    device: A target device to compute on (e.g. &quot;cuda&quot; or &quot;cpu&quot;).</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">  Returns:</span></span><br><span class="line"><span class="string">    A dictionary of training and testing loss as well as training and</span></span><br><span class="line"><span class="string">    testing accuracy metrics. Each metric has a value in a list for </span></span><br><span class="line"><span class="string">    each epoch.</span></span><br><span class="line"><span class="string">    In the form: &#123;train_loss: [...],</span></span><br><span class="line"><span class="string">                  train_acc: [...],</span></span><br><span class="line"><span class="string">                  test_loss: [...],</span></span><br><span class="line"><span class="string">                  test_acc: [...]&#125; </span></span><br><span class="line"><span class="string">    For example if training for epochs=2: </span></span><br><span class="line"><span class="string">                 &#123;train_loss: [2.0616, 1.0537],</span></span><br><span class="line"><span class="string">                  train_acc: [0.3945, 0.3945],</span></span><br><span class="line"><span class="string">                  test_loss: [1.2641, 1.5706],</span></span><br><span class="line"><span class="string">                  test_acc: [0.3400, 0.2973]&#125; </span></span><br><span class="line"><span class="string">  &quot;&quot;&quot;</span></span><br><span class="line">  <span class="comment"># Create empty results dictionary</span></span><br><span class="line">  results = &#123;<span class="string">&quot;train_loss&quot;</span>: [],</span><br><span class="line">      <span class="string">&quot;train_acc&quot;</span>: [],</span><br><span class="line">      <span class="string">&quot;test_loss&quot;</span>: [],</span><br><span class="line">      <span class="string">&quot;test_acc&quot;</span>: []</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment"># Loop through training and testing steps for a number of epochs</span></span><br><span class="line">  <span class="keyword">for</span> epoch <span class="keyword">in</span> tqdm(<span class="built_in">range</span>(epochs)):</span><br><span class="line">      train_loss, train_acc = train_step(model=model,</span><br><span class="line">                                          dataloader=train_dataloader,</span><br><span class="line">                                          loss_fn=loss_fn,</span><br><span class="line">                                          optimizer=optimizer,</span><br><span class="line">                                          device=device)</span><br><span class="line">      test_loss, test_acc = test_step(model=model,</span><br><span class="line">          dataloader=test_dataloader,</span><br><span class="line">          loss_fn=loss_fn,</span><br><span class="line">          device=device)</span><br><span class="line"></span><br><span class="line">      <span class="comment"># Print out what&#x27;s happening</span></span><br><span class="line">      <span class="built_in">print</span>(</span><br><span class="line">          <span class="string">f&quot;Epoch: <span class="subst">&#123;epoch+<span class="number">1</span>&#125;</span> | &quot;</span></span><br><span class="line">          <span class="string">f&quot;train_loss: <span class="subst">&#123;train_loss:<span class="number">.4</span>f&#125;</span> | &quot;</span></span><br><span class="line">          <span class="string">f&quot;train_acc: <span class="subst">&#123;train_acc:<span class="number">.4</span>f&#125;</span> | &quot;</span></span><br><span class="line">          <span class="string">f&quot;test_loss: <span class="subst">&#123;test_loss:<span class="number">.4</span>f&#125;</span> | &quot;</span></span><br><span class="line">          <span class="string">f&quot;test_acc: <span class="subst">&#123;test_acc:<span class="number">.4</span>f&#125;</span>&quot;</span></span><br><span class="line">      )</span><br><span class="line"></span><br><span class="line">      <span class="comment"># Update results dictionary</span></span><br><span class="line">      results[<span class="string">&quot;train_loss&quot;</span>].append(train_loss)</span><br><span class="line">      results[<span class="string">&quot;train_acc&quot;</span>].append(train_acc)</span><br><span class="line">      results[<span class="string">&quot;test_loss&quot;</span>].append(test_loss)</span><br><span class="line">      results[<span class="string">&quot;test_acc&quot;</span>].append(test_acc)</span><br><span class="line"></span><br><span class="line">  <span class="comment"># Return the filled results at the end of the epochs</span></span><br><span class="line">  <span class="keyword">return</span> results</span><br></pre></td></tr></table></figure></p><p>可以通过以下方式从中导入函数：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Import engine.py</span></span><br><span class="line"><span class="keyword">from</span> going_modular <span class="keyword">import</span> engine</span><br><span class="line"></span><br><span class="line"><span class="comment"># Use train() by calling it from engine.py</span></span><br><span class="line">engine.train(...)</span><br></pre></td></tr></table></figure><h1 id="5-Creating-a-function-to-save-the-model-utils-py-创建一个函数来保存模型（utils-py）"><a href="#5-Creating-a-function-to-save-the-model-utils-py-创建一个函数来保存模型（utils-py）" class="headerlink" title="5. Creating a function to save the model (utils.py) 创建一个函数来保存模型（utils.py）"></a>5. Creating a function to save the model (utils.py) 创建一个函数来保存模型（utils.py）</h1><p>通常您会希望在训练期间或训练后保存模型。</p><p>由于我们已经在之前的笔记本中编写了几次保存模型的代码，因此将其转换为函数并将其保存到文件中是有意义的。</p><p>将辅助函数存储在名为 (utilities 的缩写) 的文件中是一种常见的做法<code>utils.py</code>。</p><p>我们将函数保存到名为以下行的<code>save_model()</code>文件中：<code>utils.py%%writefile going_modular/utils.py</code></p><p><code>utils.py</code><br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line">%%writefile going_modular/utils.py</span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">Contains various utility functions for PyTorch model training and saving.</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> pathlib <span class="keyword">import</span> Path</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">save_model</span>(<span class="params">model: torch.nn.Module,</span></span><br><span class="line"><span class="params">               target_dir: <span class="built_in">str</span>,</span></span><br><span class="line"><span class="params">               model_name: <span class="built_in">str</span></span>):</span><br><span class="line">  <span class="string">&quot;&quot;&quot;Saves a PyTorch model to a target directory.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">  Args:</span></span><br><span class="line"><span class="string">    model: A target PyTorch model to save.</span></span><br><span class="line"><span class="string">    target_dir: A directory for saving the model to.</span></span><br><span class="line"><span class="string">    model_name: A filename for the saved model. Should include</span></span><br><span class="line"><span class="string">      either &quot;.pth&quot; or &quot;.pt&quot; as the file extension.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">  Example usage:</span></span><br><span class="line"><span class="string">    save_model(model=model_0,</span></span><br><span class="line"><span class="string">               target_dir=&quot;models&quot;,</span></span><br><span class="line"><span class="string">               model_name=&quot;05_going_modular_tingvgg_model.pth&quot;)</span></span><br><span class="line"><span class="string">  &quot;&quot;&quot;</span></span><br><span class="line">  <span class="comment"># Create target directory</span></span><br><span class="line">  target_dir_path = Path(target_dir)</span><br><span class="line">  target_dir_path.mkdir(parents=<span class="literal">True</span>,</span><br><span class="line">                        exist_ok=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">  <span class="comment"># Create model save path</span></span><br><span class="line">  <span class="keyword">assert</span> model_name.endswith(<span class="string">&quot;.pth&quot;</span>) <span class="keyword">or</span> model_name.endswith(<span class="string">&quot;.pt&quot;</span>), <span class="string">&quot;model_name should end with &#x27;.pt&#x27; or &#x27;.pth&#x27;&quot;</span></span><br><span class="line">  model_save_path = target_dir_path / model_name</span><br><span class="line"></span><br><span class="line">  <span class="comment"># Save the model state_dict()</span></span><br><span class="line">  <span class="built_in">print</span>(<span class="string">f&quot;[INFO] Saving model to: <span class="subst">&#123;model_save_path&#125;</span>&quot;</span>)</span><br><span class="line">  torch.save(obj=model.state_dict(),</span><br><span class="line">             f=model_save_path)</span><br></pre></td></tr></table></figure></p><p>现在，如果我们想使用我们的<code>save_model()</code>函数，而不必重新编写它，我们可以导入它并通过以下方式使用它：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Import utils.py</span></span><br><span class="line"><span class="keyword">from</span> going_modular <span class="keyword">import</span> utils</span><br><span class="line"></span><br><span class="line"><span class="comment"># Save a model to file</span></span><br><span class="line">save_model(model=...</span><br><span class="line">           target_dir=...,</span><br><span class="line">           model_name=...)</span><br></pre></td></tr></table></figure><h1 id="6-Train-evaluate-and-save-the-model-train-py-训练、评估并保存模型（train-py）"><a href="#6-Train-evaluate-and-save-the-model-train-py-训练、评估并保存模型（train-py）" class="headerlink" title="6. Train, evaluate and save the model (train.py)训练、评估并保存模型（train.py）"></a>6. Train, evaluate and save the model (train.py)训练、评估并保存模型（train.py）</h1><p>如前所述，您经常会遇到将所有功能组合在一个<code>train.py</code>文件中的 <code>PyTorch</code> 存储库。</p><p>该文件本质上是在说“使用任何可用的数据来训练模型”。</p><p>在我们的 <code>train.py</code> 文件中，我们将结合我们创建的其他 Python 脚本的所有功能并使用它来训练模型。</p><p>这样，我们就可以使用命令行中的一行代码来训练 PyTorch 模型：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python train.py</span><br></pre></td></tr></table></figure><p>要创建 <code>train.py</code>，我们将执行以下步骤：</p><ul><li>导入各种依赖项，即 <code>torch</code>、<code>os</code>、<code>torchvision.transforms</code> 和来自 <code>going_modular</code> 目录、<code>data_setup</code>、<code>engine</code>、<code>model_builder</code>、<code>utils</code> 的所有脚本。</li><li>注意：由于 <code>train.py</code> 将位于 <code>going_modular</code> 目录中，我们可以通过 <code>import ...</code> 而不是 <code>from going_modular import ....</code> 来导入其他模块。</li><li>设置各种超参数，例如批处理大小、时期数、学习率和隐藏单元数（这些可以在将来通过 Python 的 <code>argparse</code> 设置）。</li><li>设置训练和测试目录。</li><li>设置与设备无关的代码。</li><li>创建必要的数据转换。</li><li>使用 <code>data_setup.py</code> 创建 <code>DataLoaders</code>。</li><li>使用 <code>model_builder.py</code> 创建模型。</li><li>设置损失函数和优化器。</li><li>使用 <code>engine.py</code> 训练模型。</li><li>使用 <code>utils.py</code> 保存模型。</li></ul><p>我们可以使用以下行从笔记本单元创建文件<code>%%writefile going_modular/train.py</code>：</p><p><code>train.py</code><br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br></pre></td><td class="code"><pre><span class="line">%%writefile going_modular/train.py</span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">Trains a PyTorch image classification model using device-agnostic code.</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> data_setup, engine, model_builder, utils</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> transforms</span><br><span class="line"></span><br><span class="line"><span class="comment"># Setup hyperparameters</span></span><br><span class="line">NUM_EPOCHS = <span class="number">5</span></span><br><span class="line">BATCH_SIZE = <span class="number">32</span></span><br><span class="line">HIDDEN_UNITS = <span class="number">10</span></span><br><span class="line">LEARNING_RATE = <span class="number">0.001</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Setup directories</span></span><br><span class="line">train_dir = <span class="string">&quot;data/pizza_steak_sushi/train&quot;</span></span><br><span class="line">test_dir = <span class="string">&quot;data/pizza_steak_sushi/test&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Setup target device</span></span><br><span class="line">device = <span class="string">&quot;cuda&quot;</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&quot;cpu&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Create transforms</span></span><br><span class="line">data_transform = transforms.Compose([</span><br><span class="line">  transforms.Resize((<span class="number">64</span>, <span class="number">64</span>)),</span><br><span class="line">  transforms.ToTensor()</span><br><span class="line">])</span><br><span class="line"></span><br><span class="line"><span class="comment"># Create DataLoaders with help from data_setup.py</span></span><br><span class="line">train_dataloader, test_dataloader, class_names = data_setup.create_dataloaders(</span><br><span class="line">    train_dir=train_dir,</span><br><span class="line">    test_dir=test_dir,</span><br><span class="line">    transform=data_transform,</span><br><span class="line">    batch_size=BATCH_SIZE</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Create model with help from model_builder.py</span></span><br><span class="line">model = model_builder.TinyVGG(</span><br><span class="line">    input_shape=<span class="number">3</span>,</span><br><span class="line">    hidden_units=HIDDEN_UNITS,</span><br><span class="line">    output_shape=<span class="built_in">len</span>(class_names)</span><br><span class="line">).to(device)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Set loss and optimizer</span></span><br><span class="line">loss_fn = torch.nn.CrossEntropyLoss()</span><br><span class="line">optimizer = torch.optim.Adam(model.parameters(),</span><br><span class="line">                             lr=LEARNING_RATE)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Start training with help from engine.py</span></span><br><span class="line">engine.train(model=model,</span><br><span class="line">             train_dataloader=train_dataloader,</span><br><span class="line">             test_dataloader=test_dataloader,</span><br><span class="line">             loss_fn=loss_fn,</span><br><span class="line">             optimizer=optimizer,</span><br><span class="line">             epochs=NUM_EPOCHS,</span><br><span class="line">             device=device)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Save the model with help from utils.py</span></span><br><span class="line">utils.save_model(model=model,</span><br><span class="line">                 target_dir=<span class="string">&quot;models&quot;</span>,</span><br><span class="line">                 model_name=<span class="string">&quot;05_going_modular_script_mode_tinyvgg_model.pth&quot;</span>)</span><br></pre></td></tr></table></figure></p><p>现在我们可以通过在命令行上运行以下行来训练 PyTorch 模型：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python train.py</span><br></pre></td></tr></table></figure><p>这样做将利用我们创建的所有其他代码脚本。</p><p>如果我们愿意，我们可以调整我们的train.py文件以使用 Pythonargparse模块的参数标志输入，这将允许我们提供不同的超参数设置，如前所述：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python train.py --model MODEL_NAME --batch_size BATCH_SIZE --lr LEARNING_RATE --num_epochs NUM_EPOCHS</span><br></pre></td></tr></table></figure><h1 id="Exercises"><a href="#Exercises" class="headerlink" title="Exercises"></a>Exercises</h1><p><strong>资源：</strong></p><ul><li><a href="https://github.com/mrdbourke/pytorch-deep-learning/blob/main/extras/exercises/05_pytorch_going_modular_exercise_template.ipynb">05 年练习模板笔记本</a></li><li>05 示例解决方案笔记本<ul><li><a href="https://youtu.be/ijgFhMK3pp4">YouTube 上 05 解决方案笔记本</a>的实时编码演示</li></ul></li></ul><p><strong>练习：</strong></p><ol><li><p>将获取数据的代码（来自上面的 1.获取数据部分）转换为 Python 脚本，例如<code>get_data.py</code></p><ul><li>当您运行脚本时，<code>python get_data.py</code>它应该检查数据是否已经存在，如果存在则跳过下载。</li><li>如果数据下载成功，您应该能够<code>pizza_steak_sushi</code>从<code>data</code>目录访问图像。</li></ul></li><li><p>使用<br>Python 的<code>argparse</code>模块能够发送<code>train.py</code>训练程序的自定义超参数值。</p><ul><li>添加使用不同方法的参数：<ul><li>训练/测试目录</li><li>学习率</li><li>批次大小</li><li>训练的周期数</li><li>TinyVGG 模型中的隐藏单元数量</li></ul></li><li>保持上述每个参数的默认值不变（如笔记本 05 中所示）。</li><li>例如，您应该能够运行类似于以下代码行的程序来训练一个学习率为 0.003、批量大小为 64 的 TinyVGG 模型，为期 20 个时期：<code>python train.py --learning_rate 0.003 --batch_size 64 --num_epochs 20</code>。</li><li><strong>注意：</strong>由于<code>train.py</code>利用了我们在 05 节中创建的其他脚本，例如、<code>model_builder.py</code>和<code>utils.py</code>，<code>engine.py</code>因此您必须确保它们也可供使用。您可以在<a href="https://github.com/mrdbourke/pytorch-deep-learning/tree/main/going_modular/going_modular"><code>going_modular</code>课程 GitHub 上的文件夹</a>中找到这些脚本。</li></ul></li><li><p><code>predict.py</code>创建一个脚本来对给定已保存模型的文件路径的目标图像进行预测（例如）。</p><ul><li>例如，您应该能够运行命令<code>python predict.py some_image.jpeg</code>并让训练有素的 PyTorch 模型对图像进行预测并返回其预测。</li><li>要查看示例预测代码，请查看<a href="https://www.learnpytorch.io/04_pytorch_custom_datasets/#113-putting-custom-image-prediction-together-building-a-function">笔记本 04 中的自定义图像预测部分</a>。</li><li>您可能还需要编写代码来加载经过训练的模型。</li></ul></li></ol><h1 id="Extra-curriculum"><a href="#Extra-curriculum" class="headerlink" title="Extra-curriculum"></a>Extra-curriculum</h1><ul><li>要了解有关构建 Python 项目的更多信息，请查看 Real Python 的<a href="https://realpython.com/python-application-layouts/">Python 应用程序布局</a>指南。</li><li>有关 PyTorch 代码样式的想法，请查看<a href="https://github.com/IgorSusmelj/pytorch-styleguide#recommended-code-structure-for-training-your-model">Igor Susmelj 的 PyTorch 样式指南</a>（本章中的大部分样式均基于本指南 + 各种类似的 PyTorch 存储库）。</li><li><code>train.py</code>有关PyTorch 团队编写的用于训练最先进的图像分类模型的示例脚本和各种其他 PyTorch 脚本，请查看<a href="https://github.com/pytorch/vision/tree/main/references/classification"><code>classification</code>GitHub 上的存储库</a>。</li></ul>]]></content>
    
    
    <summary type="html">PyTorch-26H-6</summary>
    
    
    
    <category term="PyTorch" scheme="http://hibiscidai.com/categories/PyTorch/"/>
    
    
    <category term="学习笔记" scheme="http://hibiscidai.com/tags/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
    <category term="PyTorch" scheme="http://hibiscidai.com/tags/PyTorch/"/>
    
  </entry>
  
  <entry>
    <title>PyTorch-26H-5</title>
    <link href="http://hibiscidai.com/2024/08/18/PyTorch-26H-5/"/>
    <id>http://hibiscidai.com/2024/08/18/PyTorch-26H-5/</id>
    <published>2024-08-18T12:00:00.000Z</published>
    <updated>2024-11-18T07:04:49.000Z</updated>
    
    <content type="html"><![CDATA[<img src="/2024/08/18/PyTorch-26H-5/PyTorch-26H-5.png" class="" title="PyTorch-26H-5"><p>PyTorch-26H-5</p><span id="more"></span><h1 id="PyTorch-26H-5"><a href="#PyTorch-26H-5" class="headerlink" title="PyTorch-26H-5"></a>PyTorch-26H-5</h1><p>主页：<a href="https://www.freecodecamp.org/news/learn-pytorch-for-deep-learning-in-day/">https://www.freecodecamp.org/news/learn-pytorch-for-deep-learning-in-day/</a></p><p>youtub：<a href="https://youtu.be/V_xro1bcAuA">https://youtu.be/V_xro1bcAuA</a></p><p>github：<a href="https://github.com/mrdbourke/pytorch-deep-learning">https://github.com/mrdbourke/pytorch-deep-learning</a></p><p>Learn PyTorch for Deep Learning: Zero to Mastery book：<a href="https://www.learnpytorch.io/">https://www.learnpytorch.io/</a></p><p>PyTorch documentation：<a href="https://pytorch.org/docs/stable/index.html">https://pytorch.org/docs/stable/index.html</a></p><p>找到一个数据集，将数据集转换为数字，建立一个模型（或找到一个现有模型）以在这些数字中找到可用于预测的模式。</p><p>PyTorch 有许多内置数据集，可用于广泛的机器学习基准测试，但是，您通常希望使用自己的自定义数据集。</p><h1 id="What-is-a-custom-dataset-什么是自定义数据集？"><a href="#What-is-a-custom-dataset-什么是自定义数据集？" class="headerlink" title="What is a custom dataset? 什么是自定义数据集？"></a>What is a custom dataset? 什么是自定义数据集？</h1><p>自定义数据集是与您正在处理的特定问题相关的数据集合。</p><p>本质上，自定义数据集几乎可以包含任何内容。</p><p>例如，如果我们正在构建像<a href="https://nutrify.app/">Nutrify</a>这样的食物图像分类应用程序，我们的自定义数据集可能是食物图像。</p><p>或者，如果我们尝试建立一个模型来对网站上的基于文本的评论是正面的还是负面的进行分类，我们的自定义数据集可能是现有客户评论及其评级的示例。</p><p>或者，如果我们尝试构建声音分类应用程序，我们的自定义数据集可能是声音样本及其样本标签。</p><p>或者，如果我们尝试为在我们的网站上购买商品的客户建立推荐系统，我们的自定义数据集可能是其他人购买过的产品的示例。</p><img src="/2024/08/18/PyTorch-26H-5/PyTorch-26H-5-1.png" class="" title="PyTorch-26H-5-1"><p>PyTorch 包含许多现有函数，可加载 <em><a href="https://pytorch.org/vision/stable/index.html"><code>TorchVision</code></a>, <a href="https://pytorch.org/text/stable/index.html"><code>TorchText</code></a>, <a href="https://pytorch.org/audio/stable/index.html"><code>TorchAudio</code></a> and <a href="https://pytorch.org/torchrec/"><code>TorchRec</code></a></em>  域库中的各种自定义数据集。</p><p>但有时这些现有的功能可能还不够。</p><p>在这种情况下，我们总是可以 <code>torch.utils.data.Dataset</code> 根据自己的喜好对其进行子类化和定制。</p><h1 id="What-we’re-going-to-cover-将要讨论的内容"><a href="#What-we’re-going-to-cover-将要讨论的内容" class="headerlink" title="What we’re going to cover? 将要讨论的内容"></a>What we’re going to cover? 将要讨论的内容</h1><img src="/2024/08/18/PyTorch-26H-5/PyTorch-26H-5-2.png" class="" title="PyTorch-26H-5-2"><p>使用 <code>torchvision.datasets</code> 以及我们自己的自定义 <code>Dataset</code> 类来加载食物图像，然后构建一个 PyTorch 计算机视觉模型，希望能够对它们进行分类。</p><div class="table-container"><table><thead><tr><th style="text-align:center">话题</th><th style="text-align:center">内容</th></tr></thead><tbody><tr><td style="text-align:center">0. 导入 PyTorch 并设置与设备无关的代码</td><td style="text-align:center">加载 PyTorch，代码设置为与设备无关。</td></tr><tr><td style="text-align:center">1. 获取数据</td><td style="text-align:center">使用自己的披萨、牛排和寿司图像数据集</td></tr><tr><td style="text-align:center">2. 与数据融为一体（数据准备）</td><td style="text-align:center">在开始任何新的机器学习问题时，了解正在处理的数据至关重要。一些步骤来弄清楚我们拥有哪些数据。</td></tr><tr><td style="text-align:center">3. 转换数据</td><td style="text-align:center">通常，获得的数据并不能 100% 地用于机器学习模型，在这里我们将介绍可以采取的一些步骤来转换图像，以便它们可以用于模型。</td></tr><tr><td style="text-align:center">4. 使用 ImageFolder 加载数据（选项 1）</td><td style="text-align:center">PyTorch 有许多针对常见数据类型的内置数据加载函数。如果我们的图像是标准图像分类格式，ImageFolder 会很有用。</td></tr><tr><td style="text-align:center">5. 使用自定义数据集加载图像数据</td><td style="text-align:center">如果 PyTorch 没有内置函数来加载数据怎么办？这时我们可以构建自己的 torch.utils.data.Dataset 自定义子类。</td></tr><tr><td style="text-align:center">6. 其他形式的变换（数据增强）</td><td style="text-align:center">数据增强是扩展训练数据多样性的常用技术。探索 torchvision 的一些内置数据增强功能。</td></tr><tr><td style="text-align:center">7. 模型 0：未进行数据增强的 TinyVGG</td><td style="text-align:center">已经准备好数据，建立一个能够拟合它的模型。创建一些训练和测试函数来训练和评估我们的模型。</td></tr><tr><td style="text-align:center">8. 探索损失曲线</td><td style="text-align:center">损失曲线是查看模型如何随时间训练/改进的好方法。它也是查看模型是欠拟合还是过拟合的好方法。</td></tr><tr><td style="text-align:center">9. 模型 1：具有数据增强的 TinyVGG</td><td style="text-align:center">已经尝试了一个没有数据增强的模型，那尝试一个有数据增强的模型怎么样？</td></tr><tr><td style="text-align:center">10. 比较模型结果</td><td style="text-align:center">比较不同模型的损失曲线，看看哪个表现更好，并讨论一些提高性能的选项。</td></tr><tr><td style="text-align:center">11. 对自定义图像进行预测</td><td style="text-align:center">模型是在披萨、牛排和寿司图像的数据集上进行训练的。介绍如何使用我们训练过的模型来预测现有数据集之外的图像。</td></tr></tbody></table></div><h1 id="0-Importing-PyTorch-and-setting-up-device-agnostic-code-导入-PyTorch-并设置与设备无关的代码"><a href="#0-Importing-PyTorch-and-setting-up-device-agnostic-code-导入-PyTorch-并设置与设备无关的代码" class="headerlink" title="0. Importing PyTorch and setting up device-agnostic code 导入 PyTorch 并设置与设备无关的代码"></a>0. Importing PyTorch and setting up device-agnostic code 导入 PyTorch 并设置与设备无关的代码</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"></span><br><span class="line"><span class="comment"># Note: this notebook requires torch &gt;= 1.10.0</span></span><br><span class="line">torch.__version__</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&#x27;2.4.1&#x27;</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Setup device-agnostic code</span></span><br><span class="line">device = <span class="string">&quot;cuda&quot;</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&quot;cpu&quot;</span></span><br><span class="line">device</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&#x27;cuda&#x27;</span><br></pre></td></tr></table></figure><h1 id="1-Get-data"><a href="#1-Get-data" class="headerlink" title="1. Get data"></a>1. Get data</h1><p>机器学习是一个迭代过程，从小处着手，逐渐取得成效，并在必要时不断增强。</p><p>使用的数据是<a href="https://data.vision.ee.ethz.ch/cvl/datasets_extra/food-101/">Food101 数据集</a>的一个子集。<br>Food101 是流行的计算机视觉基准，它包含 101 种不同食物的 1000 张图像，总计 101,000 张图像（75,750 张训练集和 25,250 张测试集）。<br>不会从 101 个食物类别开始，而是从 3 个开始：披萨、牛排和寿司。<br>我们不是每个类别有 1,000 张图像，而是从随机的 10% 开始（从小处开始，必要时增加）。</p><ul><li>原始<a href="https://data.vision.ee.ethz.ch/cvl/datasets_extra/food-101/">Food101 数据集和论文网站</a>。</li><li><a href="https://pytorch.org/vision/main/generated/torchvision.datasets.Food101.html"><code>torchvision.datasets.Food101</code></a>- 我为这本笔记本下载的数据版本。</li><li><a href="https://github.com/mrdbourke/pytorch-deep-learning/blob/main/extras/04_custom_data_creation.ipynb"><code>extras/04_custom_data_creation.ipynb</code></a>- 我用来格式化 Food101 数据集以供此笔记本使用的笔记本。</li><li><a href="https://github.com/mrdbourke/pytorch-deep-learning/blob/main/data/pizza_steak_sushi.zip"><code>data/pizza_steak_sushi.zip</code></a>- 使用上面链接的笔记本创建的 Food101 披萨、牛排和寿司图片的 zip 档案。</li></ul><blockquote><p>注意：即将使用的数据集已预先格式化，以适应我们的用途。但是，无论你正在处理什么问题，你通常都必须格式化自己的数据集。这是机器学习领域的常规做法。</p></blockquote><ul><li>需要去google Colab下载</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">import</span> zipfile</span><br><span class="line"><span class="keyword">from</span> pathlib <span class="keyword">import</span> Path</span><br><span class="line"></span><br><span class="line"><span class="comment"># Setup path to data folder</span></span><br><span class="line">data_path = Path(<span class="string">&quot;data/&quot;</span>)</span><br><span class="line">image_path = data_path / <span class="string">&quot;pizza_steak_sushi&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># If the image folder doesn&#x27;t exist, download it and prepare it... </span></span><br><span class="line"><span class="keyword">if</span> image_path.is_dir():</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;<span class="subst">&#123;image_path&#125;</span> directory exists.&quot;</span>)</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;Did not find <span class="subst">&#123;image_path&#125;</span> directory, creating one...&quot;</span>)</span><br><span class="line">    image_path.mkdir(parents=<span class="literal">True</span>, exist_ok=<span class="literal">True</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Download pizza, steak, sushi data</span></span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(data_path / <span class="string">&quot;pizza_steak_sushi.zip&quot;</span>, <span class="string">&quot;wb&quot;</span>) <span class="keyword">as</span> f:</span><br><span class="line">        request = requests.get(<span class="string">&quot;https://github.com/mrdbourke/pytorch-deep-learning/raw/main/data/pizza_steak_sushi.zip&quot;</span>)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;Downloading pizza, steak, sushi data...&quot;</span>)</span><br><span class="line">        f.write(request.content)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Unzip pizza, steak, sushi data</span></span><br><span class="line">    <span class="keyword">with</span> zipfile.ZipFile(data_path / <span class="string">&quot;pizza_steak_sushi.zip&quot;</span>, <span class="string">&quot;r&quot;</span>) <span class="keyword">as</span> zip_ref:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;Unzipping pizza, steak, sushi data...&quot;</span>) </span><br><span class="line">        zip_ref.extractall(image_path)</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Did not find data/pizza_steak_sushi directory, creating one...</span><br><span class="line">Downloading pizza, steak, sushi data...</span><br><span class="line">Unzipping pizza, steak, sushi data...</span><br></pre></td></tr></table></figure><h1 id="2-Become-one-with-the-data-data-preparation-与数据融为一体（数据准备）"><a href="#2-Become-one-with-the-data-data-preparation-与数据融为一体（数据准备）" class="headerlink" title="2. Become one with the data (data preparation) 与数据融为一体（数据准备）"></a>2. Become one with the data (data preparation) 与数据融为一体（数据准备）</h1><p>在开始一个项目或建立任何类型的模型之前，了解正在处理的数据非常重要。</p><p>在我案例中，有标准图像分类格式的披萨、牛排和寿司图像。<br>图像分类格式包含位于单独目录中的不同类别的图像，这些类别以特定的类名命名。<br>例如，所有<code>pizza</code>图像都包含在<code>pizza/</code>目录中。<br>这种格式在许多不同的图像分类基准中很流行，包括<a href="https://www.image-net.org/">ImageNet</a>（最流行的计算机视觉基准数据集）。<br>可以在下面看到存储格式的示例，图像数量是任意的。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">pizza_steak_sushi/ &lt;- overall dataset folder</span><br><span class="line">    train/ &lt;- training images</span><br><span class="line">        pizza/ &lt;- class name as folder name</span><br><span class="line">            image01.jpeg</span><br><span class="line">            image02.jpeg</span><br><span class="line">            ...</span><br><span class="line">        steak/</span><br><span class="line">            image24.jpeg</span><br><span class="line">            image25.jpeg</span><br><span class="line">            ...</span><br><span class="line">        sushi/</span><br><span class="line">            image37.jpeg</span><br><span class="line">            ...</span><br><span class="line"></span><br><span class="line">    test/ &lt;- testing images</span><br><span class="line">        pizza/</span><br><span class="line">            image101.jpeg</span><br><span class="line">            image102.jpeg</span><br><span class="line">            ...</span><br><span class="line">        steak/</span><br><span class="line">            image154.jpeg</span><br><span class="line">            image155.jpeg</span><br><span class="line">            ...</span><br><span class="line">        sushi/</span><br><span class="line">            image167.jpeg</span><br><span class="line">            ...</span><br></pre></td></tr></table></figure><p>采用这种数据存储结构并将其转换为可供 PyTorch 使用的数据集。</p><blockquote><p>注意：您处理的数据结构将根据您正在处理的问题而有所不同。但前提仍然存在：与数据融为一体，然后找到一种最佳方法将其转换为与 PyTorch 兼容的数据集。</p></blockquote><p>通过编写一个小辅助函数来遍历每个子目录并计算存在的文件数量，从而检查数据目录中的内容。</p><p>使用 Python 的内置<a href="https://docs.python.org/3/library/os.html#os.walk"><code>os.walk()</code></a>。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">walk_through_dir</span>(<span class="params">dir_path</span>):</span><br><span class="line">  <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">  Walks through dir_path returning its contents.</span></span><br><span class="line"><span class="string">  Args:</span></span><br><span class="line"><span class="string">    dir_path (str or pathlib.Path): target directory</span></span><br><span class="line"><span class="string">  </span></span><br><span class="line"><span class="string">  Returns:</span></span><br><span class="line"><span class="string">    A print out of:</span></span><br><span class="line"><span class="string">      number of subdiretories in dir_path</span></span><br><span class="line"><span class="string">      number of images (files) in each subdirectory</span></span><br><span class="line"><span class="string">      name of each subdirectory</span></span><br><span class="line"><span class="string">  &quot;&quot;&quot;</span></span><br><span class="line">  <span class="keyword">for</span> dirpath, dirnames, filenames <span class="keyword">in</span> os.walk(dir_path):</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;There are <span class="subst">&#123;<span class="built_in">len</span>(dirnames)&#125;</span> directories and <span class="subst">&#123;<span class="built_in">len</span>(filenames)&#125;</span> images in &#x27;<span class="subst">&#123;dirpath&#125;</span>&#x27;.&quot;</span>)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">walk_through_dir(image_path)</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">There are 2 directories and 0 images in &#x27;data\pizza_steak_sushi&#x27;.</span><br><span class="line">There are 3 directories and 0 images in &#x27;data\pizza_steak_sushi\test&#x27;.</span><br><span class="line">There are 0 directories and 25 images in &#x27;data\pizza_steak_sushi\test\pizza&#x27;.</span><br><span class="line">There are 0 directories and 19 images in &#x27;data\pizza_steak_sushi\test\steak&#x27;.</span><br><span class="line">There are 0 directories and 31 images in &#x27;data\pizza_steak_sushi\test\sushi&#x27;.</span><br><span class="line">There are 3 directories and 0 images in &#x27;data\pizza_steak_sushi\train&#x27;.</span><br><span class="line">There are 0 directories and 78 images in &#x27;data\pizza_steak_sushi\train\pizza&#x27;.</span><br><span class="line">There are 0 directories and 75 images in &#x27;data\pizza_steak_sushi\train\steak&#x27;.</span><br><span class="line">There are 0 directories and 72 images in &#x27;data\pizza_steak_sushi\train\sushi&#x27;.</span><br></pre></td></tr></table></figure><p>每个训练类大约有 75 张图像，每个测试类大约有 25 张图像。图像是原始 Food101 数据集的子集。</p><p>设置一下训练和测试路径。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Setup train and testing paths</span></span><br><span class="line">train_dir = image_path / <span class="string">&quot;train&quot;</span></span><br><span class="line">test_dir = image_path / <span class="string">&quot;test&quot;</span></span><br><span class="line"></span><br><span class="line">train_dir, test_dir</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">(WindowsPath(&#x27;data/pizza_steak_sushi/train&#x27;),</span><br><span class="line"> WindowsPath(&#x27;data/pizza_steak_sushi/test&#x27;))</span><br></pre></td></tr></table></figure><h2 id="2-1-Visualize-an-image-可视化图像"><a href="#2-1-Visualize-an-image-可视化图像" class="headerlink" title="2.1 Visualize an image 可视化图像"></a>2.1 Visualize an image 可视化图像</h2><ul><li>使用  <a href="https://docs.python.org/3/library/pathlib.html#pathlib.Path.glob"><code>pathlib.Path.glob()</code></a> 获取所有图像路径，以查找所有以 .jpg 结尾的文件。</li><li>使用 Python 的 <a href="https://docs.python.org/3/library/random.html#random.choice"><code>random.choice()</code></a>.选择一个随机图像路径。</li><li>使用 <a href="https://docs.python.org/3/library/pathlib.html#pathlib.PurePath.parent"><code>pathlib.Path.parent.stem</code></a>. 获取图像类名。</li><li>由于我们正在处理图像，我们将使用 <a href="https://pillow.readthedocs.io/en/stable/reference/Image.html#PIL.Image.open"><code>PIL.Image.open()</code></a>（PIL 代表 Python 图像库）打开随机图像路径。</li><li>然后我们将显示图像并打印一些元数据。</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> random</span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"></span><br><span class="line"><span class="comment"># Set seed</span></span><br><span class="line">random.seed(<span class="number">42</span>) <span class="comment"># &lt;- try changing this and see what happens</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 1. Get all image paths (* means &quot;any combination&quot;) 获取所有图像路径（* 表示“任意组合”）</span></span><br><span class="line">image_path_list = <span class="built_in">list</span>(image_path.glob(<span class="string">&quot;*/*/*.jpg&quot;</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 2. Get random image path 获取随机图像路径</span></span><br><span class="line">random_image_path = random.choice(image_path_list)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 3. Get image class from path name (the image class is the name of the directory where the image is stored) 从路径名获取图像类（图像类是存储图像的目录名称）</span></span><br><span class="line">image_class = random_image_path.parent.stem</span><br><span class="line"></span><br><span class="line"><span class="comment"># 4. Open image 打开图片</span></span><br><span class="line">img = Image.<span class="built_in">open</span>(random_image_path)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 5. Print metadata 打印元数据</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Random image path: <span class="subst">&#123;random_image_path&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Image class: <span class="subst">&#123;image_class&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Image height: <span class="subst">&#123;img.height&#125;</span>&quot;</span>) </span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Image width: <span class="subst">&#123;img.width&#125;</span>&quot;</span>)</span><br><span class="line">img</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">Random image path: data\pizza_steak_sushi\test\sushi\2394442.jpg</span><br><span class="line">Image class: sushi</span><br><span class="line">Image height: 408</span><br><span class="line">Image width: 512</span><br></pre></td></tr></table></figure><img src="/2024/08/18/PyTorch-26H-5/PyTorch-26H-5-3.png" class="" title="PyTorch-26H-5-3"><p>我们可以使用 <a href="https://matplotlib.org/3.5.0/api/_as_gen/matplotlib.pyplot.imshow.html"><code>matplotlib.pyplot.imshow()</code></a> 执行相同操作，但我们必须先将图像转换为 NumPy 数组。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="comment"># Turn the image into an array</span></span><br><span class="line">img_as_array = np.asarray(img)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Plot the image with matplotlib</span></span><br><span class="line">plt.figure(figsize=(<span class="number">10</span>, <span class="number">7</span>))</span><br><span class="line">plt.imshow(img_as_array)</span><br><span class="line">plt.title(<span class="string">f&quot;Image class: <span class="subst">&#123;image_class&#125;</span> | Image shape: <span class="subst">&#123;img_as_array.shape&#125;</span> -&gt; [height, width, color_channels]&quot;</span>)</span><br><span class="line">plt.axis(<span class="literal">False</span>);</span><br></pre></td></tr></table></figure><img src="/2024/08/18/PyTorch-26H-5/PyTorch-26H-5-4.png" class="" title="PyTorch-26H-5-4"><h1 id="3-Transforming-data-转换数据"><a href="#3-Transforming-data-转换数据" class="headerlink" title="3. Transforming data 转换数据"></a>3. Transforming data 转换数据</h1><p>使用 PyTorch 使用图像数据之前，我们需要：</p><ul><li>将其转换为张量（我们图像的数值表示）。</li><li>将其变成<code>torch.utils.data.Dataset</code>和随后的<code>torch.utils.data.DataLoader</code>，我们简称为<code>Dataset</code>和<code>DataLoader</code>。</li></ul><p>PyTorch 有几种不同类型的预构建数据集和数据集加载器，具体取决于您正在处理的问题。</p><div class="table-container"><table><thead><tr><th style="text-align:center">问题空间</th><th style="text-align:center">预建数据集和函数</th></tr></thead><tbody><tr><td style="text-align:center">视觉 Vision</td><td style="text-align:center"><a href="https://pytorch.org/vision/stable/datasets.html"><code>torchvision.datasets</code></a></td></tr><tr><td style="text-align:center">音频 Audio</td><td style="text-align:center"><a href="https://pytorch.org/audio/stable/datasets.html"><code>torchaudio.datasets</code></a></td></tr><tr><td style="text-align:center">文本 Text</td><td style="text-align:center"><a href="https://pytorch.org/text/stable/datasets.html"><code>torchtext.datasets</code></a></td></tr><tr><td style="text-align:center">推荐系统 Recommendation system</td><td style="text-align:center"><a href="https://pytorch.org/torchrec/torchrec.datasets.html"><code>torchrec.datasets</code></a></td></tr></tbody></table></div><p>由于我们正在处理视觉问题，因此我们将研究<code>torchvision.datasets</code>数据加载功能以及<a href="https://pytorch.org/vision/stable/transforms.html"><code>torchvision.transforms</code></a>如何准备数据。</p><p>引入基本库</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> DataLoader</span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> datasets, transforms</span><br></pre></td></tr></table></figure><h2 id="3-1-Transforming-data-with-torchvision-transforms"><a href="#3-1-Transforming-data-with-torchvision-transforms" class="headerlink" title="3.1 Transforming data with torchvision.transforms"></a>3.1 Transforming data with <code>torchvision.transforms</code></h2><p>有图像文件夹，但在使用 PyTorch 之前，我们需要将它们转换为张量。<br>可以做到这一点的方法之一是使用 <code>torchvision.transforms</code> 模块。<br><code>torchvision.transforms</code>包含许多预先构建的方法，用于格式化图像、将它们转换为张量，甚至操纵它们以进行数据增强（改变数据以使模型更难学习的做法，我们稍后会看到）目的。</p><p>编写一系列转换步骤：</p><ul><li>使用 <a href="https://pytorch.org/vision/stable/generated/torchvision.transforms.Resize.html#torchvision.transforms.Resize"><code>transforms.Resize()</code></a> 调整图像大小（从大约 512x512 到 64x64，与  <a href="https://poloclub.github.io/cnn-explainer/">CNN Explainer website</a> 网站上的图像形状相同）。</li><li>使用 <a href="https://pytorch.org/vision/stable/generated/torchvision.transforms.RandomHorizontalFlip.html#torchvision.transforms.RandomHorizontalFlip"><code>transforms.RandomHorizontalFlip()</code></a> 在水平方向上随机翻转图像（这可以被视为一种数据增强形式，因为它会人为地改变我们的图像数据）。</li><li>使用  <a href="https://pytorch.org/vision/stable/generated/torchvision.transforms.ToTensor.html#torchvision.transforms.ToTensor"><code>transforms.ToTensor()</code></a>将图像从 PIL 图像转换为 PyTorch 张量。</li></ul><p>我们可以使用 <a href="https://pytorch.org/vision/stable/generated/torchvision.transforms.Compose.html#torchvision.transforms.Compose"><code>torchvision.transforms.Compose()</code></a> 编译所有这些步骤。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Write transform for image</span></span><br><span class="line"><span class="comment"># 编写图像变换</span></span><br><span class="line">data_transform = transforms.Compose([</span><br><span class="line">    <span class="comment"># Resize the images to 64x64</span></span><br><span class="line">    <span class="comment"># 将图像大小调整为 64x64</span></span><br><span class="line">    transforms.Resize(size=(<span class="number">64</span>, <span class="number">64</span>)),</span><br><span class="line">    <span class="comment"># Flip the images randomly on the horizontal</span></span><br><span class="line">    <span class="comment"># 水平随机翻转图像</span></span><br><span class="line">    transforms.RandomHorizontalFlip(p=<span class="number">0.5</span>), <span class="comment"># p = probability of flip, 0.5 = 50% chance## p = 翻转概率，0.5 = 50% 概率</span></span><br><span class="line">    <span class="comment"># Turn the image into a torch.Tensor</span></span><br><span class="line">    <span class="comment"># 将图像转换为 torch.Tensor</span></span><br><span class="line">    transforms.ToTensor() <span class="comment"># this also converts all pixel values from 0 to 255 to be between 0.0 and 1.0  # 这还将所有像素值从 0 到 255 转换为 0.0 到 1.0 之间</span></span><br><span class="line">])</span><br></pre></td></tr></table></figure><p>现在我们已经有了变换的组合，让我们编写一个函数来在各种图像上尝试它们。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">plot_transformed_images</span>(<span class="params">image_paths, transform, n=<span class="number">3</span>, seed=<span class="number">42</span></span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Plots a series of random images from image_paths.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Will open n image paths from image_paths, transform them</span></span><br><span class="line"><span class="string">    with transform and plot them side by side.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        image_paths (list): List of target image paths. </span></span><br><span class="line"><span class="string">        transform (PyTorch Transforms): Transforms to apply to images.</span></span><br><span class="line"><span class="string">        n (int, optional): Number of images to plot. Defaults to 3.</span></span><br><span class="line"><span class="string">        seed (int, optional): Random seed for the random generator. Defaults to 42.</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    random.seed(seed)</span><br><span class="line">    random_image_paths = random.sample(image_paths, k=n)</span><br><span class="line">    <span class="keyword">for</span> image_path <span class="keyword">in</span> random_image_paths:</span><br><span class="line">        <span class="keyword">with</span> Image.<span class="built_in">open</span>(image_path) <span class="keyword">as</span> f:</span><br><span class="line">            fig, ax = plt.subplots(<span class="number">1</span>, <span class="number">2</span>)</span><br><span class="line">            ax[<span class="number">0</span>].imshow(f) </span><br><span class="line">            ax[<span class="number">0</span>].set_title(<span class="string">f&quot;Original \nSize: <span class="subst">&#123;f.size&#125;</span>&quot;</span>)</span><br><span class="line">            ax[<span class="number">0</span>].axis(<span class="string">&quot;off&quot;</span>)</span><br><span class="line"></span><br><span class="line">            <span class="comment"># Transform and plot image</span></span><br><span class="line">            <span class="comment"># Note: permute() will change shape of image to suit matplotlib </span></span><br><span class="line">            <span class="comment"># (PyTorch default is [C, H, W] but Matplotlib is [H, W, C])</span></span><br><span class="line">            transformed_image = transform(f).permute(<span class="number">1</span>, <span class="number">2</span>, <span class="number">0</span>) </span><br><span class="line">            ax[<span class="number">1</span>].imshow(transformed_image) </span><br><span class="line">            ax[<span class="number">1</span>].set_title(<span class="string">f&quot;Transformed \nSize: <span class="subst">&#123;transformed_image.shape&#125;</span>&quot;</span>)</span><br><span class="line">            ax[<span class="number">1</span>].axis(<span class="string">&quot;off&quot;</span>)</span><br><span class="line"></span><br><span class="line">            fig.suptitle(<span class="string">f&quot;Class: <span class="subst">&#123;image_path.parent.stem&#125;</span>&quot;</span>, fontsize=<span class="number">16</span>)</span><br><span class="line"></span><br><span class="line">plot_transformed_images(image_path_list, </span><br><span class="line">                        transform=data_transform, </span><br><span class="line">                        n=<span class="number">3</span>)</span><br></pre></td></tr></table></figure><img src="/2024/08/18/PyTorch-26H-5/PyTorch-26H-5-5.png" class="" title="PyTorch-26H-5-5"><p>可以使用 <code>torchvision.transforms</code> 将图像转换为张量。</p><p>如果需要，还会操纵它们的大小和方向（某些模型更喜欢不同大小和形状的图像）。<br>一般来说，图像的形状越大，模型能够恢复的信息就越多。<br>例如，大小为 [256, 256, 3] 的图像的像素数将比大小为 [64, 64, 3] 的图像多 16 倍 ((256 <em> 256 </em> 3) / (64 <em> 64 </em> 3) = 16)。<br>代价是像素越多，计算量就越大。</p><blockquote><p>注释掉 data_transform 中的一个转换并再次运行绘图函数 plot_transformed_images()，会发生什么？</p></blockquote><h1 id="4-Option-1-Loading-Image-Data-Using-ImageFolder"><a href="#4-Option-1-Loading-Image-Data-Using-ImageFolder" class="headerlink" title="4. Option 1: Loading Image Data Using ImageFolder"></a>4. Option 1: Loading Image Data Using <code>ImageFolder</code></h1><p>是时候将我们的图像数据转换为能够与 PyTorch 一起使用的数据集了。<br>由于数据是标准图像分类格式，可以使用类<a href="https://pytorch.org/vision/stable/generated/torchvision.datasets.ImageFolder.html#torchvision.datasets.ImageFolder"><code>torchvision.datasets.ImageFolder</code></a>。<br>可以在其中传递目标图像目录的文件路径以及我们想要对图像执行的一系列转换。<br>在数据文件夹 <code>train_dir</code> 和 <code>test_dir</code> 上进行测试，传入 <code>transform=data_transform</code> 以将图像转换为张量。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Use ImageFolder to create dataset(s)</span></span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> datasets</span><br><span class="line">train_data = datasets.ImageFolder(root=train_dir, <span class="comment"># target folder of images</span></span><br><span class="line">                                  transform=data_transform, <span class="comment"># transforms to perform on data (images)</span></span><br><span class="line">                                  target_transform=<span class="literal">None</span>) <span class="comment"># transforms to perform on labels (if necessary)</span></span><br><span class="line"></span><br><span class="line">test_data = datasets.ImageFolder(root=test_dir, </span><br><span class="line">                                 transform=data_transform)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Train data:\n<span class="subst">&#123;train_data&#125;</span>\nTest data:\n<span class="subst">&#123;test_data&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">Train data:</span><br><span class="line">Dataset ImageFolder</span><br><span class="line">    Number of datapoints: 225</span><br><span class="line">    Root location: data\pizza_steak_sushi\train</span><br><span class="line">    StandardTransform</span><br><span class="line">Transform: Compose(</span><br><span class="line">               Resize(size=(64, 64), interpolation=bilinear, max_size=None, antialias=True)</span><br><span class="line">               RandomHorizontalFlip(p=0.5)</span><br><span class="line">               ToTensor()</span><br><span class="line">           )</span><br><span class="line">Test data:</span><br><span class="line">Dataset ImageFolder</span><br><span class="line">    Number of datapoints: 75</span><br><span class="line">    Root location: data\pizza_steak_sushi\test</span><br><span class="line">    StandardTransform</span><br><span class="line">Transform: Compose(</span><br><span class="line">               Resize(size=(64, 64), interpolation=bilinear, max_size=None, antialias=True)</span><br><span class="line">               RandomHorizontalFlip(p=0.5)</span><br><span class="line">               ToTensor()</span><br><span class="line">           )</span><br></pre></td></tr></table></figure><p>通过检查 <code>classes</code> 和 <code>class_to_idx</code> 属性以及训练和测试集的长度来检查它们。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Get class names as a list</span></span><br><span class="line">class_names = train_data.classes</span><br><span class="line">class_names</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[&#x27;pizza&#x27;, &#x27;steak&#x27;, &#x27;sushi&#x27;]</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Can also get class names as a dict</span></span><br><span class="line">class_dict = train_data.class_to_idx</span><br><span class="line">class_dict</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&#123;&#x27;pizza&#x27;: 0, &#x27;steak&#x27;: 1, &#x27;sushi&#x27;: 2&#125;</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Check the lengths</span></span><br><span class="line"><span class="built_in">len</span>(train_data), <span class="built_in">len</span>(test_data)</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">(225, 75)</span><br></pre></td></tr></table></figure><p>在 <code>train_data</code> 和 <code>test_data</code> 数据集上建立索引来查找样本及其目标标签。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">img, label = train_data[<span class="number">0</span>][<span class="number">0</span>], train_data[<span class="number">0</span>][<span class="number">1</span>]</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Image tensor:\n<span class="subst">&#123;img&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Image shape: <span class="subst">&#123;img.shape&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Image datatype: <span class="subst">&#123;img.dtype&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Image label: <span class="subst">&#123;label&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Label datatype: <span class="subst">&#123;<span class="built_in">type</span>(label)&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">Image tensor:</span><br><span class="line">tensor([[[0.1176, 0.1216, 0.1255,  ..., 0.0980, 0.1020, 0.1137],</span><br><span class="line">         [0.1294, 0.1294, 0.1294,  ..., 0.0980, 0.0980, 0.1059],</span><br><span class="line">         [0.1333, 0.1333, 0.1333,  ..., 0.0941, 0.0980, 0.1020],</span><br><span class="line">         ...,</span><br><span class="line">         [0.1686, 0.1647, 0.1686,  ..., 0.1255, 0.1098, 0.1098],</span><br><span class="line">         [0.1686, 0.1647, 0.1686,  ..., 0.1098, 0.0941, 0.0863],</span><br><span class="line">         [0.1647, 0.1647, 0.1686,  ..., 0.0980, 0.0863, 0.0863]],</span><br><span class="line"></span><br><span class="line">        [[0.0588, 0.0588, 0.0588,  ..., 0.0745, 0.0706, 0.0745],</span><br><span class="line">         [0.0627, 0.0627, 0.0627,  ..., 0.0745, 0.0706, 0.0706],</span><br><span class="line">         [0.0706, 0.0706, 0.0706,  ..., 0.0745, 0.0745, 0.0706],</span><br><span class="line">         ...,</span><br><span class="line">         [0.2392, 0.2392, 0.2510,  ..., 0.1373, 0.1333, 0.1255],</span><br><span class="line">         [0.2314, 0.2392, 0.2510,  ..., 0.1255, 0.1176, 0.1098],</span><br><span class="line">         [0.2275, 0.2353, 0.2431,  ..., 0.1137, 0.1059, 0.1020]],</span><br><span class="line"></span><br><span class="line">        [[0.0196, 0.0196, 0.0196,  ..., 0.0902, 0.0902, 0.0941],</span><br><span class="line">         [0.0196, 0.0157, 0.0196,  ..., 0.0902, 0.0863, 0.0902],</span><br><span class="line">         [0.0196, 0.0157, 0.0157,  ..., 0.0902, 0.0902, 0.0902],</span><br><span class="line">         ...,</span><br><span class="line">         [0.1804, 0.1882, 0.1961,  ..., 0.1490, 0.1333, 0.1294],</span><br><span class="line">         [0.1804, 0.1843, 0.1922,  ..., 0.1255, 0.1137, 0.1098],</span><br><span class="line">         [0.1765, 0.1804, 0.1843,  ..., 0.1059, 0.1020, 0.1059]]])</span><br><span class="line">Image shape: torch.Size([3, 64, 64])</span><br><span class="line">Image datatype: torch.float32</span><br><span class="line">Image label: 0</span><br><span class="line">Label datatype: &lt;class &#x27;int&#x27;&gt;</span><br></pre></td></tr></table></figure><p>图像现在采用张量的形式（形状为 [3, 64, 64]），标签采用与特定类相关的整数形式（由 class_to_idx 属性引用）。</p><p>我们如何使用 matplotlib 绘制单个图像张量？<br>我们首先必须进行置换（重新排列其维度的顺序）以使其兼容。<br>现在我们的图像尺寸采用 CHW（颜色通道、高度、宽度）格式，但 matplotlib 更喜欢 HWC（高度、宽度、颜色通道）。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Rearrange the order of dimensions</span></span><br><span class="line">img_permute = img.permute(<span class="number">1</span>, <span class="number">2</span>, <span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Print out different shapes (before and after permute)</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Original shape: <span class="subst">&#123;img.shape&#125;</span> -&gt; [color_channels, height, width]&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Image permute shape: <span class="subst">&#123;img_permute.shape&#125;</span> -&gt; [height, width, color_channels]&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Plot the image</span></span><br><span class="line">plt.figure(figsize=(<span class="number">10</span>, <span class="number">7</span>))</span><br><span class="line">plt.imshow(img.permute(<span class="number">1</span>, <span class="number">2</span>, <span class="number">0</span>))</span><br><span class="line">plt.axis(<span class="string">&quot;off&quot;</span>)</span><br><span class="line">plt.title(class_names[label], fontsize=<span class="number">14</span>);</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Original shape: torch.Size([3, 64, 64]) -&gt; [color_channels, height, width]</span><br><span class="line">Image permute shape: torch.Size([64, 64, 3]) -&gt; [height, width, color_channels]</span><br></pre></td></tr></table></figure><img src="/2024/08/18/PyTorch-26H-5/PyTorch-26H-5-6.png" class="" title="PyTorch-26H-5-6"><p>请注意，图像现在更加像素化（质量更低）。</p><p>这是因为图像的大小从 512x512 调整为 64x64 像素。</p><p>这里的直觉是，如果认为图像更难识别发生了什么，那么模型也可能会发现它更难理解。</p><h2 id="4-1-Turn-loaded-images-into-DataLoader’s"><a href="#4-1-Turn-loaded-images-into-DataLoader’s" class="headerlink" title="4.1 Turn loaded images into DataLoader’s"></a>4.1 Turn loaded images into DataLoader’s</h2><p>我们已经将图像作为 PyTorch 数据集，但现在让我们将它们转换为 DataLoader。</p><p>我们将使用 <a href="https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader"><code>torch.utils.data.DataLoader</code></a> 进行此操作。</p><p>将数据集转换为 DataLoader 使它们可迭代，因此模型可以遍历并了解样本和目标（特征和标签）之间的关系。</p><p>为简单起见，我们将使用 <code>batch_size=1</code> 和 <code>num_workers=1</code>。</p><p><code>num_workers</code> 是什么：它定义了将创建多少个子进程来加载您的数据。<br><code>num_workers</code> 设置的值越高，PyTorch 将使用越多的计算能力来加载您的数据。<br>通常通过 Python 的 <a href="https://docs.python.org/3/library/os.html#os.cpu_count"><code>os.cpu_count()</code></a> 将其设置为我机器上的 CPU 总数。<br>这可确保 <code>DataLoader</code> 使用尽可能多的核心来加载数据。</p><blockquote><p>注意：使用<a href="https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader">PyTorch documentation</a>中的 torch.utils.data.DataLoader 熟悉更多参数。</p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Turn train and test Datasets into DataLoaders</span></span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> DataLoader</span><br><span class="line">train_dataloader = DataLoader(dataset=train_data, </span><br><span class="line">                              batch_size=<span class="number">1</span>, <span class="comment"># how many samples per batch?</span></span><br><span class="line">                              num_workers=<span class="number">1</span>, <span class="comment"># how many subprocesses to use for data loading? (higher = more)</span></span><br><span class="line">                              shuffle=<span class="literal">True</span>) <span class="comment"># shuffle the data?</span></span><br><span class="line"></span><br><span class="line">test_dataloader = DataLoader(dataset=test_data, </span><br><span class="line">                             batch_size=<span class="number">1</span>, </span><br><span class="line">                             num_workers=<span class="number">1</span>, </span><br><span class="line">                             shuffle=<span class="literal">False</span>) <span class="comment"># don&#x27;t usually need to shuffle testing data</span></span><br><span class="line"></span><br><span class="line">train_dataloader, test_dataloader</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">(&lt;torch.utils.data.dataloader.DataLoader at 0x277ca8a84c0&gt;,</span><br><span class="line"> &lt;torch.utils.data.dataloader.DataLoader at 0x277ca8a83a0&gt;)</span><br></pre></td></tr></table></figure><p>现在我们的数据是可迭代的，让我们尝试一下并检查形状。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">img, label = <span class="built_in">next</span>(<span class="built_in">iter</span>(train_dataloader))</span><br><span class="line"></span><br><span class="line"><span class="comment"># Batch size will now be 1, try changing the batch_size parameter above and see what happens</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Image shape: <span class="subst">&#123;img.shape&#125;</span> -&gt; [batch_size, color_channels, height, width]&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Label shape: <span class="subst">&#123;label.shape&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Image shape: torch.Size([1, 3, 64, 64]) -&gt; [batch_size, color_channels, height, width]</span><br><span class="line">Label shape: torch.Size([1])</span><br></pre></td></tr></table></figure><p>现在可以将这些 DataLoader 与训练和测试循环一起使用来训练模型。</p><p>但在此之前，先看看加载图像（或几乎任何其他类型的数据）的另一种选择。</p><h1 id="5-Option-2-Loading-Image-Data-with-a-Custom-Dataset-使用自定义数据集"><a href="#5-Option-2-Loading-Image-Data-with-a-Custom-Dataset-使用自定义数据集" class="headerlink" title="5. Option 2: Loading Image Data with a Custom Dataset 使用自定义数据集"></a>5. Option 2: Loading Image Data with a Custom <code>Dataset</code> 使用自定义数据集</h1><p>如果没有预先构建的 <code>Dataset</code> 创建器（如  <a href="https://pytorch.org/vision/stable/datasets.html#torchvision.datasets.ImageFolder"><code>torchvision.datasets.ImageFolder()</code></a>）怎么办？</p><p>或者没有针对特定问题的数据集创建器？自己构建。<br>创建自己的 Custom <code>Dataset</code> 加载方式有什么优缺点？</p><div class="table-container"><table><thead><tr><th style="text-align:center">创建自定义数据集的优点</th><th style="text-align:center">创建自定义数据集的缺点</th></tr></thead><tbody><tr><td style="text-align:center">几乎任何东西都可以创建数据集。</td><td style="text-align:center">尽管你可以用几乎任何东西创建数据集，但这并不意味着它会起作用。</td></tr><tr><td style="text-align:center">不限于 PyTorch 预构建的 Dataset 函数。</td><td style="text-align:center">使用自定义数据集通常会导致编写更多代码，这很容易出现错误或性能问题。</td></tr></tbody></table></div><p>要查看实际效果，让我们通过子类化 <code>torch.utils.data.Dataset</code>（PyTorch 中所有 Dataset 的基类）来复制 <code>torchvision.datasets.ImageFolder()</code>。</p><p>导入所需的模块：</p><ul><li>用于处理目录的 Python <code>os</code>（我们的数据存储在目录中）。</li><li>用于处理文件路径的 Python <code>pathlib</code>（我们的每张图片都有一个唯一的文件路径）。</li><li>用于所有 PyTorch 内容的 <code>torch</code>。</li><li>用于加载图像的 PIL <code>Image</code>类。</li><li>用于子类化并创建我们自己的自定义 <code>Dataset</code> 的 <code>torchvision.transforms</code> 将我们的图像转换为张量。</li><li>来自 Python 的 <code>typing</code> 模块的各种类型，用于将类型提示添加到我们的代码中。</li></ul><blockquote><p>注意：您可以根据自己的数据集自定义以下步骤。前提是：编写代码以您想要的格式加载数据。</p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> pathlib</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> Dataset</span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> transforms</span><br><span class="line"><span class="keyword">from</span> typing <span class="keyword">import</span> <span class="type">Tuple</span>, <span class="type">Dict</span>, <span class="type">List</span></span><br></pre></td></tr></table></figure><p>还记得我们的 <code>torchvision.datasets.ImageFolder()</code> 实例如何允许我们使用 <code>classes</code> 和 <code>class_to_idx</code> 属性吗？</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Instance of torchvision.datasets.ImageFolder()</span></span><br><span class="line">train_data.classes, train_data.class_to_idx</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">([&#x27;pizza&#x27;, &#x27;steak&#x27;, &#x27;sushi&#x27;], &#123;&#x27;pizza&#x27;: 0, &#x27;steak&#x27;: 1, &#x27;sushi&#x27;: 2&#125;)</span><br></pre></td></tr></table></figure><h2 id="5-1-Creating-a-helper-function-to-get-class-names-创建一个辅助函数来获取类"><a href="#5-1-Creating-a-helper-function-to-get-class-names-创建一个辅助函数来获取类" class="headerlink" title="5.1 Creating a helper function to get class names 创建一个辅助函数来获取类"></a>5.1 Creating a helper function to get class names 创建一个辅助函数来获取类</h2><p>编写一个辅助函数，该函数能够在给定目录路径的情况下创建类名列表和类名及其索引的字典。</p><ul><li>使用 <code>os.scandir()</code> 遍历目标目录（理想情况下，目录采用标准图像分类格式）获取类名。</li><li>如果未找到类名，则引发错误（如果发生这种情况，则目录结构可能有问题）。</li><li>将类名转换为数字标签字典，每个类一个。</li></ul><p>在编写完整函数之前，让我们先看第 1 步的一个小例子。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Setup path for target directory</span></span><br><span class="line">target_directory = train_dir</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Target directory: <span class="subst">&#123;target_directory&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Get the class names from the target directory</span></span><br><span class="line">class_names_found = <span class="built_in">sorted</span>([entry.name <span class="keyword">for</span> entry <span class="keyword">in</span> <span class="built_in">list</span>(os.scandir(image_path / <span class="string">&quot;train&quot;</span>))])</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Class names found: <span class="subst">&#123;class_names_found&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Target directory: data\pizza_steak_sushi\train</span><br><span class="line">Class names found: [&#x27;pizza&#x27;, &#x27;steak&#x27;, &#x27;sushi&#x27;]</span><br></pre></td></tr></table></figure><p>如何将它变成一个完整的功能？</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Make function to find classes in target directory</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">find_classes</span>(<span class="params">directory: <span class="built_in">str</span></span>) -&gt; <span class="type">Tuple</span>[<span class="type">List</span>[<span class="built_in">str</span>], <span class="type">Dict</span>[<span class="built_in">str</span>, <span class="built_in">int</span>]]:</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Finds the class folder names in a target directory.</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    Assumes target directory is in standard image classification format.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        directory (str): target directory to load classnames from.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">        Tuple[List[str], Dict[str, int]]: (list_of_class_names, dict(class_name: idx...))</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    Example:</span></span><br><span class="line"><span class="string">        find_classes(&quot;food_images/train&quot;)</span></span><br><span class="line"><span class="string">        &gt;&gt;&gt; ([&quot;class_1&quot;, &quot;class_2&quot;], &#123;&quot;class_1&quot;: 0, ...&#125;)</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="comment"># 1. Get the class names by scanning the target directory</span></span><br><span class="line">    <span class="comment"># 1. 通过扫描目标目录获取类名</span></span><br><span class="line">    classes = <span class="built_in">sorted</span>(entry.name <span class="keyword">for</span> entry <span class="keyword">in</span> os.scandir(directory) <span class="keyword">if</span> entry.is_dir())</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 2. Raise an error if class names not found</span></span><br><span class="line">    <span class="comment"># 2. 如果找不到类名则抛出错误</span></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> classes:</span><br><span class="line">        <span class="keyword">raise</span> FileNotFoundError(<span class="string">f&quot;Couldn&#x27;t find any classes in <span class="subst">&#123;directory&#125;</span>.&quot;</span>)</span><br><span class="line">        </span><br><span class="line">    <span class="comment"># 3. Create a dictionary of index labels (computers prefer numerical rather than string labels)</span></span><br><span class="line">    <span class="comment"># 3. 创建索引标签词典（计算机更喜欢数字而不是字符串标签）</span></span><br><span class="line">    class_to_idx = &#123;cls_name: i <span class="keyword">for</span> i, cls_name <span class="keyword">in</span> <span class="built_in">enumerate</span>(classes)&#125;</span><br><span class="line">    <span class="keyword">return</span> classes, class_to_idx</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">find_classes(train_dir)</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">([&#x27;pizza&#x27;, &#x27;steak&#x27;, &#x27;sushi&#x27;], &#123;&#x27;pizza&#x27;: 0, &#x27;steak&#x27;: 1, &#x27;sushi&#x27;: 2&#125;)</span><br></pre></td></tr></table></figure><h2 id="5-2-Create-a-custom-Dataset-to-replicate-ImageFolder-创建自定义Dataset来复制-ImageFolder"><a href="#5-2-Create-a-custom-Dataset-to-replicate-ImageFolder-创建自定义Dataset来复制-ImageFolder" class="headerlink" title="5.2 Create a custom Dataset  to replicate ImageFolder 创建自定义Dataset来复制 ImageFolder"></a>5.2 Create a custom <code>Dataset</code>  to replicate <code>ImageFolder</code> 创建自定义Dataset来复制 ImageFolder</h2><p>准备好构建自己的自定义<code>Dataset</code>。<br>构建一个数据集来复制 <code>torchvision.datasets.ImageFolder()</code> 的功能。<br>这将是一个很好的做法，此外，它还会揭示创建自己的自定义数据集所需的一些步骤。</p><p>实现步骤：</p><ul><li><code>torch.utils.data.Dataset</code> 的子类。</li><li>使用 <code>targ_dir</code> 参数（目标数据目录）和 <code>transform</code> 参数初始化我们的子类（这样我们就可以选择在需要时转换数据）。</li><li>为<code>paths</code>（目标图像的路径）、<code>transform</code>（我们可能想要使用的转换，可以是 <code>None</code>）、<code>classes</code> 和 <code>class_to_idx</code>（来自我们的 <code>find_classes()</code> 函数）创建几个属性。</li><li>创建一个函数来从文件加载图像并返回它们，这可以使用 <code>PIL</code> 或  <a href="https://pytorch.org/vision/stable/io.html#image"><code>torchvision.io</code></a>（用于视觉数据的输入/输出）。</li><li>覆盖 <code>torch.utils.data.Dataset</code> 的 <code>__len__</code> 方法以返回 <code>Dataset</code> 中的样本数，这是推荐的，但不是必需的。这样就可以调用 <code>len(Dataset)</code>。</li><li>覆盖 <code>torch.utils.data.Dataset</code> 的<code>__getitem__</code> 方法以从数据集返回单个样本，这是必需的。</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Write a custom dataset class (inherits from torch.utils.data.Dataset)</span></span><br><span class="line"><span class="comment"># 编写自定义数据集类（继承自 torch.utils.data.Dataset）</span></span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> Dataset</span><br><span class="line"></span><br><span class="line"><span class="comment"># 1. Subclass torch.utils.data.Dataset</span></span><br><span class="line"><span class="comment"># 1. 子类 torch.utils.data.Dataset</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">ImageFolderCustom</span>(<span class="title class_ inherited__">Dataset</span>):</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 2. Initialize with a targ_dir and transform (optional) parameter</span></span><br><span class="line">    <span class="comment"># 2. 使用 targ_dir 和 transform （可选）参数进行初始化</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, targ_dir: <span class="built_in">str</span>, transform=<span class="literal">None</span></span>) -&gt; <span class="literal">None</span>:</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 3. Create class attributes</span></span><br><span class="line">        <span class="comment"># 3. 创建类属性</span></span><br><span class="line">        <span class="comment"># Get all image paths</span></span><br><span class="line">        <span class="comment"># 获取所有图片路径</span></span><br><span class="line">        self.paths = <span class="built_in">list</span>(pathlib.Path(targ_dir).glob(<span class="string">&quot;*/*.jpg&quot;</span>)) <span class="comment"># note: you&#x27;d have to update this if you&#x27;ve got .png&#x27;s or .jpeg&#x27;s # 注意：如果你有 .png 或 .jpeg 则必须更新它</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Setup transforms</span></span><br><span class="line">        <span class="comment"># 设置变换</span></span><br><span class="line">        self.transform = transform</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Create classes and class_to_idx attributes</span></span><br><span class="line">        <span class="comment"># 创建类和 class_to_idx 属性</span></span><br><span class="line">        self.classes, self.class_to_idx = find_classes(targ_dir)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 4. Make function to load images</span></span><br><span class="line">    <span class="comment"># 4. 制作加载图像的函数</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">load_image</span>(<span class="params">self, index: <span class="built_in">int</span></span>) -&gt; Image.Image:</span><br><span class="line">        <span class="string">&quot;Opens an image via a path and returns it.&quot;</span></span><br><span class="line">        image_path = self.paths[index]</span><br><span class="line">        <span class="keyword">return</span> Image.<span class="built_in">open</span>(image_path) </span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 5. Overwrite the __len__() method (optional but recommended for subclasses of torch.utils.data.Dataset)</span></span><br><span class="line">    <span class="comment"># 5. 重写__len__()方法（可选，但建议用于torch.utils.data.Dataset的子类）</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__len__</span>(<span class="params">self</span>) -&gt; <span class="built_in">int</span>:</span><br><span class="line">        <span class="string">&quot;Returns the total number of samples.&quot;</span></span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">len</span>(self.paths)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 6. Overwrite the __getitem__() method (required for subclasses of torch.utils.data.Dataset)</span></span><br><span class="line">    <span class="comment"># 6. 重写 __getitem__() 方法（torch.utils.data.Dataset 子类所需）</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__getitem__</span>(<span class="params">self, index: <span class="built_in">int</span></span>) -&gt; <span class="type">Tuple</span>[torch.Tensor, <span class="built_in">int</span>]:</span><br><span class="line">        <span class="string">&quot;Returns one sample of data, data and label (X, y).&quot;</span></span><br><span class="line">        img = self.load_image(index)</span><br><span class="line">        class_name  = self.paths[index].parent.name <span class="comment"># expects path in data_folder/class_name/image.jpeg # 期望路径在 data_folder/class_name/image.jpeg 中</span></span><br><span class="line">        class_idx = self.class_to_idx[class_name]</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Transform if necessary</span></span><br><span class="line">        <span class="comment"># 必要时进行转换</span></span><br><span class="line">        <span class="keyword">if</span> self.transform:</span><br><span class="line">            <span class="keyword">return</span> self.transform(img), class_idx <span class="comment"># return data, label (X, y)</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">return</span> img, class_idx <span class="comment"># return data, label (X, y)</span></span><br></pre></td></tr></table></figure><p>加载图像需要一大堆代码。这是创建自定义<code>Dataset</code>的缺点之一。</p><p>但是，现在我们已经编写了一次，我们可以将其与其他一些有用的数据函数一起移到 <code>.py</code> 文件中，例如 <code>data_loader.py</code>，并在以后重复使用。</p><p>在测试新的 <code>ImageFolderCustom</code> 类之前，让我们创建一些转换来准备图像。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Augment train data</span></span><br><span class="line">train_transforms = transforms.Compose([</span><br><span class="line">    transforms.Resize((<span class="number">64</span>, <span class="number">64</span>)),</span><br><span class="line">    transforms.RandomHorizontalFlip(p=<span class="number">0.5</span>),</span><br><span class="line">    transforms.ToTensor()</span><br><span class="line">])</span><br><span class="line"></span><br><span class="line"><span class="comment"># Don&#x27;t augment test data, only reshape</span></span><br><span class="line">test_transforms = transforms.Compose([</span><br><span class="line">    transforms.Resize((<span class="number">64</span>, <span class="number">64</span>)),</span><br><span class="line">    transforms.ToTensor()</span><br><span class="line">])</span><br></pre></td></tr></table></figure><p>使用自己的 <code>ImageFolderCustom</code> 类将我们的训练图像（包含在 <code>train_dir</code> 中）和测试图像（包含在 <code>test_dir</code> 中）转换为数据集。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">train_data_custom = ImageFolderCustom(targ_dir=train_dir, </span><br><span class="line">                                      transform=train_transforms)</span><br><span class="line">test_data_custom = ImageFolderCustom(targ_dir=test_dir, </span><br><span class="line">                                     transform=test_transforms)</span><br><span class="line">train_data_custom, test_data_custom</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">(&lt;__main__.ImageFolderCustom at 0x277ca8b76a0&gt;,</span><br><span class="line"> &lt;__main__.ImageFolderCustom at 0x277ca8b7d90&gt;)</span><br></pre></td></tr></table></figure><p>让我们尝试在新的数据集上调用 <code>len()</code> 并找到 <code>classes</code> 和 <code>class_to_idx</code> 属性。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">len</span>(train_data_custom), <span class="built_in">len</span>(test_data_custom)</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">(225, 75)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">train_data_custom.classes</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[&#x27;pizza&#x27;, &#x27;steak&#x27;, &#x27;sushi&#x27;]</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">train_data_custom.class_to_idx</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&#123;&#x27;pizza&#x27;: 0, &#x27;steak&#x27;: 1, &#x27;sushi&#x27;: 2&#125;</span><br></pre></td></tr></table></figure><p><code>len(test_data_custom) == len(test_data)</code> and <code>len(test_data_custom) == len(test_data)</code></p><p>我们也可以检查与由 <code>torchvision.datasets.ImageFolder()</code> 类创建的 <code>Dataset</code> 是否相等。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Check for equality amongst our custom Dataset and ImageFolder Dataset</span></span><br><span class="line"><span class="built_in">print</span>((<span class="built_in">len</span>(train_data_custom) == <span class="built_in">len</span>(train_data)) &amp; (<span class="built_in">len</span>(test_data_custom) == <span class="built_in">len</span>(test_data)))</span><br><span class="line"><span class="built_in">print</span>(train_data_custom.classes == train_data.classes)</span><br><span class="line"><span class="built_in">print</span>(train_data_custom.class_to_idx == train_data.class_to_idx)</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">True</span><br><span class="line">True</span><br><span class="line">True</span><br></pre></td></tr></table></figure><p>我们如何进一步绘制一些随机图像来测试我们的<code>__getitem__</code>覆写？</p><h2 id="5-3-Create-a-function-to-display-random-images-创建一个显示随机图像的函数"><a href="#5-3-Create-a-function-to-display-random-images-创建一个显示随机图像的函数" class="headerlink" title="5.3 Create a function to display random images 创建一个显示随机图像的函数"></a>5.3 Create a function to display random images 创建一个显示随机图像的函数</h2><p>创建一个名为的辅助函数<code>display_random_images()</code>，帮助我们在<code>Dataset</code>‘s 中可视化图像。</p><ul><li>接收一个 <code>Dataset</code> 和许多其他参数，例如 <code>classes</code> （我们的目标类的名称）、要显示的图像数量（<code>n</code>）和随机种子。</li><li>为了防止显示失控，我们将 <code>n</code> 限制为 10 张图像。</li><li>设置可重现图的随机种子（如果设置了<code>seed</code>）。</li><li>获取随机样本索引列表（我们可以使用 Python 的 <code>random.sample()</code> 进行绘制）。</li><li>设置 <code>matplotlib</code> 图。</li><li>循环遍历步骤 4 中找到的随机样本索引并使用 <code>matplotlib</code> 绘制它们。</li><li>确保样本图像的形状为 <code>HWC</code>（高度、宽度、颜色通道），以便我们可以绘制它们。</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 1. Take in a Dataset as well as a list of class names</span></span><br><span class="line"><span class="comment"># 1. 获取数据集以及类名列表</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">display_random_images</span>(<span class="params">dataset: torch.utils.data.dataset.Dataset,</span></span><br><span class="line"><span class="params">                          classes: <span class="type">List</span>[<span class="built_in">str</span>] = <span class="literal">None</span>,</span></span><br><span class="line"><span class="params">                          n: <span class="built_in">int</span> = <span class="number">10</span>,</span></span><br><span class="line"><span class="params">                          display_shape: <span class="built_in">bool</span> = <span class="literal">True</span>,</span></span><br><span class="line"><span class="params">                          seed: <span class="built_in">int</span> = <span class="literal">None</span></span>):</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 2. Adjust display if n too high</span></span><br><span class="line">    <span class="comment"># 2. 如果 n 太高则调整显示</span></span><br><span class="line">    <span class="keyword">if</span> n &gt; <span class="number">10</span>:</span><br><span class="line">        n = <span class="number">10</span></span><br><span class="line">        display_shape = <span class="literal">False</span></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;For display purposes, n shouldn&#x27;t be larger than 10, setting to 10 and removing shape display.&quot;</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 3. Set random seed</span></span><br><span class="line">    <span class="comment"># 3. 设置随机种子</span></span><br><span class="line">    <span class="keyword">if</span> seed:</span><br><span class="line">        random.seed(seed)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 4. Get random sample indexes</span></span><br><span class="line">    <span class="comment"># 4. 获取随机样本索引</span></span><br><span class="line">    random_samples_idx = random.sample(<span class="built_in">range</span>(<span class="built_in">len</span>(dataset)), k=n)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 5. Setup plot</span></span><br><span class="line">    <span class="comment"># 5. 设置plot</span></span><br><span class="line">    plt.figure(figsize=(<span class="number">16</span>, <span class="number">8</span>))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 6. Loop through samples and display random samples </span></span><br><span class="line">    <span class="comment"># 6. 循环遍历样本并显示随机样本</span></span><br><span class="line">    <span class="keyword">for</span> i, targ_sample <span class="keyword">in</span> <span class="built_in">enumerate</span>(random_samples_idx):</span><br><span class="line">        targ_image, targ_label = dataset[targ_sample][<span class="number">0</span>], dataset[targ_sample][<span class="number">1</span>]</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 7. Adjust image tensor shape for plotting: [color_channels, height, width] -&gt; [color_channels, height, width]</span></span><br><span class="line">        <span class="comment"># 7. 调整图像张量形状以便绘图：[color_channels，height，width] -&gt; [color_channels，height，width]</span></span><br><span class="line">        targ_image_adjust = targ_image.permute(<span class="number">1</span>, <span class="number">2</span>, <span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Plot adjusted samples</span></span><br><span class="line">        <span class="comment"># 绘制调整后的样本</span></span><br><span class="line">        plt.subplot(<span class="number">1</span>, n, i+<span class="number">1</span>)</span><br><span class="line">        plt.imshow(targ_image_adjust)</span><br><span class="line">        plt.axis(<span class="string">&quot;off&quot;</span>)</span><br><span class="line">        <span class="keyword">if</span> classes:</span><br><span class="line">            title = <span class="string">f&quot;class: <span class="subst">&#123;classes[targ_label]&#125;</span>&quot;</span></span><br><span class="line">            <span class="keyword">if</span> display_shape:</span><br><span class="line">                title = title + <span class="string">f&quot;\nshape: <span class="subst">&#123;targ_image_adjust.shape&#125;</span>&quot;</span></span><br><span class="line">        plt.title(title)</span><br></pre></td></tr></table></figure><p>先使用用 <code>torchvision.datasets.ImageFolder()</code> 创建的数据集进行测试。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Display random images from ImageFolder created Dataset</span></span><br><span class="line">display_random_images(train_data, </span><br><span class="line">                      n=<span class="number">5</span>, </span><br><span class="line">                      classes=class_names,</span><br><span class="line">                      seed=<span class="literal">None</span>)</span><br></pre></td></tr></table></figure><img src="/2024/08/18/PyTorch-26H-5/PyTorch-26H-5-7.png" class="" title="PyTorch-26H-5-7"><p>使用自己的 <code>ImageFolderCustom</code> 创建的数据集。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Display random images from ImageFolderCustom Dataset</span></span><br><span class="line">display_random_images(train_data_custom, </span><br><span class="line">                      n=<span class="number">12</span>, </span><br><span class="line">                      classes=class_names,</span><br><span class="line">                      seed=<span class="literal">None</span>) <span class="comment"># Try setting the seed for reproducible images</span></span><br></pre></td></tr></table></figure><img src="/2024/08/18/PyTorch-26H-5/PyTorch-26H-5-8.png" class="" title="PyTorch-26H-5-8"><h2 id="5-4-Turn-custom-loaded-images-into-DataLoader’s-将自定义加载的图像转换DataLoader"><a href="#5-4-Turn-custom-loaded-images-into-DataLoader’s-将自定义加载的图像转换DataLoader" class="headerlink" title="5.4 Turn custom loaded images into DataLoader’s 将自定义加载的图像转换DataLoader"></a>5.4 Turn custom loaded images into DataLoader’s 将自定义加载的图像转换DataLoader</h2><p>有一种方法可以通过 <code>ImageFolderCustom</code> 类将原始图像转换为 <code>Dataset</code>（将特征映射到标签或将 <code>X</code> 映射到 <code>y</code>）。<br>如何将自定义 <code>Dataset</code> 转换为 <code>DataLoader</code>？<br>使用 <code>torch.utils.data.DataLoader()</code><br>由于自定义 <code>Dataset</code> 是 <code>torch.utils.data.Dataset</code> 的子类，因此可以直接通过 <code>torch.utils.data.DataLoader()</code> 使用。<br>可以使用与之前非常相似的步骤，只是这次我们将使用我们自定义创建的 <code>Dataset</code>。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Turn train and test custom Dataset&#x27;s into DataLoader&#x27;s</span></span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> DataLoader</span><br><span class="line">train_dataloader_custom = DataLoader(dataset=train_data_custom, <span class="comment"># use custom created train Dataset</span></span><br><span class="line">                                     batch_size=<span class="number">1</span>, <span class="comment"># how many samples per batch?</span></span><br><span class="line">                                     num_workers=<span class="number">0</span>, <span class="comment"># how many subprocesses to use for data loading? (higher = more)</span></span><br><span class="line">                                     shuffle=<span class="literal">True</span>) <span class="comment"># shuffle the data?</span></span><br><span class="line"></span><br><span class="line">test_dataloader_custom = DataLoader(dataset=test_data_custom, <span class="comment"># use custom created test Dataset</span></span><br><span class="line">                                    batch_size=<span class="number">1</span>, </span><br><span class="line">                                    num_workers=<span class="number">0</span>, </span><br><span class="line">                                    shuffle=<span class="literal">False</span>) <span class="comment"># don&#x27;t usually need to shuffle testing data</span></span><br><span class="line"></span><br><span class="line">train_dataloader_custom, test_dataloader_custom</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">(&lt;torch.utils.data.dataloader.DataLoader at 0x277cc3e9580&gt;,</span><br><span class="line"> &lt;torch.utils.data.dataloader.DataLoader at 0x277cc3e94c0&gt;)</span><br></pre></td></tr></table></figure><p>样本的形状看起来是否相同？</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Get image and label from custom DataLoader</span></span><br><span class="line">img_custom, label_custom = <span class="built_in">next</span>(<span class="built_in">iter</span>(train_dataloader_custom))</span><br><span class="line"></span><br><span class="line"><span class="comment"># Batch size will now be 1, try changing the batch_size parameter above and see what happens</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Image shape: <span class="subst">&#123;img_custom.shape&#125;</span> -&gt; [batch_size, color_channels, height, width]&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Label shape: <span class="subst">&#123;label_custom.shape&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Image shape: torch.Size([1, 3, 64, 64]) -&gt; [batch_size, color_channels, height, width]</span><br><span class="line">Label shape: torch.Size([1])</span><br></pre></td></tr></table></figure><p>现在让我们看一下其他形式的数据转换。</p><h1 id="6-Other-forms-of-transforms-data-augmentation-其他形式的变换（数据增强）"><a href="#6-Other-forms-of-transforms-data-augmentation-其他形式的变换（数据增强）" class="headerlink" title="6. Other forms of transforms (data augmentation) 其他形式的变换（数据增强）"></a>6. Other forms of transforms (data augmentation) 其他形式的变换（数据增强）</h1><p>还有很多数据上的变换，参考 <a href="https://pytorch.org/vision/stable/transforms.html"><code>torchvision.transforms</code> documentation</a>。</p><p>变换的目的是以某种方式改变图像。将图像变成张量，或者裁剪它或随机删除一部分或随机旋转它们，进行这些类型的转换通常称为数据增强。</p><p>数据增强是以人为增加训练集多样性的方式改变数据的过程。<br>在这个人工改变的数据集上训练模型有望产生一个能够更好地泛化的模型（它学习的模式对未来看不见的示例更具鲁棒性）。</p><p>在 <a href="https://pytorch.org/vision/main/auto_examples/transforms/plot_transforms_illustrations.html">Illustration of Transforms example</a>.中看到使用 <code>torchvision.transforms</code> 对图像执行数据增强的许多不同示例。</p><p>机器学习就是要利用随机性的力量，研究表明，随机变换（如 t <a href="https://pytorch.org/vision/stable/auto_examples/plot_transforms.html#randaugment"><code>transforms.RandAugment()</code></a>和 <a href="https://pytorch.org/vision/stable/auto_examples/plot_transforms.html#trivialaugmentwide"><code>transforms.TrivialAugmentWide()</code></a>）通常比手工挑选的变换表现更好。背后的想法是：<a href="https://arxiv.org/abs/2103.10158">TrivialAugment</a></p><p>您有一组变换，您可以随机选择其中的一些变换在图像上执行，并在给定范围内以随机幅度执行（幅度越大，强度越大）。</p><p>PyTorch 团队甚至使用<a href="https://pytorch.org/blog/how-to-train-state-of-the-art-models-using-torchvision-latest-primitives/#break-down-of-key-accuracy-improvements">used TrivialAugment it to train their latest state-of-the-art vision models</a>.来训练他们最新的先进视觉模型。</p><p>TrivialAugment 是最近对各种 PyTorch 视觉模型进行先进训练升级时使用的要素之一。</p><p>我们如何在我们自己的一些图像上测试它？</p><p>在 <code>transforms.TrivialAugmentWide()</code> 中要注意的主要参数是 <code>num_magnitude_bins=31</code>。它定义了将选择强度值的范围以应用特定变换，<code>0</code> 表示无范围，<code>31</code> 表示最大范围（最高强度的可能性最高）。<br>我们可以将 <code>transforms.TrivialAugmentWide()</code> 合并到 <code>transforms.Compose()</code> 中。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> transforms</span><br><span class="line"></span><br><span class="line">train_transforms = transforms.Compose([</span><br><span class="line">    transforms.Resize((<span class="number">224</span>, <span class="number">224</span>)),</span><br><span class="line">    transforms.TrivialAugmentWide(num_magnitude_bins=<span class="number">31</span>), <span class="comment"># how intense </span></span><br><span class="line">    transforms.ToTensor() <span class="comment"># use ToTensor() last to get everything between 0 &amp; 1</span></span><br><span class="line">])</span><br><span class="line"></span><br><span class="line"><span class="comment"># Don&#x27;t need to perform augmentation on the test data</span></span><br><span class="line">test_transforms = transforms.Compose([</span><br><span class="line">    transforms.Resize((<span class="number">224</span>, <span class="number">224</span>)), </span><br><span class="line">    transforms.ToTensor()</span><br><span class="line">])</span><br></pre></td></tr></table></figure><blockquote><p>注意：通常不会对测试集执行数据增强。数据增强的理念是人为地增加训练集的多样性，以便更好地预测测试集。<br>但是，需要确保将测试集图像转换为张量。将测试图像的大小调整为与训练图像相同的大小，但是，如果需要，可以对不同大小的图像进行推理（尽管这可能会改变性能）。</p></blockquote><p>目前有了训练转换（有数据增强）和测试转换（没有数据增强）。</p><p>测试一下数据增强：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Get all image paths</span></span><br><span class="line">image_path_list = <span class="built_in">list</span>(image_path.glob(<span class="string">&quot;*/*/*.jpg&quot;</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># Plot random images</span></span><br><span class="line">plot_transformed_images(</span><br><span class="line">    image_paths=image_path_list,</span><br><span class="line">    transform=train_transforms,</span><br><span class="line">    n=<span class="number">3</span>,</span><br><span class="line">    seed=<span class="literal">None</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure><img src="/2024/08/18/PyTorch-26H-5/PyTorch-26H-5-9.png" class="" title="PyTorch-26H-5-9"><p>尝试运行上述单元格几次，并观察原始图像在转换过程中如何变化。</p><h1 id="7-Model-0-TinyVGG-without-data-augmentation"><a href="#7-Model-0-TinyVGG-without-data-augmentation" class="headerlink" title="7. Model 0: TinyVGG without data augmentation"></a>7. Model 0: TinyVGG without data augmentation</h1><p>已经了解了如何将数据从文件夹中的图像转换为转换后的张量。</p><p>构建一个计算机视觉模型，看看能否对图像是披萨、牛排还是寿司进行分类。</p><p>首先，将从一个简单的转换开始，只将图像的大小调整为 (64, 64) 并将它们转换为张量。</p><h2 id="7-1-Creating-transforms-and-loading-data-for-Model-0-为模型-0-创建变换并加载数据"><a href="#7-1-Creating-transforms-and-loading-data-for-Model-0-为模型-0-创建变换并加载数据" class="headerlink" title="7.1 Creating transforms and loading data for Model 0 为模型 0 创建变换并加载数据"></a>7.1 Creating transforms and loading data for Model 0 为模型 0 创建变换并加载数据</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Create simple transform</span></span><br><span class="line">simple_transform = transforms.Compose([ </span><br><span class="line">    transforms.Resize((<span class="number">64</span>, <span class="number">64</span>)),</span><br><span class="line">    transforms.ToTensor(),</span><br><span class="line">])</span><br></pre></td></tr></table></figure><p>有了一个简单的转换：</p><ul><li>加载数据，首先使用 <code>torchvision.datasets.ImageFolder()</code> 将我们的每个训练和测试文件夹转换为数据集。</li><li>然后使用 <code>torch.utils.data.DataLoader()</code> 转换为 <code>DataLoader</code>。</li><li>我们将 <code>batch_size=32</code> 和 <code>num_workers</code> 设置为机器上的 CPU 数量（这取决于使用的机器）。</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 1. Load and transform data</span></span><br><span class="line"><span class="comment"># 1. 加载和转换数据</span></span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> datasets</span><br><span class="line">train_data_simple = datasets.ImageFolder(root=train_dir, transform=simple_transform)</span><br><span class="line">test_data_simple = datasets.ImageFolder(root=test_dir, transform=simple_transform)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 2. Turn data into DataLoaders</span></span><br><span class="line"><span class="comment"># 2. 将数据转换为 DataLoaders</span></span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> DataLoader</span><br><span class="line"></span><br><span class="line"><span class="comment"># Setup batch size and number of workers </span></span><br><span class="line"><span class="comment"># 设置批次大小和工人数量</span></span><br><span class="line">BATCH_SIZE = <span class="number">32</span></span><br><span class="line">NUM_WORKERS = os.cpu_count()</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Creating DataLoader&#x27;s with batch size <span class="subst">&#123;BATCH_SIZE&#125;</span> and <span class="subst">&#123;NUM_WORKERS&#125;</span> workers.&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Create DataLoader&#x27;s</span></span><br><span class="line"><span class="comment"># 创建 DataLoader</span></span><br><span class="line">train_dataloader_simple = DataLoader(train_data_simple, </span><br><span class="line">                                     batch_size=BATCH_SIZE, </span><br><span class="line">                                     shuffle=<span class="literal">True</span>, </span><br><span class="line">                                     num_workers=NUM_WORKERS)</span><br><span class="line"></span><br><span class="line">test_dataloader_simple = DataLoader(test_data_simple, </span><br><span class="line">                                    batch_size=BATCH_SIZE, </span><br><span class="line">                                    shuffle=<span class="literal">False</span>, </span><br><span class="line">                                    num_workers=NUM_WORKERS)</span><br><span class="line"></span><br><span class="line">train_dataloader_simple, test_dataloader_simple</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Creating DataLoader&#x27;s with batch size 32 and 96 workers.</span><br><span class="line">(&lt;torch.utils.data.dataloader.DataLoader at 0x277ce4fc220&gt;,</span><br><span class="line"> &lt;torch.utils.data.dataloader.DataLoader at 0x277ce4fcca0&gt;)</span><br></pre></td></tr></table></figure><h2 id="7-2-Create-TinyVGG-model-class"><a href="#7-2-Create-TinyVGG-model-class" class="headerlink" title="7.2 Create TinyVGG model class"></a>7.2 Create TinyVGG model class</h2><p>在上一节中，我们使用了 <a href="https://poloclub.github.io/cnn-explainer/">CNN Explainer website</a>上的 TinyVGG 模型。</p><p>让我们重新创建相同的模型，但这次我们将使用彩色图像而不是灰度图像（对于 RGB 像素，<code>in_channels=3</code> 而不是 <code>in_channels=1</code>）。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">TinyVGG</span>(nn.Module):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Model architecture copying TinyVGG from: </span></span><br><span class="line"><span class="string">    https://poloclub.github.io/cnn-explainer/</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, input_shape: <span class="built_in">int</span>, hidden_units: <span class="built_in">int</span>, output_shape: <span class="built_in">int</span></span>) -&gt; <span class="literal">None</span>:</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.conv_block_1 = nn.Sequential(</span><br><span class="line">            nn.Conv2d(in_channels=input_shape, </span><br><span class="line">                      out_channels=hidden_units, </span><br><span class="line">                      kernel_size=<span class="number">3</span>, <span class="comment"># how big is the square that&#x27;s going over the image?</span></span><br><span class="line">                      stride=<span class="number">1</span>, <span class="comment"># default</span></span><br><span class="line">                      padding=<span class="number">1</span>), <span class="comment"># options = &quot;valid&quot; (no padding) or &quot;same&quot; (output has same shape as input) or int for specific number </span></span><br><span class="line">            nn.ReLU(),</span><br><span class="line">            nn.Conv2d(in_channels=hidden_units, </span><br><span class="line">                      out_channels=hidden_units,</span><br><span class="line">                      kernel_size=<span class="number">3</span>,</span><br><span class="line">                      stride=<span class="number">1</span>,</span><br><span class="line">                      padding=<span class="number">1</span>),</span><br><span class="line">            nn.ReLU(),</span><br><span class="line">            nn.MaxPool2d(kernel_size=<span class="number">2</span>,</span><br><span class="line">                         stride=<span class="number">2</span>) <span class="comment"># default stride value is same as kernel_size</span></span><br><span class="line">        )</span><br><span class="line">        self.conv_block_2 = nn.Sequential(</span><br><span class="line">            nn.Conv2d(hidden_units, hidden_units, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>),</span><br><span class="line">            nn.ReLU(),</span><br><span class="line">            nn.Conv2d(hidden_units, hidden_units, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>),</span><br><span class="line">            nn.ReLU(),</span><br><span class="line">            nn.MaxPool2d(<span class="number">2</span>)</span><br><span class="line">        )</span><br><span class="line">        self.classifier = nn.Sequential(</span><br><span class="line">            nn.Flatten(),</span><br><span class="line">            <span class="comment"># Where did this in_features shape come from? </span></span><br><span class="line">            <span class="comment"># It&#x27;s because each layer of our network compresses and changes the shape of our input data.</span></span><br><span class="line">            nn.Linear(in_features=hidden_units*<span class="number">16</span>*<span class="number">16</span>,</span><br><span class="line">                      out_features=output_shape)</span><br><span class="line">        )</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x: torch.Tensor</span>):</span><br><span class="line">        x = self.conv_block_1(x)</span><br><span class="line">        <span class="comment"># print(x.shape)</span></span><br><span class="line">        x = self.conv_block_2(x)</span><br><span class="line">        <span class="comment"># print(x.shape)</span></span><br><span class="line">        x = self.classifier(x)</span><br><span class="line">        <span class="comment"># print(x.shape)</span></span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line">        <span class="comment"># return self.classifier(self.conv_block_2(self.conv_block_1(x))) # &lt;- leverage the benefits of operator fusion</span></span><br><span class="line"></span><br><span class="line">torch.manual_seed(<span class="number">42</span>)</span><br><span class="line">model_0 = TinyVGG(input_shape=<span class="number">3</span>, <span class="comment"># number of color channels (3 for RGB) </span></span><br><span class="line">                  hidden_units=<span class="number">10</span>, </span><br><span class="line">                  output_shape=<span class="built_in">len</span>(train_data.classes)).to(device)</span><br><span class="line">model_0</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">TinyVGG(</span><br><span class="line">  (conv_block_1): Sequential(</span><br><span class="line">    (0): Conv2d(3, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))</span><br><span class="line">    (1): ReLU()</span><br><span class="line">    (2): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))</span><br><span class="line">    (3): ReLU()</span><br><span class="line">    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)</span><br><span class="line">  )</span><br><span class="line">  (conv_block_2): Sequential(</span><br><span class="line">    (0): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))</span><br><span class="line">    (1): ReLU()</span><br><span class="line">    (2): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))</span><br><span class="line">    (3): ReLU()</span><br><span class="line">    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)</span><br><span class="line">  )</span><br><span class="line">  (classifier): Sequential(</span><br><span class="line">    (0): Flatten(start_dim=1, end_dim=-1)</span><br><span class="line">    (1): Linear(in_features=2560, out_features=3, bias=True)</span><br><span class="line">  )</span><br><span class="line">)</span><br></pre></td></tr></table></figure><p>注意：加速深度学习模型在 GPU 上的计算的方法之一是利用运算符融合<code>operator fusion</code>。<br>这意味着在我们上述模型的 <code>forward()</code> 方法中，我们不是每次都调用一个层块并重新分配 <code>x</code>，而是连续调用每个块（请参阅上述模型中 <code>forward()</code> 方法的最后一行作为示例）。<br>这节省了重新分配 <code>x</code> 所花费的时间（占用大量内存），并且只专注于计算 <code>x</code>。<br>请参阅 Horace He 的《从第一原理开始让深度学习变得很棒 <a href="https://horace.io/brrr_intro.html">Making Deep Learning Go Brrrr From First Principles</a>》，了解更多有关如何加速机器学习模型的方法。</p><p>现在，这是一个漂亮的模型！用单张图片的前向传递来测试一下怎么样？</p><h2 id="7-3-Try-a-forward-pass-on-a-single-image-to-test-the-model-尝试在单个图像上进行前向传递（以测试模型）"><a href="#7-3-Try-a-forward-pass-on-a-single-image-to-test-the-model-尝试在单个图像上进行前向传递（以测试模型）" class="headerlink" title="7.3 Try a forward pass on a single image (to test the model) 尝试在单个图像上进行前向传递（以测试模型）"></a>7.3 Try a forward pass on a single image (to test the model) 尝试在单个图像上进行前向传递（以测试模型）</h2><p>测试模型的一个好方法是对单个数据进行前向传递，这也是测试不同层的输入和输出形状的便捷方法。</p><p>要对单个图像进行前向传递：</p><ul><li>从 <code>DataLoader</code> 获取一批图像和标签。</li><li>从批次中获取单个图像并 <code>unsqueeze()</code> 该图像，使其批次大小为 <code>1</code>（因此其形状适合模型）。</li><li>对单个图像执行推理（确保将图像发送到目标设备）。</li><li>打印出正在发生的事情并使用 <code>torch.softmax()</code> 将模型的原始输出 <code>logits</code> 转换为预测概率（因为我们正在处理多类数据），并使用 <code>torch.argmax()</code> 将预测概率转换为预测标签。</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 1. Get a batch of images and labels from the DataLoader</span></span><br><span class="line"><span class="comment"># 1.从DataLoader获取一批图像和标签</span></span><br><span class="line">img_batch, label_batch = <span class="built_in">next</span>(<span class="built_in">iter</span>(train_dataloader_simple))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 2. Get a single image from the batch and unsqueeze the image so its shape fits the model</span></span><br><span class="line"><span class="comment"># 2. 从批次中获取单个图像并解压图像，使其形状适合模型</span></span><br><span class="line">img_single, label_single = img_batch[<span class="number">0</span>].unsqueeze(dim=<span class="number">0</span>), label_batch[<span class="number">0</span>]</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Single image shape: <span class="subst">&#123;img_single.shape&#125;</span>\n&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 3. Perform a forward pass on a single image</span></span><br><span class="line"><span class="comment"># 3. 对单个图像执行前向传递</span></span><br><span class="line">model_0.<span class="built_in">eval</span>()</span><br><span class="line"><span class="keyword">with</span> torch.inference_mode():</span><br><span class="line">    pred = model_0(img_single.to(device))</span><br><span class="line">    </span><br><span class="line"><span class="comment"># 4. Print out what&#x27;s happening and convert model logits -&gt; pred probs -&gt; pred label</span></span><br><span class="line"><span class="comment"># 4. 打印出正在发生的事情并转换模型 logits -&gt; pred probs -&gt; pred label</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Output logits:\n<span class="subst">&#123;pred&#125;</span>\n&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Output prediction probabilities:\n<span class="subst">&#123;torch.softmax(pred, dim=<span class="number">1</span>)&#125;</span>\n&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Output prediction label:\n<span class="subst">&#123;torch.argmax(torch.softmax(pred, dim=<span class="number">1</span>), dim=<span class="number">1</span>)&#125;</span>\n&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Actual label:\n<span class="subst">&#123;label_single&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">Single image shape: torch.Size([1, 3, 64, 64])</span><br><span class="line"></span><br><span class="line">Output logits:</span><br><span class="line">tensor([[0.0578, 0.0634, 0.0352]], device=&#x27;cuda:0&#x27;)</span><br><span class="line"></span><br><span class="line">Output prediction probabilities:</span><br><span class="line">tensor([[0.3352, 0.3371, 0.3277]], device=&#x27;cuda:0&#x27;)</span><br><span class="line"></span><br><span class="line">Output prediction label:</span><br><span class="line">tensor([1], device=&#x27;cuda:0&#x27;)</span><br><span class="line"></span><br><span class="line">Actual label:</span><br><span class="line">2</span><br></pre></td></tr></table></figure><p>太棒了，看起来我们的模型输出的正是我们期望它输出的内容。<br>可以运行上面的单元格几次，每次预测不同的图像。<br>会注意到预测经常是错误的。<br>这是可以预料到的，因为模型尚未经过训练，它本质上是使用随机权重进行猜测。</p><h2 id="7-4-Use-torchinfo-to-get-an-idea-of-the-shapes-going-through-our-model-使用-torchinfo-了解模型中的形状"><a href="#7-4-Use-torchinfo-to-get-an-idea-of-the-shapes-going-through-our-model-使用-torchinfo-了解模型中的形状" class="headerlink" title="7.4 Use torchinfo to get an idea of the shapes going through our model 使用 torchinfo 了解模型中的形状"></a>7.4 Use torchinfo to get an idea of the shapes going through our model 使用 torchinfo 了解模型中的形状</h2><p>使用 <code>print(model)</code> 打印出我们的模型可以让我们了解模型的运行情况。</p><p>我们可以在整个 <code>forward()</code> 方法中打印出数据的形状。</p><p>但是，从模型中获取信息的一个有用方法是使用  <a href="https://github.com/TylerYep/torchinfo"><code>torchinfo</code></a>。</p><p><code>torchinfo</code> 附带一个 <code>summary()</code> 方法，该方法采用 PyTorch 模型以及 <code>input_shape</code> 并返回张量在模型中移动时发生的情况。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Install torchinfo if it&#x27;s not available, import it if it is</span></span><br><span class="line"><span class="keyword">try</span>: </span><br><span class="line">    <span class="keyword">import</span> torchinfo</span><br><span class="line"><span class="keyword">except</span>:</span><br><span class="line">    !pip install torchinfo</span><br><span class="line">    <span class="keyword">import</span> torchinfo</span><br><span class="line"></span><br><span class="line"><span class="comment"># pip install torchinfo    </span></span><br><span class="line"><span class="keyword">from</span> torchinfo <span class="keyword">import</span> summary</span><br><span class="line">summary(model_0, input_size=[<span class="number">1</span>, <span class="number">3</span>, <span class="number">64</span>, <span class="number">64</span>]) <span class="comment"># do a test pass through of an example input size </span></span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">==========================================================================================</span><br><span class="line">Layer (type:depth-idx)                   Output Shape              Param #</span><br><span class="line">==========================================================================================</span><br><span class="line">TinyVGG                                  [1, 3]                    --</span><br><span class="line">├─Sequential: 1-1                        [1, 10, 32, 32]           --</span><br><span class="line">│    └─Conv2d: 2-1                       [1, 10, 64, 64]           280</span><br><span class="line">│    └─ReLU: 2-2                         [1, 10, 64, 64]           --</span><br><span class="line">│    └─Conv2d: 2-3                       [1, 10, 64, 64]           910</span><br><span class="line">│    └─ReLU: 2-4                         [1, 10, 64, 64]           --</span><br><span class="line">│    └─MaxPool2d: 2-5                    [1, 10, 32, 32]           --</span><br><span class="line">├─Sequential: 1-2                        [1, 10, 16, 16]           --</span><br><span class="line">│    └─Conv2d: 2-6                       [1, 10, 32, 32]           910</span><br><span class="line">│    └─ReLU: 2-7                         [1, 10, 32, 32]           --</span><br><span class="line">│    └─Conv2d: 2-8                       [1, 10, 32, 32]           910</span><br><span class="line">│    └─ReLU: 2-9                         [1, 10, 32, 32]           --</span><br><span class="line">│    └─MaxPool2d: 2-10                   [1, 10, 16, 16]           --</span><br><span class="line">├─Sequential: 1-3                        [1, 3]                    --</span><br><span class="line">│    └─Flatten: 2-11                     [1, 2560]                 --</span><br><span class="line">│    └─Linear: 2-12                      [1, 3]                    7,683</span><br><span class="line">==========================================================================================</span><br><span class="line">Total params: 10,693</span><br><span class="line">Trainable params: 10,693</span><br><span class="line">Non-trainable params: 0</span><br><span class="line">Total mult-adds (M): 6.75</span><br><span class="line">==========================================================================================</span><br><span class="line">Input size (MB): 0.05</span><br><span class="line">Forward/backward pass size (MB): 0.82</span><br><span class="line">Params size (MB): 0.04</span><br><span class="line">Estimated Total Size (MB): 0.91</span><br><span class="line">==========================================================================================</span><br></pre></td></tr></table></figure><p><code>torchinfo.summary()</code> 的输出为我们提供了有关模型的大量信息。<br>例如<code>Total params</code>、模型中的参数总数、<code>Estimated Total Size (MB)</code>，即模型的大小。<br>当特定 <code>input_size</code> 的数据在我们的模型中移动时，您还可以看到输入和输出形状的变化。<br>目前，我们的参数数量和模型总大小很低。<br>这是因为我们从一个小模型开始。</p><h2 id="7-5-Create-train-amp-test-loop-functions-创建训练和测试循环函数"><a href="#7-5-Create-train-amp-test-loop-functions-创建训练和测试循环函数" class="headerlink" title="7.5 Create train &amp; test loop functions 创建训练和测试循环函数"></a>7.5 Create train &amp; test loop functions 创建训练和测试循环函数</h2><p>我们有数据，也有模型。</p><p>现在让我们制作一些训练和测试循环函数，以便在训练数据上训练我们的模型，并在测试数据上评估我们的模型。</p><p>为了确保我们可以再次使用这些训练和测试循环，我们将对它们进行函数化。</p><p>具体来说，我们将制作三个函数：</p><ul><li><code>train_step()</code> - 接受一个模型、一个 <code>DataLoader</code>、一个损失函数和一个优化器，并在 <code>DataLoader</code> 上训练模型。</li><li><code>test_step()</code> - 接受一个模型、一个 <code>DataLoader</code> 和一个损失函数，并在 <code>DataLoader</code> 上评估模型。</li><li><code>train()</code> - 在给定的周期数内同时执行 1. 和 2.，并返回结果字典。</li></ul><blockquote><p>注意：我们在笔记本 01 中介绍了 PyTorch 优化循环中的步骤，以及非官方 PyTorch 优化循环歌曲，并且我们在笔记本 03 中构建了类似的功能。</p></blockquote><h3 id="train-step"><a href="#train-step" class="headerlink" title="train_step()"></a>train_step()</h3><p>因为在 <code>DataLoader</code> 中处理批次，所以会在训练期间累积模型损失和准确度值（通过为每个批次将它们相加），然后在最后调整它们，然后再返回它们。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">train_step</span>(<span class="params">model: torch.nn.Module, </span></span><br><span class="line"><span class="params">               dataloader: torch.utils.data.DataLoader, </span></span><br><span class="line"><span class="params">               loss_fn: torch.nn.Module, </span></span><br><span class="line"><span class="params">               optimizer: torch.optim.Optimizer</span>):</span><br><span class="line">    <span class="comment"># Put model in train mode</span></span><br><span class="line">    <span class="comment"># 将模型置于训练模式</span></span><br><span class="line">    model.train()</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Setup train loss and train accuracy values</span></span><br><span class="line">    <span class="comment"># 设置训练损失和训练准确度值</span></span><br><span class="line">    train_loss, train_acc = <span class="number">0</span>, <span class="number">0</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Loop through data loader data batches</span></span><br><span class="line">    <span class="comment"># 循环遍历数据加载器数据批次</span></span><br><span class="line">    <span class="keyword">for</span> batch, (X, y) <span class="keyword">in</span> <span class="built_in">enumerate</span>(dataloader):</span><br><span class="line">        <span class="comment"># Send data to target device</span></span><br><span class="line">        <span class="comment"># 发送数据到目标设备</span></span><br><span class="line">        X, y = X.to(device), y.to(device)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 1. Forward pass</span></span><br><span class="line">        <span class="comment"># 1. 前向传递</span></span><br><span class="line">        y_pred = model(X)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 2. Calculate and accumulate loss</span></span><br><span class="line">        <span class="comment"># 2. 计算并累计损失</span></span><br><span class="line">        loss = loss_fn(y_pred, y)</span><br><span class="line">        train_loss += loss.item() </span><br><span class="line"></span><br><span class="line">        <span class="comment"># 3. Optimizer zero grad</span></span><br><span class="line">        <span class="comment"># 3. 优化器零梯度</span></span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 4. Loss backward</span></span><br><span class="line">        <span class="comment"># 4. 损失反向</span></span><br><span class="line">        loss.backward()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 5. Optimizer step</span></span><br><span class="line">        <span class="comment"># 5. 优化器步骤</span></span><br><span class="line">        optimizer.step()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Calculate and accumulate accuracy metrics across all batches</span></span><br><span class="line">        <span class="comment"># 计算并累积所有批次的准确度指标</span></span><br><span class="line">        y_pred_class = torch.argmax(torch.softmax(y_pred, dim=<span class="number">1</span>), dim=<span class="number">1</span>)</span><br><span class="line">        train_acc += (y_pred_class == y).<span class="built_in">sum</span>().item()/<span class="built_in">len</span>(y_pred)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Adjust metrics to get average loss and accuracy per batch</span></span><br><span class="line">    <span class="comment"># 调整指标以获得每批的平均损失和准确率</span></span><br><span class="line">    train_loss = train_loss / <span class="built_in">len</span>(dataloader)</span><br><span class="line">    train_acc = train_acc / <span class="built_in">len</span>(dataloader)</span><br><span class="line">    <span class="keyword">return</span> train_loss, train_acc</span><br></pre></td></tr></table></figure><h3 id="test-step"><a href="#test-step" class="headerlink" title="test_step()"></a>test_step()</h3><p>这里的主要区别在于 <code>test_step()</code> 不会采用优化器，因此不会执行梯度下降。<br>但由于我们要进行推理，因此我们将确保打开 <code>torch.inference_mode()</code> 上下文管理器来进行预测。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">test_step</span>(<span class="params">model: torch.nn.Module, </span></span><br><span class="line"><span class="params">              dataloader: torch.utils.data.DataLoader, </span></span><br><span class="line"><span class="params">              loss_fn: torch.nn.Module</span>):</span><br><span class="line">    <span class="comment"># Put model in eval mode</span></span><br><span class="line">    <span class="comment"># 将模型置于评估模式</span></span><br><span class="line">    model.<span class="built_in">eval</span>() </span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Setup test loss and test accuracy values</span></span><br><span class="line">    <span class="comment"># 设置测试损失和测试准确度值</span></span><br><span class="line">    test_loss, test_acc = <span class="number">0</span>, <span class="number">0</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Turn on inference context manager</span></span><br><span class="line">    <span class="comment"># 开启推理上下文管理器</span></span><br><span class="line">    <span class="keyword">with</span> torch.inference_mode():</span><br><span class="line">        <span class="comment"># Loop through DataLoader batches</span></span><br><span class="line">        <span class="comment"># 循环遍历 DataLoader 批次</span></span><br><span class="line">        <span class="keyword">for</span> batch, (X, y) <span class="keyword">in</span> <span class="built_in">enumerate</span>(dataloader):</span><br><span class="line">            <span class="comment"># Send data to target device</span></span><br><span class="line">            <span class="comment"># 发送数据到目标设备</span></span><br><span class="line">            X, y = X.to(device), y.to(device)</span><br><span class="line">    </span><br><span class="line">            <span class="comment"># 1. Forward pass</span></span><br><span class="line">            <span class="comment"># 1. 前向传递</span></span><br><span class="line">            test_pred_logits = model(X)</span><br><span class="line"></span><br><span class="line">            <span class="comment"># 2. Calculate and accumulate loss</span></span><br><span class="line">            <span class="comment"># 2. 计算并累计损失</span></span><br><span class="line">            loss = loss_fn(test_pred_logits, y)</span><br><span class="line">            test_loss += loss.item()</span><br><span class="line">            </span><br><span class="line">            <span class="comment"># Calculate and accumulate accuracy</span></span><br><span class="line">            <span class="comment"># 计算并累计准确率</span></span><br><span class="line">            test_pred_labels = test_pred_logits.argmax(dim=<span class="number">1</span>)</span><br><span class="line">            test_acc += ((test_pred_labels == y).<span class="built_in">sum</span>().item()/<span class="built_in">len</span>(test_pred_labels))</span><br><span class="line">            </span><br><span class="line">    <span class="comment"># Adjust metrics to get average loss and accuracy per batch </span></span><br><span class="line">    <span class="comment"># 调整指标以获得每批的平均损失和准确率</span></span><br><span class="line">    test_loss = test_loss / <span class="built_in">len</span>(dataloader)</span><br><span class="line">    test_acc = test_acc / <span class="built_in">len</span>(dataloader)</span><br><span class="line">    <span class="keyword">return</span> test_loss, test_acc</span><br></pre></td></tr></table></figure><h3 id="train-Creating-a-train-function-to-combine-train-step-and-test-step-训练-创建一个-train-函数来结合-train-step-和-test-step"><a href="#train-Creating-a-train-function-to-combine-train-step-and-test-step-训练-创建一个-train-函数来结合-train-step-和-test-step" class="headerlink" title="train | Creating a train() function to combine train_step() and test_step() 训练 | 创建一个 train() 函数来结合 train_step() 和 test_step()"></a>train | Creating a train() function to combine train_step() and test_step() 训练 | 创建一个 train() 函数来结合 train_step() 和 test_step()</h3><p>现在我们需要一种方法来将 train_step() 和 test_step() 函数放在一起。<br>为此，我们将它们打包在 train() 函数中。<br>此函数将训练模型并对其进行评估。</p><p>具体来说：</p><ul><li>接收一个模型、一个用于训练和测试集的 <code>DataLoader</code>、一个优化器、一个损失函数以及每个训练和测试步骤要执行多少个 epoch。</li><li>为 <code>train_loss</code>、<code>train_acc</code>、<code>test_loss</code> 和 <code>test_acc</code> 值创建一个空的结果字典（我们可以在训练过程中填充它）。</li><li>循环执行多个 epoch 的训练和测试步骤函数。</li><li>打印出每个 epoch 结束时发生的情况。</li><li>使用每个 epoch 更新后的指标更新空的结果字典。</li><li>返回已填充的。</li></ul><p>为了跟踪我们经历过的 <code>epochs</code> 数，让我们从 <code>tqdm.auto</code> 导入 <code>tqdm</code>（<code>tqdm</code> 是 Python 最流行的进度条库之一，<code>tqdm.auto</code> 会自动决定哪种进度条最适合的计算环境，例如 <code>Jupyter Notebook</code> 与 <code>Python</code> 脚本）。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># conda install tqdm</span></span><br><span class="line"><span class="keyword">from</span> tqdm.auto <span class="keyword">import</span> tqdm</span><br><span class="line"></span><br><span class="line"><span class="comment"># 1. Take in various parameters required for training and test steps</span></span><br><span class="line"><span class="comment"># 1. 接受训练和测试步骤所需的各种参数</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">train</span>(<span class="params">model: torch.nn.Module, </span></span><br><span class="line"><span class="params">          train_dataloader: torch.utils.data.DataLoader, </span></span><br><span class="line"><span class="params">          test_dataloader: torch.utils.data.DataLoader, </span></span><br><span class="line"><span class="params">          optimizer: torch.optim.Optimizer,</span></span><br><span class="line"><span class="params">          loss_fn: torch.nn.Module = nn.CrossEntropyLoss(<span class="params"></span>),</span></span><br><span class="line"><span class="params">          epochs: <span class="built_in">int</span> = <span class="number">5</span></span>):</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 2. Create empty results dictionary</span></span><br><span class="line">    <span class="comment"># 2. 创建空的结果字典</span></span><br><span class="line">    results = &#123;<span class="string">&quot;train_loss&quot;</span>: [],</span><br><span class="line">        <span class="string">&quot;train_acc&quot;</span>: [],</span><br><span class="line">        <span class="string">&quot;test_loss&quot;</span>: [],</span><br><span class="line">        <span class="string">&quot;test_acc&quot;</span>: []</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 3. Loop through training and testing steps for a number of epochs</span></span><br><span class="line">    <span class="comment"># 3. 循环进行多个 epoch 的训练和测试步骤</span></span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> tqdm(<span class="built_in">range</span>(epochs)):</span><br><span class="line">        train_loss, train_acc = train_step(model=model,</span><br><span class="line">                                           dataloader=train_dataloader,</span><br><span class="line">                                           loss_fn=loss_fn,</span><br><span class="line">                                           optimizer=optimizer)</span><br><span class="line">        test_loss, test_acc = test_step(model=model,</span><br><span class="line">            dataloader=test_dataloader,</span><br><span class="line">            loss_fn=loss_fn)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 4. Print out what&#x27;s happening</span></span><br><span class="line">        <span class="comment"># 4. 打印出正在发生的事情</span></span><br><span class="line">        <span class="built_in">print</span>(</span><br><span class="line">            <span class="string">f&quot;Epoch: <span class="subst">&#123;epoch+<span class="number">1</span>&#125;</span> | &quot;</span></span><br><span class="line">            <span class="string">f&quot;train_loss: <span class="subst">&#123;train_loss:<span class="number">.4</span>f&#125;</span> | &quot;</span></span><br><span class="line">            <span class="string">f&quot;train_acc: <span class="subst">&#123;train_acc:<span class="number">.4</span>f&#125;</span> | &quot;</span></span><br><span class="line">            <span class="string">f&quot;test_loss: <span class="subst">&#123;test_loss:<span class="number">.4</span>f&#125;</span> | &quot;</span></span><br><span class="line">            <span class="string">f&quot;test_acc: <span class="subst">&#123;test_acc:<span class="number">.4</span>f&#125;</span>&quot;</span></span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 5. Update results dictionary</span></span><br><span class="line">        <span class="comment"># 5. 更新结果字典</span></span><br><span class="line">        <span class="comment"># Ensure all data is moved to CPU and converted to float for storage</span></span><br><span class="line">        <span class="comment"># 确保所有数据都移至 CPU 并转换为浮点数进行存储</span></span><br><span class="line">        results[<span class="string">&quot;train_loss&quot;</span>].append(train_loss.item() <span class="keyword">if</span> <span class="built_in">isinstance</span>(train_loss, torch.Tensor) <span class="keyword">else</span> train_loss)</span><br><span class="line">        results[<span class="string">&quot;train_acc&quot;</span>].append(train_acc.item() <span class="keyword">if</span> <span class="built_in">isinstance</span>(train_acc, torch.Tensor) <span class="keyword">else</span> train_acc)</span><br><span class="line">        results[<span class="string">&quot;test_loss&quot;</span>].append(test_loss.item() <span class="keyword">if</span> <span class="built_in">isinstance</span>(test_loss, torch.Tensor) <span class="keyword">else</span> test_loss)</span><br><span class="line">        results[<span class="string">&quot;test_acc&quot;</span>].append(test_acc.item() <span class="keyword">if</span> <span class="built_in">isinstance</span>(test_acc, torch.Tensor) <span class="keyword">else</span> test_acc)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 6. Return the filled results at the end of the epochs</span></span><br><span class="line">    <span class="comment"># 6. 返回 epoch 结束时的填充结果</span></span><br><span class="line">    <span class="keyword">return</span> results</span><br></pre></td></tr></table></figure><h2 id="7-6-Train-and-Evaluate-Model-0-训练和评估模型-0"><a href="#7-6-Train-and-Evaluate-Model-0-训练和评估模型-0" class="headerlink" title="7.6 Train and Evaluate Model 0 训练和评估模型 0"></a>7.6 Train and Evaluate Model 0 训练和评估模型 0</h2><p>目前已经拥有了训练和评估模型所需的所有要素。<br>将 <code>TinyVGG</code> 模型、<code>DataLoader</code> 和 <code>train()</code> 函数放在一起，看看我们是否可以构建一个能够区分披萨、牛排和寿司的模型！<br>让我们重新创建 <code>model_0</code>（不需要，但为了完整起见我们会这样做），然后调用 <code>train()</code> 函数并传入必要的参数。<br>为了让我们的实验快速进行，我们将训练我们的模型 5 epochs（可以根据需要增加这个时期）。<br>至于 <code>optimizer</code> 优化器和 <code>loss function</code> 损失函数，我们将分别使用 <code>torch.nn.CrossEntropyLoss()</code>（因为我们正在处理多类分类数据）和 <code>torch.optim.Adam()</code>，学习率为 <code>1e-3</code>。<br>为了了解需要多长时间，我们将导入 Python 的 <a href="https://docs.python.org/3/library/timeit.html#timeit.default_timer"><code>timeit.default_timer()</code></a> 方法来计算训练时间。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Set random seeds</span></span><br><span class="line">torch.manual_seed(<span class="number">42</span>) </span><br><span class="line">torch.cuda.manual_seed(<span class="number">42</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Set number of epochs</span></span><br><span class="line">NUM_EPOCHS = <span class="number">5</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Recreate an instance of TinyVGG</span></span><br><span class="line">model_0 = TinyVGG(input_shape=<span class="number">3</span>, <span class="comment"># number of color channels (3 for RGB) </span></span><br><span class="line">                  hidden_units=<span class="number">10</span>, </span><br><span class="line">                  output_shape=<span class="built_in">len</span>(train_data.classes)).to(device)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Setup loss function and optimizer</span></span><br><span class="line">loss_fn = nn.CrossEntropyLoss()</span><br><span class="line">optimizer = torch.optim.Adam(params=model_0.parameters(), lr=<span class="number">0.001</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Start the timer</span></span><br><span class="line"><span class="keyword">from</span> timeit <span class="keyword">import</span> default_timer <span class="keyword">as</span> timer </span><br><span class="line">start_time = timer()</span><br><span class="line"></span><br><span class="line"><span class="comment"># Train model_0 </span></span><br><span class="line">model_0_results = train(model=model_0, </span><br><span class="line">                        train_dataloader=train_dataloader_simple,</span><br><span class="line">                        test_dataloader=test_dataloader_simple,</span><br><span class="line">                        optimizer=optimizer,</span><br><span class="line">                        loss_fn=loss_fn, </span><br><span class="line">                        epochs=NUM_EPOCHS)</span><br><span class="line"></span><br><span class="line"><span class="comment"># End the timer and print out how long it took</span></span><br><span class="line">end_time = timer()</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Total training time: <span class="subst">&#123;end_time-start_time:<span class="number">.3</span>f&#125;</span> seconds&quot;</span>)</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"></span><br></pre></td></tr></table></figure><p>模型表现相当糟糕。有哪些方法可以改进它？</p><blockquote><p>注意：查看 <a href="https://www.learnpytorch.io/02_pytorch_classification/#5-improving-a-model-from-a-model-perspective"><em>Improving a model (from a model perspective)</em> section in notebook 02</a>笔记本 02 中的改进模型（从模型角度）部分，了解有关改进我们的 TinyVGG 模型的想法。</p></blockquote><h2 id="7-7-Plot-the-loss-curves-of-Model-0-绘制模型-0-的损失曲线"><a href="#7-7-Plot-the-loss-curves-of-Model-0-绘制模型-0-的损失曲线" class="headerlink" title="7.7 Plot the loss curves of Model 0 绘制模型 0 的损失曲线"></a>7.7 Plot the loss curves of Model 0 绘制模型 0 的损失曲线</h2><p>从我们 <code>model_0</code> 训练的打印输出来看，它似乎表现不太好。</p><p>但我们可以通过绘制模型的 <code>loss curves</code> 损失曲线来进一步评估它。</p><p><code>Loss curves</code> 损失曲线显示了模型随时间的变化结果。</p><p>它们是查看模型在不同数据集（例如训练和测试）上的表现的好方法。</p><p>让我们创建一个函数来绘制 <code>model_0_results</code> 字典中的值。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Check the model_0_results keys</span></span><br><span class="line">model_0_results.keys()</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">Epoch: 1 | train_loss: 1.1078 | train_acc: 0.2578 | test_loss: 1.1360 | test_acc: 0.2604</span><br><span class="line">Epoch: 2 | train_loss: 1.0847 | train_acc: 0.4258 | test_loss: 1.1620 | test_acc: 0.1979</span><br><span class="line">Epoch: 3 | train_loss: 1.1157 | train_acc: 0.2930 | test_loss: 1.1697 | test_acc: 0.1979</span><br><span class="line">Epoch: 4 | train_loss: 1.0955 | train_acc: 0.4141 | test_loss: 1.1385 | test_acc: 0.1979</span><br><span class="line">Epoch: 5 | train_loss: 1.0985 | train_acc: 0.2930 | test_loss: 1.1430 | test_acc: 0.1979</span><br><span class="line">Total training time: 199.209 seconds</span><br></pre></td></tr></table></figure><p>我们需要提取每个key并将它们转换成一个图。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Check the model_0_results keys</span></span><br><span class="line">model_0_results.keys()</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">dict_keys([&#x27;train_loss&#x27;, &#x27;train_acc&#x27;, &#x27;test_loss&#x27;, &#x27;test_acc&#x27;])</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">plot_loss_curves</span>(<span class="params">results: <span class="type">Dict</span>[<span class="built_in">str</span>, <span class="type">List</span>[<span class="built_in">float</span>]]</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Plots training curves of a results dictionary.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        results (dict): dictionary containing list of values, e.g.</span></span><br><span class="line"><span class="string">            &#123;&quot;train_loss&quot;: [...],</span></span><br><span class="line"><span class="string">             &quot;train_acc&quot;: [...],</span></span><br><span class="line"><span class="string">             &quot;test_loss&quot;: [...],</span></span><br><span class="line"><span class="string">             &quot;test_acc&quot;: [...]&#125;</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Get the loss values of the results dictionary (training and test)</span></span><br><span class="line">    <span class="comment"># 获取结果字典（训练和测试）的损失值</span></span><br><span class="line">    loss = results[<span class="string">&#x27;train_loss&#x27;</span>]</span><br><span class="line">    test_loss = results[<span class="string">&#x27;test_loss&#x27;</span>]</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Get the accuracy values of the results dictionary (training and test)</span></span><br><span class="line">    <span class="comment"># 获取结果字典（训练和测试）的准确度值</span></span><br><span class="line">    accuracy = results[<span class="string">&#x27;train_acc&#x27;</span>]</span><br><span class="line">    test_accuracy = results[<span class="string">&#x27;test_acc&#x27;</span>]</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Figure out how many epochs there were</span></span><br><span class="line">    <span class="comment"># 计算出有多少个 epoch</span></span><br><span class="line">    epochs = <span class="built_in">range</span>(<span class="built_in">len</span>(results[<span class="string">&#x27;train_loss&#x27;</span>]))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Setup a plot </span></span><br><span class="line">    <span class="comment"># 设置情节</span></span><br><span class="line">    plt.figure(figsize=(<span class="number">15</span>, <span class="number">7</span>))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Plot loss</span></span><br><span class="line">    <span class="comment"># 绘制损失</span></span><br><span class="line">    plt.subplot(<span class="number">1</span>, <span class="number">2</span>, <span class="number">1</span>)</span><br><span class="line">    plt.plot(epochs, loss, label=<span class="string">&#x27;train_loss&#x27;</span>)</span><br><span class="line">    plt.plot(epochs, test_loss, label=<span class="string">&#x27;test_loss&#x27;</span>)</span><br><span class="line">    plt.title(<span class="string">&#x27;Loss&#x27;</span>)</span><br><span class="line">    plt.xlabel(<span class="string">&#x27;Epochs&#x27;</span>)</span><br><span class="line">    plt.legend()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Plot accuracy</span></span><br><span class="line">    <span class="comment"># 绘制准确度</span></span><br><span class="line">    plt.subplot(<span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>)</span><br><span class="line">    plt.plot(epochs, accuracy, label=<span class="string">&#x27;train_accuracy&#x27;</span>)</span><br><span class="line">    plt.plot(epochs, test_accuracy, label=<span class="string">&#x27;test_accuracy&#x27;</span>)</span><br><span class="line">    plt.title(<span class="string">&#x27;Accuracy&#x27;</span>)</span><br><span class="line">    plt.xlabel(<span class="string">&#x27;Epochs&#x27;</span>)</span><br><span class="line">    plt.legend();</span><br></pre></td></tr></table></figure><p>测试一下<code>plot_loss_curves()</code> 函数。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">plot_loss_curves(model_0_results)</span><br></pre></td></tr></table></figure><img src="/2024/08/18/PyTorch-26H-5/PyTorch-26H-5-10.png" class="" title="PyTorch-26H-5-10"><p>看起来一切都乱七八糟……<br>但我们大概知道这一点，因为我们的模型在训练期间打印出来的结果并没有显示出太大的希望。<br>您可以尝试更长时间地训练模型，看看在更长的时间范围内绘制损失曲线时会发生什么。</p><h1 id="8-What-should-an-ideal-loss-curve-look-like-理想的损失曲线应该是什么样的？"><a href="#8-What-should-an-ideal-loss-curve-look-like-理想的损失曲线应该是什么样的？" class="headerlink" title="8. What should an ideal loss curve look like?理想的损失曲线应该是什么样的？"></a>8. What should an ideal loss curve look like?理想的损失曲线应该是什么样的？</h1><p>查看训练和测试损失曲线是查看模型是否 <code>overfitting</code> 过度拟合的好方法。<br>过度拟合模型是指在训练集上的表现优于（通常相差很大）验证/测试集的模型。<br>如果您的训练损失远低于测试损失，则您的模型 <code>overfitting</code> 过度拟合。<br>也就是说，它在训练中学习模式太好，而这些模式并没有推广到测试数据。<br>另一方面，当您的训练和测试损失没有您想要的那么低时，这被认为是 <code>underfitting</code> 欠拟合。<br>训练和测试损失曲线的理想位置是它们彼此紧密对齐。</p><img src="/2024/08/18/PyTorch-26H-5/PyTorch-26H-5-11.png" class="" title="PyTorch-26H-5-11"><p>左图：如果您的训练和测试损失曲线没有您想要的那么低，则被视为欠拟合。<br>中图：当您的测试/验证损失高于训练损失时，这被视为过度拟合。<br>右图：理想的情况是您的训练和测试损失曲线随时间排列整齐。这意味着您的模型具有良好的泛化能力。<br>损失曲线可以有更多组合和不同功能，有关更多信息，请参阅 Google 的<a href="https://developers.google.com/machine-learning/testing-debugging/metrics/interpretic">Interpreting Loss Curves guide</a>。</p><h2 id="8-1-How-to-deal-with-overfitting-如何处理过度拟合"><a href="#8-1-How-to-deal-with-overfitting-如何处理过度拟合" class="headerlink" title="8.1 How to deal with overfitting 如何处理过度拟合"></a>8.1 How to deal with overfitting 如何处理过度拟合</h2><p>由于过度拟合的主要问题在于您的模型与训练数据的拟合<em>度过高</em>，因此您需要使用技术来“控制它”。</p><p>防止过度拟合的一种常见技术称为<a href="https://ml-cheatsheet.readthedocs.io/en/latest/regularization.html"><strong>正则化</strong></a>。</p><p>我喜欢将其视为“使我们的模型更加规则”，即能够适应<em>更多</em>种类的数据。</p><p>几种防止过度拟合的方法：</p><div class="table-container"><table><thead><tr><th style="text-align:center">防止过拟合的方法</th><th style="text-align:center">是什么？</th></tr></thead><tbody><tr><td style="text-align:center">获取更多数据</td><td style="text-align:center">拥有更多数据可以为模型提供更多机会来学习模式，这些模式可能更适用于新的例子。</td></tr><tr><td style="text-align:center">简化模型</td><td style="text-align:center">如果当前模型已经过度拟合训练数据，则可能是模型过于复杂。这意味着它对数据模式的学习太好，无法很好地推广到未见过的数据。简化模型的一种方法是减少其使用的层数或减少每层中的隐藏单元数量。</td></tr><tr><td style="text-align:center">使用数据增强</td><td style="text-align:center"><a href="https://developers.google.com/machine-learning/glossary#data-augmentation"><strong>数据增强</strong></a>会以某种方式操纵训练数据，使模型更难学习，因为它会人为地增加数据的多样性。如果模型能够学习增强数据中的模式，那么该模型可能能够更好地推广到未见过的数据。</td></tr><tr><td style="text-align:center">使用迁移学习</td><td style="text-align:center"><a href="https://developers.google.com/machine-learning/glossary#transfer-learning"><strong>迁移学习</strong></a>涉及利用模型已学会的模式（也称为预训练权重）作为您自己的任务的基础。在我们的案例中，我们可以使用一个在大量图像上预训练的计算机视觉模型，然后对其进行稍微调整，使其更专门用于食物图像。</td></tr><tr><td style="text-align:center">使用 dropout 层</td><td style="text-align:center">Dropout 层会随机移除神经网络中隐藏层之间的连接，从而有效简化模型，同时改善剩余连接。<a href="https://pytorch.org/docs/stable/generated/torch.nn.Dropout.html"><code>torch.nn.Dropout()</code></a>更多信息请参见。</td></tr><tr><td style="text-align:center">使用学习率衰减</td><td style="text-align:center">这里的想法是随着模型的训练慢慢降低学习率。这类似于伸手去拿沙发后面的硬币。你越接近，你的步子就越小。学习率也是一样，你越接近收敛，你就越希望你的体重更新越小。</td></tr><tr><td style="text-align:center">使用早期停止</td><td style="text-align:center"><a href="https://developers.google.com/machine-learning/glossary#early_stopping"><strong>提前停止</strong></a>会在模型开始过度拟合之前停止训练。例如，假设模型的损失在过去 10 个时期（这个数字是任意的）已经停止下降，您可能希望在这里停止模型训练，并使用损失最低的模型权重（10 个时期之前）。</td></tr></tbody></table></div><p>还有更多处理过度拟合的方法，但这些是一些主要方法。<br>当你开始构建越来越多的深度模型时，你会发现，由于深度学习非常擅长学习数据中的模式，处理过度拟合是深度学习的主要问题之一。</p><h2 id="8-2-How-to-deal-with-underfitting-如何处理欠拟合"><a href="#8-2-How-to-deal-with-underfitting-如何处理欠拟合" class="headerlink" title="8.2 How to deal with underfitting 如何处理欠拟合"></a>8.2 How to deal with underfitting 如何处理欠拟合</h2><p>当模型<a href="https://developers.google.com/machine-learning/glossary#underfitting"><strong>拟合不足</strong></a>时，它被认为对训练和测试集的预测能力较差。</p><p>本质上，欠拟合模型将无法将损失值降低到所需的水平。</p><p>现在，查看我们当前的损失曲线，我认为我们的<code>TinyVGG</code>模型<code>model_0</code>对数据拟合不足。</p><p>处理欠拟合背后的主要思想是 提高 模型的预测能力。</p><p>有几种方法可以做到这一点：</p><div class="table-container"><table><thead><tr><th style="text-align:center">防止欠拟合的方法</th><th style="text-align:center">它是什么？</th></tr></thead><tbody><tr><td style="text-align:center">向模型添加更多层/单元</td><td style="text-align:center">如果模型拟合不足，则它可能没有足够的能力来学习所需的数据 模式/权重/表示 patterns/weights/representations 以实现预测。增加模型预测能力的一种方法是增加这些层中的隐藏层/单元的数量。</td></tr><tr><td style="text-align:center">调整学习率</td><td style="text-align:center">也许模型的学习率一开始就太高了。它试图在每个时期更新太多权重，结果什么都没学到。在这种情况下，你可以降低学习率，看看会发生什么。</td></tr><tr><td style="text-align:center">使用迁移学习</td><td style="text-align:center">迁移学习能够防止过度拟合和欠拟合。它涉及使用以前工作模型中的模式并根据自己的问题进行调整。</td></tr><tr><td style="text-align:center">训练更长时间</td><td style="text-align:center">有时模型只是需要更多时间来学习数据表示。如果在较小的实验中，模型没有学到任何东西，那么让它训练更多的时期可能会带来更好的性能。</td></tr><tr><td style="text-align:center">减少正则化</td><td style="text-align:center">也许模型拟合不足，是因为人为试图防止过度拟合。抑制正则化技术可以帮助模型更好地拟合数据。</td></tr></tbody></table></div><h2 id="8-3-The-balance-between-overfitting-and-underfitting-过度拟合与欠拟合之间的平衡"><a href="#8-3-The-balance-between-overfitting-and-underfitting-过度拟合与欠拟合之间的平衡" class="headerlink" title="8.3 The balance between overfitting and underfitting 过度拟合与欠拟合之间的平衡"></a>8.3 The balance between overfitting and underfitting 过度拟合与欠拟合之间的平衡</h2><p>上面讨论的方法都不是灵丹妙药，也就是说，它们并不总是有效。</p><p>防止过度拟合和欠拟合可能是机器学习研究最活跃的领域。</p><p>由于每个人都希望他们的模型拟合得更好（更少的欠拟合），但又不是太好，所以它们不能很好地概括并在现实世界中表现不佳（更少的过度拟合）。</p><p>过度拟合与欠拟合之间存在着一线之隔。</p><p>因为任何一种因素过多都可能引发另一种因素。</p><p>当涉及到解决过度拟合和欠拟合的问题时，迁移学习可能是最强大的技术之一。</p><p>迁移学习不需要手工制作不同的过度拟合和欠拟合技术，而是可以让你采用与你的问题空间类似的问题空间中已经可以工作的模型（比如来自paperswithcode.com/sota或Hugging Face 模型的模型）并将其应用到你自己的数据集中。</p><p>我们将在后面的笔记本中看到迁移学习的威力。</p><h1 id="9-Model-1-TinyVGG-with-Data-Augmentation-模型1：具有数据增强的TinyVGG"><a href="#9-Model-1-TinyVGG-with-Data-Augmentation-模型1：具有数据增强的TinyVGG" class="headerlink" title="9. Model 1: TinyVGG with Data Augmentation 模型1：具有数据增强的TinyVGG"></a>9. Model 1: TinyVGG with Data Augmentation 模型1：具有数据增强的TinyVGG</h1><p>是时候尝试另一个模型了！</p><p>这次，让我们加载数据并使用<strong>数据增强</strong>来看看它是否可以改善我们的结果。</p><p>首先，我们将编写一个训练变换来包含<code>transforms.TrivialAugmentWide()</code>、调整图像大小并将其转换为张量。</p><p>我们将对测试转换执行相同的操作，只是没有数据增强。</p><h2 id="9-1-Create-transform-with-data-augmentation-使用数据增强创建变换"><a href="#9-1-Create-transform-with-data-augmentation-使用数据增强创建变换" class="headerlink" title="9.1 Create transform with data augmentation 使用数据增强创建变换"></a>9.1 Create transform with data augmentation 使用数据增强创建变换</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Create training transform with TrivialAugment</span></span><br><span class="line">train_transform_trivial_augment = transforms.Compose([</span><br><span class="line">    transforms.Resize((<span class="number">64</span>, <span class="number">64</span>)),</span><br><span class="line">    transforms.TrivialAugmentWide(num_magnitude_bins=<span class="number">31</span>),</span><br><span class="line">    transforms.ToTensor() </span><br><span class="line">])</span><br><span class="line"></span><br><span class="line"><span class="comment"># Create testing transform (no data augmentation)</span></span><br><span class="line">test_transform = transforms.Compose([</span><br><span class="line">    transforms.Resize((<span class="number">64</span>, <span class="number">64</span>)),</span><br><span class="line">    transforms.ToTensor()</span><br><span class="line">])</span><br></pre></td></tr></table></figure><p>使用 <code>torchvision.datasets.ImageFolder()</code> 将图像转换为 <code>Dataset</code>，然后使用 <code>torch.utils.data.DataLoader()</code> 将其转换为 <code>DataLoader</code>。</p><h2 id="9-2-Create-train-and-test-Dataset’s-and-DataLoader’s-创建训练和测试数据集和数据加载器"><a href="#9-2-Create-train-and-test-Dataset’s-and-DataLoader’s-创建训练和测试数据集和数据加载器" class="headerlink" title="9.2 Create train and test Dataset’s and DataLoader’s 创建训练和测试数据集和数据加载器"></a>9.2 Create train and test Dataset’s and DataLoader’s 创建训练和测试数据集和数据加载器</h2><p>我们将确保训练 <code>Dataset</code> 使用 <code>train_transform_trivial_augment</code>，而测试 <code>Dataset</code> 使用<code>test_transform</code>。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Turn image folders into Datasets</span></span><br><span class="line">train_data_augmented = datasets.ImageFolder(train_dir, transform=train_transform_trivial_augment)</span><br><span class="line">test_data_simple = datasets.ImageFolder(test_dir, transform=test_transform)</span><br><span class="line"></span><br><span class="line">train_data_augmented, test_data_simple</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">(Dataset ImageFolder</span><br><span class="line">     Number of datapoints: 225</span><br><span class="line">     Root location: data\pizza_steak_sushi\train</span><br><span class="line">     StandardTransform</span><br><span class="line"> Transform: Compose(</span><br><span class="line">                Resize(size=(64, 64), interpolation=bilinear, max_size=None, antialias=True)</span><br><span class="line">                TrivialAugmentWide(num_magnitude_bins=31, interpolation=InterpolationMode.NEAREST, fill=None)</span><br><span class="line">                ToTensor()</span><br><span class="line">            ),</span><br><span class="line"> Dataset ImageFolder</span><br><span class="line">     Number of datapoints: 75</span><br><span class="line">     Root location: data\pizza_steak_sushi\test</span><br><span class="line">     StandardTransform</span><br><span class="line"> Transform: Compose(</span><br><span class="line">                Resize(size=(64, 64), interpolation=bilinear, max_size=None, antialias=True)</span><br><span class="line">                ToTensor()</span><br><span class="line">            ))</span><br></pre></td></tr></table></figure><p>我们将 <code>DataLoader</code> 的 <code>batch_size</code> 设置为 32，并将 <code>num_workers</code> 设置为我们机器上可用的 CPU 数量（我们可以使用 Python 的 <code>os.cpu_count()</code> 获取该数量）。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Turn Datasets into DataLoader&#x27;s</span></span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line">BATCH_SIZE = <span class="number">32</span></span><br><span class="line">NUM_WORKERS = os.cpu_count()</span><br><span class="line"></span><br><span class="line">torch.manual_seed(<span class="number">42</span>)</span><br><span class="line">train_dataloader_augmented = DataLoader(train_data_augmented, </span><br><span class="line">                                        batch_size=BATCH_SIZE, </span><br><span class="line">                                        shuffle=<span class="literal">True</span>,</span><br><span class="line">                                        num_workers=NUM_WORKERS)</span><br><span class="line"></span><br><span class="line">test_dataloader_simple = DataLoader(test_data_simple, </span><br><span class="line">                                    batch_size=BATCH_SIZE, </span><br><span class="line">                                    shuffle=<span class="literal">False</span>, </span><br><span class="line">                                    num_workers=NUM_WORKERS)</span><br><span class="line"></span><br><span class="line">train_dataloader_augmented, test_dataloader</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">(&lt;torch.utils.data.dataloader.DataLoader at 0x277ca662370&gt;,</span><br><span class="line"> &lt;torch.utils.data.dataloader.DataLoader at 0x277ca8a83a0&gt;)</span><br></pre></td></tr></table></figure><h2 id="9-3-Construct-and-train-Model-1"><a href="#9-3-Construct-and-train-Model-1" class="headerlink" title="9.3 Construct and train Model 1"></a>9.3 Construct and train Model 1</h2><p>构建下一个模型 <code>model_1</code>，我们可以重用之前的 <code>TinyVGG</code> 类。<br>我们将确保将其发送到目标设备。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Create model_1 and send it to the target device</span></span><br><span class="line">torch.manual_seed(<span class="number">42</span>)</span><br><span class="line">model_1 = TinyVGG(</span><br><span class="line">    input_shape=<span class="number">3</span>,</span><br><span class="line">    hidden_units=<span class="number">10</span>,</span><br><span class="line">    output_shape=<span class="built_in">len</span>(train_data_augmented.classes)).to(device)</span><br><span class="line">model_1</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">TinyVGG(</span><br><span class="line">  (conv_block_1): Sequential(</span><br><span class="line">    (0): Conv2d(3, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))</span><br><span class="line">    (1): ReLU()</span><br><span class="line">    (2): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))</span><br><span class="line">    (3): ReLU()</span><br><span class="line">    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)</span><br><span class="line">  )</span><br><span class="line">  (conv_block_2): Sequential(</span><br><span class="line">    (0): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))</span><br><span class="line">    (1): ReLU()</span><br><span class="line">    (2): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))</span><br><span class="line">    (3): ReLU()</span><br><span class="line">    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)</span><br><span class="line">  )</span><br><span class="line">  (classifier): Sequential(</span><br><span class="line">    (0): Flatten(start_dim=1, end_dim=-1)</span><br><span class="line">    (1): Linear(in_features=2560, out_features=3, bias=True)</span><br><span class="line">  )</span><br><span class="line">)</span><br></pre></td></tr></table></figure><p>由于我们已经获得了训练循环 (<code>train_step()</code>) 和测试循环 (<code>test_step()</code>) 的函数以及将它们组合在 <code>train()</code> 中的函数，因此让我们重复使用它们。</p><p>我们将使用与 <code>model_0</code> 相同的设置，只有 <code>train_dataloader</code>参数有所不同：</p><ul><li>训练 5 个时期。</li><li>使用 <code>train_dataloader=train_dataloader_augmented</code> 作为 train() 中的训练数据。</li><li>使用 <code>torch.nn.CrossEntropyLoss()</code> 作为损失函数（因为我们处理的是多类分类）。</li><li>使用 <code>torch.optim.Adam()</code> 并以 <code>lr=0.001</code> 作为优化器的学习率。</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Set random seeds</span></span><br><span class="line">torch.manual_seed(<span class="number">42</span>) </span><br><span class="line">torch.cuda.manual_seed(<span class="number">42</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Set number of epochs</span></span><br><span class="line">NUM_EPOCHS = <span class="number">5</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Setup loss function and optimizer</span></span><br><span class="line">loss_fn = nn.CrossEntropyLoss()</span><br><span class="line">optimizer = torch.optim.Adam(params=model_1.parameters(), lr=<span class="number">0.001</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Start the timer</span></span><br><span class="line"><span class="keyword">from</span> timeit <span class="keyword">import</span> default_timer <span class="keyword">as</span> timer </span><br><span class="line">start_time = timer()</span><br><span class="line"></span><br><span class="line"><span class="comment"># Train model_1</span></span><br><span class="line">model_1_results = train(model=model_1, </span><br><span class="line">                        train_dataloader=train_dataloader_augmented,</span><br><span class="line">                        test_dataloader=test_dataloader_simple,</span><br><span class="line">                        optimizer=optimizer,</span><br><span class="line">                        loss_fn=loss_fn, </span><br><span class="line">                        epochs=NUM_EPOCHS)</span><br><span class="line"></span><br><span class="line"><span class="comment"># End the timer and print out how long it took</span></span><br><span class="line">end_time = timer()</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Total training time: <span class="subst">&#123;end_time-start_time:<span class="number">.3</span>f&#125;</span> seconds&quot;</span>)</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">Epoch: 1 | train_loss: 1.1074 | train_acc: 0.2500 | test_loss: 1.1058 | test_acc: 0.2604</span><br><span class="line">Epoch: 2 | train_loss: 1.0791 | train_acc: 0.4258 | test_loss: 1.1381 | test_acc: 0.2604</span><br><span class="line">Epoch: 3 | train_loss: 1.0800 | train_acc: 0.4258 | test_loss: 1.1693 | test_acc: 0.2604</span><br><span class="line">Epoch: 4 | train_loss: 1.1284 | train_acc: 0.3047 | test_loss: 1.1616 | test_acc: 0.2604</span><br><span class="line">Epoch: 5 | train_loss: 1.0882 | train_acc: 0.4258 | test_loss: 1.1471 | test_acc: 0.2604</span><br><span class="line">Total training time: 199.736 seconds</span><br></pre></td></tr></table></figure><p>效果依旧很差。</p><h2 id="9-4-Plot-the-loss-curves-of-Model-1"><a href="#9-4-Plot-the-loss-curves-of-Model-1" class="headerlink" title="9.4 Plot the loss curves of Model 1"></a>9.4 Plot the loss curves of Model 1</h2><p>由于已将 <code>model_1</code> 的结果保存在结果字典 <code>model_1_results</code> 中，因此可以使用 <code>plot_loss_curves()</code> 绘制。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">plot_loss_curves(model_1_results)</span><br></pre></td></tr></table></figure><img src="/2024/08/18/PyTorch-26H-5/PyTorch-26H-5-12.png" class="" title="PyTorch-26H-5-12"><p>模型是欠拟合还是过拟合？还是两者兼而有之？<br>理想情况下，希望它具有更高的准确度和更低的损失。</p><h1 id="10-Compare-model-results-比较模型结果"><a href="#10-Compare-model-results-比较模型结果" class="headerlink" title="10. Compare model results 比较模型结果"></a>10. Compare model results 比较模型结果</h1><p>尽管我们的模型表现很差，我们仍然可以编写代码来比较它们。</p><p>让我们首先将模型结果转换为 pandas DataFrames。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line">model_0_df = pd.DataFrame(model_0_results)</span><br><span class="line">model_1_df = pd.DataFrame(model_1_results)</span><br><span class="line">model_0_df</span><br></pre></td></tr></table></figure><div class="table-container"><table><thead><tr><th style="text-align:center"></th><th style="text-align:center">train_loss</th><th style="text-align:center">train_acc</th><th style="text-align:center">test_loss</th><th style="text-align:center">test_acc</th></tr></thead><tbody><tr><td style="text-align:center">0</td><td style="text-align:center">1.107833</td><td style="text-align:center">0.257812</td><td style="text-align:center">1.136041</td><td style="text-align:center">0.260417</td></tr><tr><td style="text-align:center">1</td><td style="text-align:center">1.084713</td><td style="text-align:center">0.425781</td><td style="text-align:center">1.162014</td><td style="text-align:center">0.197917</td></tr><tr><td style="text-align:center">2</td><td style="text-align:center">1.115697</td><td style="text-align:center">0.292969</td><td style="text-align:center">1.169704</td><td style="text-align:center">0.197917</td></tr><tr><td style="text-align:center">3</td><td style="text-align:center">1.095564</td><td style="text-align:center">0.414062</td><td style="text-align:center">1.138373</td><td style="text-align:center">0.197917</td></tr><tr><td style="text-align:center">4</td><td style="text-align:center">1.098520</td><td style="text-align:center">0.292969</td><td style="text-align:center">1.142631</td><td style="text-align:center">0.197917</td></tr></tbody></table></div><p>现在我们可以使用 <code>matplotlib</code> 编写一些绘图代码来一起可视化 <code>model_0</code> 和 <code>model_1</code> 的结果。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Setup a plot </span></span><br><span class="line">plt.figure(figsize=(<span class="number">15</span>, <span class="number">10</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># Get number of epochs</span></span><br><span class="line">epochs = <span class="built_in">range</span>(<span class="built_in">len</span>(model_0_df))</span><br><span class="line"></span><br><span class="line"><span class="comment"># Plot train loss</span></span><br><span class="line">plt.subplot(<span class="number">2</span>, <span class="number">2</span>, <span class="number">1</span>)</span><br><span class="line">plt.plot(epochs, model_0_df[<span class="string">&quot;train_loss&quot;</span>], label=<span class="string">&quot;Model 0&quot;</span>)</span><br><span class="line">plt.plot(epochs, model_1_df[<span class="string">&quot;train_loss&quot;</span>], label=<span class="string">&quot;Model 1&quot;</span>)</span><br><span class="line">plt.title(<span class="string">&quot;Train Loss&quot;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&quot;Epochs&quot;</span>)</span><br><span class="line">plt.legend()</span><br><span class="line"></span><br><span class="line"><span class="comment"># Plot test loss</span></span><br><span class="line">plt.subplot(<span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>)</span><br><span class="line">plt.plot(epochs, model_0_df[<span class="string">&quot;test_loss&quot;</span>], label=<span class="string">&quot;Model 0&quot;</span>)</span><br><span class="line">plt.plot(epochs, model_1_df[<span class="string">&quot;test_loss&quot;</span>], label=<span class="string">&quot;Model 1&quot;</span>)</span><br><span class="line">plt.title(<span class="string">&quot;Test Loss&quot;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&quot;Epochs&quot;</span>)</span><br><span class="line">plt.legend()</span><br><span class="line"></span><br><span class="line"><span class="comment"># Plot train accuracy</span></span><br><span class="line">plt.subplot(<span class="number">2</span>, <span class="number">2</span>, <span class="number">3</span>)</span><br><span class="line">plt.plot(epochs, model_0_df[<span class="string">&quot;train_acc&quot;</span>], label=<span class="string">&quot;Model 0&quot;</span>)</span><br><span class="line">plt.plot(epochs, model_1_df[<span class="string">&quot;train_acc&quot;</span>], label=<span class="string">&quot;Model 1&quot;</span>)</span><br><span class="line">plt.title(<span class="string">&quot;Train Accuracy&quot;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&quot;Epochs&quot;</span>)</span><br><span class="line">plt.legend()</span><br><span class="line"></span><br><span class="line"><span class="comment"># Plot test accuracy</span></span><br><span class="line">plt.subplot(<span class="number">2</span>, <span class="number">2</span>, <span class="number">4</span>)</span><br><span class="line">plt.plot(epochs, model_0_df[<span class="string">&quot;test_acc&quot;</span>], label=<span class="string">&quot;Model 0&quot;</span>)</span><br><span class="line">plt.plot(epochs, model_1_df[<span class="string">&quot;test_acc&quot;</span>], label=<span class="string">&quot;Model 1&quot;</span>)</span><br><span class="line">plt.title(<span class="string">&quot;Test Accuracy&quot;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&quot;Epochs&quot;</span>)</span><br><span class="line">plt.legend();</span><br></pre></td></tr></table></figure><img src="/2024/08/18/PyTorch-26H-5/PyTorch-26H-5-13.png" class="" title="PyTorch-26H-5-13"><p>看起来我们的模型表现同样糟糕，而且有点不稳定（指标急剧上升和下降）。</p><h1 id="11-Make-a-prediction-on-a-custom-image-对自定义图像进行预测"><a href="#11-Make-a-prediction-on-a-custom-image-对自定义图像进行预测" class="headerlink" title="11. Make a prediction on a custom image 对自定义图像进行预测"></a>11. Make a prediction on a custom image 对自定义图像进行预测</h1><p>如果您已经在某个数据集上训练了模型，那么您很可能想要对自己的自定义数据进行预测。</p><p>在我们的例子中，由于我们已经在披萨、牛排和寿司图像上训练了模型，那么我们如何使用我们的模型对我们自己的一张图像进行预测呢？</p><p>为此，我们可以加载图像，然后以与我们的模型训练的数据类型相匹配的方式对其进行预处理。</p><p>换句话说，我们必须将我们自己的自定义图像转换为张量，并确保它具有正确的数据类型，然后再将其传递给我们的模型。</p><p>让我们从下载自定义图像开始。</p><p>由于我们的模型可以预测图像中是否包含披萨、牛排或寿司，所以我们<a href="https://github.com/mrdbourke/pytorch-deep-learning/blob/main/images/04-pizza-dad.jpeg">从学习 PyTorch 进行深度学习 GitHub 下载一张我爸爸对大披萨竖起两个大拇指</a>的照片。</p><p>我们使用 Python 的模块下载图像<code>requests</code>。</p><blockquote><p>注意：如果您使用的是 Google Colab，您也可以通过转到左侧菜单 -&gt; 文件 -&gt; 上传到会话存储将图像上传到当前会话。但请注意，当您的 Google Colab 会话结束时，此图像将被删除。</p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Download custom image</span></span><br><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"></span><br><span class="line"><span class="comment"># Setup custom image path</span></span><br><span class="line">custom_image_path = data_path / <span class="string">&quot;04-pizza-dad.jpeg&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Download the image if it doesn&#x27;t already exist</span></span><br><span class="line"><span class="keyword">if</span> <span class="keyword">not</span> custom_image_path.is_file():</span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(custom_image_path, <span class="string">&quot;wb&quot;</span>) <span class="keyword">as</span> f:</span><br><span class="line">        <span class="comment"># When downloading from GitHub, need to use the &quot;raw&quot; file link</span></span><br><span class="line">        request = requests.get(<span class="string">&quot;https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/images/04-pizza-dad.jpeg&quot;</span>)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;Downloading <span class="subst">&#123;custom_image_path&#125;</span>...&quot;</span>)</span><br><span class="line">        f.write(request.content)</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;<span class="subst">&#123;custom_image_path&#125;</span> already exists, skipping download.&quot;</span>)</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">data/04-pizza-dad.jpeg already exists, skipping download.</span><br></pre></td></tr></table></figure><h2 id="11-1-Loading-in-a-custom-image-with-PyTorch-使用-PyTorch-加载自定义图像"><a href="#11-1-Loading-in-a-custom-image-with-PyTorch-使用-PyTorch-加载自定义图像" class="headerlink" title="11.1 Loading in a custom image with PyTorch 使用 PyTorch 加载自定义图像"></a>11.1 Loading in a custom image with PyTorch 使用 PyTorch 加载自定义图像</h2><p>看起来我们已经下载了一个自定义图像，并准备在 <code>data/04-pizza-dad.jpeg</code> 中使用。</p><p>是时候加载它了。</p><p>PyTorch 的 <code>torchvision</code> 有几种输入和输出（简称“IO”或“io”）方法，用于在<a href="https://pytorch.org/vision/stable/io.html"><code>torchvision.io</code></a> 中读取和写入图像和视频。</p><p>由于我们要加载图像，我们将使用 <a href="https://pytorch.org/vision/stable/generated/torchvision.io.read_image.html#torchvision.io.read_image"><code>torchvision.io.read_image()</code></a>。</p><p>此方法将读取 JPEG 或 PNG 图像并将其转换为 3 维 RGB 或灰度 <code>torch.Tensor</code>，其数据类型为 uint8，值在 [0, 255] 范围内。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"></span><br><span class="line"><span class="comment"># Read in custom image</span></span><br><span class="line">custom_image_uint8 = torchvision.io.read_image(<span class="built_in">str</span>(custom_image_path))</span><br><span class="line"></span><br><span class="line"><span class="comment"># Print out image data</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Custom image tensor:\n<span class="subst">&#123;custom_image_uint8&#125;</span>\n&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Custom image shape: <span class="subst">&#123;custom_image_uint8.shape&#125;</span>\n&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Custom image dtype: <span class="subst">&#123;custom_image_uint8.dtype&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">Custom image tensor:</span><br><span class="line">tensor([[[154, 173, 181,  ...,  21,  18,  14],</span><br><span class="line">         [146, 165, 181,  ...,  21,  18,  15],</span><br><span class="line">         [124, 146, 172,  ...,  18,  17,  15],</span><br><span class="line">         ...,</span><br><span class="line">         [ 72,  59,  45,  ..., 152, 150, 148],</span><br><span class="line">         [ 64,  55,  41,  ..., 150, 147, 144],</span><br><span class="line">         [ 64,  60,  46,  ..., 149, 146, 143]],</span><br><span class="line"></span><br><span class="line">        [[171, 190, 193,  ...,  22,  19,  15],</span><br><span class="line">         [163, 182, 193,  ...,  22,  19,  16],</span><br><span class="line">         [141, 163, 184,  ...,  19,  18,  16],</span><br><span class="line">         ...,</span><br><span class="line">         [ 55,  42,  28,  ..., 107, 104, 103],</span><br><span class="line">         [ 47,  38,  24,  ..., 108, 104, 102],</span><br><span class="line">         [ 47,  43,  29,  ..., 107, 104, 101]],</span><br><span class="line"></span><br><span class="line">        [[119, 138, 147,  ...,  17,  14,  10],</span><br><span class="line">         [111, 130, 145,  ...,  17,  14,  11],</span><br><span class="line">         [ 87, 111, 136,  ...,  14,  13,  11],</span><br><span class="line">         ...,</span><br><span class="line">         [ 35,  22,   8,  ...,  52,  52,  48],</span><br><span class="line">         [ 27,  18,   4,  ...,  50,  49,  44],</span><br><span class="line">         [ 27,  23,   9,  ...,  49,  46,  43]]], dtype=torch.uint8)</span><br><span class="line"></span><br><span class="line">Custom image shape: torch.Size([3, 4032, 3024])</span><br><span class="line"></span><br><span class="line">Custom image dtype: torch.uint8</span><br></pre></td></tr></table></figure><p>很好！看起来我们的图像是张量格式，但是，这种图像格式与我们的模型兼容吗？</p><p>我们的 <code>custom_image</code> 张量的数据类型是 <code>torch.uint8</code>，其值介于 [0, 255] 之间。</p><p>但是我们的模型采用数据类型为 <code>torch.float32</code> 的图像张量，其值介于 [0, 1] 之间。</p><p>因此，在将自定义图像与模型一起使用之前，我们需要将其转换为与模型训练数据相同的格式。</p><p>如果我们不这样做，我们的模型就会出错。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Try to make a prediction on image in uint8 format (this will error)</span></span><br><span class="line">model_1.<span class="built_in">eval</span>()</span><br><span class="line"><span class="keyword">with</span> torch.inference_mode():</span><br><span class="line">    model_1(custom_image_uint8.to(device))</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">RuntimeError: Input type (unsigned char) and bias type (float) should be the same</span><br></pre></td></tr></table></figure><p>如果我们尝试对与我们的模型训练不同的数据类型的图像进行预测，我们会收到如下错误：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">RuntimeError: Input type (torch.cuda.ByteTensor) and weight type (torch.cuda.FloatTensor) should be the same</span><br></pre></td></tr></table></figure><p>让我们通过将自定义图像转换为与我们的模型训练相同的数据类型来解决这个问题（<code>torch.float32</code>）。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Load in custom image and convert the tensor values to float32</span></span><br><span class="line">custom_image = torchvision.io.read_image(<span class="built_in">str</span>(custom_image_path)).<span class="built_in">type</span>(torch.float32)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Divide the image pixel values by 255 to get them between [0, 1]</span></span><br><span class="line">custom_image = custom_image / <span class="number">255.</span> </span><br><span class="line"></span><br><span class="line"><span class="comment"># Print out image data</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Custom image tensor:\n<span class="subst">&#123;custom_image&#125;</span>\n&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Custom image shape: <span class="subst">&#123;custom_image.shape&#125;</span>\n&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Custom image dtype: <span class="subst">&#123;custom_image.dtype&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">Custom image tensor:</span><br><span class="line">tensor([[[0.6039, 0.6784, 0.7098,  ..., 0.0824, 0.0706, 0.0549],</span><br><span class="line">         [0.5725, 0.6471, 0.7098,  ..., 0.0824, 0.0706, 0.0588],</span><br><span class="line">         [0.4863, 0.5725, 0.6745,  ..., 0.0706, 0.0667, 0.0588],</span><br><span class="line">         ...,</span><br><span class="line">         [0.2824, 0.2314, 0.1765,  ..., 0.5961, 0.5882, 0.5804],</span><br><span class="line">         [0.2510, 0.2157, 0.1608,  ..., 0.5882, 0.5765, 0.5647],</span><br><span class="line">         [0.2510, 0.2353, 0.1804,  ..., 0.5843, 0.5725, 0.5608]],</span><br><span class="line"></span><br><span class="line">        [[0.6706, 0.7451, 0.7569,  ..., 0.0863, 0.0745, 0.0588],</span><br><span class="line">         [0.6392, 0.7137, 0.7569,  ..., 0.0863, 0.0745, 0.0627],</span><br><span class="line">         [0.5529, 0.6392, 0.7216,  ..., 0.0745, 0.0706, 0.0627],</span><br><span class="line">         ...,</span><br><span class="line">         [0.2157, 0.1647, 0.1098,  ..., 0.4196, 0.4078, 0.4039],</span><br><span class="line">         [0.1843, 0.1490, 0.0941,  ..., 0.4235, 0.4078, 0.4000],</span><br><span class="line">         [0.1843, 0.1686, 0.1137,  ..., 0.4196, 0.4078, 0.3961]],</span><br><span class="line"></span><br><span class="line">        [[0.4667, 0.5412, 0.5765,  ..., 0.0667, 0.0549, 0.0392],</span><br><span class="line">         [0.4353, 0.5098, 0.5686,  ..., 0.0667, 0.0549, 0.0431],</span><br><span class="line">         [0.3412, 0.4353, 0.5333,  ..., 0.0549, 0.0510, 0.0431],</span><br><span class="line">         ...,</span><br><span class="line">         [0.1373, 0.0863, 0.0314,  ..., 0.2039, 0.2039, 0.1882],</span><br><span class="line">         [0.1059, 0.0706, 0.0157,  ..., 0.1961, 0.1922, 0.1725],</span><br><span class="line">         [0.1059, 0.0902, 0.0353,  ..., 0.1922, 0.1804, 0.1686]]])</span><br><span class="line"></span><br><span class="line">Custom image shape: torch.Size([3, 4032, 3024])</span><br><span class="line"></span><br><span class="line">Custom image dtype: torch.float32</span><br></pre></td></tr></table></figure><h2 id="11-2-Predicting-on-custom-images-with-a-trained-PyTorch-model-使用训练好的-PyTorch-模型对自定义图像进行预测"><a href="#11-2-Predicting-on-custom-images-with-a-trained-PyTorch-model-使用训练好的-PyTorch-模型对自定义图像进行预测" class="headerlink" title="11.2 Predicting on custom images with a trained PyTorch model 使用训练好的 PyTorch 模型对自定义图像进行预测"></a>11.2 Predicting on custom images with a trained PyTorch model 使用训练好的 PyTorch 模型对自定义图像进行预测</h2><p>看起来我们的图像数据现在与我们的模型训练的格式相同。</p><p>除了一件事……</p><p>它是shape。</p><p>我们的模型是在具有形状的图像上进行训练的[3, 64, 64]，而我们的自定义图像目前是[3, 4032, 3024]。</p><p>我们如何确保我们的自定义图像与我们的模型训练的图像具有相同的形状？</p><p>有沒有任何<code>torchvision.transforms</code>可以幫助的？</p><p>在回答这个问题之前，让我们先绘制图像<code>matplotlib</code>以确保它看起来不错，记住我们必须将尺寸从<code>CHW</code>到<code>HWC</code>排列以满足的<code>matplotlib</code>要求。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Plot custom image</span></span><br><span class="line">plt.imshow(custom_image.permute(<span class="number">1</span>, <span class="number">2</span>, <span class="number">0</span>)) <span class="comment"># need to permute image dimensions from CHW -&gt; HWC otherwise matplotlib will error</span></span><br><span class="line">plt.title(<span class="string">f&quot;Image shape: <span class="subst">&#123;custom_image.shape&#125;</span>&quot;</span>)</span><br><span class="line">plt.axis(<span class="literal">False</span>);</span><br></pre></td></tr></table></figure><img src="/2024/08/18/PyTorch-26H-5/PyTorch-26H-5-14.png" class="" title="PyTorch-26H-5-14"><p>竖起两个大拇指！</p><p>现在我们如何才能让我们的图像与我们的模型训练的图像具有相同的大小？</p><p>其中一种方法是使用<code>torchvision.transforms.Resize()</code>。</p><p>让我们编写一个转换管道<code>transform pipeline</code>来实现这一点。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Create transform pipleine to resize image</span></span><br><span class="line">custom_image_transform = transforms.Compose([</span><br><span class="line">    transforms.Resize((<span class="number">64</span>, <span class="number">64</span>)),</span><br><span class="line">])</span><br><span class="line"></span><br><span class="line"><span class="comment"># Transform target image</span></span><br><span class="line">custom_image_transformed = custom_image_transform(custom_image)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Print out original shape and new shape</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Original shape: <span class="subst">&#123;custom_image.shape&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;New shape: <span class="subst">&#123;custom_image_transformed.shape&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Original shape: torch.Size([3, 4032, 3024])</span><br><span class="line">New shape: torch.Size([3, 64, 64])</span><br></pre></td></tr></table></figure><p>最后我们来对我们自己的自定义图像进行预测。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">model_1.<span class="built_in">eval</span>()</span><br><span class="line"><span class="keyword">with</span> torch.inference_mode():</span><br><span class="line">    custom_image_pred = model_1(custom_image_transformed)</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument weight in method wrapper_CUDA___slow_conv2d_forward)</span><br></pre></td></tr></table></figure><p>尽管我们做好了准备，但我们的自定义图像和模型仍在不同的设备上。</p><p>让我们通过将我们的放到<code>custom_image_transformed</code>目标设备上来解决这个问题。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">model_1.<span class="built_in">eval</span>()</span><br><span class="line"><span class="keyword">with</span> torch.inference_mode():</span><br><span class="line">    custom_image_pred = model_1(custom_image_transformed.to(device))</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">RuntimeError: mat1 and mat2 shapes cannot be multiplied (10x256 and 2560x3)</span><br></pre></td></tr></table></figure><p>形状错误。</p><p>我们将自定义图像转换为与我们的模型训练图像相同的尺寸……</p><p>哦，等等……</p><p>我们忘记了一个维度。</p><p>批次大小。</p><p>我们的模型期望图像张量在开始时具有批量大小维度（NCHW其中N是批量大小）。</p><p>除了我们的自定义图像目前只有CHW。</p><p>我们可以添加批量大小维度<code>torch.unsqueeze(dim=0)</code>来为图像添加额外的维度，最后做出预测。</p><p>本质上，我们将告诉我们的模型根据单个图像（1个<code>batch_size=1</code>的图像）进行预测。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">model_1.<span class="built_in">eval</span>()</span><br><span class="line"><span class="keyword">with</span> torch.inference_mode():</span><br><span class="line">    <span class="comment"># Add an extra dimension to image</span></span><br><span class="line">    custom_image_transformed_with_batch_size = custom_image_transformed.unsqueeze(dim=<span class="number">0</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Print out different shapes</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;Custom image transformed shape: <span class="subst">&#123;custom_image_transformed.shape&#125;</span>&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;Unsqueezed custom image shape: <span class="subst">&#123;custom_image_transformed_with_batch_size.shape&#125;</span>&quot;</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Make a prediction on image with an extra dimension</span></span><br><span class="line">    custom_image_pred = model_1(custom_image_transformed.unsqueeze(dim=<span class="number">0</span>).to(device))</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Custom image transformed shape: torch.Size([3, 64, 64])</span><br><span class="line">Unsqueezed custom image shape: torch.Size([1, 3, 64, 64])</span><br></pre></td></tr></table></figure><p>注意：我们刚刚经历了三个经典且最常见的深度学习和 PyTorch 问题：</p><ul><li>错误的数据类型 ： 我们的模型需要 <code>torch.float32</code>，而我们原始的自定义图像是 <code>uint8</code>。</li><li>错误的设备 ： 我们的模型在目标设备上（在我们的例子中是 GPU），而我们的目标数据尚未移动到目标设备。</li><li>错误的形状 ： 我们的模型需要形状为 <code>[N, C, H, W]</code> 或 <code>[batch_size, color_channels, height, width]</code> 的输入图像，而我们的自定义图像张量的形状为 <code>[color_channels, height, width]</code>。</li></ul><p>请记住，这些错误不仅仅用于预测自定义图像。<br>它们存在于您处理的几乎所有数据类型（文本、音频、结构化数据）和问题中。</p><p>现在让我们来看看我们的模型的预测。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">custom_image_pred</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tensor([[ 0.1188,  0.0250, -0.1444]], device=&#x27;cuda:0&#x27;)</span><br></pre></td></tr></table></figure><p>好的，这些仍然是logit 形式（模型的原始输出称为 logit）。</p><p>让我们将它们从日志-&gt;预测概率-&gt;预测标签进行转换。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Print out prediction logits</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Prediction logits: <span class="subst">&#123;custom_image_pred&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Convert logits -&gt; prediction probabilities (using torch.softmax() for multi-class classification)</span></span><br><span class="line">custom_image_pred_probs = torch.softmax(custom_image_pred, dim=<span class="number">1</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Prediction probabilities: <span class="subst">&#123;custom_image_pred_probs&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Convert prediction probabilities -&gt; prediction labels</span></span><br><span class="line">custom_image_pred_label = torch.argmax(custom_image_pred_probs, dim=<span class="number">1</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Prediction label: <span class="subst">&#123;custom_image_pred_label&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Prediction logits: tensor([[ 0.1188,  0.0250, -0.1444]], device=&#x27;cuda:0&#x27;)</span><br><span class="line">Prediction probabilities: tensor([[0.3733, 0.3398, 0.2869]], device=&#x27;cuda:0&#x27;)</span><br><span class="line">Prediction label: tensor([0], device=&#x27;cuda:0&#x27;)</span><br></pre></td></tr></table></figure><p>但当然我们的预测标签仍然是索引/张量形式。</p><p>我们可以通过在 <code>class_names</code> 列表上建立索引将其转换为字符串类名预测。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Find the predicted label</span></span><br><span class="line">custom_image_pred_class = class_names[custom_image_pred_label.cpu()] <span class="comment"># put pred label to CPU, otherwise will error</span></span><br><span class="line">custom_image_pred_class</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&#x27;pizza&#x27;</span><br></pre></td></tr></table></figure><p>尽管根据我们的评估指标，模型的表现很差，但它似乎预测正确。</p><blockquote><p>注意：无论给出什么图像，当前形式的模型都会预测“披萨”、“牛排”或“寿司”。如果您希望模型预测不同的类别，则必须对其进行训练。</p></blockquote><p>但如果我们检查一下<code>custom_image_pred_probs</code>，我们会注意到模型给予每个类别几乎相同的权重（值相似）。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># The values of the prediction probabilities are quite similar</span></span><br><span class="line">custom_image_pred_probs</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tensor([[0.3733, 0.3398, 0.2869]], device=&#x27;cuda:0&#x27;)</span><br></pre></td></tr></table></figure><p>具有如此相似的预测概率可能意味着几件事：</p><ul><li>该模型试图同时预测所有三个类别（可能有一张包含披萨、牛排和寿司的图像）。</li><li>该模型实际上并不知道它想要预测什么，而只是为每个类别分配相似的值。</li></ul><p>我们的案例是 2，由于我们的模型训练不佳，所以它基本上是在猜测预测。</p><h2 id="11-3-Putting-custom-image-prediction-together-building-a-function-将自定义图像预测整合在一起：构建函数"><a href="#11-3-Putting-custom-image-prediction-together-building-a-function-将自定义图像预测整合在一起：构建函数" class="headerlink" title="11.3 Putting custom image prediction together: building a function 将自定义图像预测整合在一起：构建函数"></a>11.3 Putting custom image prediction together: building a function 将自定义图像预测整合在一起：构建函数</h2><p>每次您想要对自定义图像进行预测时执行上述所有步骤很快就会变得乏味。</p><p>所以让我们将它们放在一起，形成一个可以轻松反复使用的函数。</p><p>具体来说，让我们创建一个函数：</p><ul><li>获取目标图像路径并转换为适合我们模型的正确数据类型（torch.float32）。</li><li>确保目标图像像素值在范围内[0, 1]。</li><li>如果有必要的话，变换目标图像。</li><li>确保模型在目标设备上。</li><li>使用训练好的模型对目标图像进行预测（确保图像大小正确且与模型位于同一设备上）。</li><li>将模型的输出逻辑转换为预测概率。</li><li>将预测概率转换为预测标签。</li><li>绘制目标图像以及模型预测和预测概率。</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">pred_and_plot_image</span>(<span class="params">model: torch.nn.Module, </span></span><br><span class="line"><span class="params">                        image_path: <span class="built_in">str</span>, </span></span><br><span class="line"><span class="params">                        class_names: <span class="type">List</span>[<span class="built_in">str</span>] = <span class="literal">None</span>, </span></span><br><span class="line"><span class="params">                        transform=<span class="literal">None</span>,</span></span><br><span class="line"><span class="params">                        device: torch.device = device</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Makes a prediction on a target image and plots the image with its prediction.&quot;&quot;&quot;</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 1. Load in image and convert the tensor values to float32</span></span><br><span class="line">    target_image = torchvision.io.read_image(<span class="built_in">str</span>(image_path)).<span class="built_in">type</span>(torch.float32)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 2. Divide the image pixel values by 255 to get them between [0, 1]</span></span><br><span class="line">    target_image = target_image / <span class="number">255.</span> </span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 3. Transform if necessary</span></span><br><span class="line">    <span class="keyword">if</span> transform:</span><br><span class="line">        target_image = transform(target_image)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 4. Make sure the model is on the target device</span></span><br><span class="line">    model.to(device)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 5. Turn on model evaluation mode and inference mode</span></span><br><span class="line">    model.<span class="built_in">eval</span>()</span><br><span class="line">    <span class="keyword">with</span> torch.inference_mode():</span><br><span class="line">        <span class="comment"># Add an extra dimension to the image</span></span><br><span class="line">        target_image = target_image.unsqueeze(dim=<span class="number">0</span>)</span><br><span class="line">    </span><br><span class="line">        <span class="comment"># Make a prediction on image with an extra dimension and send it to the target device</span></span><br><span class="line">        target_image_pred = model(target_image.to(device))</span><br><span class="line">        </span><br><span class="line">    <span class="comment"># 6. Convert logits -&gt; prediction probabilities (using torch.softmax() for multi-class classification)</span></span><br><span class="line">    target_image_pred_probs = torch.softmax(target_image_pred, dim=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 7. Convert prediction probabilities -&gt; prediction labels</span></span><br><span class="line">    target_image_pred_label = torch.argmax(target_image_pred_probs, dim=<span class="number">1</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 8. Plot the image alongside the prediction and prediction probability</span></span><br><span class="line">    plt.imshow(target_image.squeeze().permute(<span class="number">1</span>, <span class="number">2</span>, <span class="number">0</span>)) <span class="comment"># make sure it&#x27;s the right size for matplotlib</span></span><br><span class="line">    <span class="keyword">if</span> class_names:</span><br><span class="line">        title = <span class="string">f&quot;Pred: <span class="subst">&#123;class_names[target_image_pred_label.cpu()]&#125;</span> | Prob: <span class="subst">&#123;target_image_pred_probs.<span class="built_in">max</span>().cpu():<span class="number">.3</span>f&#125;</span>&quot;</span></span><br><span class="line">    <span class="keyword">else</span>: </span><br><span class="line">        title = <span class="string">f&quot;Pred: <span class="subst">&#123;target_image_pred_label&#125;</span> | Prob: <span class="subst">&#123;target_image_pred_probs.<span class="built_in">max</span>().cpu():<span class="number">.3</span>f&#125;</span>&quot;</span></span><br><span class="line">    plt.title(title)</span><br><span class="line">    plt.axis(<span class="literal">False</span>);</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Pred on our custom image</span></span><br><span class="line">pred_and_plot_image(model=model_1,</span><br><span class="line">                    image_path=custom_image_path,</span><br><span class="line">                    class_names=class_names,</span><br><span class="line">                    transform=custom_image_transform,</span><br><span class="line">                    device=device)</span><br></pre></td></tr></table></figure><img src="/2024/08/18/PyTorch-26H-5/PyTorch-26H-5-15.png" class="" title="PyTorch-26H-5-15"><p>看起来我们的模型仅凭猜测就得到了正确的预测。</p><p>但其他图像并不总是如此……</p><p>图像也像素化了，因为我们<code>[64, 64]</code>使用调整了它的大小<code>custom_image_transform</code>。</p><h1 id="Main-takeaways"><a href="#Main-takeaways" class="headerlink" title="Main takeaways"></a>Main takeaways</h1><ul><li>PyTorch 有许多内置函数来处理各种数据，从视觉到文本到音频到推荐系统。</li><li>如果 PyTorch 的内置数据加载函数不符合您的要求，您可以编写代码通过子类化来创建自己的自定义数据集<code>torch.utils.data.Dataset</code>。</li><li><code>torch.utils.data.DataLoaderPyTorch</code> 中的 帮助将您的 转变<code>Dataset</code>为可在训练和测试模型时使用的可迭代对象。</li><li>许多机器学习都在处理过度拟合和欠拟合之间的平衡（我们针对上述情况讨论了不同的方法，因此一个很好的练习是进行更多研究并编写代码来尝试不同的技术）。</li><li>只要你将数据格式化为与模型训练时类似的格式，就可以使用经过训练的模型预测你自己的自定义数据。确保处理好 PyTorch 和深度学习的三大错误：</li><li>错误的数据类型–<code>torch.float32</code>当您的数据为 时，您的模型是预期的<code>torch.uint8</code>。</li><li>错误的数据形状<code>[batch_size, color_channels, height, width]</code>-当您的数据为 时，您的模型是预期的<code>[color_channels, height, width]</code>。</li><li>错误的设备- 您的模型在 GPU 上，但您的数据在 CPU 上。</li></ul><h1 id="Exercises"><a href="#Exercises" class="headerlink" title="Exercises"></a>Exercises</h1><p>所有练习都集中于练习以上部分中的代码。</p><p>您应该能够通过参考每个部分或按照链接的资源来完成它们。</p><p>所有练习都应使用与<a href="https://pytorch.org/docs/stable/notes/cuda.html#device-agnostic-code">设备无关的代码</a>来完成。</p><p><strong>资源：</strong></p><ul><li><a href="https://github.com/mrdbourke/pytorch-deep-learning/blob/main/extras/exercises/04_pytorch_custom_datasets_exercises.ipynb">04 年练习模板笔记本</a></li><li><a href="https://github.com/mrdbourke/pytorch-deep-learning/blob/main/extras/solutions/04_pytorch_custom_datasets_exercise_solutions.ipynb">04 示例解决方案笔记本</a>（在查看<em>之前先</em>尝试练习）</li></ul><ol><li>我们的模型表现不佳（不能很好地拟合数据）。防止拟合不足的 3 种方法是什么？写下来并用一句话解释每种方法。</li><li>重新创建我们在第 1、2、3 和 4 节中构建的数据加载函数。您应该已经<code>DataLoader</code>准备好训练和测试了。</li><li>重新创建<code>model_0</code>我们在第 7 节中构建的内容。</li><li>为 建立训练和测试功能<code>model_0</code>。</li><li>尝试对你在练习 3 中创建的模型进行 5、20 和 50 个时期的训练，结果会怎样？<ul><li>使用<code>torch.optim.Adam()</code>学习率为 0.001 作为优化器。</li></ul></li><li>将模型中的隐藏单元数量加倍，并训练 20 个时期，结果会发生什么变化？</li><li>将您在模型中使用的数据增加一倍，并进行 20 个时期的训练，结果会怎样？<ul><li><strong>注意：</strong>您可以使用<a href="https://github.com/mrdbourke/pytorch-deep-learning/blob/main/extras/04_custom_data_creation.ipynb">自定义数据创建笔记本</a>来扩大您的 Food101 数据集。</li><li>您还可以在 GitHub 上找到<a href="https://github.com/mrdbourke/pytorch-deep-learning/blob/main/data/pizza_steak_sushi_20_percent.zip">已经格式化的双倍数据（20% 而不是 10% 子集）数据集</a>，您需要像练习 2 中那样编写下载代码才能将其放入此笔记本中。</li></ul></li><li>对您自己定制的披萨/牛排/寿司图像做出预测（您甚至可以从互联网上下载一个）并分享您的预测。<ul><li>你在练习 7 中训练的模型正确吗？</li><li>如果不是，您认为可以做些什么来改善它？</li></ul></li></ol><h1 id="Extra-curriculum"><a href="#Extra-curriculum" class="headerlink" title="Extra-curriculum"></a>Extra-curriculum</h1><ul><li><p>通过 PyTorch<a href="https://pytorch.org/tutorials/beginner/basics/data_tutorial.html">数据集和数据加载器教程笔记本</a>练习对 PyTorch<code>Dataset</code>和 的知识。<code>DataLoader</code></p></li><li><p>花 10 分钟阅读  PyTorch<code>torchvision.transforms</code>文档</p><ul><li><a href="https://pytorch.org/vision/main/auto_examples/transforms/plot_transforms_illustrations.html">您可以在变换教程的插图</a>中看到变换的实际演示。</li></ul></li><li><p>花 10 分钟阅读 PyTorch <code>torchvision.datasets</code>文档</p><ul><li>哪些数据集令您印象深刻？</li><li>您如何尝试基于这些来建立模型？</li></ul></li><li><p><a href="https://pytorch.org/data/beta/index.html">TorchData 目前处于测试阶段</a>（截至 2022 年 4 月），它将成为未来在 PyTorch 中加载数据的一种方式，但您现在就可以开始检查它。</p></li><li><p>为了加速深度学习模型，你可以使用一些技巧来改进计算、内存和开销计算，更多信息请阅读Horace He 的文章<a href="https://horace.io/brrr_intro.html"><em>《从第一原理开始让深度学习变得更好》 。</em></a></p></li></ul>]]></content>
    
    
    <summary type="html">PyTorch-26H-5</summary>
    
    
    
    <category term="PyTorch" scheme="http://hibiscidai.com/categories/PyTorch/"/>
    
    
    <category term="学习笔记" scheme="http://hibiscidai.com/tags/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
    <category term="PyTorch" scheme="http://hibiscidai.com/tags/PyTorch/"/>
    
  </entry>
  
  <entry>
    <title>PyTorch-26H-4</title>
    <link href="http://hibiscidai.com/2024/08/17/PyTorch-26H-4/"/>
    <id>http://hibiscidai.com/2024/08/17/PyTorch-26H-4/</id>
    <published>2024-08-17T12:00:00.000Z</published>
    <updated>2024-12-25T14:07:12.000Z</updated>
    
    <content type="html"><![CDATA[<img src="/2024/08/17/PyTorch-26H-4/PyTorch-26H-4.png" class="" title="PyTorch-26H-4"><p>PyTorch-26H-4</p><span id="more"></span><h1 id="PyTorch-26H-4"><a href="#PyTorch-26H-4" class="headerlink" title="PyTorch-26H-4"></a>PyTorch-26H-4</h1><p>主页：<a href="https://www.freecodecamp.org/news/learn-pytorch-for-deep-learning-in-day/">https://www.freecodecamp.org/news/learn-pytorch-for-deep-learning-in-day/</a></p><p>youtub：<a href="https://youtu.be/V_xro1bcAuA">https://youtu.be/V_xro1bcAuA</a></p><p>github：<a href="https://github.com/mrdbourke/pytorch-deep-learning">https://github.com/mrdbourke/pytorch-deep-learning</a></p><p>Learn PyTorch for Deep Learning: Zero to Mastery book：<a href="https://www.learnpytorch.io/">https://www.learnpytorch.io/</a></p><p>PyTorch documentation：<a href="https://pytorch.org/docs/stable/index.html">https://pytorch.org/docs/stable/index.html</a></p><p>计算机视觉<a href="https://en.wikipedia.org/wiki/Computer_vision">Computer vision</a>是教计算机看东西的艺术。</p><p>例如，它可能涉及建立一个模型来对照片是猫还是狗进行分类（二元分类<a href="https://developers.google.com/machine-learning/glossary#binary-classification">binary classification</a>）。</p><p>或者照片是猫、狗还是鸡（多类分类<a href="https://developers.google.com/machine-learning/glossary#multi-class-classification">multi-class classification</a>）。</p><p>或者识别汽车在视频帧中出现的位置（物体检测<a href="https://en.wikipedia.org/wiki/Object_detection">object detection</a>）。</p><p>或者弄清楚图像中不同物体可以分离的位置（全景分割<a href="https://arxiv.org/abs/1801.00868">panoptic segmentation</a>）。</p><p><a href="https://machinelearning.apple.com/">machinelearning_apple</a></p><img src="/2024/08/17/PyTorch-26H-4/PyTorch-26H-4-1.png" class="" title="PyTorch-26H-4-1"><h1 id="Where-does-computer-vision-get-used"><a href="#Where-does-computer-vision-get-used" class="headerlink" title="Where does computer vision get used?"></a>Where does computer vision get used?</h1><p>如果您使用智能手机，那么您已 经使用了计算机视觉。</p><p>相机和照片应用程序使用计算机视觉来增强<a href="https://machinelearning.apple.com/research/panoptic-segmentation">computer vision to enhance</a>和分类图像。</p><p>现代汽车使用计算机视觉<a href="https://youtu.be/j0z4FweCy4M?t=2989">computer vision</a>来避开其他车辆并保持在车道线内。</p><img src="/2024/08/17/PyTorch-26H-4/PyTorch-26H-4-1_2.png" class="" title="PyTorch-26H-4-1_2"><p>制造商使用计算机视觉来识别各种产品的缺陷。</p><p>安全摄像机使用计算机视觉来检测潜在的入侵者。</p><p>本质上，任何能够用视觉描述的事物都可能成为潜在的计算机视觉问题。</p><h2 id="input-and-output-shape"><a href="#input-and-output-shape" class="headerlink" title="input and output shape"></a>input and output shape</h2><img src="/2024/08/17/PyTorch-26H-4/PyTorch-26H-4-1_3.png" class="" title="PyTorch-26H-4-1_3"><img src="/2024/08/17/PyTorch-26H-4/PyTorch-26H-4-1_4.png" class="" title="PyTorch-26H-4-1_4"><img src="/2024/08/17/PyTorch-26H-4/PyTorch-26H-4-1_5.png" class="" title="PyTorch-26H-4-1_5"><h1 id="What-is-a-convolutional-neural-network-CNN"><a href="#What-is-a-convolutional-neural-network-CNN" class="headerlink" title="What is a convolutional neural network(CNN)"></a>What is a convolutional neural network(CNN)</h1><img src="/2024/08/17/PyTorch-26H-4/PyTorch-26H-4-1_6.png" class="" title="PyTorch-26H-4-1_6"><p><a href="https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html">torch.nn.Conv2d</a></p><h1 id="What-we’re-going-to-cover"><a href="#What-we’re-going-to-cover" class="headerlink" title="What we’re going to cover"></a>What we’re going to cover</h1><ul><li>Getting a vision dataset to work with using <code>torchvision.datasets</code></li><li>使用 <code>torchvision.datasets</code> 获取视觉数据集</li><li>Architecture of a convolutional neural network (CNN) with PyTorch</li><li>使用 PyTorch 构建卷积神经网络 (CNN) 架构</li><li>An end-to-end multi-class image classification problem</li><li>端到端多类图像分类问题</li><li>Steps in modelling with CNNs in PyTorch</li><li>使用 PyTorch 中的 CNN 建模的步骤</li><li>Creating a CNN model with PyTorch</li><li>使用 PyTorch 创建 CNN 模型</li><li>Picking a loss and optimizer</li><li>选择损失和优化器</li><li>Training a PyTorch computer vision model</li><li>训练 PyTorch 计算机视觉模型</li><li>Evaluating a model</li><li>评估模型</li></ul><div class="table-container"><table><thead><tr><th style="text-align:center">话题</th><th style="text-align:center">内容</th></tr></thead><tbody><tr><td style="text-align:center">0. PyTorch 中的计算机视觉库</td><td style="text-align:center">PyTorch 有许多内置的有用的计算机视觉库</td></tr><tr><td style="text-align:center">1. 加载数据</td><td style="text-align:center">为了练习计算机视觉，我们将从FashionMNIST](<a href="https://github.com/zalandoresearch/fashion-mnist)中的一些不同服装的图像开始。">https://github.com/zalandoresearch/fashion-mnist)中的一些不同服装的图像开始。</a></td></tr><tr><td style="text-align:center">2.准备数据</td><td style="text-align:center">我们有一些图像，让我们用 <a href="https://pytorch.org/docs/stable/data.html">PyTorch <code>DataLoader</code></a>加载它们，以便我们可以在训练循环中使用它们。</td></tr><tr><td style="text-align:center">3. 模型 0：建立基线模型</td><td style="text-align:center">在这里我们将创建一个多类分类模型来学习数据中的模式，我们还将选择一个损失函数 <strong>loss function</strong>、优化器 <strong>optimizer</strong>并建立一个训练循环<strong>training loop</strong>.。</td></tr><tr><td style="text-align:center">4. 做出预测并评估模型 0</td><td style="text-align:center">让我们用基线模型做出一些预测并对其进行评估。</td></tr><tr><td style="text-align:center">5. 为未来型号设置与设备无关的代码</td><td style="text-align:center">编写与设备无关的代码是最佳做法，因此让我们进行设置。</td></tr><tr><td style="text-align:center">6. 模型 1：添加非线性</td><td style="text-align:center">实验是机器学习的重要组成部分，让我们尝试通过添加非线性层来改进我们的基线模型。</td></tr><tr><td style="text-align:center">7.模型2：卷积神经网络（CNN）</td><td style="text-align:center">是时候具体了解计算机视觉并介绍强大的卷积神经网络架构了。</td></tr><tr><td style="text-align:center">8. 比较我们的模型</td><td style="text-align:center">我们建立了三个不同的模型，让我们对它们进行比较。</td></tr><tr><td style="text-align:center">9.评估我们的最佳模型</td><td style="text-align:center">让我们对随机图像做出一些预测并评估我们最好的模型。</td></tr><tr><td style="text-align:center">10. 制作混淆矩阵</td><td style="text-align:center">混淆矩阵是评估分类模型的好方法，让我们看看如何创建一个混淆矩阵。</td></tr><tr><td style="text-align:center">11.保存并加载性能最佳的模型</td><td style="text-align:center">因为我们可能需要稍后使用我们的模型，所以我们保存它并确保它能正确加载。</td></tr></tbody></table></div><h1 id="0-Computer-vision-libraries-in-PyTorch"><a href="#0-Computer-vision-libraries-in-PyTorch" class="headerlink" title="0. Computer vision libraries in PyTorch"></a>0. Computer vision libraries in PyTorch</h1><p>PyTorch 计算机视觉库</p><div class="table-container"><table><thead><tr><th style="text-align:center">PyTorch模块</th><th style="text-align:center">作用</th></tr></thead><tbody><tr><td style="text-align:center"><a href="https://pytorch.org/vision/stable/index.html"><code>torchvision</code></a></td><td style="text-align:center">包含常用于计算机视觉问题的数据集、模型架构和图像转换。</td></tr><tr><td style="text-align:center"><a href="https://pytorch.org/vision/stable/datasets.html"><code>torchvision.datasets</code></a></td><td style="text-align:center">许多示例计算机视觉数据集，用于解决图像分类、对象检测、图像字幕、视频分类等一系列问题。它还包含<a href="https://pytorch.org/vision/stable/datasets.html#base-classes-for-custom-datasets">一系列用于制作自定义数据集的基类</a>。</td></tr><tr><td style="text-align:center"><a href="https://pytorch.org/vision/stable/models.html"><code>torchvision.models</code></a></td><td style="text-align:center">该模块包含在 PyTorch 中实现的性能良好且常用的计算机视觉模型架构。</td></tr><tr><td style="text-align:center"><a href="https://pytorch.org/vision/stable/transforms.html"><code>torchvision.transforms</code></a></td><td style="text-align:center">通常，图像需要在用于模型之前进行转换（转换为数字/处理/增强），常见的图像转换可以在这里找到。</td></tr><tr><td style="text-align:center"><a href="https://pytorch.org/docs/stable/data.html#torch.utils.data.Dataset"><code>torch.utils.data.Dataset</code></a></td><td style="text-align:center">PyTorch 的基础数据集类。</td></tr><tr><td style="text-align:center"><a href="https://pytorch.org/docs/stable/data.html#module-torch.utils.data"><code>torch.utils.data.DataLoader</code></a></td><td style="text-align:center">在数据集上创建一个 Python 可迭代对象（使用 创建<code>torch.utils.data.Dataset</code>）。</td></tr></tbody></table></div><p><code>torch.utils.data.Dataset</code>和类<code>torch.utils.data.DataLoader</code>不仅适用于 PyTorch 中的计算机视觉，它们还能够处理许多不同类型的数据。</p><p><a href="https://pytorch.org/vision/stable/transforms.html">torchvison文档</a></p><p>导入相关依赖项：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Import PyTorch</span></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"></span><br><span class="line"><span class="comment"># Import torchvision </span></span><br><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> datasets</span><br><span class="line"><span class="keyword">from</span> torchvision.transforms <span class="keyword">import</span> ToTensor</span><br><span class="line"></span><br><span class="line"><span class="comment"># Import matplotlib for visualization</span></span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="comment"># Check versions</span></span><br><span class="line"><span class="comment"># Note: your PyTorch version shouldn&#x27;t be lower than 1.10.0 and torchvision version shouldn&#x27;t be lower than 0.11</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;PyTorch version: <span class="subst">&#123;torch.__version__&#125;</span>\ntorchvision version: <span class="subst">&#123;torchvision.__version__&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">PyTorch version: 2.4.1</span><br><span class="line">torchvision version: 0.19.1</span><br></pre></td></tr></table></figure><h1 id="1-Getting-a-dataset-获取数据集"><a href="#1-Getting-a-dataset-获取数据集" class="headerlink" title="1. Getting a dataset 获取数据集"></a>1. Getting a dataset 获取数据集</h1><p>从 FashionMNIST 开始。</p><p>MNIST，Modified National Institute of Standards and Technology，修改后的国家标准与技术研究院</p><p><a href="https://en.wikipedia.org/wiki/MNIST_database">original MNIST dataset</a>原始 MNIST 数据集包含数千个手写数字示例（从 0 到 9），用于构建计算机视觉模型来识别邮政服务的数字。</p><p><a href="https://github.com/zalandoresearch/fashion-mnist">FashionMNIST</a>Zalando Research 制作的FashionMNIST是一个类似的设置。</p><p>包含 10 种不同服装的灰度图像。</p><img src="/2024/08/17/PyTorch-26H-4/PyTorch-26H-4-2.png" class="" title="PyTorch-26H-4-2"><p><code>torchvision.datasets</code>包含大量示例数据集，可用于练习编写计算机视觉代码。<code>FashionMNIST</code> 就是其中一个数据集。由于它有 10 个不同的图像类别（不同类型的服装），因此它是一个多类别分类问题。</p><p>稍后，我们将构建一个计算机视觉神经网络来识别这些图像中不同风格的服装。</p><p>PyTorch 中存储了大量常见的计算机视觉数据集<code>torchvision.datasets</code>。</p><p>为了下载它，我们提供以下参数：</p><ul><li><code>root: str</code>，将数据下载到哪个文件夹？</li><li><code>train: Bool</code>，要训练还是测试分割？</li><li><code>download: Bool</code>，是否应该下载数据？</li><li><code>transform: torchvision.transforms</code>，想对数据进行哪些转换？</li><li><code>target_transform</code>， 如果您愿意，可以转换目标（标签）。</li></ul><p>许多其他数据集torchvision都有这些参数选项。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Setup training data</span></span><br><span class="line">train_data = datasets.FashionMNIST(</span><br><span class="line">    root=<span class="string">&quot;data&quot;</span>, <span class="comment"># where to download data to?</span></span><br><span class="line">    train=<span class="literal">True</span>, <span class="comment"># get training data</span></span><br><span class="line">    download=<span class="literal">True</span>, <span class="comment"># download data if it doesn&#x27;t exist on disk</span></span><br><span class="line">    transform=ToTensor(), <span class="comment"># images come as PIL format, we want to turn into Torch tensors</span></span><br><span class="line">    target_transform=<span class="literal">None</span> <span class="comment"># you can transform labels as well</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Setup testing data</span></span><br><span class="line">test_data = datasets.FashionMNIST(</span><br><span class="line">    root=<span class="string">&quot;data&quot;</span>,</span><br><span class="line">    train=<span class="literal">False</span>, <span class="comment"># get test data</span></span><br><span class="line">    download=<span class="literal">True</span>,</span><br><span class="line">    transform=ToTensor()</span><br><span class="line">)</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz</span><br><span class="line">Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to data/FashionMNIST/raw/train-images-idx3-ubyte.gz</span><br><span class="line"><span class="meta prompt_">100%</span><span class="language-bash">|██████████| 26.4M/26.4M [00:01&lt;00:00, 14.2MB/s]</span></span><br><span class="line">Extracting data/FashionMNIST/raw/train-images-idx3-ubyte.gz to data/FashionMNIST/raw</span><br><span class="line"></span><br><span class="line">Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz</span><br><span class="line">Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to data/FashionMNIST/raw/train-labels-idx1-ubyte.gz</span><br><span class="line"><span class="meta prompt_">100%</span><span class="language-bash">|██████████| 29.5k/29.5k [00:00&lt;00:00, 232kB/s]</span></span><br><span class="line">Extracting data/FashionMNIST/raw/train-labels-idx1-ubyte.gz to data/FashionMNIST/raw</span><br><span class="line"></span><br><span class="line">Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz</span><br><span class="line">Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz</span><br><span class="line"><span class="meta prompt_">100%</span><span class="language-bash">|██████████| 4.42M/4.42M [00:01&lt;00:00, 4.32MB/s]</span></span><br><span class="line">Extracting data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to data/FashionMNIST/raw</span><br><span class="line"></span><br><span class="line">Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz</span><br><span class="line">Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz</span><br><span class="line"><span class="meta prompt_">100%</span><span class="language-bash">|██████████| 5.15k/5.15k [00:00&lt;00:00, 15.8MB/s]Extracting data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to data/FashionMNIST/raw</span></span><br></pre></td></tr></table></figure><p>国内下载有问题，使用google colab上传代码下载后加载到本地。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">len</span>(train_data),<span class="built_in">len</span>(test_data)</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">(60000, 10000)</span><br></pre></td></tr></table></figure><img src="/2024/08/17/PyTorch-26H-4/PyTorch-26H-4-3.png" class="" title="PyTorch-26H-4-3"><p>查看第一个训练样本：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">image, label = train_data[<span class="number">0</span>]</span><br><span class="line">image, label</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">(tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,...</span><br><span class="line">, 9)</span><br></pre></td></tr></table></figure><h2 id="1-1-Input-and-output-shapes-of-a-computer-vision-model-计算机视觉模型的输入和输出形状"><a href="#1-1-Input-and-output-shapes-of-a-computer-vision-model-计算机视觉模型的输入和输出形状" class="headerlink" title="1.1 Input and output shapes of a computer vision model 计算机视觉模型的输入和输出形状"></a>1.1 Input and output shapes of a computer vision model 计算机视觉模型的输入和输出形状</h2><p>得到了一个很大的值张量（图像），它可以得出目标的单一值（标签）。</p><ul><li>看图像形状</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">image.shape</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.Size([1, 28, 28])</span><br></pre></td></tr></table></figure><p>图像张量的形状<code>[1, 28, 28]</code>具体如下：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[color_channels=1, height=28, width=28]</span><br></pre></td></tr></table></figure><p>有<code>color_channels=1</code>意味着图像是灰度的。</p><img src="/2024/08/17/PyTorch-26H-4/PyTorch-26H-4-4.png" class="" title="PyTorch-26H-4-4"><p>不同的问题会有不同的输入和输出形状。<br>但前提是不变的：将数据编码为数字，建立模型来寻找这些数字中的模式，将这些模式转换成有意义的东西。</p><p>如果<code>color_channels=3</code>，图像的像素值为红、绿和蓝（这也称为RGB 颜色模型）。</p><p>我们当前张量的顺序通常被称为<code>CHW</code>（颜色通道、高度、宽度）。</p><p><strong>关于图像通道，channel last</strong></p><blockquote><p>关于图像应该表示为<code>CHW</code>（颜色通道优先）还是<code>HWC</code>（颜色通道最后）存在争议。<br>注意：还将看到<code>NCHW</code>和<code>NHWC</code>格式，其中<code>N</code>代表图像数量。例如，如果有<code>batch_size=32</code>，则张量形状可能是<code>[32, 1, 28, 28]</code>。我们稍后会介绍批量大小。<br>PyTorch 通常接受<code>NCHW</code>（通道优先）作为许多运算符的默认设置。<br>不过，PyTorch 也解释说<code>NHWC</code>（通道最后）表现更好，被认为是最佳实践<a href="https://pytorch.org/blog/tensor-memory-format-matters/#pytorch-best-practice">considered best practice</a>.。<br>由于我们的数据集和模型相对较小，这不会产生太大的影响。<br>但是当处理更大的图像数据集并使用卷积神经网络时请记住这一点（我们稍后会看到这些）。</p></blockquote><ul><li>检查数据的更多形状</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># How many samples are there? </span></span><br><span class="line"><span class="built_in">len</span>(train_data.data), <span class="built_in">len</span>(train_data.targets), <span class="built_in">len</span>(test_data.data), <span class="built_in">len</span>(test_data.targets)</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">(60000, 60000, 10000, 10000)</span><br></pre></td></tr></table></figure><p>我们有 60,000 个训练样本和 10,000 个测试样本。</p><ul><li>检查数据类别</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># See classes</span></span><br><span class="line">class_names = train_data.classes</span><br><span class="line">class_names</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">[&#x27;T-shirt/top&#x27;,</span><br><span class="line"> &#x27;Trouser&#x27;,</span><br><span class="line"> &#x27;Pullover&#x27;,</span><br><span class="line"> &#x27;Dress&#x27;,</span><br><span class="line"> &#x27;Coat&#x27;,</span><br><span class="line"> &#x27;Sandal&#x27;,</span><br><span class="line"> &#x27;Shirt&#x27;,</span><br><span class="line"> &#x27;Sneaker&#x27;,</span><br><span class="line"> &#x27;Bag&#x27;,</span><br><span class="line"> &#x27;Ankle boot&#x27;]</span><br></pre></td></tr></table></figure><p>10个类别的衣服，意味着多分类模型。</p><h2 id="1-2-Visualizing-our-data"><a href="#1-2-Visualizing-our-data" class="headerlink" title="1.2 Visualizing our data"></a>1.2 Visualizing our data</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">image, label = train_data[<span class="number">0</span>]</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Image shape: <span class="subst">&#123;image.shape&#125;</span>&quot;</span>)</span><br><span class="line">plt.imshow(image.squeeze()) <span class="comment"># image shape is [1, 28, 28] (colour channels, height, width)</span></span><br><span class="line">plt.title(label);</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Image shape: torch.Size([1, 28, 28])</span><br></pre></td></tr></table></figure><img src="/2024/08/17/PyTorch-26H-4/PyTorch-26H-4-5.png" class="" title="PyTorch-26H-4-5"><p>我们可以使用<code>plt.imshow()</code>的<code>cmap</code>参数将图像转换为灰度。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">plt.imshow(image.squeeze(), cmap=<span class="string">&quot;gray&quot;</span>)</span><br><span class="line">plt.title(class_names[label]);</span><br></pre></td></tr></table></figure><img src="/2024/08/17/PyTorch-26H-4/PyTorch-26H-4-6.png" class="" title="PyTorch-26H-4-6"><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Plot more images</span></span><br><span class="line">torch.manual_seed(<span class="number">42</span>)</span><br><span class="line">fig = plt.figure(figsize=(<span class="number">9</span>, <span class="number">9</span>))</span><br><span class="line">rows, cols = <span class="number">4</span>, <span class="number">4</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, rows * cols + <span class="number">1</span>):</span><br><span class="line">    random_idx = torch.randint(<span class="number">0</span>, <span class="built_in">len</span>(train_data), size=[<span class="number">1</span>]).item()</span><br><span class="line">    img, label = train_data[random_idx]</span><br><span class="line">    fig.add_subplot(rows, cols, i)</span><br><span class="line">    plt.imshow(img.squeeze(), cmap=<span class="string">&quot;gray&quot;</span>)</span><br><span class="line">    plt.title(class_names[label])</span><br><span class="line">    plt.axis(<span class="literal">False</span>);</span><br></pre></td></tr></table></figure><img src="/2024/08/17/PyTorch-26H-4/PyTorch-26H-4-7.png" class="" title="PyTorch-26H-4-7"><h1 id="2-Prepare-DataLoader"><a href="#2-Prepare-DataLoader" class="headerlink" title="2. Prepare DataLoader"></a>2. Prepare DataLoader</h1><p>已经准备好数据集了，下一步是用<code>torch.utils.data.DataLoader</code>或准备。</p><p>它有助于将数据加载到模型中，用于训练和推理。</p><p>它将较大的数据转换 <code>Dataset</code> 成由较小块组成的 Python 可迭代数据。<br>这些较小的块称为批次或小批次，可以通过参数设置 <code>batch_size</code>。</p><p>在理想世界中，您可以一次对所有数据进行前向传递和后向传递。<br>但是一旦你开始使用非常大的数据集，除非你拥有无限的计算能力，否则将它们分成几批会更容易。</p><p>对于小批量（数据的一小部分），梯度下降在每个时期执行得更频繁（每个小批量一次，而不是每个时期一次）。合适的批次大小是多少？<a href="https://twitter.com/ylecun/status/989610208497360896?s=20&amp;t=N96J_jotN--PYuJk2WcjMw">32 是一个好的起点</a><br>但由于这是一个您可以设置的值（超参数），您可以尝试各种不同的值，尽管通常最常使用 2 的幂（例如 32、64、128、256、512）。</p><img src="/2024/08/17/PyTorch-26H-4/PyTorch-26H-4-8.png" class="" title="PyTorch-26H-4-8"><p>对 FashionMNIST 进行批处理，批处理大小为 32，并开启随机排序功能。其他数据集也会发生类似的批处理过程，但会根据批处理大小而有所不同。</p><p><a href="https://pytorch.org/docs/stable/data.html">torch.utils.data</a></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> DataLoader</span><br><span class="line"></span><br><span class="line"><span class="comment"># Setup the batch size hyperparameter</span></span><br><span class="line">BATCH_SIZE = <span class="number">32</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Turn datasets into iterables (batches)</span></span><br><span class="line">train_dataloader = DataLoader(train_data, <span class="comment"># dataset to turn into iterable</span></span><br><span class="line">    batch_size=BATCH_SIZE, <span class="comment"># how many samples per batch? </span></span><br><span class="line">    shuffle=<span class="literal">True</span> <span class="comment"># shuffle data every epoch?</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">test_dataloader = DataLoader(test_data,</span><br><span class="line">    batch_size=BATCH_SIZE,</span><br><span class="line">    shuffle=<span class="literal">False</span> <span class="comment"># don&#x27;t necessarily have to shuffle the testing data</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Let&#x27;s check out what we&#x27;ve created</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Dataloaders: <span class="subst">&#123;train_dataloader, test_dataloader&#125;</span>&quot;</span>) </span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Length of train datalo ader: <span class="subst">&#123;<span class="built_in">len</span>(train_dataloader)&#125;</span> batches of <span class="subst">&#123;BATCH_SIZE&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Length of test dataloader: <span class="subst">&#123;<span class="built_in">len</span>(test_dataloader)&#125;</span> batches of <span class="subst">&#123;BATCH_SIZE&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Dataloaders: (&lt;torch.utils.data.dataloader.DataLoader object at 0x00000248133AACA0&gt;, &lt;torch.utils.data.dataloader.DataLoader object at 0x0000024813313580&gt;)</span><br><span class="line">Length of train dataloader: 1875 batches of 32</span><br><span class="line">Length of test dataloader: 313 batches of 32</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Check out what&#x27;s inside the training dataloader</span></span><br><span class="line">train_features_batch, train_labels_batch = <span class="built_in">next</span>(<span class="built_in">iter</span>(train_dataloader))</span><br><span class="line">train_features_batch.shape, train_labels_batch.shape</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">(torch.Size([32, 1, 28, 28]), torch.Size([32]))</span><br></pre></td></tr></table></figure><p>我们通过检查单个样本可以看到数据保持不变。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Show a sample</span></span><br><span class="line">torch.manual_seed(<span class="number">42</span>)</span><br><span class="line">random_idx = torch.randint(<span class="number">0</span>, <span class="built_in">len</span>(train_features_batch), size=[<span class="number">1</span>]).item()</span><br><span class="line">img, label = train_features_batch[random_idx], train_labels_batch[random_idx]</span><br><span class="line">plt.imshow(img.squeeze(), cmap=<span class="string">&quot;gray&quot;</span>)</span><br><span class="line">plt.title(class_names[label])</span><br><span class="line">plt.axis(<span class="string">&quot;Off&quot;</span>);</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Image size: <span class="subst">&#123;img.shape&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Label: <span class="subst">&#123;label&#125;</span>, label size: <span class="subst">&#123;label.shape&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Image size: torch.Size([1, 28, 28])</span><br><span class="line">Label: 6, label size: torch.Size([])</span><br></pre></td></tr></table></figure><img src="/2024/08/17/PyTorch-26H-4/PyTorch-26H-4-9.png" class="" title="PyTorch-26H-4-9"><h1 id="3-Model-0-Build-a-baseline-model-模型-0：建立基线模型"><a href="#3-Model-0-Build-a-baseline-model-模型-0：建立基线模型" class="headerlink" title="3. Model 0: Build a baseline model 模型 0：建立基线模型"></a>3. Model 0: Build a baseline model 模型 0：建立基线模型</h1><p>通过子类化来构建<code>基线模型</code> <code>nn.Module</code>了。</p><p><code>基线模型</code>是你所能想象到的最简单的模型之一。</p><p>您使用基线作为起点，并尝试使用后续更复杂的模型对其进行改进。</p><p>基线模型将由两层组成<code>nn.Linear()</code>。</p><p>因为我们正在处理图像数据，所以我们将使用不同的层来开始。</p><p>这就是<code>nn.Flatten()</code>层。</p><p><code>nn.Flatten()</code>将张量的维度压缩为单个向量。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Create a flatten layer</span></span><br><span class="line">flatten_model = nn.Flatten() <span class="comment"># all nn modules function as a model (can do a forward pass)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Get a single sample</span></span><br><span class="line">x = train_features_batch[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># Flatten the sample</span></span><br><span class="line">output = flatten_model(x) <span class="comment"># perform forward pass</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Print out what happened</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Shape before flattening: <span class="subst">&#123;x.shape&#125;</span> -&gt; [color_channels, height, width]&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Shape after flattening: <span class="subst">&#123;output.shape&#125;</span> -&gt; [color_channels, height*width]&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Try uncommenting below and see what happens</span></span><br><span class="line"><span class="comment">#print(x)</span></span><br><span class="line"><span class="comment">#print(output)</span></span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Shape before flattening: torch.Size([1, 28, 28]) -&gt; [color_channels, height, width]</span><br><span class="line">Shape after flattening: torch.Size([1, 784]) -&gt; [color_channels, height*width]</span><br></pre></td></tr></table></figure><p><code>nn.Flatten()</code>将形状从<code>[color_channels, height, width]</code>变为<code>[color_channels, height*width]</code></p><p>已经将像素数据从高度和宽度维度转换为一个长特征向量。<br>并且<code>nn.Linear()</code>层喜欢将其输入视为特征向量的形式。<br>让我们使用它<code>nn.Flatten()</code>作为第一层来创建我们的第一个模型。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"><span class="keyword">class</span> <span class="title class_">FashionMNISTModelV0</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, input_shape: <span class="built_in">int</span>, hidden_units: <span class="built_in">int</span>, output_shape: <span class="built_in">int</span></span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.layer_stack = nn.Sequential(</span><br><span class="line">            nn.Flatten(), <span class="comment"># neural networks like their inputs in vector form</span></span><br><span class="line">            nn.Linear(in_features=input_shape, out_features=hidden_units), <span class="comment"># in_features = number of features in a data sample (784 pixels)</span></span><br><span class="line">            nn.Linear(in_features=hidden_units, out_features=output_shape)</span><br><span class="line">        )</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        <span class="keyword">return</span> self.layer_stack(x)</span><br></pre></td></tr></table></figure><p>实例化模型，设置以下参数：</p><ul><li><code>input_shape=784</code>，这是模型中所拥有的特征数，在我们的例子中，目标图像中每个像素都有一个特征（28 像素高 x 28 像素宽 = 784 个特征）。</li><li><code>hidden_units=10</code>，隐藏层中的单元/神经元的数量，这个数字可以是任何你想要的，但为了保持模型较小，我们将从开始10。</li><li><code>output_shape=len(class_names)</code>，因为我们正在处理多类分类问题，所以我们需要数据集中每个类一个输出神经元。</li></ul><p>创建模型的一个实例并将其发送到 CPU（我们将很快在 CPU 上运行一个小测试，model_0对比在 GPU 上运行的类似模型）。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">torch.manual_seed(<span class="number">42</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Need to setup model with input parameters</span></span><br><span class="line">model_0 = FashionMNISTModelV0(input_shape=<span class="number">784</span>, <span class="comment"># one for every pixel (28x28)</span></span><br><span class="line">    hidden_units=<span class="number">10</span>, <span class="comment"># how many units in the hidden layer</span></span><br><span class="line">    output_shape=<span class="built_in">len</span>(class_names) <span class="comment"># one for every class</span></span><br><span class="line">)</span><br><span class="line">model_0.to(<span class="string">&quot;cpu&quot;</span>) <span class="comment"># keep model on CPU to begin with </span></span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">FashionMNISTModelV0(</span><br><span class="line">  (layer_stack): Sequential(</span><br><span class="line">    (0): Flatten(start_dim=1, end_dim=-1)</span><br><span class="line">    (1): Linear(in_features=784, out_features=10, bias=True)</span><br><span class="line">    (2): Linear(in_features=10, out_features=10, bias=True)</span><br><span class="line">  )</span><br><span class="line">)</span><br></pre></td></tr></table></figure><h2 id="3-1-Setup-loss-optimizer-and-evaluation-metrics-设置损失、优化器和评估指标"><a href="#3-1-Setup-loss-optimizer-and-evaluation-metrics-设置损失、优化器和评估指标" class="headerlink" title="3.1 Setup loss, optimizer and evaluation metrics 设置损失、优化器和评估指标"></a>3.1 Setup loss, optimizer and evaluation metrics 设置损失、优化器和评估指标</h2><p><code>损失函数</code>：由于我们处理的是多类数据，因此我们的损失函数将是 <code>nn.crossEntropyLoss( )</code><br><code>优化器</code>：我们的优化器 <code>torch.optim.sGD()</code>(随机梯度下降)<br><code>评估指标</code>：由于我们正在处理分类问题，因此我们使用准确率作为评估指标</p><p>因为我们正在研究分类问题，所以我们引入<code>helper_functions.py</code> 脚本，然后引入<code>accuracy_fn()</code> 我们在笔记本 02中定义的脚本。</p><p><strong>您可以从</strong><a href="https://torchmetrics.readthedocs.io/en/latest/">TorchMetrics 包</a>中导入各种评估指标，而不是导入和使用我们自己的准确性函数或评估指标。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">from</span> pathlib <span class="keyword">import</span> Path </span><br><span class="line"></span><br><span class="line"><span class="comment"># Download helper functions from Learn PyTorch repo (if not already downloaded)</span></span><br><span class="line"><span class="keyword">if</span> Path(<span class="string">&quot;helper_functions.py&quot;</span>).is_file():</span><br><span class="line">  <span class="built_in">print</span>(<span class="string">&quot;helper_functions.py already exists, skipping download&quot;</span>)</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">  <span class="built_in">print</span>(<span class="string">&quot;Downloading helper_functions.py&quot;</span>)</span><br><span class="line">  <span class="comment"># Note: you need the &quot;raw&quot; GitHub URL for this to work</span></span><br><span class="line">  request = requests.get(<span class="string">&quot;https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/helper_functions.py&quot;</span>)</span><br><span class="line">  <span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&quot;helper_functions.py&quot;</span>, <span class="string">&quot;wb&quot;</span>) <span class="keyword">as</span> f:</span><br><span class="line">    f.write(request.content)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Import accuracy metric</span></span><br><span class="line"><span class="comment"># 导入准确度指标</span></span><br><span class="line"><span class="keyword">from</span> helper_functions <span class="keyword">import</span> accuracy_fn <span class="comment"># Note: could also use torchmetrics.Accuracy(task = &#x27;multiclass&#x27;, num_classes=len(class_names)).to(device)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Setup loss function and optimizer</span></span><br><span class="line"><span class="comment"># 设置损失函数和优化器</span></span><br><span class="line">loss_fn = nn.CrossEntropyLoss() <span class="comment"># this is also called &quot;criterion&quot;/&quot;cost function&quot; in some places</span></span><br><span class="line"><span class="comment"># 在某些地方这也被称为“标准”/“成本函数”</span></span><br><span class="line">optimizer = torch.optim.SGD(params=model_0.parameters(), lr=<span class="number">0.1</span>)</span><br></pre></td></tr></table></figure><h2 id="3-2-Creating-a-function-to-time-our-experiments-创建一个函数来计时我们的实验"><a href="#3-2-Creating-a-function-to-time-our-experiments-创建一个函数来计时我们的实验" class="headerlink" title="3.2 Creating a function to time our experiments 创建一个函数来计时我们的实验"></a>3.2 Creating a function to time our experiments 创建一个函数来计时我们的实验</h2><p>机器学习非常具有实验性。<br>您经常想要跟踪的两个主要内容是：</p><ol><li>模型的性能（损失和准确度值等）</li><li>运行速度</li></ol><p>制作一个计时函数来测量我们的模型在 CPU 上训练所需的时间与使用 GPU 所需的时间。</p><p>我们将在 CPU 上训练这个模型，然后在 GPU 上训练下一个模型，看看会发生什么。</p><p>我们的计时函数将从Python <a href="https://docs.python.org/3/library/timeit.html">timeit</a> 模块导入<a href="https://docs.python.org/3/library/timeit.html#timeit.default_timer">timeit.default_timer()</a> 函数。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> timeit <span class="keyword">import</span> default_timer <span class="keyword">as</span> timer </span><br><span class="line"><span class="keyword">def</span> <span class="title function_">print_train_time</span>(<span class="params">start: <span class="built_in">float</span>, end: <span class="built_in">float</span>, device: torch.device = <span class="literal">None</span></span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Prints difference between start and end time.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        start (float): Start time of computation (preferred in timeit format). </span></span><br><span class="line"><span class="string">        end (float): End time of computation.</span></span><br><span class="line"><span class="string">        device ([type], optional): Device that compute is running on. Defaults to None.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">        float: time between start and end in seconds (higher is longer).</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    total_time = end - start</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;Train time on <span class="subst">&#123;device&#125;</span>: <span class="subst">&#123;total_time:<span class="number">.3</span>f&#125;</span> seconds&quot;</span>)</span><br><span class="line">    <span class="keyword">return</span> total_time</span><br></pre></td></tr></table></figure><h2 id="3-3-Creating-a-training-loop-and-training-a-model-on-batches-of-data-创建训练循环并在批量数据上训练模型"><a href="#3-3-Creating-a-training-loop-and-training-a-model-on-batches-of-data-创建训练循环并在批量数据上训练模型" class="headerlink" title="3.3 Creating a training loop and training a model on batches of data 创建训练循环并在批量数据上训练模型"></a>3.3 Creating a training loop and training a model on batches of data 创建训练循环并在批量数据上训练模型</h2><p>已经准备的东西：一个计时器、一个损失函数、一个优化器、一个模型。</p><p>创建一个训练循环和一个测试循环来训练和评估我们的模型。</p><p>我们将使用与以前的笔记本相同的步骤，但由于我们的数据现在是批量形式，我们将添加另一个循环来循环遍历我们的数据批次。</p><p>我们的数据批次包含在我们的<code>DataLoaders</code> 中，<code>train_dataloader</code>分别<code>test_dataloader</code>用于训练和测试数据分割。</p><p>一个批次是 <code>X</code>（特征）和 <code>y</code>（标签）的 <code>BATCH_SIZE</code> 个样本，因为我们使用 <code>BATCH_SIZE=32</code>，所以我们的批次有 32 个图像和目标样本。</p><p>由于我们正在对批量数据进行计算，因此我们的损失和评估指标将按批次计算，而不是按整个数据集计算。</p><p>这意味着我们必须将损失和准确度值除以每个数据集各自的数据加载器中的批次数。</p><p>让我们逐步进行：</p><p>1、循环历经各个时期。<br>2、循环训练批次，执行训练步骤，计算每个批次的 train loss 训练损失。<br>3、循环测试批次，执行测试步骤，计算每个批次的 test loss 测试损失。<br>4、打印出正在发生的事情。<br>5、计时全部内容（为了好玩）。</p><p><a href="https://github.com/tqdm/tqdm">tqdm</a> ：开源的进度条，colab内置了tqdm，不需要导入。只需要将tqdm装入迭代器就可以使用。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Import tqdm for progress bar</span></span><br><span class="line"><span class="keyword">from</span> tqdm.auto <span class="keyword">import</span> tqdm</span><br><span class="line"></span><br><span class="line"><span class="comment"># Set the seed and start the timer</span></span><br><span class="line">torch.manual_seed(<span class="number">42</span>)</span><br><span class="line">train_time_start_on_cpu = timer()</span><br><span class="line"></span><br><span class="line"><span class="comment"># Set the number of epochs (we&#x27;ll keep this small for faster training times)</span></span><br><span class="line">epochs = <span class="number">3</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Create training and testing loop</span></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> tqdm(<span class="built_in">range</span>(epochs)):</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;Epoch: <span class="subst">&#123;epoch&#125;</span>\n-------&quot;</span>)</span><br><span class="line">    <span class="comment">### Training</span></span><br><span class="line">    train_loss = <span class="number">0</span></span><br><span class="line">    <span class="comment"># Add a loop to loop through training batches</span></span><br><span class="line">    <span class="keyword">for</span> batch, (X, y) <span class="keyword">in</span> <span class="built_in">enumerate</span>(train_dataloader):</span><br><span class="line">        model_0.train() </span><br><span class="line">        <span class="comment"># 1. Forward pass</span></span><br><span class="line">        y_pred = model_0(X)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 2. Calculate loss (per batch)</span></span><br><span class="line">        loss = loss_fn(y_pred, y)</span><br><span class="line">        train_loss += loss <span class="comment"># accumulatively add up the loss per epoch </span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 3. Optimizer zero grad</span></span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 4. Loss backward</span></span><br><span class="line">        loss.backward()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 5. Optimizer step</span></span><br><span class="line">        optimizer.step()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Print out how many samples have been seen</span></span><br><span class="line">        <span class="keyword">if</span> batch % <span class="number">400</span> == <span class="number">0</span>:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&quot;Looked at <span class="subst">&#123;batch * <span class="built_in">len</span>(X)&#125;</span>/<span class="subst">&#123;<span class="built_in">len</span>(train_dataloader.dataset)&#125;</span> samples&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Divide total train loss by length of train dataloader (average loss per batch per epoch)</span></span><br><span class="line">    train_loss /= <span class="built_in">len</span>(train_dataloader)</span><br><span class="line">    </span><br><span class="line">    <span class="comment">### Testing</span></span><br><span class="line">    <span class="comment"># Setup variables for accumulatively adding up loss and accuracy </span></span><br><span class="line">    test_loss, test_acc = <span class="number">0</span>, <span class="number">0</span> </span><br><span class="line">    model_0.<span class="built_in">eval</span>()</span><br><span class="line">    <span class="keyword">with</span> torch.inference_mode():</span><br><span class="line">        <span class="keyword">for</span> X, y <span class="keyword">in</span> test_dataloader:</span><br><span class="line">            <span class="comment"># 1. Forward pass</span></span><br><span class="line">            test_pred = model_0(X)</span><br><span class="line">           </span><br><span class="line">            <span class="comment"># 2. Calculate loss (accumulatively)</span></span><br><span class="line">            test_loss += loss_fn(test_pred, y) <span class="comment"># accumulatively add up the loss per epoch</span></span><br><span class="line"></span><br><span class="line">            <span class="comment"># 3. Calculate accuracy (preds need to be same as y_true)</span></span><br><span class="line">            test_acc += accuracy_fn(y_true=y, y_pred=test_pred.argmax(dim=<span class="number">1</span>))</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Calculations on test metrics need to happen inside torch.inference_mode()</span></span><br><span class="line">        <span class="comment"># Divide total test loss by length of test dataloader (per batch)</span></span><br><span class="line">        test_loss /= <span class="built_in">len</span>(test_dataloader)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Divide total accuracy by length of test dataloader (per batch)</span></span><br><span class="line">        test_acc /= <span class="built_in">len</span>(test_dataloader)</span><br><span class="line"></span><br><span class="line">    <span class="comment">## Print out what&#x27;s happening</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;\nTrain loss: <span class="subst">&#123;train_loss:<span class="number">.5</span>f&#125;</span> | Test loss: <span class="subst">&#123;test_loss:<span class="number">.5</span>f&#125;</span>, Test acc: <span class="subst">&#123;test_acc:<span class="number">.2</span>f&#125;</span>%\n&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Calculate training time      </span></span><br><span class="line">train_time_end_on_cpu = timer()</span><br><span class="line">total_train_time_model_0 = print_train_time(start=train_time_start_on_cpu, </span><br><span class="line">                                           end=train_time_end_on_cpu,</span><br><span class="line">                                           device=<span class="built_in">str</span>(<span class="built_in">next</span>(model_0.parameters()).device))</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">Epoch: 0</span><br><span class="line">-------</span><br><span class="line">Looked at 0/60000 samples</span><br><span class="line">Looked at 12800/60000 samples</span><br><span class="line">Looked at 25600/60000 samples</span><br><span class="line">Looked at 38400/60000 samples</span><br><span class="line">Looked at 51200/60000 samples</span><br><span class="line"></span><br><span class="line">Train loss: 0.59039 | Test loss: 0.50954, Test acc: 82.04%</span><br><span class="line"></span><br><span class="line">Epoch: 1</span><br><span class="line">-------</span><br><span class="line">Looked at 0/60000 samples</span><br><span class="line">Looked at 12800/60000 samples</span><br><span class="line">Looked at 25600/60000 samples</span><br><span class="line">Looked at 38400/60000 samples</span><br><span class="line">Looked at 51200/60000 samples</span><br><span class="line"></span><br><span class="line">Train loss: 0.47633 | Test loss: 0.47989, Test acc: 83.20%</span><br><span class="line"></span><br><span class="line">Epoch: 2</span><br><span class="line">-------</span><br><span class="line">Looked at 0/60000 samples</span><br><span class="line">Looked at 12800/60000 samples</span><br><span class="line">Looked at 25600/60000 samples</span><br><span class="line">Looked at 38400/60000 samples</span><br><span class="line">Looked at 51200/60000 samples</span><br><span class="line"></span><br><span class="line">Train loss: 0.45503 | Test loss: 0.47664, Test acc: 83.43%</span><br><span class="line"></span><br><span class="line">Train time on cpu: 44.767 seconds</span><br></pre></td></tr></table></figure><h1 id="4-Make-predictions-and-get-Model-0-results-进行预测并获取模型-0-结果"><a href="#4-Make-predictions-and-get-Model-0-results-进行预测并获取模型-0-结果" class="headerlink" title="4. Make predictions and get Model 0 results 进行预测并获取模型 0 结果"></a>4. Make predictions and get Model 0 results 进行预测并获取模型 0 结果</h1><p>创建一个函数，它包含一个训练好的模型、一个DataLoader、一个损失函数和一个准确度函数。</p><p>该函数将使用模型对数据进行预测DataLoader，然后我们可以使用损失函数和准确度函数评估这些预测。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line">torch.manual_seed(<span class="number">42</span>)</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">eval_model</span>(<span class="params">model: torch.nn.Module, </span></span><br><span class="line"><span class="params">               data_loader: torch.utils.data.DataLoader, </span></span><br><span class="line"><span class="params">               loss_fn: torch.nn.Module, </span></span><br><span class="line"><span class="params">               accuracy_fn</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Returns a dictionary containing the results of model predicting on data_loader.返回包含 data_loader 模型预测结果的字典。</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        model (torch.nn.Module): A PyTorch model capable of making predictions on data_loader.能够对 data_loader 进行预测的 PyTorch 模型。</span></span><br><span class="line"><span class="string">        data_loader (torch.utils.data.DataLoader): The target dataset to predict on.要进行预测的目标数据集。</span></span><br><span class="line"><span class="string">        loss_fn (torch.nn.Module): The loss function of model.模型的损失函数。</span></span><br><span class="line"><span class="string">        accuracy_fn: An accuracy function to compare the models predictions to the truth labels.用于将模型预测与真实标签进行比较的准确度函数。</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">        (dict): Results of model making predictions on data_loader.模型对 data_loader 进行预测的结果。</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    loss, acc = <span class="number">0</span>, <span class="number">0</span></span><br><span class="line">    model.<span class="built_in">eval</span>()</span><br><span class="line">    <span class="keyword">with</span> torch.inference_mode():</span><br><span class="line">        <span class="keyword">for</span> X, y <span class="keyword">in</span> tqdm(data_loader):</span><br><span class="line">            <span class="comment"># Make predictions with the model</span></span><br><span class="line">            y_pred = model(X)</span><br><span class="line">            </span><br><span class="line">            <span class="comment"># Accumulate the loss and accuracy values per batch</span></span><br><span class="line">            loss += loss_fn(y_pred, y)</span><br><span class="line">            acc += accuracy_fn(y_true=y, </span><br><span class="line">                                y_pred=y_pred.argmax(dim=<span class="number">1</span>)) <span class="comment"># For accuracy, need the prediction labels (logits -&gt; pred_prob -&gt; pred_labels)</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Scale loss and acc to find the average loss/acc per batch放损失和 acc 以找到每批的平均损失/ acc</span></span><br><span class="line">        loss /= <span class="built_in">len</span>(data_loader)</span><br><span class="line">        acc /= <span class="built_in">len</span>(data_loader)</span><br><span class="line">        </span><br><span class="line">    <span class="keyword">return</span> &#123;<span class="string">&quot;model_name&quot;</span>: model.__class__.__name__, <span class="comment"># only works when model was created with a class</span></span><br><span class="line">            <span class="string">&quot;model_loss&quot;</span>: loss.item(),</span><br><span class="line">            <span class="string">&quot;model_acc&quot;</span>: acc&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># Calculate model 0 results on test dataset</span></span><br><span class="line">model_0_results = eval_model(model=model_0, data_loader=test_dataloader,</span><br><span class="line">    loss_fn=loss_fn, accuracy_fn=accuracy_fn</span><br><span class="line">)</span><br><span class="line">model_0_results</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&#123;&#x27;model_name&#x27;: &#x27;FashionMNISTModelV0&#x27;,</span><br><span class="line"> &#x27;model_loss&#x27;: 0.47663888335227966,</span><br><span class="line"> &#x27;model_acc&#x27;: 83.42651757188499&#125;</span><br></pre></td></tr></table></figure><p>可以使用这个词典将基线模型结果与其他模型进行比较。</p><p>模型训练时间取决于所用的硬件。通常，处理器越多意味着训练速度越快，较小数据集上的较小模型通常比大型模型和大型数据集训练速度更快。</p><h1 id="5-Setup-device-agnostic-code-for-using-a-GPU-if-there-is-one-设置设备无关代码（如果有-GPU-则使用-GPU）"><a href="#5-Setup-device-agnostic-code-for-using-a-GPU-if-there-is-one-设置设备无关代码（如果有-GPU-则使用-GPU）" class="headerlink" title="5. Setup device agnostic-code (for using a GPU if there is one)设置设备无关代码（如果有 GPU 则使用 GPU）"></a>5. Setup device agnostic-code (for using a GPU if there is one)设置设备无关代码（如果有 GPU 则使用 GPU）</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Setup device agnostic code</span></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line">device = <span class="string">&quot;cuda&quot;</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&quot;cpu&quot;</span></span><br><span class="line">device</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cuda</span><br></pre></td></tr></table></figure><h1 id="6-Model-1-Building-a-better-model-with-non-linearity-构建更好的非线性模型"><a href="#6-Model-1-Building-a-better-model-with-non-linearity-构建更好的非线性模型" class="headerlink" title="6. Model 1: Building a better model with non-linearity 构建更好的非线性模型"></a>6. Model 1: Building a better model with non-linearity 构建更好的非线性模型</h1><p>我们将通过重新创建与之前类似的模型来实现此目的，但这次我们将在每个线性层之间放置非线性函数（<code>nn.ReLU()</code>）。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Create a model with non-linear and linear layers</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">FashionMNISTModelV1</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, input_shape: <span class="built_in">int</span>, hidden_units: <span class="built_in">int</span>, output_shape: <span class="built_in">int</span></span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.layer_stack = nn.Sequential(</span><br><span class="line">            nn.Flatten(), <span class="comment"># flatten inputs into single vector</span></span><br><span class="line">            nn.Linear(in_features=input_shape, out_features=hidden_units),</span><br><span class="line">            nn.ReLU(),</span><br><span class="line">            nn.Linear(in_features=hidden_units, out_features=output_shape),</span><br><span class="line">            nn.ReLU()</span><br><span class="line">        )</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x: torch.Tensor</span>):</span><br><span class="line">        <span class="keyword">return</span> self.layer_stack(x)</span><br></pre></td></tr></table></figure><p>用之前使用的相同设置来实例化它。我们需要<code>input_shape=784</code>（等于我们的图像数据的特征数量）、<code>hidden_units=10</code>（从小处开始并与我们的基线模型相同）和<code>output_shape=len(class_names)</code>（每个类一个输出单元）。</p><blockquote><p>除了添加非线性层之外，我们保持模型的大多数设置不变。这是运行一系列机器学习实验的标准做法，更改一件事并查看会发生什么，然后重复、重复、重复。</p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">torch.manual_seed(<span class="number">42</span>)</span><br><span class="line">model_1 = FashionMNISTModelV1(input_shape=<span class="number">784</span>, <span class="comment"># number of input features</span></span><br><span class="line">    hidden_units=<span class="number">10</span>,</span><br><span class="line">    output_shape=<span class="built_in">len</span>(class_names) <span class="comment"># number of output classes desired</span></span><br><span class="line">).to(device) <span class="comment"># send model to GPU if it&#x27;s available</span></span><br><span class="line"><span class="built_in">next</span>(model_1.parameters()).device <span class="comment"># check model device</span></span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">device(type=&#x27;cuda&#x27;, index=0)</span><br></pre></td></tr></table></figure><h2 id="6-1-Setup-loss-optimizer-and-evaluation-metrics-设置损失、优化器和评估指标"><a href="#6-1-Setup-loss-optimizer-and-evaluation-metrics-设置损失、优化器和评估指标" class="headerlink" title="6.1 Setup loss, optimizer and evaluation metrics 设置损失、优化器和评估指标"></a>6.1 Setup loss, optimizer and evaluation metrics 设置损失、优化器和评估指标</h2><p>像往常一样，我们将设置一个损失函数、一个优化器和一个评估指标（我们可以做多个评估指标，但目前我们将坚持准确性）</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> helper_functions <span class="keyword">import</span> accuracy_fn</span><br><span class="line">loss_fn = nn.CrossEntropyLoss()</span><br><span class="line">optimizer = torch.optim.SGD(params=model_1.parameters(), </span><br><span class="line">                            lr=<span class="number">0.1</span>)</span><br></pre></td></tr></table></figure><h2 id="6-2-Functionizing-training-and-evaluation-testing-loops-功能化训练和测试循环"><a href="#6-2-Functionizing-training-and-evaluation-testing-loops-功能化训练和测试循环" class="headerlink" title="6.2 Functionizing training and evaluation/testing loops 功能化训练和测试循环"></a>6.2 Functionizing training and evaluation/testing loops 功能化训练和测试循环</h2><p>training loop - train_step()<br>testing loop - test_step()</p><p>到目前为止，我们一直在反复编写训练和测试循环。</p><p>让我们再次编写它们，但这次我们将把它们放在函数中，以便可以反复调用它们。</p><p>而且因为我们现在使用的是与设备无关的代码，所以我们一定要在特征 (X) 和目标 (y) 张量上调用 .to(device)。</p><p>对于训练循环，我们将创建一个名为 <code>train_step()</code> 的函数，它接受一个模型、一个 DataLoader、一个损失函数和一个优化器。</p><p>测试循环将类似，但它将被称为 <code>test_step()</code>，它将接受一个模型、一个 DataLoader、一个损失函数和一个评估函数。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">train_step</span>(<span class="params">model: torch.nn.Module,</span></span><br><span class="line"><span class="params">               data_loader: torch.utils.data.DataLoader,</span></span><br><span class="line"><span class="params">               loss_fn: torch.nn.Module,</span></span><br><span class="line"><span class="params">               optimizer: torch.optim.Optimizer,</span></span><br><span class="line"><span class="params">               accuracy_fn,</span></span><br><span class="line"><span class="params">               device: torch.device = device</span>):</span><br><span class="line">    train_loss, train_acc = <span class="number">0</span>, <span class="number">0</span></span><br><span class="line">    model.to(device)</span><br><span class="line">    <span class="keyword">for</span> batch, (X, y) <span class="keyword">in</span> <span class="built_in">enumerate</span>(data_loader):</span><br><span class="line">        <span class="comment"># Send data to GPU</span></span><br><span class="line">        X, y = X.to(device), y.to(device)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 1. Forward pass</span></span><br><span class="line">        y_pred = model(X)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 2. Calculate loss</span></span><br><span class="line">        loss = loss_fn(y_pred, y)</span><br><span class="line">        train_loss += loss</span><br><span class="line">        train_acc += accuracy_fn(y_true=y,</span><br><span class="line">                                 y_pred=y_pred.argmax(dim=<span class="number">1</span>)) <span class="comment"># Go from logits -&gt; pred labels</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 3. Optimizer zero grad</span></span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 4. Loss backward</span></span><br><span class="line">        loss.backward()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 5. Optimizer step</span></span><br><span class="line">        optimizer.step()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Calculate loss and accuracy per epoch and print out what&#x27;s happening</span></span><br><span class="line">    train_loss /= <span class="built_in">len</span>(data_loader)</span><br><span class="line">    train_acc /= <span class="built_in">len</span>(data_loader)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;Train loss: <span class="subst">&#123;train_loss:<span class="number">.5</span>f&#125;</span> | Train accuracy: <span class="subst">&#123;train_acc:<span class="number">.2</span>f&#125;</span>%&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">test_step</span>(<span class="params">data_loader: torch.utils.data.DataLoader,</span></span><br><span class="line"><span class="params">              model: torch.nn.Module,</span></span><br><span class="line"><span class="params">              loss_fn: torch.nn.Module,</span></span><br><span class="line"><span class="params">              accuracy_fn,</span></span><br><span class="line"><span class="params">              device: torch.device = device</span>):</span><br><span class="line">    test_loss, test_acc = <span class="number">0</span>, <span class="number">0</span></span><br><span class="line">    model.to(device)</span><br><span class="line">    model.<span class="built_in">eval</span>() <span class="comment"># put model in eval mode</span></span><br><span class="line">    <span class="comment"># Turn on inference context manager</span></span><br><span class="line">    <span class="keyword">with</span> torch.inference_mode(): </span><br><span class="line">        <span class="keyword">for</span> X, y <span class="keyword">in</span> data_loader:</span><br><span class="line">            <span class="comment"># Send data to GPU</span></span><br><span class="line">            X, y = X.to(device), y.to(device)</span><br><span class="line">            </span><br><span class="line">            <span class="comment"># 1. Forward pass</span></span><br><span class="line">            test_pred = model(X)</span><br><span class="line">            </span><br><span class="line">            <span class="comment"># 2. Calculate loss and accuracy</span></span><br><span class="line">            test_loss += loss_fn(test_pred, y)</span><br><span class="line">            test_acc += accuracy_fn(y_true=y,</span><br><span class="line">                y_pred=test_pred.argmax(dim=<span class="number">1</span>) <span class="comment"># Go from logits -&gt; pred labels</span></span><br><span class="line">            )</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Adjust metrics and print out</span></span><br><span class="line">        test_loss /= <span class="built_in">len</span>(data_loader)</span><br><span class="line">        test_acc /= <span class="built_in">len</span>(data_loader)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;Test loss: <span class="subst">&#123;test_loss:<span class="number">.5</span>f&#125;</span> | Test accuracy: <span class="subst">&#123;test_acc:<span class="number">.2</span>f&#125;</span>%\n&quot;</span>)</span><br></pre></td></tr></table></figure><blockquote><p>可以自定义执行测试步骤的频率。有时人们每 5 个 epoch 或 10 个 epoch 执行一次，或者在我们的情况下，每个 epoch 执行一次。</p></blockquote><p>计时一下，看看代码在 GPU 上运行需要多长时间。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">torch.manual_seed(<span class="number">42</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Measure time</span></span><br><span class="line"><span class="keyword">from</span> timeit <span class="keyword">import</span> default_timer <span class="keyword">as</span> timer</span><br><span class="line">train_time_start_on_gpu = timer()</span><br><span class="line"></span><br><span class="line">epochs = <span class="number">3</span></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> tqdm(<span class="built_in">range</span>(epochs)):</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;Epoch: <span class="subst">&#123;epoch&#125;</span>\n---------&quot;</span>)</span><br><span class="line">    train_step(data_loader=train_dataloader, </span><br><span class="line">        model=model_1, </span><br><span class="line">        loss_fn=loss_fn,</span><br><span class="line">        optimizer=optimizer,</span><br><span class="line">        accuracy_fn=accuracy_fn</span><br><span class="line">    )</span><br><span class="line">    test_step(data_loader=test_dataloader,</span><br><span class="line">        model=model_1,</span><br><span class="line">        loss_fn=loss_fn,</span><br><span class="line">        accuracy_fn=accuracy_fn</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">train_time_end_on_gpu = timer()</span><br><span class="line">total_train_time_model_1 = print_train_time(start=train_time_start_on_gpu,</span><br><span class="line">                                            end=train_time_end_on_gpu,</span><br><span class="line">                                            device=device)</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">Epoch: 0</span><br><span class="line">---------</span><br><span class="line">Train loss: 1.09199 | Train accuracy: 61.34%</span><br><span class="line">Test loss: 0.95636 | Test accuracy: 65.00%</span><br><span class="line"></span><br><span class="line">Epoch: 1</span><br><span class="line">---------</span><br><span class="line">Train loss: 0.78101 | Train accuracy: 71.93%</span><br><span class="line">Test loss: 0.72227 | Test accuracy: 73.91%</span><br><span class="line"></span><br><span class="line">Epoch: 2</span><br><span class="line">---------</span><br><span class="line">Train loss: 0.67027 | Train accuracy: 75.94%</span><br><span class="line">Test loss: 0.68500 | Test accuracy: 75.02%</span><br><span class="line"></span><br><span class="line">Train time on cuda: 41.929 seconds</span><br></pre></td></tr></table></figure><blockquote><p>CUDA 与 CPU 上的训练时间在很大程度上取决于您使用的 CPU/GPU 的质量。<br>问：“我使用了 GPU，但我的模型训练速度并没有更快，这可能是为什么？”<br>答：一个原因可能是因为数据集和模型都太小（就像我们正在处理的数据集和模型一样），使用 GPU 的好处被实际将数据传输到那里所需的时间所抵消。将数据从 CPU 内存（默认）复制到 GPU 内存之间存在一个小瓶颈。因此，对于较小的模型和数据集，CPU 实际上可能是计算的最佳位置。<br>但对于更大的数据集和模型，GPU 提供的计算速度通常远远超过获取数据的成本。不过，这很大程度上取决于使用的硬件。通过练习，你会习惯训练模型的最佳位置。</p></blockquote><p>让<code>model_1</code>使用<code>eval_model()</code>函数来评估训练并看看它进展如何。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">torch.manual_seed(<span class="number">42</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Note: This will error due to `eval_model()` not using device agnostic code </span></span><br><span class="line">model_1_results = eval_model(model=model_1, </span><br><span class="line">    data_loader=test_dataloader,</span><br><span class="line">    loss_fn=loss_fn, </span><br><span class="line">    accuracy_fn=accuracy_fn) </span><br><span class="line">model_1_results </span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument mat1 in method wrapper_CUDA_addmm)</span><br></pre></td></tr></table></figure><p>这是因为已经设置了数据和模型来使用与设备无关的代码，但没有设置评估函数。<br>如何通过将目标<code>device</code>参数传递给<code>eval_model()</code>函数来解决这个问题？</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Move values to device</span></span><br><span class="line">torch.manual_seed(<span class="number">42</span>)</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">eval_model</span>(<span class="params">model: torch.nn.Module, </span></span><br><span class="line"><span class="params">               data_loader: torch.utils.data.DataLoader, </span></span><br><span class="line"><span class="params">               loss_fn: torch.nn.Module, </span></span><br><span class="line"><span class="params">               accuracy_fn, </span></span><br><span class="line"><span class="params">               device: torch.device = device</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Evaluates a given model on a given dataset.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        model (torch.nn.Module): A PyTorch model capable of making predictions on data_loader.</span></span><br><span class="line"><span class="string">        data_loader (torch.utils.data.DataLoader): The target dataset to predict on.</span></span><br><span class="line"><span class="string">        loss_fn (torch.nn.Module): The loss function of model.</span></span><br><span class="line"><span class="string">        accuracy_fn: An accuracy function to compare the models predictions to the truth labels.</span></span><br><span class="line"><span class="string">        device (str, optional): Target device to compute on. Defaults to device.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">        (dict): Results of model making predictions on data_loader.</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    loss, acc = <span class="number">0</span>, <span class="number">0</span></span><br><span class="line">    model.<span class="built_in">eval</span>()</span><br><span class="line">    <span class="keyword">with</span> torch.inference_mode():</span><br><span class="line">        <span class="keyword">for</span> X, y <span class="keyword">in</span> data_loader:</span><br><span class="line">            <span class="comment"># Send data to the target device</span></span><br><span class="line">            X, y = X.to(device), y.to(device)</span><br><span class="line">            y_pred = model(X)</span><br><span class="line">            loss += loss_fn(y_pred, y)</span><br><span class="line">            acc += accuracy_fn(y_true=y, y_pred=y_pred.argmax(dim=<span class="number">1</span>))</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Scale loss and acc</span></span><br><span class="line">        loss /= <span class="built_in">len</span>(data_loader)</span><br><span class="line">        acc /= <span class="built_in">len</span>(data_loader)</span><br><span class="line">    <span class="keyword">return</span> &#123;<span class="string">&quot;model_name&quot;</span>: model.__class__.__name__, <span class="comment"># only works when model was created with a class</span></span><br><span class="line">            <span class="string">&quot;model_loss&quot;</span>: loss.item(),</span><br><span class="line">            <span class="string">&quot;model_acc&quot;</span>: acc&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># Calculate model 1 results with device-agnostic code </span></span><br><span class="line">model_1_results = eval_model(model=model_1, data_loader=test_dataloader,</span><br><span class="line">    loss_fn=loss_fn, accuracy_fn=accuracy_fn,</span><br><span class="line">    device=device</span><br><span class="line">)</span><br><span class="line">model_1_results</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&#123;&#x27;model_name&#x27;: &#x27;FashionMNISTModelV1&#x27;,</span><br><span class="line"> &#x27;model_loss&#x27;: 0.6850008964538574,</span><br><span class="line"> &#x27;model_acc&#x27;: 75.01996805111821&#125;</span><br></pre></td></tr></table></figure><p>在这种情况下，在模型中添加非线性似乎使得它的性能比基线更差。<br>这是机器学习中需要注意的一点，有时你认为应该起作用的东西却不起作用。<br>然后，你原本认为可能行不通的事情却真的发生了。<br>它既是科学，又是艺术。</p><p>从表面上看，我们的模型似乎对训练数据<strong>过度拟合</strong>。<br>过度拟合意味着我们的模型很好地学习了训练数据，但是这些模式不能推广到测试数据。</p><p><strong>解决过度拟合的两种主要方法包括：<br>1、使用较小或不同的模型（某些模型比其他模型更适合某些类型的数据）。<br>2、使用更大的数据集（数据越多，模型学习可概括模式的机会就越大）。</strong></p><h1 id="7-Model-2-Building-a-Convolutional-Neural-Network-CNN-模型2：建立卷积神经网络（CNN）"><a href="#7-Model-2-Building-a-Convolutional-Neural-Network-CNN-模型2：建立卷积神经网络（CNN）" class="headerlink" title="7. Model 2: Building a Convolutional Neural Network (CNN)模型2：建立卷积神经网络（CNN）"></a>7. Model 2: Building a Convolutional Neural Network (CNN)模型2：建立卷积神经网络（CNN）</h1><p>现在是时候创建一个<a href="https://en.wikipedia.org/wiki/Convolutional_neural_network">卷积神经网络</a>（CNN 或 ConvNet）了</p><p>由于我们处理的是视觉数据，让我们看看使用 CNN 模型是否可以改进我们的基线。</p><p>我们将要使用的 CNN 模型是来自<a href="https://poloclub.github.io/cnn-explainer/">CNN Explainer</a>网站的 TinyVGG。</p><p>它遵循卷积神经网络的典型结构：</p><p><code>Input layer -&gt; [Convolutional layer -&gt; activation layer -&gt; pooling layer] -&gt; Output layer</code></p><p>根据需要，其中的内容<code>[Convolutional layer -&gt; activation layer -&gt; pooling layer]</code>可以放大和重复多次。</p><h2 id="What-model-should-I-use-我应该使用什么模型？"><a href="#What-model-should-I-use-我应该使用什么模型？" class="headerlink" title="What model should I use?我应该使用什么模型？"></a>What model should I use?我应该使用什么模型？</h2><div class="table-container"><table><thead><tr><th style="text-align:center">问题类型</th><th style="text-align:center">使用的模型（一般）</th><th style="text-align:center">代码示例</th></tr></thead><tbody><tr><td style="text-align:center">结构化数据（Excel 电子表格、行和列数据）</td><td style="text-align:center">Gradient boosted models梯度增强模型、Random Forests随机森林、XGBoost</td><td style="text-align:center"><a href="https://scikit-learn.org/stable/modules/classes.html#module-sklearn.ensemble"><code>sklearn.ensemble</code></a>, <a href="https://xgboost.readthedocs.io/en/stable/">XGBoost library</a></td></tr><tr><td style="text-align:center">非结构化数据（图像、音频、语言）</td><td style="text-align:center">Convolutional Neural卷积神经网络、Transformer</td><td style="text-align:center"><a href="https://pytorch.org/vision/stable/models.html"><code>torchvision.models</code></a>, <a href="https://huggingface.co/docs/transformers/index">HuggingFace Transformers</a></td></tr></tbody></table></div><p><a href="https://poloclub.github.io/cnn-explainer/">关于模型的讨论已经足够了，现在让我们构建一个 CNN 来复制CNN Explainer 网站</a>上的模型。</p><p>为此，我们将利用<a href="https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html"><code>nn.Conv2d()</code></a>和<a href="https://pytorch.org/docs/stable/generated/torch.nn.MaxPool2d.html"><code>nn.MaxPool2d()</code></a>层<code>torch.nn</code>。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Create a convolutional neural network </span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">FashionMNISTModelV2</span>(nn.Module):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Model architecture copying TinyVGG from: </span></span><br><span class="line"><span class="string">    https://poloclub.github.io/cnn-explainer/</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, input_shape: <span class="built_in">int</span>, hidden_units: <span class="built_in">int</span>, output_shape: <span class="built_in">int</span></span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.block_1 = nn.Sequential(</span><br><span class="line">            nn.Conv2d(in_channels=input_shape, </span><br><span class="line">                      out_channels=hidden_units, </span><br><span class="line">                      kernel_size=<span class="number">3</span>, <span class="comment"># how big is the square that&#x27;s going over the image?</span></span><br><span class="line">                      stride=<span class="number">1</span>, <span class="comment"># default</span></span><br><span class="line">                      padding=<span class="number">1</span>),<span class="comment"># options = &quot;valid&quot; (no padding) or &quot;same&quot; (output has same shape as input) or int for specific number </span></span><br><span class="line">            nn.ReLU(),</span><br><span class="line">            nn.Conv2d(in_channels=hidden_units, </span><br><span class="line">                      out_channels=hidden_units,</span><br><span class="line">                      kernel_size=<span class="number">3</span>,</span><br><span class="line">                      stride=<span class="number">1</span>,</span><br><span class="line">                      padding=<span class="number">1</span>),</span><br><span class="line">            nn.ReLU(),</span><br><span class="line">            nn.MaxPool2d(kernel_size=<span class="number">2</span>,</span><br><span class="line">                         stride=<span class="number">2</span>) <span class="comment"># default stride value is same as kernel_size</span></span><br><span class="line">        )</span><br><span class="line">        self.block_2 = nn.Sequential(</span><br><span class="line">            nn.Conv2d(hidden_units, hidden_units, <span class="number">3</span>, padding=<span class="number">1</span>),</span><br><span class="line">            nn.ReLU(),</span><br><span class="line">            nn.Conv2d(hidden_units, hidden_units, <span class="number">3</span>, padding=<span class="number">1</span>),</span><br><span class="line">            nn.ReLU(),</span><br><span class="line">            nn.MaxPool2d(<span class="number">2</span>)</span><br><span class="line">        )</span><br><span class="line">        self.classifier = nn.Sequential(</span><br><span class="line">            nn.Flatten(),</span><br><span class="line">            <span class="comment"># Where did this in_features shape come from? </span></span><br><span class="line">            <span class="comment"># It&#x27;s because each layer of our network compresses and changes the shape of our input data.</span></span><br><span class="line">            nn.Linear(in_features=hidden_units*<span class="number">7</span>*<span class="number">7</span>, </span><br><span class="line">                      out_features=output_shape)</span><br><span class="line">        )</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x: torch.Tensor</span>):</span><br><span class="line">        x = self.block_1(x)</span><br><span class="line">        <span class="comment"># print(x.shape)</span></span><br><span class="line">        x = self.block_2(x)</span><br><span class="line">        <span class="comment"># print(x.shape)</span></span><br><span class="line">        x = self.classifier(x)</span><br><span class="line">        <span class="comment"># print(x.shape)</span></span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line">torch.manual_seed(<span class="number">42</span>)</span><br><span class="line">model_2 = FashionMNISTModelV2(input_shape=<span class="number">1</span>, </span><br><span class="line">    hidden_units=<span class="number">10</span>, </span><br><span class="line">    output_shape=<span class="built_in">len</span>(class_names)).to(device)</span><br><span class="line">model_2</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">FashionMNISTModelV2(</span><br><span class="line">  (block_1): Sequential(</span><br><span class="line">    (0): Conv2d(1, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))</span><br><span class="line">    (1): ReLU()</span><br><span class="line">    (2): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))</span><br><span class="line">    (3): ReLU()</span><br><span class="line">    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)</span><br><span class="line">  )</span><br><span class="line">  (block_2): Sequential(</span><br><span class="line">    (0): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))</span><br><span class="line">    (1): ReLU()</span><br><span class="line">    (2): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))</span><br><span class="line">    (3): ReLU()</span><br><span class="line">    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)</span><br><span class="line">  )</span><br><span class="line">  (classifier): Sequential(</span><br><span class="line">    (0): Flatten(start_dim=1, end_dim=-1)</span><br><span class="line">    (1): Linear(in_features=490, out_features=10, bias=True)</span><br><span class="line">  )</span><br><span class="line">)</span><br></pre></td></tr></table></figure><h2 id="7-1-Stepping-throughnn-Conv2d"><a href="#7-1-Stepping-throughnn-Conv2d" class="headerlink" title="7.1 Stepping throughnn.Conv2d()"></a>7.1 Stepping through<code>nn.Conv2d()</code></h2><p>我们可以开始使用上面的模型，看看会发生什么，但让我们首先逐步了解我们添加的两个新层：</p><ul><li><a href="https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html"><code>nn.Conv2d()</code></a>，也称为卷积层。</li><li><a href="https://pytorch.org/docs/stable/generated/torch.nn.MaxPool2d.html"><code>nn.MaxPool2d()</code></a>，也称为最大池化层。</li></ul><blockquote><p>问题：nn.Conv2d()中的“2d”代表什么？<br>2d 表示二维数据。例如，我们的图像有两个维度：高度和宽度。是的，有颜色通道维度，但每个颜色通道维度也有两个维度：高度和宽度。<br>对于其他维度数据（例如文本的 1D 或 3D 对象的 3D），还有nn.Conv1d()和nn.Conv3d()。</p></blockquote><p>为了测试这些层，让我们创建一些玩具数据，就像 CNN Explainer 上使用的数据一样。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">torch.manual_seed(<span class="number">42</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Create sample batch of random numbers with same size as image batch</span></span><br><span class="line">images = torch.randn(size=(<span class="number">32</span>, <span class="number">3</span>, <span class="number">64</span>, <span class="number">64</span>)) <span class="comment"># [batch_size, color_channels, height, width]</span></span><br><span class="line">test_image = images[<span class="number">0</span>] <span class="comment"># get a single image for testing</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Image batch shape: <span class="subst">&#123;images.shape&#125;</span> -&gt; [batch_size, color_channels, height, width]&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Single image shape: <span class="subst">&#123;test_image.shape&#125;</span> -&gt; [color_channels, height, width]&quot;</span>) </span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Single image pixel values:\n<span class="subst">&#123;test_image&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">Image batch shape: torch.Size([32, 3, 64, 64]) -&gt; [batch_size, color_channels, height, width]</span><br><span class="line">Single image shape: torch.Size([3, 64, 64]) -&gt; [color_channels, height, width]</span><br><span class="line">Single image pixel values:</span><br><span class="line">tensor([[[ 1.9269,  1.4873,  0.9007,  ...,  1.8446, -1.1845,  1.3835],...)</span><br></pre></td></tr></table></figure><p>让我们创建一个<code>nn.Conv2d()</code>具有各种参数的示例：</p><ul><li><code>in_channels(int)</code>， 输入图像中的通道数。</li><li><code>out_channels(int)</code>，卷积产生的通道数。</li><li><code>kernel_size(int or tuple)</code>，卷积核/过滤器的大小。</li><li><code>stride(int or tuple, optional)</code>，卷积核每次采取的步长。默认值：1。</li><li><code>padding(int, tuple, str)</code>，在输入的四边添加填充。默认值：0。</li></ul><img src="/2024/08/17/PyTorch-26H-4/PyTorch-26H-4-10.gif" class="" title="PyTorch-26H-4-10"><p>更改某<code>nn.Conv2d()</code>一层的超参数时发生的情况的示例。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">torch.manual_seed(<span class="number">42</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Create a convolutional layer with same dimensions as TinyVGG </span></span><br><span class="line"><span class="comment"># (try changing any of the parameters and see what happens)</span></span><br><span class="line">conv_layer = nn.Conv2d(in_channels=<span class="number">3</span>,</span><br><span class="line">                       out_channels=<span class="number">10</span>,</span><br><span class="line">                       kernel_size=<span class="number">3</span>,</span><br><span class="line">                       stride=<span class="number">1</span>,</span><br><span class="line">                       padding=<span class="number">0</span>) <span class="comment"># also try using &quot;valid&quot; or &quot;same&quot; here </span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Pass the data through the convolutional layer</span></span><br><span class="line">conv_layer(test_image) <span class="comment"># Note: If running PyTorch &lt;1.11.0, this will error because of shape issues (nn.Conv.2d() expects a 4d tensor as input) </span></span><br></pre></td></tr></table></figure><p>如果尝试传入单张图像，我们会收到形状不匹配错误：</p><blockquote><p>RuntimeError: Expected 4-dimensional input for 4-dimensional weight [10, 3, 3, 3], but got 3-dimensional input of size [3, 64, 64] instead</p></blockquote><p>这是因为我们的<code>nn.Conv2d()</code>层需要一个大小为 <code>(N, C, H, W)</code> 或 <code>[batch_size, color_channels, height, width]</code> 的4 维张量作为输入。</p><p>目前我们的单幅图像 <code>test_image</code> 只有 <code>[color_channels, height, width]</code> 或 <code>[3, 64, 64]</code> 的形状。</p><p>我们可以使用 <code>test_image.unsqueeze(dim=0)</code> 为单个图像修复此问题，为 <code>N</code> 添加额外的维度。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Add extra dimension to test image</span></span><br><span class="line">test_image.unsqueeze(dim=<span class="number">0</span>).shape</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.Size([1, 3, 64, 64])</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Pass test image with extra dimension through conv_layer</span></span><br><span class="line">conv_layer(test_image.unsqueeze(dim=<span class="number">0</span>)).shape</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.Size([1, 10, 62, 62])</span><br></pre></td></tr></table></figure><p>嗯，注意我们的形状发生了什么变化（与<a href="https://poloclub.github.io/cnn-explainer/">CNN Explainer</a>上 TinyVGG 的第一层形状相同），我们得到了不同的通道大小以及不同的像素大小。</p><p>如果我们改变 <code>conv_layer</code> 的值会怎样？</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">torch.manual_seed(<span class="number">42</span>)</span><br><span class="line"><span class="comment"># Create a new conv_layer with different values (try setting these to whatever you like)</span></span><br><span class="line">conv_layer_2 = nn.Conv2d(in_channels=<span class="number">3</span>, <span class="comment"># same number of color channels as our input image</span></span><br><span class="line">                         out_channels=<span class="number">10</span>,</span><br><span class="line">                         kernel_size=(<span class="number">5</span>, <span class="number">5</span>), <span class="comment"># kernel is usually a square so a tuple also works</span></span><br><span class="line">                         stride=<span class="number">2</span>,</span><br><span class="line">                         padding=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Pass single image through new conv_layer_2 (this calls nn.Conv2d()&#x27;s forward() method on the input)</span></span><br><span class="line">conv_layer_2(test_image.unsqueeze(dim=<span class="number">0</span>)).shape</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.Size([1, 10, 30, 30])</span><br></pre></td></tr></table></figure><p>哇，我们的形状又发生了变化。</p><p>现在我们的图像是形状<code>[1, 10, 30, 30]</code>（如果使用不同的值，它会有所不同）或<code>[batch_size=1, color_channels=10, height=30, width=30]</code>。</p><p>这里发生了什么事？</p><p>在幕后，我们<code>nn.Conv2d()</code>正在压缩图像中存储的信息。</p><p>它通过根据其内部参数对输入（我们的测试图像）执行操作来实现这一点。</p><p>其目标与我们一直在构建的所有其他神经网络类似。</p><p>数据输入后，各层会在优化器的帮助下尝试更新其内部参数（模式）以降低损失函数。</p><p>唯一的区别在于不同层如何计算它们的参数更新，或者用 PyTorch 术语来说，层方法中存在的操作<code>forward()</code>。</p><p>如果我们检查一下，<code>conv_layer_2.state_dict()</code>我们会发现与我们之前看到的类似的权重和偏差设置。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Check out the conv_layer_2 internal parameters</span></span><br><span class="line"><span class="built_in">print</span>(conv_layer_2.state_dict())</span><br></pre></td></tr></table></figure><p>权重和偏差张量的一堆随机数。</p><p><code>nn.Conv2d()</code>它们的形状由我们在设置时传递的输入来操纵。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Get shapes of weight and bias tensors within conv_layer_2</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;conv_layer_2 weight shape: \n<span class="subst">&#123;conv_layer_2.weight.shape&#125;</span> -&gt; [out_channels=10, in_channels=3, kernel_size=5, kernel_size=5]&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;\nconv_layer_2 bias shape: \n<span class="subst">&#123;conv_layer_2.bias.shape&#125;</span> -&gt; [out_channels=10]&quot;</span>)</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">conv_layer_2 weight shape: </span><br><span class="line">torch.Size([10, 3, 5, 5]) -&gt; [out_channels=10, in_channels=3, kernel_size=5, kernel_size=5]</span><br><span class="line"></span><br><span class="line">conv_layer_2 bias shape: </span><br><span class="line">torch.Size([10]) -&gt; [out_channels=10]</span><br></pre></td></tr></table></figure><blockquote><p>问题：我们应该如何设置图层的参数nn.Conv2d()？<br>这是个好主意。但与机器学习中的许多其他事物类似，这些值并不是一成不变的（回想一下，因为这些值是我们可以自己设置的，所以它们被称为“超参数”）。<br>找出答案的最佳方法是尝试不同的值并观察它们如何影响模型的性能。<br>或者更好的是，找到一个与您的问题类似的工作示例（就像我们对 TinyVGG 所做的那样）并复制它。</p></blockquote><p>但前提保持不变：从随机数开始并更新它们以更好地表示数据。</p><h2 id="7-2-Stepping-through-nn-MaxPool2d"><a href="#7-2-Stepping-through-nn-MaxPool2d" class="headerlink" title="7.2 Stepping through nn.MaxPool2d()"></a>7.2 Stepping through <code>nn.MaxPool2d()</code></h2><p>让我们检查一下当我们移动<code>nn.MaxPool2d()</code>数据时会发生什么。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Print out original image shape without and with unsqueezed dimension</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Test image original shape: <span class="subst">&#123;test_image.shape&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Test image with unsqueezed dimension: <span class="subst">&#123;test_image.unsqueeze(dim=<span class="number">0</span>).shape&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Create a sample nn.MaxPoo2d() layer</span></span><br><span class="line">max_pool_layer = nn.MaxPool2d(kernel_size=<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Pass data through just the conv_layer</span></span><br><span class="line">test_image_through_conv = conv_layer(test_image.unsqueeze(dim=<span class="number">0</span>))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Shape after going through conv_layer(): <span class="subst">&#123;test_image_through_conv.shape&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Pass data through the max pool layer</span></span><br><span class="line">test_image_through_conv_and_max_pool = max_pool_layer(test_image_through_conv)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Shape after going through conv_layer() and max_pool_layer(): <span class="subst">&#123;test_image_through_conv_and_max_pool.shape&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">Test image original shape: torch.Size([3, 64, 64])</span><br><span class="line">Test image with unsqueezed dimension: torch.Size([1, 3, 64, 64])</span><br><span class="line">Shape after going through conv_layer(): torch.Size([1, 10, 62, 62])</span><br><span class="line">Shape after going through conv_layer() and max_pool_layer(): torch.Size([1, 10, 31, 31])</span><br></pre></td></tr></table></figure><p>注意层内和层外发生的形状的变化<code>nn.MaxPool2d()</code>。</p><p><code>kernel_size</code>层的将<code>nn.MaxPool2d()</code>影响输出形状的大小。</p><p>在我们的例子中，形状从一幅<code>62x62</code>图像分成另<code>31x31</code>一幅图像。</p><p>让我们用较小的张量看一下这个工作。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">torch.manual_seed(<span class="number">42</span>)</span><br><span class="line"><span class="comment"># Create a random tensor with a similar number of dimensions to our images</span></span><br><span class="line">random_tensor = torch.randn(size=(<span class="number">1</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Random tensor:\n<span class="subst">&#123;random_tensor&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Random tensor shape: <span class="subst">&#123;random_tensor.shape&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Create a max pool layer</span></span><br><span class="line">max_pool_layer = nn.MaxPool2d(kernel_size=<span class="number">2</span>) <span class="comment"># see what happens when you change the kernel_size value </span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Pass the random tensor through the max pool layer</span></span><br><span class="line">max_pool_tensor = max_pool_layer(random_tensor)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;\nMax pool tensor:\n<span class="subst">&#123;max_pool_tensor&#125;</span> &lt;- this is the maximum value from random_tensor&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Max pool tensor shape: <span class="subst">&#123;max_pool_tensor.shape&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">Random tensor:</span><br><span class="line">tensor([[[[0.3367, 0.1288],</span><br><span class="line">          [0.2345, 0.2303]]]])</span><br><span class="line">Random tensor shape: torch.Size([1, 1, 2, 2])</span><br><span class="line"></span><br><span class="line">Max pool tensor:</span><br><span class="line">tensor([[[[0.3367]]]]) &lt;- this is the maximum value from random_tensor</span><br><span class="line">Max pool tensor shape: torch.Size([1, 1, 1, 1])</span><br></pre></td></tr></table></figure><p>注意 <code>random_tensor</code> 和 <code>max_pool_tensor</code> 之间的最后两个维度，它们从 <code>[2, 2]</code> 变为 <code>[1, 1]</code>。<br>本质上，它们减半了。<br>对于 <code>nn.MaxPool2d()</code>，<code>kernel_size</code> 的不同值，变化会有所不同。<br>还要注意，<code>max_pool_tensor</code> 中剩余的值是 <code>random_tensor</code> 中的最大值。</p><p>这里发生了什么事？<br>这是神经网络难题的另一个重要部分。<br>本质上，<strong>神经网络中的每一层都试图将数据从高维空间压缩到低维空间。</strong><br>换句话说，获取大量数字（原始数据）并从这些数字中学习模式，这些模式具有预测性，同时其规模也比原始值小。</p><p>从人工智能的角度来看，你可以将神经网络的整个目标视为压缩信息。</p><img src="/2024/08/17/PyTorch-26H-4/PyTorch-26H-4-11.png" class="" title="PyTorch-26H-4-11"><p>这意味着，从神经网络的角度来看，智能就是压缩。</p><p>这是使用<code>nn.MaxPool2d()</code>层的想法：从张量的一部分中取最大值，而忽略其余部分。</p><p>本质上，降低张量的维数，同时仍然保留（希望）很大一部分信息。</p><p>对于层来说也是同样的情况nn.Conv2d()。</p><p>除了不只是取最大值之外，还对数据执行卷积运算（请参阅<a href="https://poloclub.github.io/cnn-explainer/">CNN 解释器网页</a><code>nn.Conv2d()</code>上的实际操作）。</p><blockquote><p><strong>练习：</strong>您认为该<a href="https://pytorch.org/docs/stable/generated/torch.nn.AvgPool2d.html"><code>nn.AvgPool2d()</code></a>层的作用是什么？尝试像上面一样创建一个随机张量并将其传递出去。检查输入和输出形状以及输入和输出值。<br><strong>课外活动：</strong>查找“最常见的卷积神经网络”，你找到了哪些架构？库中包含其中的任何架构吗<a href="https://pytorch.org/vision/stable/models.html"><code>torchvision.models</code></a>？你认为你可以用它们做什么？</p></blockquote><h2 id="7-3-Setup-a-loss-function-and-optimizer-for-model-2"><a href="#7-3-Setup-a-loss-function-and-optimizer-for-model-2" class="headerlink" title="7.3 Setup a loss function and optimizer for model_2"></a>7.3 Setup a loss function and optimizer for <code>model_2</code></h2><p>我们将像以前一样使用这些函数，<code>nn.CrossEntropyLoss()</code> 作为损失函数（因为我们处理的是多类分类数据）。</p><p>并使用 <code>torch.optim.SGD()</code> 作为优化器，以 0.1 的学习率优化 <code>model_2.parameters()</code>。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Setup loss and optimizer</span></span><br><span class="line">loss_fn = nn.CrossEntropyLoss()</span><br><span class="line">optimizer = torch.optim.SGD(params=model_2.parameters(), </span><br><span class="line">                             lr=<span class="number">0.1</span>)</span><br></pre></td></tr></table></figure><h2 id="7-4-Training-and-testing-model-2-using-our-training-and-test-functions"><a href="#7-4-Training-and-testing-model-2-using-our-training-and-test-functions" class="headerlink" title="7.4 Training and testing model_2 using our training and test functions"></a>7.4 Training and testing <code>model_2</code> using our training and test functions</h2><p>损失和优化器已准备好！训练和测试的时间。<br>我们将使用之前创建的<code>train_step()</code>和<code>test_step()</code>函数。<br>我们还将测量时间以将其与我们的其他模型进行比较。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">torch.manual_seed(<span class="number">42</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Measure time</span></span><br><span class="line"><span class="keyword">from</span> timeit <span class="keyword">import</span> default_timer <span class="keyword">as</span> timer</span><br><span class="line">train_time_start_model_2 = timer()</span><br><span class="line"></span><br><span class="line"><span class="comment"># Train and test model </span></span><br><span class="line">epochs = <span class="number">3</span></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> tqdm(<span class="built_in">range</span>(epochs)):</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;Epoch: <span class="subst">&#123;epoch&#125;</span>\n---------&quot;</span>)</span><br><span class="line">    train_step(data_loader=train_dataloader, </span><br><span class="line">        model=model_2, </span><br><span class="line">        loss_fn=loss_fn,</span><br><span class="line">        optimizer=optimizer,</span><br><span class="line">        accuracy_fn=accuracy_fn,</span><br><span class="line">        device=device</span><br><span class="line">    )</span><br><span class="line">    test_step(data_loader=test_dataloader,</span><br><span class="line">        model=model_2,</span><br><span class="line">        loss_fn=loss_fn,</span><br><span class="line">        accuracy_fn=accuracy_fn,</span><br><span class="line">        device=device</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">train_time_end_model_2 = timer()</span><br><span class="line">total_train_time_model_2 = print_train_time(start=train_time_start_model_2,</span><br><span class="line">                                           end=train_time_end_model_2,</span><br><span class="line">                                           device=device)</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">Epoch: 0</span><br><span class="line">---------</span><br><span class="line">Train loss: 0.59664 | Train accuracy: 78.43%</span><br><span class="line">Test loss: 0.38824 | Test accuracy: 86.24%</span><br><span class="line"></span><br><span class="line">Epoch: 1</span><br><span class="line">---------</span><br><span class="line">Train loss: 0.35712 | Train accuracy: 87.12%</span><br><span class="line">Test loss: 0.34803 | Test accuracy: 87.15%</span><br><span class="line"></span><br><span class="line">Epoch: 2</span><br><span class="line">---------</span><br><span class="line">Train loss: 0.31907 | Train accuracy: 88.50%</span><br><span class="line">Test loss: 0.32589 | Test accuracy: 88.37%</span><br><span class="line"></span><br><span class="line">Train time on cuda: 51.457 seconds</span><br></pre></td></tr></table></figure><p>看起来卷积层和最大池化层有助于提高性能。</p><p>让我们<code>model_2</code>用我们的函数评估的结果<code>eval_model()</code>。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Get model_2 results </span></span><br><span class="line">model_2_results = eval_model(</span><br><span class="line">    model=model_2,</span><br><span class="line">    data_loader=test_dataloader,</span><br><span class="line">    loss_fn=loss_fn,</span><br><span class="line">    accuracy_fn=accuracy_fn</span><br><span class="line">)</span><br><span class="line">model_2_results</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&#123;&#x27;model_name&#x27;: &#x27;FashionMNISTModelV2&#x27;,</span><br><span class="line"> &#x27;model_loss&#x27;: 0.3258868157863617,</span><br><span class="line"> &#x27;model_acc&#x27;: 88.36861022364218&#125;</span><br></pre></td></tr></table></figure><h1 id="8-Compare-model-results-and-training-time-比较模型结果和训练时间"><a href="#8-Compare-model-results-and-training-time-比较模型结果和训练时间" class="headerlink" title="8. Compare model results and training time 比较模型结果和训练时间"></a>8. Compare model results and training time 比较模型结果和训练时间</h1><p>我们训练了三种不同的模型。</p><ul><li><code>model_0</code>，我们的基线模型有两层<code>nn.Linear()</code>。</li><li><code>model_1</code>，与我们的基线模型设置相同，只是层与层<code>nn.ReLU()</code>之间有层<code>nn.Linear()</code>。</li><li><code>model_2</code>，我们的第一个 CNN 模型模仿了 CNN Explainer 网站上的 TinyVGG 架构。</li></ul><p>这是机器学习的常规做法。</p><p>建立多个模型并进行多次训练实验，以查看哪个表现最佳。</p><p>让我们将模型结果字典合并到 DataFrame 中并找出答案。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line">compare_results = pd.DataFrame([model_0_results, model_1_results, model_2_results])</span><br><span class="line">compare_results</span><br></pre></td></tr></table></figure><div class="table-container"><table><thead><tr><th style="text-align:center">model_name</th><th style="text-align:center">model_loss</th><th style="text-align:center">model_acc</th></tr></thead><tbody><tr><td style="text-align:center">FashionMNISTModelV0</td><td style="text-align:center">0.476639</td><td style="text-align:center">83.426518</td></tr><tr><td style="text-align:center">FashionMNISTModelV1</td><td style="text-align:center">0.685001</td><td style="text-align:center">75.019968</td></tr><tr><td style="text-align:center">FashionMNISTModelV2</td><td style="text-align:center">0.325887</td><td style="text-align:center">88.368610</td></tr></tbody></table></div><p>添加训练时间值。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Add training times to results comparison</span></span><br><span class="line">compare_results[<span class="string">&quot;training_time&quot;</span>] = [total_train_time_model_0,</span><br><span class="line">                                    total_train_time_model_1,</span><br><span class="line">                                    total_train_time_model_2]</span><br><span class="line">compare_results</span><br></pre></td></tr></table></figure><div class="table-container"><table><thead><tr><th style="text-align:center">model_name</th><th style="text-align:center">model_loss</th><th style="text-align:center">model_acc</th><th style="text-align:center">training_time</th></tr></thead><tbody><tr><td style="text-align:center">FashionMNISTModelV0</td><td style="text-align:center">0.476639</td><td style="text-align:center">83.426518</td><td style="text-align:center">463.021015</td></tr><tr><td style="text-align:center">FashionMNISTModelV1</td><td style="text-align:center">0.685001</td><td style="text-align:center">75.019968</td><td style="text-align:center">45.538106</td></tr><tr><td style="text-align:center">FashionMNISTModelV2</td><td style="text-align:center">0.325887</td><td style="text-align:center">88.368610</td><td style="text-align:center">52.672458</td></tr></tbody></table></div><p>看起来我们的 <code>CNN（FashionMNISTModelV2）</code>模型表现最佳（损失最低、准确度最高），但训练时间最长。</p><p>并且我们的<code>基线模型 ( FashionMNISTModelV0)</code> 的表现优于<code>model_1( FashionMNISTModelV1)</code>。</p><h2 id="Performance-speed-tradeoff"><a href="#Performance-speed-tradeoff" class="headerlink" title="Performance-speed tradeoff"></a>Performance-speed tradeoff</h2><p>在机器学习中需要注意的是性能和速度的权衡。</p><p>一般来说，更大、更复杂的模型会获得更好的性能（就像我们所做的那样model_2）。</p><p>然而，这种性能的提升往往是以牺牲训练速度和推理速度为代价的。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Visualize our model results</span></span><br><span class="line">compare_results.set_index(<span class="string">&quot;model_name&quot;</span>)[<span class="string">&quot;model_acc&quot;</span>].plot(kind=<span class="string">&quot;barh&quot;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&quot;accuracy (%)&quot;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&quot;model&quot;</span>);</span><br></pre></td></tr></table></figure><img src="/2024/08/17/PyTorch-26H-4/PyTorch-26H-4-12.png" class="" title="PyTorch-26H-4-12"><h1 id="9-Make-and-evaluate-random-predictions-with-best-model-使用最佳模型进行随机预测并评估"><a href="#9-Make-and-evaluate-random-predictions-with-best-model-使用最佳模型进行随机预测并评估" class="headerlink" title="9. Make and evaluate random predictions with best model 使用最佳模型进行随机预测并评估"></a>9. Make and evaluate random predictions with best model 使用最佳模型进行随机预测并评估</h1><p>将我们的模型相互比较了，让我们进一步评估我们表现最好的模型<code>model_2</code>。</p><p>为此，让我们创建一个函数<code>make_predictions()</code>，我们可以在其中传递模型和一些数据以供其预测。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">make_predictions</span>(<span class="params">model: torch.nn.Module, data: <span class="built_in">list</span>, device: torch.device = device</span>):</span><br><span class="line">    pred_probs = []</span><br><span class="line">    model.<span class="built_in">eval</span>()</span><br><span class="line">    <span class="keyword">with</span> torch.inference_mode():</span><br><span class="line">        <span class="keyword">for</span> sample <span class="keyword">in</span> data:</span><br><span class="line">            <span class="comment"># Prepare sample</span></span><br><span class="line">            sample = torch.unsqueeze(sample, dim=<span class="number">0</span>).to(device) <span class="comment"># Add an extra dimension and send sample to device</span></span><br><span class="line"></span><br><span class="line">            <span class="comment"># Forward pass (model outputs raw logit)</span></span><br><span class="line">            pred_logit = model(sample)</span><br><span class="line"></span><br><span class="line">            <span class="comment"># Get prediction probability (logit -&gt; prediction probability)</span></span><br><span class="line">            pred_prob = torch.softmax(pred_logit.squeeze(), dim=<span class="number">0</span>) <span class="comment"># note: perform softmax on the &quot;logits&quot; dimension, not &quot;batch&quot; dimension (in this case we have a batch size of 1, so can perform on dim=0)</span></span><br><span class="line"></span><br><span class="line">            <span class="comment"># Get pred_prob off GPU for further calculations</span></span><br><span class="line">            pred_probs.append(pred_prob.cpu())</span><br><span class="line">            </span><br><span class="line">    <span class="comment"># Stack the pred_probs to turn list into a tensor</span></span><br><span class="line">    <span class="keyword">return</span> torch.stack(pred_probs)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> random</span><br><span class="line">random.seed(<span class="number">42</span>)</span><br><span class="line">test_samples = []</span><br><span class="line">test_labels = []</span><br><span class="line"><span class="keyword">for</span> sample, label <span class="keyword">in</span> random.sample(<span class="built_in">list</span>(test_data), k=<span class="number">9</span>):</span><br><span class="line">    test_samples.append(sample)</span><br><span class="line">    test_labels.append(label)</span><br><span class="line"></span><br><span class="line"><span class="comment"># View the first test sample shape and label</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Test sample image shape: <span class="subst">&#123;test_samples[<span class="number">0</span>].shape&#125;</span>\nTest sample label: <span class="subst">&#123;test_labels[<span class="number">0</span>]&#125;</span> (<span class="subst">&#123;class_names[test_labels[<span class="number">0</span>]]&#125;</span>)&quot;</span>)</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Test sample image shape: torch.Size([1, 28, 28])</span><br><span class="line">Test sample label: 5 (Sandal)</span><br></pre></td></tr></table></figure><p>现在我们可以使用 <code>make_predictions()</code> 函数来预测 <code>test_samples</code>。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Make predictions on test samples with model 2</span></span><br><span class="line">pred_probs= make_predictions(model=model_2, </span><br><span class="line">                             data=test_samples)</span><br><span class="line"></span><br><span class="line"><span class="comment"># View first two prediction probabilities list</span></span><br><span class="line">pred_probs[:<span class="number">2</span>]</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">tensor([[7.7393e-08, 6.9452e-08, 7.9230e-09, 7.5061e-08, 1.0008e-08, 9.9992e-01,</span><br><span class="line">         1.6065e-06, 6.7758e-07, 6.3521e-06, 7.4828e-05],</span><br><span class="line">        [2.0884e-02, 8.1752e-01, 6.5737e-04, 6.4430e-02, 6.4946e-02, 4.4571e-04,</span><br><span class="line">         2.9005e-02, 2.8220e-04, 7.9620e-04, 1.0312e-03]])</span><br></pre></td></tr></table></figure><p>现在，我们可以通过获取 <code>torch.softmax()</code> 激活函数输出的 <code>torch.argmax()</code> 从预测概率转到预测标签。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Turn the prediction probabilities into prediction labels by taking the argmax()</span></span><br><span class="line">pred_classes = pred_probs.argmax(dim=<span class="number">1</span>)</span><br><span class="line">pred_classes</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tensor([5, 1, 7, 4, 3, 0, 4, 7, 1])</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Are our predictions in the same form as our test labels? </span></span><br><span class="line">test_labels, pred_classes</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">([5, 1, 7, 4, 3, 0, 4, 7, 1], tensor([5, 1, 7, 4, 3, 0, 4, 7, 1]))</span><br></pre></td></tr></table></figure><p>现在，我们预测的类别与测试标签的格式相同，我们可以进行比较了。<br>由于我们处理的是图像数据，因此让我们坚持数据探索者的座右铭。<br>“可视化，可视化，可视化！”</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Plot predictions</span></span><br><span class="line">plt.figure(figsize=(<span class="number">9</span>, <span class="number">9</span>))</span><br><span class="line">nrows = <span class="number">3</span></span><br><span class="line">ncols = <span class="number">3</span></span><br><span class="line"><span class="keyword">for</span> i, sample <span class="keyword">in</span> <span class="built_in">enumerate</span>(test_samples):</span><br><span class="line">  <span class="comment"># Create a subplot</span></span><br><span class="line">  plt.subplot(nrows, ncols, i+<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">  <span class="comment"># Plot the target image</span></span><br><span class="line">  plt.imshow(sample.squeeze(), cmap=<span class="string">&quot;gray&quot;</span>)</span><br><span class="line"></span><br><span class="line">  <span class="comment"># Find the prediction label (in text form, e.g. &quot;Sandal&quot;)</span></span><br><span class="line">  pred_label = class_names[pred_classes[i]]</span><br><span class="line"></span><br><span class="line">  <span class="comment"># Get the truth label (in text form, e.g. &quot;T-shirt&quot;)</span></span><br><span class="line">  truth_label = class_names[test_labels[i]] </span><br><span class="line"></span><br><span class="line">  <span class="comment"># Create the title text of the plot</span></span><br><span class="line">  title_text = <span class="string">f&quot;Pred: <span class="subst">&#123;pred_label&#125;</span> | Truth: <span class="subst">&#123;truth_label&#125;</span>&quot;</span></span><br><span class="line">  </span><br><span class="line">  <span class="comment"># Check for equality and change title colour accordingly</span></span><br><span class="line">  <span class="keyword">if</span> pred_label == truth_label:</span><br><span class="line">      plt.title(title_text, fontsize=<span class="number">10</span>, c=<span class="string">&quot;g&quot;</span>) <span class="comment"># green text if correct</span></span><br><span class="line">  <span class="keyword">else</span>:</span><br><span class="line">      plt.title(title_text, fontsize=<span class="number">10</span>, c=<span class="string">&quot;r&quot;</span>) <span class="comment"># red text if wrong</span></span><br><span class="line">  plt.axis(<span class="literal">False</span>);</span><br></pre></td></tr></table></figure><img src="/2024/08/17/PyTorch-26H-4/PyTorch-26H-4-13.png" class="" title="PyTorch-26H-4-13"><h1 id="10-Making-a-confusion-matrix-for-further-prediction-evaluation-制作混淆矩阵以进行进一步的预测评估"><a href="#10-Making-a-confusion-matrix-for-further-prediction-evaluation-制作混淆矩阵以进行进一步的预测评估" class="headerlink" title="10. Making a confusion matrix for further prediction evaluation 制作混淆矩阵以进行进一步的预测评估"></a>10. Making a confusion matrix for further prediction evaluation 制作混淆矩阵以进行进一步的预测评估</h1><p>对于分类问题，我们可以使用许多<a href="https://www.learnpytorch.io/02_pytorch_classification/#9-more-classification-evaluation-metrics">不同的评估指标。</a></p><p>最直观的一种是<a href="https://www.dataschool.io/simple-guide-to-confusion-matrix-terminology/">混淆矩阵</a>。</p><p>混淆矩阵可以显示分类模型在预测和真实标签之间混淆的地方。</p><p>为了制作混淆矩阵，我们将经历三个步骤：<br>1、使用我们训练的模型进行预测<code>model_2</code>（混淆矩阵将预测与真实标签进行比较）。<br>2、使用制作混淆矩阵<code>torchmetrics.ConfusionMatrix</code>。<br>3、使用绘制混淆矩阵<code>mlxtend.plotting.plot_confusion_matrix()</code>。</p><h2 id="首先用训练好的模型进行预测。"><a href="#首先用训练好的模型进行预测。" class="headerlink" title="首先用训练好的模型进行预测。"></a>首先用训练好的模型进行预测。</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Import tqdm for progress bar</span></span><br><span class="line"><span class="keyword">from</span> tqdm.auto <span class="keyword">import</span> tqdm</span><br><span class="line"></span><br><span class="line"><span class="comment"># 1. Make predictions with trained model</span></span><br><span class="line">y_preds = []</span><br><span class="line">model_2.<span class="built_in">eval</span>()</span><br><span class="line"><span class="keyword">with</span> torch.inference_mode():</span><br><span class="line">  <span class="keyword">for</span> X, y <span class="keyword">in</span> tqdm(test_dataloader, desc=<span class="string">&quot;Making predictions&quot;</span>):</span><br><span class="line">    <span class="comment"># Send data and targets to target device</span></span><br><span class="line">    X, y = X.to(device), y.to(device)</span><br><span class="line">    <span class="comment"># Do the forward pass</span></span><br><span class="line">    y_logit = model_2(X)</span><br><span class="line">    <span class="comment"># Turn predictions from logits -&gt; prediction probabilities -&gt; predictions labels</span></span><br><span class="line">    y_pred = torch.softmax(y_logit, dim=<span class="number">1</span>).argmax(dim=<span class="number">1</span>) <span class="comment"># note: perform softmax on the &quot;logits&quot; dimension, not &quot;batch&quot; dimension (in this case we have a batch size of 32, so can perform on dim=1)</span></span><br><span class="line">    <span class="comment"># Put predictions on CPU for evaluation</span></span><br><span class="line">    y_preds.append(y_pred.cpu())</span><br><span class="line"><span class="comment"># Concatenate list of predictions into a tensor</span></span><br><span class="line">y_pred_tensor = torch.cat(y_preds)</span><br></pre></td></tr></table></figure><h2 id="制作混淆矩阵"><a href="#制作混淆矩阵" class="headerlink" title="制作混淆矩阵"></a>制作混淆矩阵</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># See if torchmetrics exists, if not, install it</span></span><br><span class="line"><span class="keyword">try</span>:</span><br><span class="line">    <span class="keyword">import</span> torchmetrics, mlxtend</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;mlxtend version: <span class="subst">&#123;mlxtend.__version__&#125;</span>&quot;</span>)</span><br><span class="line">    <span class="keyword">assert</span> <span class="built_in">int</span>(mlxtend.__version__.split(<span class="string">&quot;.&quot;</span>)[<span class="number">1</span>]) &gt;= <span class="number">19</span>, <span class="string">&quot;mlxtend verison should be 0.19.0 or higher&quot;</span></span><br><span class="line"><span class="keyword">except</span>:</span><br><span class="line">    !pip install -q torchmetrics -U mlxtend <span class="comment"># &lt;- Note: If you&#x27;re using Google Colab, this may require restarting the runtime</span></span><br><span class="line">    <span class="keyword">import</span> torchmetrics, mlxtend</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;mlxtend version: <span class="subst">&#123;mlxtend.__version__&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Import mlxtend upgraded version</span></span><br><span class="line"><span class="keyword">import</span> mlxtend </span><br><span class="line"><span class="built_in">print</span>(mlxtend.__version__)</span><br><span class="line"><span class="keyword">assert</span> <span class="built_in">int</span>(mlxtend.__version__.split(<span class="string">&quot;.&quot;</span>)[<span class="number">1</span>]) &gt;= <span class="number">19</span> <span class="comment"># should be version 0.19.0 or higher</span></span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">0.23.1</span><br></pre></td></tr></table></figure><p><code>torchmetrics</code> 和 <code>mlxtend</code>安装完毕，让我们制作一个混淆矩阵！</p><p>首先，我们将创建一个<code>torchmetrics.ConfusionMatrix</code>实例，通过设置来告诉它我们要处理多少个类<code>num_classes=len(class_names)</code>。</p><p>然后，我们将通过向我们的实例传递模型的预测（<code>preds=y_pred_tensor</code>）和目标（<code>target=test_data.targets</code>）来创建一个混淆矩阵（张量格式）。</p><p><code>plot_confusion_matrix()</code>最后，我们可以使用中的函数绘制混淆矩阵<code>mlxtend.plotting</code>。</p><h2 id="绘制混淆矩阵"><a href="#绘制混淆矩阵" class="headerlink" title="绘制混淆矩阵"></a>绘制混淆矩阵</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> torchmetrics <span class="keyword">import</span> ConfusionMatrix</span><br><span class="line"><span class="keyword">from</span> mlxtend.plotting <span class="keyword">import</span> plot_confusion_matrix</span><br><span class="line"></span><br><span class="line"><span class="comment"># 2. Setup confusion matrix instance and compare predictions to targets</span></span><br><span class="line">confmat = ConfusionMatrix(num_classes=<span class="built_in">len</span>(class_names), task=<span class="string">&#x27;multiclass&#x27;</span>)</span><br><span class="line">confmat_tensor = confmat(preds=y_pred_tensor,</span><br><span class="line">                         target=test_data.targets)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 3. Plot the confusion matrix</span></span><br><span class="line">fig, ax = plot_confusion_matrix(</span><br><span class="line">    conf_mat=confmat_tensor.numpy(), <span class="comment"># matplotlib likes working with NumPy </span></span><br><span class="line">    class_names=class_names, <span class="comment"># turn the row and column labels into class names</span></span><br><span class="line">    figsize=(<span class="number">10</span>, <span class="number">7</span>)</span><br><span class="line">);</span><br></pre></td></tr></table></figure><img src="/2024/08/17/PyTorch-26H-4/PyTorch-26H-4-14.png" class="" title="PyTorch-26H-4-14"><p>哇哦！看起来不是很棒吗？</p><p>我们可以看到我们的模型表现相当好，因为大多数深色方块都位于从左上到右下的对角线上（理想模型只有在这些方块中有值，其他地方都为 0）。</p><p>该模型对相似的类别最为“困惑”，例如，对于实际标记为“衬衫”的图像，预测其为“套头衫”。</p><p>对于实际标记为“T 恤/上衣”的类别，预测其为“衬衫”，方法也是一样。</p><p>这种信息通常比单一的准确度指标更有帮助，因为它可以告诉我们模型哪里出了问题。</p><p>它也暗示了为什么模型可能会出现某些错误。</p><p>可以理解的是，对于标有“T 恤/上衣”的图像，模型有时会预测“衬衫”。</p><p>我们可以利用此类信息进一步检查我们的模型和数据，看看如何改进。</p><h1 id="11-Save-and-load-best-performing-model"><a href="#11-Save-and-load-best-performing-model" class="headerlink" title="11. Save and load best performing model"></a>11. Save and load best performing model</h1><p>使用以下组合来保存和加载 PyTorch 模型：</p><p><code>torch.save</code>- 用于保存整个 PyTorch 模型或模型的函数state_dict()。<br><code>torch.load</code>- 用于加载已保存的 PyTorch 对象的函数。<br><code>torch.nn.Module.load_state_dict()</code>- 将保存的<code>state_dict()</code>内容加载到现有模型实例中的功能。</p><p>保存 <code>model_2</code> 的 <code>state_dict()</code> 然后重新加载并评估它，以确保 保存 和 加载 正确进行。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pathlib <span class="keyword">import</span> Path</span><br><span class="line"></span><br><span class="line"><span class="comment"># Create models directory (if it doesn&#x27;t already exist), see: https://docs.python.org/3/library/pathlib.html#pathlib.Path.mkdir</span></span><br><span class="line">MODEL_PATH = Path(<span class="string">&quot;models&quot;</span>)</span><br><span class="line">MODEL_PATH.mkdir(parents=<span class="literal">True</span>, <span class="comment"># create parent directories if needed</span></span><br><span class="line">                 exist_ok=<span class="literal">True</span> <span class="comment"># if models directory already exists, don&#x27;t error</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Create model save path</span></span><br><span class="line">MODEL_NAME = <span class="string">&quot;03_pytorch_computer_vision_model_2.pth&quot;</span></span><br><span class="line">MODEL_SAVE_PATH = MODEL_PATH / MODEL_NAME</span><br><span class="line"></span><br><span class="line"><span class="comment"># Save the model state dict</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Saving model to: <span class="subst">&#123;MODEL_SAVE_PATH&#125;</span>&quot;</span>)</span><br><span class="line">torch.save(obj=model_2.state_dict(), <span class="comment"># only saving the state_dict() only saves the learned parameters</span></span><br><span class="line">           f=MODEL_SAVE_PATH)</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Saving model to: models/03_pytorch_computer_vision_model_2.pth</span><br></pre></td></tr></table></figure><p>现在我们已经有一个保存的模型，我们可以使用和的<code>state_dict()</code>组合将其重新加载。<code>load_state_dict()torch.load()</code></p><p>由于我们正在使用<code>load_state_dict()</code>，我们需要创建一个<code>FashionMNISTModelV2()</code>具有与我们保存的模型相同的输入参数的新实例<code>state_dict()</code>。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Create a new instance of FashionMNISTModelV2 (the same class as our saved state_dict())</span></span><br><span class="line"><span class="comment"># Note: loading model will error if the shapes here aren&#x27;t the same as the saved version</span></span><br><span class="line">loaded_model_2 = FashionMNISTModelV2(input_shape=<span class="number">1</span>, </span><br><span class="line">                                    hidden_units=<span class="number">10</span>, <span class="comment"># try changing this to 128 and seeing what happens </span></span><br><span class="line">                                    output_shape=<span class="number">10</span>) </span><br><span class="line"></span><br><span class="line"><span class="comment"># Load in the saved state_dict()</span></span><br><span class="line">loaded_model_2.load_state_dict(torch.load(f=MODEL_SAVE_PATH))</span><br><span class="line"></span><br><span class="line"><span class="comment"># Send model to GPU</span></span><br><span class="line">loaded_model_2 = loaded_model_2.to(device)</span><br></pre></td></tr></table></figure><p>现在我们已经有一个加载的模型，我们可以对其进行评估，eval_model()以确保其参数与model_2保存之前的工作方式类似。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Evaluate loaded model</span></span><br><span class="line">torch.manual_seed(<span class="number">42</span>)</span><br><span class="line"></span><br><span class="line">loaded_model_2_results = eval_model(</span><br><span class="line">    model=loaded_model_2,</span><br><span class="line">    data_loader=test_dataloader,</span><br><span class="line">    loss_fn=loss_fn, </span><br><span class="line">    accuracy_fn=accuracy_fn</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">loaded_model_2_results</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&#123;&#x27;model_name&#x27;: &#x27;FashionMNISTModelV2&#x27;,</span><br><span class="line"> &#x27;model_loss&#x27;: 0.3258868157863617,</span><br><span class="line"> &#x27;model_acc&#x27;: 88.36861022364218&#125;</span><br></pre></td></tr></table></figure><p>这些结果看起来是否相同<code>model_2_results</code>？</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">model_2_results</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&#123;&#x27;model_name&#x27;: &#x27;FashionMNISTModelV2&#x27;,</span><br><span class="line"> &#x27;model_loss&#x27;: 0.3258868157863617,</span><br><span class="line"> &#x27;model_acc&#x27;: 88.36861022364218&#125;</span><br></pre></td></tr></table></figure><p>我们可以使用 <code>torch.isclose()</code> 来确定两个张量是否彼此接近，并通过参数 <code>atol</code>（绝对容差）和 <code>rtol</code>（相对容差）传入接近度的容差级别。</p><p>如果我们的模型的结果接近，则 <code>torch.isclose()</code> 的输出应该为 true。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Check to see if results are close to each other (if they are very far away, there may be an error)</span></span><br><span class="line">torch.isclose(torch.tensor(model_2_results[<span class="string">&quot;model_loss&quot;</span>]), </span><br><span class="line">              torch.tensor(loaded_model_2_results[<span class="string">&quot;model_loss&quot;</span>]),</span><br><span class="line">              atol=<span class="number">1e-08</span>, <span class="comment"># absolute tolerance</span></span><br><span class="line">              rtol=<span class="number">0.0001</span>) <span class="comment"># relative tolerance</span></span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tensor(True)</span><br></pre></td></tr></table></figure><h1 id="Exercises"><a href="#Exercises" class="headerlink" title="Exercises"></a>Exercises</h1><p>所有练习都集中于练习以上部分中的代码。</p><p>您应该能够通过参考每个部分或按照链接的资源来完成它们。</p><p>所有练习都应使用与<a href="https://pytorch.org/docs/stable/notes/cuda.html#device-agnostic-code">设备无关的代码</a>来完成。</p><p><strong>资源：</strong></p><ul><li><a href="https://github.com/mrdbourke/pytorch-deep-learning/blob/main/extras/exercises/03_pytorch_computer_vision_exercises.ipynb">03 练习模板笔记本</a></li><li><a href="https://github.com/mrdbourke/pytorch-deep-learning/blob/main/extras/solutions/03_pytorch_computer_vision_exercise_solutions.ipynb">03 示例解决方案笔记本</a>（在查看<em>之前先</em>尝试练习）</li></ul><ol><li><p>目前计算机视觉在工业领域中的应用有哪三个？</p></li><li><p>搜索“机器学习中的过度拟合是什么”，然后写下你发现的内容。</p></li><li><p>搜索“机器学习中防止过度拟合的方法”，写下你发现的 3 件事，并写下每件事的一句话。<strong>注意：</strong>有很多这样的方法，所以不要太担心所有方法，只需选择 3 个并从中开始。</p></li><li><p>花 20 分钟阅读和点击<a href="https://poloclub.github.io/cnn-explainer/"> CNN Explainer 网站</a></p><ul><li>使用“上传”按钮上传您自己的示例图像，并查看当您的图像通过 CNN 时其每一层发生的情况。</li></ul></li><li><p>加载<a href="https://pytorch.org/vision/stable/generated/torchvision.datasets.MNIST.html#torchvision.datasets.MNIST"><code>torchvision.datasets.MNIST()</code></a>训练和测试数据集。</p></li><li><p>可视化 MNIST 训练数据集的至少 5 个不同样本。</p></li><li><p>将 MNIST 训练和测试数据集转换为数据加载器<code>torch.utils.data.DataLoader</code>，设置<code>batch_size=32</code>。</p></li><li><p>重新创建在此笔记本中使用的模型（来自<a href="https://poloclub.github.io/cnn-explainer/">CNN Explainer 网站</a><code>model_2</code>的相同模型，也称为 TinyVGG），能够适合 MNIST 数据集。</p></li><li><p>在 CPU 和 GPU 上训练你在练习 8 中构建的模型，并查看每个模型需要多长时间。</p></li><li><p>使用训练好的模型进行预测，并将其中至少 5 个预测与目标标签进行比较。</p></li><li><p>绘制混淆矩阵，将模型的预测与真实标签进行比较。</p></li><li><p>创建一个形状的随机张量<code>[1, 3, 64, 64]</code>，并将其传递到具有各种超参数设置的层（这些可以是您选择的任何设置），如果参数上升和下降，<code>nn.Conv2d()</code>您会注意到什么？<code>kernel_size</code></p></li><li><p>model_2使用与本笔记本训练的模型类似的模型对测试<code>torchvision.datasets.FashionMNIST</code> 数据集进行预测。</p><ul><li>然后绘制一些模型错误的预测以及图像的标签应该是什么。</li><li>在将这些预测可视化之后，您认为这更多的是建模错误还是数据错误？</li><li>例如，模型是否可以做得更好，或者数据的标签是否太接近（例如，“衬衫”标签太接近“T 恤/上衣”）？</li></ul></li></ol><h1 id="Extra-curriculum"><a href="#Extra-curriculum" class="headerlink" title="Extra-curriculum"></a>Extra-curriculum</h1><ul><li><strong>观看：</strong> <a href="https://www.youtube.com/watch?v=iaSUYvmCekI&amp;list=PLtBw6njQRU-rwp5__7C0oIVt26ZgjG9NI&amp;index=3">麻省理工学院的深度计算机视觉简介</a>讲座。这将让你对卷积神经网络有一个很好的直观认识。</li><li>花 10 分钟点击<a href="https://pytorch.org/vision/stable/index.html">PyTorch 视觉库</a>的不同选项，有哪些不同的模块可用？</li><li>查找“最常见的卷积神经网络”，你找到了哪些架构？这些架构中是否有任何一个包含在<a href="https://pytorch.org/vision/stable/models.html"><code>torchvision.models</code></a>库中？你认为你可以用它们做什么？</li><li>要了解大量预训练的 PyTorch 计算机视觉模型以及 PyTorch 计算机视觉功能的许多不同扩展，请查看Ross Wightman 的<a href="https://github.com/rwightman/pytorch-image-models/">PyTorch 图像模型库<code>timm</code></a>（Torch 图像模型）。</li></ul>]]></content>
    
    
    <summary type="html">PyTorch-26H-4</summary>
    
    
    
    <category term="PyTorch" scheme="http://hibiscidai.com/categories/PyTorch/"/>
    
    
    <category term="学习笔记" scheme="http://hibiscidai.com/tags/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
    <category term="PyTorch" scheme="http://hibiscidai.com/tags/PyTorch/"/>
    
  </entry>
  
  <entry>
    <title>PyTorch-26H-3</title>
    <link href="http://hibiscidai.com/2024/08/16/PyTorch-26H-3/"/>
    <id>http://hibiscidai.com/2024/08/16/PyTorch-26H-3/</id>
    <published>2024-08-16T12:00:00.000Z</published>
    <updated>2024-12-10T13:33:37.000Z</updated>
    
    <content type="html"><![CDATA[<img src="/2024/08/16/PyTorch-26H-3/PyTorch-26H-3.png" class="" title="PyTorch-26H-3"><p>PyTorch-26H-3</p><span id="more"></span><h1 id="PyTorch-26H-3"><a href="#PyTorch-26H-3" class="headerlink" title="PyTorch-26H-3"></a>PyTorch-26H-3</h1><p>主页：<a href="https://www.freecodecamp.org/news/learn-pytorch-for-deep-learning-in-day/">https://www.freecodecamp.org/news/learn-pytorch-for-deep-learning-in-day/</a></p><p>youtub：<a href="https://youtu.be/V_xro1bcAuA">https://youtu.be/V_xro1bcAuA</a></p><p>github：<a href="https://github.com/mrdbourke/pytorch-deep-learning">https://github.com/mrdbourke/pytorch-deep-learning</a></p><p>Learn PyTorch for Deep Learning: Zero to Mastery book：<a href="https://www.learnpytorch.io/">https://www.learnpytorch.io/</a></p><p>PyTorch documentation：<a href="https://pytorch.org/docs/stable/index.html">https://pytorch.org/docs/stable/index.html</a></p><h1 id="What-is-a-classification-problem-什么是分类问题？"><a href="#What-is-a-classification-problem-什么是分类问题？" class="headerlink" title="What is a classification problem? 什么是分类问题？"></a>What is a classification problem? 什么是分类问题？</h1><p><a href="https://en.wikipedia.org/wiki/Statistical_classification">classification problem</a></p><div class="table-container"><table><thead><tr><th style="text-align:center">问题类型</th><th style="text-align:center">解释</th><th style="text-align:center">例子</th></tr></thead><tbody><tr><td style="text-align:center">二元分类(Binary classification)</td><td style="text-align:center">目标可以是两个选项之一，例如是或否</td><td style="text-align:center">根据某人的健康参数预测他是否患有心脏病。</td></tr><tr><td style="text-align:center">多类别分类(Multi-class classification)</td><td style="text-align:center">目标可以是两个以上选项之一</td><td style="text-align:center">确定照片中是食物、人还是狗。</td></tr><tr><td style="text-align:center">多标签分类(Multi-label classification)</td><td style="text-align:center">目标可以分配多个选项</td><td style="text-align:center">预测应为维基百科文章分配哪些类别（例如数学、科学和哲学）。</td></tr></tbody></table></div><img src="/2024/08/16/PyTorch-26H-3/PyTorch-26H-3-1.png" class="" title="PyTorch-26H-3-1"><img src="/2024/08/16/PyTorch-26H-3/PyTorch-26H-3-2.png" class="" title="PyTorch-26H-3-2"><p>分类和回归是最常见的机器学习问题类型之一。</p><p>换句话说，获取一组输入并预测该组输入属于哪个类别。</p><h1 id="What-we’re-going-to-cover-我们将要讨论的内容"><a href="#What-we’re-going-to-cover-我们将要讨论的内容" class="headerlink" title="What we’re going to cover 我们将要讨论的内容"></a>What we’re going to cover 我们将要讨论的内容</h1><ul><li>Architecture of a neural network classification model</li><li><p>神经网络分类模型的架构</p></li><li><p>Input shapes and output shapes of a classification model (features and labels)</p></li><li><p>分类模型的输入形状和输出形状（特征和标签）</p></li><li><p>Creating custom data to view, fit on and predict on</p></li><li><p>创建自定义数据以查看、拟合和预测</p></li><li><p>Steps in modelling</p></li><li><p>建模步骤</p></li><li><p>Creating a model, setting a loss function and optimiser, creating a training loop, evaluating a<br>model</p></li><li><p>创建模型、设置损失函数和优化器、创建训练循环、评估</p></li><li><p>Saving and loading models</p></li><li><p>保存和加载模型</p></li><li><p>Harnessing the power of non-linearity</p></li><li><p>利用非线性的力量</p></li><li><p>Different classification evaluation methods</p></li><li>不同的分类评估方法</li></ul><div class="table-container"><table><thead><tr><th style="text-align:center">话题</th><th style="text-align:center">内容</th></tr></thead><tbody><tr><td style="text-align:center">0. 分类神经网络的架构</td><td style="text-align:center">神经网络几乎可以具有任何形状和大小，但它们通常遵循类似的平面图。</td></tr><tr><td style="text-align:center">1. 准备二元分类数据</td><td style="text-align:center">数据几乎可以是任何东西，但首先我们将创建一个简单的二元分类数据集。</td></tr><tr><td style="text-align:center">2.构建 PyTorch 分类模型</td><td style="text-align:center">在这里我们将创建一个模型来学习数据中的模式，我们还将选择一个损失函数、优化器并构建一个特定于分类的训练循环。</td></tr><tr><td style="text-align:center">3. 将模型拟合到数据（训练）</td><td style="text-align:center">我们有数据和模型，现在让我们让模型（尝试）在（训练）数据中寻找模式。</td></tr><tr><td style="text-align:center">4. 做出预测并评估模型（推理）</td><td style="text-align:center">我们的模型在数据中发现了模式，让我们将它的发现与实际（测试）数据进行比较。</td></tr><tr><td style="text-align:center">5. 改进模型（从模型角度）</td><td style="text-align:center">我们已经训练并评估了一个模型，但它不起作用，让我们尝试一些方法来改进它。</td></tr><tr><td style="text-align:center">6.非线性</td><td style="text-align:center">到目前为止，我们的模型只具有对直线进行建模的能力，那么非线性（非直线）线又如何呢？</td></tr><tr><td style="text-align:center">7. 复制非线性函数</td><td style="text-align:center">我们使用非线性函数来帮助建模非线性数据，但是这些函数是什么样子的？</td></tr><tr><td style="text-align:center">8. 将所有内容与多类别分类结合起来</td><td style="text-align:center">让我们将迄今为止为二元分类所做的一切与多类分类问题放在一起。</td></tr></tbody></table></div><h1 id="0-Architecture-of-a-classification-neural-network-分类神经网络的架构"><a href="#0-Architecture-of-a-classification-neural-network-分类神经网络的架构" class="headerlink" title="0. Architecture of a classification neural network 分类神经网络的架构"></a>0. Architecture of a classification neural network 分类神经网络的架构</h1><p>分类神经网络的一般架构：</p><div class="table-container"><table><thead><tr><th style="text-align:center">超参数</th><th style="text-align:center">二元分类</th><th style="text-align:center">多类分类</th></tr></thead><tbody><tr><td style="text-align:center">输入层形状 Input layer shape (in_features)</td><td style="text-align:center">与特征数量相同（例如，心脏病预测中的年龄、性别、身高、体重、吸烟状况为 5）</td><td style="text-align:center">与二元分类相同</td></tr><tr><td style="text-align:center">隐藏层 Hidden layer(s)</td><td style="text-align:center">针对具体问题，最小值 = 1，最大值 = 无限制</td><td style="text-align:center">与二元分类相同</td></tr><tr><td style="text-align:center">每个隐藏层的神经元 Neurons per hidden layer</td><td style="text-align:center">具体问题具体分析，一般为 10 到 512</td><td style="text-align:center">与二元分类相同</td></tr><tr><td style="text-align:center">输出层形状 Output layer shape (out_features)</td><td style="text-align:center">1（一个类或另一个类）</td><td style="text-align:center">每类 1 张（例如，食物、人物或狗的照片各 3 张）</td></tr><tr><td style="text-align:center">隐藏层激活 Hidden layer activation</td><td style="text-align:center">通常是<a href="https://pytorch.org/docs/stable/generated/torch.nn.ReLU.html#torch.nn.ReLU">ReLU</a>（整流线性单元），<a href="https://en.wikipedia.org/wiki/Activation_function#Table_of_activation_functions">其他激活</a></td><td style="text-align:center">与二元分类相同</td></tr><tr><td style="text-align:center">输出激活 Output activation</td><td style="text-align:center"><a href="https://en.wikipedia.org/wiki/Sigmoid_function">Sigmoid</a> <a href="https://pytorch.org/docs/stable/generated/torch.sigmoid.html">torch.sigmoid</a></td><td style="text-align:center"><a href="https://en.wikipedia.org/wiki/Softmax_function">Softmax</a> <a href="https://pytorch.org/docs/stable/generated/torch.nn.Softmax.html">torch.softmax</a></td></tr><tr><td style="text-align:center">损失函数 Loss function</td><td style="text-align:center"><a href="https://en.wikipedia.org/wiki/Cross-entropy#Cross-entropy_loss_function_and_logistic_regression">二元交叉熵Binary crossentropy</a> <a href="https://pytorch.org/docs/stable/generated/torch.nn.BCELoss.html">torch.nn.BCELoss</a></td><td style="text-align:center">交叉熵 <a href="https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html">torch.nn.CrossEntropyLoss</a></td></tr><tr><td style="text-align:center">优化器 Optimizer</td><td style="text-align:center"><a href="https://pytorch.org/docs/stable/generated/torch.optim.SGD.html">SGD stochastic gradient descent</a> ，<a href="https://pytorch.org/docs/stable/generated/torch.optim.Adam.html">Adam</a>，<a href="https://pytorch.org/docs/stable/optim.html">torch.optim</a></td><td style="text-align:center">与二元分类相同</td></tr></tbody></table></div><p>这个分类神经网络组件的成分列表会根据您正在处理的问题而有所不同。</p><img src="/2024/08/16/PyTorch-26H-3/PyTorch-26H-3-2_1.png" class="" title="PyTorch-26H-3-2_1"><h1 id="1-Make-classification-data-and-get-it-ready-分类数据制作及准备"><a href="#1-Make-classification-data-and-get-it-ready-分类数据制作及准备" class="headerlink" title="1. Make classification data and get it ready 分类数据制作及准备"></a>1. Make classification data and get it ready 分类数据制作及准备</h1><p>使用 <a href="https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_circles.html">make_circles()</a> 中的 <code>Scikit-Learn</code> 方法生成两个具有不同颜色的圆圈。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># conda install scikit-learn</span></span><br><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> make_circles</span><br><span class="line"></span><br><span class="line"><span class="comment"># Make 1000 samples </span></span><br><span class="line">n_samples = <span class="number">1000</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Create circles</span></span><br><span class="line">X, y = make_circles(n_samples,</span><br><span class="line">                    noise = <span class="number">0.03</span>, <span class="comment"># a little bit of noise to the dots</span></span><br><span class="line">                    random_state = <span class="number">42</span>) <span class="comment"># keep random state so we get the same values</span></span><br></pre></td></tr></table></figure><p>查看前5个X值y。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;First 5 X features:\n<span class="subst">&#123;X[:<span class="number">5</span>]&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;\nFirst 5 y labels:\n<span class="subst">&#123;y[:<span class="number">5</span>]&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">First 5 X features:</span><br><span class="line">[[ 0.75424625  0.23148074]</span><br><span class="line"> [-0.75615888  0.15325888]</span><br><span class="line"> [-0.81539193  0.17328203]</span><br><span class="line"> [-0.39373073  0.69288277]</span><br><span class="line"> [ 0.44220765 -0.89672343]]</span><br><span class="line"></span><br><span class="line">First 5 y labels:</span><br><span class="line">[1 1 1 1 0]</span><br></pre></td></tr></table></figure><p>可视化：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Make DataFrame of circle data</span></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line">circles = pd.DataFrame(&#123;<span class="string">&quot;X1&quot;</span>: X[:, <span class="number">0</span>],</span><br><span class="line">       <span class="string">&quot;X2&quot;</span>: X[:, <span class="number">1</span>],</span><br><span class="line">       <span class="string">&quot;label&quot;</span>: y&#125;)</span><br><span class="line">circles.head(<span class="number">10</span>)</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">X1X2label</span><br><span class="line">00.7542460.2314811</span><br><span class="line">1-0.7561590.1532591</span><br><span class="line">2-0.8153920.1732821</span><br><span class="line">3-0.3937310.6928831</span><br><span class="line">40.442208-0.8967230</span><br><span class="line">5-0.4796460.6764351</span><br><span class="line">6-0.0136480.8033491</span><br><span class="line">70.7715130.1477601</span><br><span class="line">8-0.169322-0.7934561</span><br><span class="line">9-0.1214861.0215090</span><br></pre></td></tr></table></figure><p>看起来每对X特征（X1和X2）都有一个标签（y）值，即 0 或 1。</p><p>这告诉我们我们的问题是二元分类，因为只有两个选项（0 或 1）。</p><p>每个类别有多少个值？</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Check different labels</span></span><br><span class="line">circles.label.value_counts()</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">1    500</span><br><span class="line">0    500</span><br><span class="line">Name: label, dtype: int64</span><br></pre></td></tr></table></figure><p>0和1各五百个</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Visualize with a plot</span></span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">plt.scatter(x=X[:, <span class="number">0</span>], </span><br><span class="line">            y=X[:, <span class="number">1</span>], </span><br><span class="line">            c=y, </span><br><span class="line">            cmap=plt.cm.RdYlBu);</span><br></pre></td></tr></table></figure><img src="/2024/08/16/PyTorch-26H-3/PyTorch-26H-3-3.png" class="" title="PyTorch-26H-3-3"><p>如何构建 PyTorch 神经网络来将点分类为红色（0）或蓝色（1）。</p><blockquote><p>在机器学习中，这个数据集通常被视为玩具问题（用于尝试和测试事物的问题）。但它代表了分类的主要关键，您有一些以数值表示的数据，并且您想要构建一个能够对其进行分类的模型，在我们的例子中，将其分成红点或蓝点。</p></blockquote><p><a href="https://scikit-learn.org/1.5/datasets/toy_dataset.html">scikit-learn-toy datasets</a></p><h2 id="1-1-Input-and-output-shapes-输入和输出形状"><a href="#1-1-Input-and-output-shapes-输入和输出形状" class="headerlink" title="1.1 Input and output shapes 输入和输出形状"></a>1.1 Input and output shapes 输入和输出形状</h2><img src="/2024/08/16/PyTorch-26H-3/PyTorch-26H-3-3_1.png" class="" title="PyTorch-26H-3-3_1"><img src="/2024/08/16/PyTorch-26H-3/PyTorch-26H-3-3_2.png" class="" title="PyTorch-26H-3-3_2"><p>可以设置32的batch size。使用大型 minibatch 进行训练对测试错误不利。</p><p>深度学习中最常见的错误之一是形状错误。</p><p>张量形状和张量运算不匹配将导致模型出现错误。</p><p>我们将会在整个课程中看到很多这样的情况。</p><p>输入和输出形状。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Check the shapes of our features and labels</span></span><br><span class="line">X.shape, y.shape</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">((1000, 2), (1000,))</span><br></pre></td></tr></table></figure><p>看起来我们在每个维度的第一维度上都找到了匹配项。</p><p>有 1000 个 X 和 1000 个 y。</p><p>但是 X 的第二维度是什么？</p><p>查看单个样本（特征和标签）的值和形状通常很有帮助。</p><p>这样做将帮助您了解您希望从模型中获得什么样的输入和输出形状。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># View the first example of features and labels</span></span><br><span class="line">X_sample = X[<span class="number">0</span>]</span><br><span class="line">y_sample = y[<span class="number">0</span>]</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Values for one sample of X: <span class="subst">&#123;X_sample&#125;</span> and the same for y: <span class="subst">&#123;y_sample&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Shapes for one sample of X: <span class="subst">&#123;X_sample.shape&#125;</span> and the same for y: <span class="subst">&#123;y_sample.shape&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Values for one sample of X: [0.75424625 0.23148074] and the same for y: 1</span><br><span class="line">Shapes for one sample of X: (2,) and the same for y: ()</span><br></pre></td></tr></table></figure><p>这告诉我们 X 的第二个维度意味着它有两个特征（向量vector），而 y 只有一个特征（标量scalar）。</p><p>我们有两个输入和一个输出。</p><h2 id="1-2-Turn-data-into-tensors-and-create-train-and-test-splits-将数据转换为张量并创建训练和测试分割"><a href="#1-2-Turn-data-into-tensors-and-create-train-and-test-splits-将数据转换为张量并创建训练和测试分割" class="headerlink" title="1.2 Turn data into tensors and create train and test splits 将数据转换为张量并创建训练和测试分割"></a>1.2 Turn data into tensors and create train and test splits 将数据转换为张量并创建训练和测试分割</h2><p>1、将我们的数据转换成张量（现在我们的数据在 NumPy 数组中，PyTorch 更喜欢使用 PyTorch 张量）。<br>2、<code>X</code>将我们的数据分成训练集和测试集（我们将在训练集上训练一个模型来学习和之间的模式，<code>y</code>然后在测试数据集上评估这些学习到的模式）。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Turn data into tensors</span></span><br><span class="line"><span class="comment"># Otherwise this causes issues with computations later on</span></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line">X = torch.from_numpy(X).<span class="built_in">type</span>(torch.<span class="built_in">float</span>)</span><br><span class="line">y = torch.from_numpy(y).<span class="built_in">type</span>(torch.<span class="built_in">float</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># View the first five samples</span></span><br><span class="line">X[:<span class="number">5</span>], y[:<span class="number">5</span>]</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">(tensor([[ 0.7542,  0.2315],</span><br><span class="line">         [-0.7562,  0.1533],</span><br><span class="line">         [-0.8154,  0.1733],</span><br><span class="line">         [-0.3937,  0.6929],</span><br><span class="line">         [ 0.4422, -0.8967]]),</span><br><span class="line"> tensor([1., 1., 1., 1., 0.]))</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">type</span>(X), X.dtype, y.dtype</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">(torch.Tensor, torch.float32, torch.float32)</span><br></pre></td></tr></table></figure><p>现在我们的数据是张量格式，让我们将其分成训练集和测试集。</p><p>使用 Scikit-Learn 中 <a href="https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html">train_test_split()</a> 函数。</p><p>我们将使用<code>test_size=0.2</code>（80％训练，20％测试），并且由于分割在数据中随机发生，<code>random_state=42</code>因此我们使用可重现的分割。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Split data into train and test sets</span></span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"></span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(X, </span><br><span class="line">                            y, </span><br><span class="line">                            test_size=<span class="number">0.2</span>, <span class="comment"># 20% test, 80% train</span></span><br><span class="line">                            random_state=<span class="number">42</span>) <span class="comment"># make the random split reproducible</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">len</span>(X_train), <span class="built_in">len</span>(X_test), <span class="built_in">len</span>(y_train), <span class="built_in">len</span>(y_test)</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">(800, 200, 800, 200)</span><br></pre></td></tr></table></figure><p>现在有 800 个训练样本和 200 个测试样本。</p><h1 id="2-Building-a-model-建立模型"><a href="#2-Building-a-model-建立模型" class="headerlink" title="2. Building a model 建立模型"></a>2. Building a model 建立模型</h1><p>模型需要分为几个部分。</p><p>1、设置与设备无关的代码（这样我们的模型可以在 CPU 或 GPU 上运行）。<br>2、通过子类化构建模型 <code>nn.Module</code>。<br>3、定义损失函数和优化器。<br>4、创建训练循环。</p><h2 id="设置与设备无关的代码"><a href="#设置与设备无关的代码" class="headerlink" title="设置与设备无关的代码"></a>设置与设备无关的代码</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Standard PyTorch imports</span></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"></span><br><span class="line"><span class="comment"># Make device agnostic code</span></span><br><span class="line">device = <span class="string">&quot;cuda&quot;</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&quot;cpu&quot;</span></span><br><span class="line">device</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&#x27;cuda&#x27;</span><br></pre></td></tr></table></figure><h2 id="通过子类化构建模型"><a href="#通过子类化构建模型" class="headerlink" title="通过子类化构建模型"></a>通过子类化构建模型</h2><p>我们需要一个模型，能够处理我们的<code>X</code>数据作为输入，并生成与我们的数据形状相同<code>y</code>的输出。</p><p>换句话说，给定<code>X</code>（特征feature），我们希望我们的模型预测<code>y</code>（标签label）。</p><p>这种具有特征和标签的设置称为<code>监督学习</code>。因为你的数据会告诉你的模型，给定某个输入，应该得到什么样的输出。</p><p>要创建这样的模型，需要处理<code>X</code>和的输入和输出形状<code>y</code>。</p><p>创建一个模型类：</p><p>1、子类 <code>nn.Module</code>（几乎所有 PyTorch 模型都是 <code>nn.Module</code> 的子类）。<br>2、在构造函数中创建 2 个 <code>nn.Linear</code> 层，能够处理 <code>X</code> 和 <code>y</code> 的输入和输出形状。<br>3、定义一个包含模型前向传递计算的 <code>forward()</code> 方法。<br>4、实例化模型类并将其发送到目标设备。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 1. Construct a model class that subclasses nn.Module</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">CircleModelV0</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        <span class="comment"># 2. Create 2 nn.Linear layers capable of handling X and y input and output shapes</span></span><br><span class="line">        self.layer_1 = nn.Linear(in_features=<span class="number">2</span>, out_features=<span class="number">5</span>) <span class="comment"># takes in 2 features (X), produces 5 features</span></span><br><span class="line">        self.layer_2 = nn.Linear(in_features=<span class="number">5</span>, out_features=<span class="number">1</span>) <span class="comment"># takes in 5 features, produces 1 feature (y)</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 3. Define a forward method containing the forward pass computation</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        <span class="comment"># Return the output of layer_2, a single feature, the same shape as y</span></span><br><span class="line">        <span class="keyword">return</span> self.layer_2(self.layer_1(x)) <span class="comment"># computation goes through layer_1 first then the output of layer_1 goes through layer_2</span></span><br><span class="line">    <span class="comment"># x -&gt; layer_1 -&gt;  layer_2 -&gt; output</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 4. Create an instance of the model and send it to target device</span></span><br><span class="line">model_0 = CircleModelV0().to(device)</span><br><span class="line">model_0</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">CircleModelV0(</span><br><span class="line">  (layer_1): Linear(in_features=2, out_features=5, bias=True)</span><br><span class="line">  (layer_2): Linear(in_features=5, out_features=1, bias=True)</span><br><span class="line">)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">device</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&#x27;cuda&#x27;</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">next</span>(model_0.parameters()).device</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">device(type=&#x27;cuda&#x27;, index=0)</span><br></pre></td></tr></table></figure><img src="/2024/08/16/PyTorch-26H-3/PyTorch-26H-3-3_3.png" class="" title="PyTorch-26H-3-3_3"><p>50%的准确率，跟盲猜一样。</p><p>唯一的重大变化是 <code>self.layer_1</code> 和 <code>self.layer_2</code> 之间发生的事情。</p><p><code>self.layer_1</code> 接受 2 个输入特征 <code>in_features=2</code> 并产生 5 个输出特征 <code>out_features=5</code>。</p><p>这被称为具有 5 个隐藏单元或神经元。该层将输入数据从 2 个特征变为 5 个特征。</p><p>这使得模型可以从 5 个数字而不是仅仅 2 个数字中学习模式，从而可能产生更好的输出。</p><p>在神经网络层中使用的隐藏单元的数量是一个<code>超参数</code>（可以自己设置的值），并且没有必须使用的固定值。<br>通常情况下，数量越多越好，但也可能太多。您选择的数量取决于您的模型类型和您正在使用的数据集。</p><p>由于我们的数据集很小而且简单，因此我们会将其保持较小。</p><p>隐藏单元的唯一规则是下一层（在我们的例子中为 <code>self.layer_2</code>）必须采用与前一层 <code>out_features</code> 相同的 <code>in_features</code>。</p><p>这就是为什么 <code>self.layer_2</code> 有 <code>in_features=5</code>，它从 <code>self.layer_1</code> 中获取 <code>out_features=5</code> 并对它们执行线性计算，将它们转换为 <code>out_features=1</code>（与 y 相同的形状）。</p><p>与我们刚刚构建的分类神经网络类似的视觉示例。尝试在 <a href="https://playground.tensorflow.org/#activation=tanh&amp;batchSize=10&amp;dataset=circle&amp;regDataset=reg-plane&amp;learningRate=0.03&amp;regularizationRate=0&amp;noise=0&amp;networkShape=4,2&amp;seed=0.57514&amp;showTestData=false&amp;discretize=false&amp;percTrainData=50&amp;x=true&amp;y=true&amp;xTimesY=false&amp;xSquared=false&amp;ySquared=false&amp;cosX=false&amp;sinX=false&amp;cosY=false&amp;sinY=false&amp;collectStats=false&amp;problem=classification&amp;initZero=false&amp;hideText=false">TensorFlow Playground</a> 网站上创建一个您自己的神经网络。</p><h3 id="Sequential-和-nn-model的区别"><a href="#Sequential-和-nn-model的区别" class="headerlink" title="Sequential 和 nn.model的区别"></a>Sequential 和 nn.model的区别</h3><p>您也可以使用 <code>nn.Sequential</code> 执行与上述相同的操作。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Replicate CircleModelV0 with nn.Sequential</span></span><br><span class="line">model_0 = nn.Sequential(</span><br><span class="line">    nn.Linear(in_features=<span class="number">2</span>, out_features=<span class="number">5</span>),</span><br><span class="line">    nn.Linear(in_features=<span class="number">5</span>, out_features=<span class="number">1</span>)</span><br><span class="line">).to(device)</span><br><span class="line"></span><br><span class="line">model_0</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">Sequential(</span><br><span class="line">  (0): Linear(in_features=2, out_features=5, bias=True)</span><br><span class="line">  (1): Linear(in_features=5, out_features=1, bias=True)</span><br><span class="line">)</span><br></pre></td></tr></table></figure><p>这看起来比子类化简单多了 <code>nn.Module</code>，为什么不总是使用呢<code>nn.Sequential</code>？</p><p><code>nn.Sequential</code>对于直接计算来说非常棒，但是，正如命名空间所说，它总是按顺序运行。</p><p>因此，如果您希望发生其他事情（而不仅仅是直接的顺序计算），您将需要定义自己的自定义<code>nn.Module</code>子类。</p><p>例如使用<code>Sequential</code>建立的模型，可以融合到<code>nn.model</code>中去</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">model_0 = nn.Sequential(</span><br><span class="line">    nn.Linear(in_features=<span class="number">2</span>, out_features=<span class="number">5</span>),</span><br><span class="line">    nn.Linear(in_features=<span class="number">5</span>, out_features=<span class="number">1</span>)</span><br><span class="line">).to(device)</span><br><span class="line"></span><br><span class="line"><span class="comment">#↓</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">CircleModelV0</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        </span><br><span class="line">      self.two_linear_layer = nn.Sequential(</span><br><span class="line">      nn.Liner(in_features=<span class="number">2</span>, out_features=<span class="number">5</span>),</span><br><span class="line">      nn.Liner(in_features=<span class="number">5</span>, out_features=<span class="number">1</span>)</span><br><span class="line">      )</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">      <span class="keyword">return</span> self.two_linear_layer(x)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">model_0.state_dict()</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">OrderedDict([(&#x27;0.weight&#x27;,</span><br><span class="line">              tensor([[ 0.2259, -0.3071],</span><br><span class="line">                      [ 0.1391, -0.4125],</span><br><span class="line">                      [ 0.0519, -0.6626],</span><br><span class="line">                      [ 0.0739,  0.2506],</span><br><span class="line">                      [ 0.3370,  0.2946]])),</span><br><span class="line">             (&#x27;0.bias&#x27;, tensor([0.0039, 0.5227, 0.4068, 0.2547, 0.0523])),</span><br><span class="line">             (&#x27;1.weight&#x27;,</span><br><span class="line">              tensor([[ 0.0300, -0.3890,  0.2665,  0.0364,  0.2124]])),</span><br><span class="line">             (&#x27;1.bias&#x27;, tensor([-0.2119]))])</span><br></pre></td></tr></table></figure><p>修改模型隐藏层个数 会产生不同的<code>state_dict</code>信息</p><h3 id="观察模型传递数据"><a href="#观察模型传递数据" class="headerlink" title="观察模型传递数据"></a>观察模型传递数据</h3><p>通过模型传递一些数据时会发生什么。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Make predictions with the model</span></span><br><span class="line">untrained_preds = model_0(X_test.to(device))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Length of predictions: <span class="subst">&#123;<span class="built_in">len</span>(untrained_preds)&#125;</span>, Shape: <span class="subst">&#123;untrained_preds.shape&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Length of test samples: <span class="subst">&#123;<span class="built_in">len</span>(y_test)&#125;</span>, Shape: <span class="subst">&#123;y_test.shape&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;\nFirst 10 predictions:\n<span class="subst">&#123;untrained_preds[:<span class="number">10</span>]&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;\nFirst 10 test labels:\n<span class="subst">&#123;y_test[:<span class="number">10</span>]&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">Length of predictions: 200, Shape: torch.Size([200, 1])</span><br><span class="line">Length of test samples: 200, Shape: torch.Size([200])</span><br><span class="line"></span><br><span class="line">First 10 predictions:</span><br><span class="line">tensor([[-0.1631],</span><br><span class="line">        [-0.4051],</span><br><span class="line">        [ 0.3693],</span><br><span class="line">        [-0.3135],</span><br><span class="line">        [ 0.2072],</span><br><span class="line">        [ 0.0607],</span><br><span class="line">        [-0.4923],</span><br><span class="line">        [-0.3836],</span><br><span class="line">        [ 0.3753],</span><br><span class="line">        [-0.4231]], device=&#x27;cuda:0&#x27;, grad_fn=&lt;SliceBackward0&gt;)</span><br><span class="line"></span><br><span class="line">First 10 test labels:</span><br><span class="line">tensor([1., 0., 1., 0., 1., 1., 0., 0., 1., 0.])</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Make predictions</span></span><br><span class="line"><span class="keyword">with</span> torch.inference_mode():</span><br><span class="line">  untrained_preds = model_0(X_test.to(device))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Length of predictions: <span class="subst">&#123;<span class="built_in">len</span>(untrained_preds)&#125;</span>, Shape: <span class="subst">&#123;untrained_preds.shape&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Length of test samples: <span class="subst">&#123;<span class="built_in">len</span>(X_test)&#125;</span>, Shape: <span class="subst">&#123;X_test.shape&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;\nFirst 10 predictions:\n<span class="subst">&#123;torch.<span class="built_in">round</span>(untrained_preds[:<span class="number">10</span>])&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;\nFirst 10 labels:\n<span class="subst">&#123;y_test[:<span class="number">10</span>]&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">Length of predictions: 200, Shape: torch.Size([200, 1])</span><br><span class="line">Length of test samples: 200, Shape: torch.Size([200, 2])</span><br><span class="line"></span><br><span class="line">First 10 predictions:</span><br><span class="line">tensor([[-0.],</span><br><span class="line">        [-0.],</span><br><span class="line">        [-0.],</span><br><span class="line">        [-0.],</span><br><span class="line">        [0.],</span><br><span class="line">        [0.],</span><br><span class="line">        [-0.],</span><br><span class="line">        [-0.],</span><br><span class="line">        [-0.],</span><br><span class="line">        [-0.]], device=&#x27;cuda:0&#x27;)</span><br><span class="line"></span><br><span class="line">First 10 labels:</span><br><span class="line">tensor([1., 0., 1., 0., 1., 1., 0., 0., 1., 0.])</span><br></pre></td></tr></table></figure><p>预测的数量与测试标签的数量相同，但是预测的形式或形状看起来与测试标签不一样。</p><h2 id="定义损失函数和优化器"><a href="#定义损失函数和优化器" class="headerlink" title="定义损失函数和优化器"></a>定义损失函数和优化器</h2><p>不同类型的问题需要不同的损失函数。</p><p><strong>损失函数衡量模型预测的 错误 程度。</strong></p><p>回归问题（预测数字）：使用平均绝对误差（MAE）损失。<br>二元分类问题（目前的问题），使用<a href="https://towardsdatascience.com/understanding-binary-cross-entropy-log-loss-a-visual-explanation-a3ac6025181a">二元交叉熵</a>作为损失函数。</p><p>相同的优化器函数通常可用于不同的问题空间。</p><p>随机梯度下降优化器（<code>SGD，torch.optim.SGD()</code>）可用于解决一系列问题，Adam 优化器（<code>torch.optim.Adam()</code>）同样适用。</p><div class="table-container"><table><thead><tr><th style="text-align:center">损失函数/优化器</th><th style="text-align:center">问题类型</th><th style="text-align:center">PyTorch代码</th></tr></thead><tbody><tr><td style="text-align:center">随机梯度下降（SGD）优化器</td><td style="text-align:center">分类、回归等</td><td style="text-align:center"><a href="https://pytorch.org/docs/stable/generated/torch.optim.SGD.html">torch.optim.SGD()</a></td></tr><tr><td style="text-align:center">Adam 优化器</td><td style="text-align:center">分类、回归等</td><td style="text-align:center"><a href="https://pytorch.org/docs/stable/generated/torch.optim.Adam.html">torch.optim.Adam()</a></td></tr><tr><td style="text-align:center">二元交叉熵损失</td><td style="text-align:center">二元分类</td><td style="text-align:center"><a href="https://pytorch.org/docs/stable/generated/torch.nn.BCEWithLogitsLoss.html">torch.nn.BCELossWithLogits</a> 或者 <a href="https://pytorch.org/docs/stable/generated/torch.nn.BCELoss.html">torch.nn.BCELoss</a></td></tr><tr><td style="text-align:center">交叉熵损失</td><td style="text-align:center">多类别分类</td><td style="text-align:center"><a href="https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html">torch.nn.CrossEntropyLoss</a></td></tr><tr><td style="text-align:center">平均绝对误差 (MAE) 或 L1 损失</td><td style="text-align:center">回归</td><td style="text-align:center"><a href="https://pytorch.org/docs/stable/generated/torch.nn.L1Loss.html">torch.nn.L1Loss</a></td></tr><tr><td style="text-align:center">均方误差 (MSE) 或 L2 损失</td><td style="text-align:center">回归</td><td style="text-align:center"><a href="https://pytorch.org/docs/stable/generated/torch.nn.MSELoss.html#torch.nn.MSELoss">torch.nn.MSELoss</a></td></tr></tbody></table></div><p>由于我们正在处理二元分类问题，因此我们使用二元交叉熵损失函数。</p><ul><li>什么是logit？</li></ul><script type="math/tex; mode=display">logit(p) = log(\frac{p}{1-p})</script><p><a href="https://en.wikipedia.org/wiki/Logit">logit-wiki</a><br><a href="https://www.learnpytorch.io/02_pytorch_classification/#21-setup-loss-function-and-optimizer">有关损失函数和优化器的一些常见选择 </a><br>对于损失函数，我们将使用 <code>torch.nn.BECWithLogitsLoss()</code>，有关二元交叉熵 (BCE) 的更多信息，请查看<a href="https://towardsdatascience.com/understanding-binary-cross-entropy-log-loss-a-visual-explanation-a3ac6025181a">本文</a><br><a href="https://stackoverflow.com/a/52111173/7900723">有关深度学习中 logit 的定义</a><br>有关不同的优化器，请参阅 <code>torch.optim</code></p><ul><li>PyTorch 有两种二元交叉熵实现：</li></ul><p>1、<a href="https://pytorch.org/docs/stable/generated/torch.nn.BCELoss.html">torch.nn.BCELoss()</a>- 创建一个损失函数，测量目标（标签）和输入（特征）之间的二元交叉熵。<br>2、<a href="https://pytorch.org/docs/stable/generated/torch.nn.BCEWithLogitsLoss.html">torch.nn.BCEWithLogitsLoss()</a> - 这与上面的相同，只是它有一个内置的 sigmoid 层 (<a href="https://pytorch.org/docs/stable/generated/torch.nn.Sigmoid.html">nn.Sigmoid</a>)</p><p><a href="https://pytorch.org/docs/stable/generated/torch.nn.BCEWithLogitsLoss.html">torch.nn.BCEWithLogitsLoss()</a> 的<a href="https://pytorch.org/docs/stable/generated/torch.nn.BCEWithLogitsLoss.html">文档</a>指出，它比在 <code>nn.Sigmoid</code> 层之后使用 <code>torch.nn.BCELoss()</code> 更具数值稳定性。</p><p>通常，实现 2 是更好的选择。但是对于高级用法，可能希望分离 <code>nn.Sigmoid</code> 和 <code>torch.nn.BCELoss()</code> 的组合，但这超出了本笔记本的范围。</p><p>了解了这一点，让我们创建一个损失函数和一个优化器。</p><ul><li>对于优化器，我们将使用 <code>torch.optim.SGD()</code> 以学习率为 0.1 来优化模型参数。</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Create a loss function</span></span><br><span class="line"><span class="comment"># loss_fn = nn.BCELoss() # BCELoss = no sigmoid built-in</span></span><br><span class="line">loss_fn = nn.BCEWithLogitsLoss() <span class="comment"># BCEWithLogitsLoss = sigmoid built-in</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Create an optimizer</span></span><br><span class="line">optimizer = torch.optim.SGD(params=model_0.parameters(), </span><br><span class="line">                            lr=<span class="number">0.1</span>)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">model_0.state_dict()</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">OrderedDict([(&#x27;0.weight&#x27;,</span><br><span class="line">              tensor([[ 0.2259, -0.3071],</span><br><span class="line">                      [ 0.1391, -0.4125],</span><br><span class="line">                      [ 0.0519, -0.6626],</span><br><span class="line">                      [ 0.0739,  0.2506],</span><br><span class="line">                      [ 0.3370,  0.2946]])),</span><br><span class="line">             (&#x27;0.bias&#x27;, tensor([0.0039, 0.5227, 0.4068, 0.2547, 0.0523])),</span><br><span class="line">             (&#x27;1.weight&#x27;,</span><br><span class="line">              tensor([[ 0.0300, -0.3890,  0.2665,  0.0364,  0.2124]])),</span><br><span class="line">             (&#x27;1.bias&#x27;, tensor([-0.2119]))])</span><br></pre></td></tr></table></figure><ul><li>创建一个评估指标</li></ul><p>损失函数衡量模型的错误程度 → 评估指标视为衡量模型的正确程度。</p><p>评估指标提供了不同的视角。<br>在评估模型时，最好从多个角度看待事物。<br>有几种评估指标可用于分类问题，但让我们从准确度开始。<br>准确度可以通过将正确预测的总数除以预测总数来衡量。<br>例如，如果一个模型在 100 个预测中做出 99 个正确的预测，则准确度为 99%。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Calculate accuracy (a classification metric)</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">accuracy_fn</span>(<span class="params">y_true, y_pred</span>):</span><br><span class="line">    correct = torch.eq(y_true, y_pred).<span class="built_in">sum</span>().item() <span class="comment"># torch.eq() calculates where two tensors are equal</span></span><br><span class="line">    acc = (correct / <span class="built_in">len</span>(y_pred)) * <span class="number">100</span> </span><br><span class="line">    <span class="keyword">return</span> acc</span><br></pre></td></tr></table></figure><p>现在可以在训练模型时使用此功能来测量其性能和损失。</p><h1 id="3-Train-model"><a href="#3-Train-model" class="headerlink" title="3. Train model"></a>3. Train model</h1><p>PyTorch 训练循环步骤：</p><p>1、前向传递 Forward pass - 模型对所有训练数据进行一次遍历，执行其 forward() 函数计算 (<code>model(x_train)</code>)。<br>2、计算损失 Calculate the loss  - 将模型的输出 (预测) 与基本事实进行比较，并进行评估以查看其错误程度 (<code>loss = loss_fn(y_pred, y_train)</code>)。<br>3、零梯度 Zero gradients  - 优化器梯度设置为零 (默认情况下是累积的)，因此可以为特定的训练步骤重新计算 (<code>optimizer.zero_grad()</code>)。<br>4、对损失执行反向传播 Perform backpropagation on the loss - 针对要更新的每个模型参数 (每个参数的 <code>require_grad=True</code>) 计算损失的梯度。这称为反向传播，因此为“向后”(<code>loss.backward()</code>)。<br>5、步进优化器 (梯度下降) Step the optimizer (gradient descent)  - 使用 <code>require_grad=True</code> 更新参数，以根据损失梯度改进它们 (<code>optimizer.step()</code>)。</p><h2 id="3-1-Going-from-raw-model-outputs-to-predicted-labels-logits-gt-prediction-probabilities-gt-prediction-labels-从原始模型输出到预测标签（logits-gt-预测概率-gt-预测标签）"><a href="#3-1-Going-from-raw-model-outputs-to-predicted-labels-logits-gt-prediction-probabilities-gt-prediction-labels-从原始模型输出到预测标签（logits-gt-预测概率-gt-预测标签）" class="headerlink" title="3.1 Going from raw model outputs to predicted labels (logits -&gt; prediction probabilities -&gt; prediction labels) 从原始模型输出到预测标签（logits -&gt; 预测概率 -&gt; 预测标签）"></a>3.1 Going from raw model outputs to predicted labels (logits -&gt; prediction probabilities -&gt; prediction labels) 从原始模型输出到预测标签（logits -&gt; 预测概率 -&gt; 预测标签）</h2><p>在训练循环步骤之前，让我们看看在前向传递过程中我们的模型会产生什么结果（前向传递由方法定义<code>forward()</code>）。</p><p>为此，让我们向模型传递一些数据。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># View the frist 5 outputs of the forward pass on the test data</span></span><br><span class="line">y_logits = model_0(X_test.to(device))[:<span class="number">5</span>]</span><br><span class="line">y_logits</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">tensor([[-0.1631],</span><br><span class="line">        [-0.4051],</span><br><span class="line">        [ 0.3693],</span><br><span class="line">        [-0.3135],</span><br><span class="line">        [ 0.2072]], device=&#x27;cuda:0&#x27;, grad_fn=&lt;SliceBackward0&gt;)</span><br></pre></td></tr></table></figure><p>由于我们的模型尚未经过训练，这些输出基本上是随机的。</p><p>但它们是什么？它们是我们的 <code>forward()</code> 方法的输出。</p><p>它实现了两层 <code>nn.Linear()</code>，它在内部调用以下方程：</p><script type="math/tex; mode=display">\mathbf{y} = x \cdot \mathbf{Weights}^T + \mathbf{bias}</script><p>该方程（$\mathbf{y}$）的原始输出（未修改），反过来，我们模型的原始输出通常被称为<code>logits</code>。</p><p>这就是我们的模型在接受输入数据（等式中的 x 或代码中的 <code>X_test</code>）时输出的内容，<code>logits</code>。</p><p>然而，这些数字很难解释。</p><p>我们希望有一些数字可以与我们的真实标签相媲美。</p><p>为了将我们模型的原始输出（logits）变成这种形式，我们可以使用 <a href="https://pytorch.org/docs/stable/generated/torch.sigmoid.html">sigmoid 激活函数</a>。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Use sigmoid on model logits</span></span><br><span class="line">y_pred_probs = torch.sigmoid(y_logits)</span><br><span class="line">y_pred_probs</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">tensor([[0.4593],</span><br><span class="line">        [0.4001],</span><br><span class="line">        [0.5913],</span><br><span class="line">        [0.4223],</span><br><span class="line">        [0.5516]], device=&#x27;cuda:0&#x27;, grad_fn=&lt;SigmoidBackward0&gt;)</span><br></pre></td></tr></table></figure><p>看起来输出现在具有某种一致性（即使它们仍然是随机的）。</p><p>它们现在采用<code>预测概率</code>的形式（我通常将其称为 <code>y_pred_probs</code>），换句话说，这些值现在是模型认为数据点属于一个类或另一个类的程度。</p><p>在我们的例子中，由于我们正在处理二元分类，所以我们的理想输出是 0 或 1。</p><p>因此这些值可以被视为决策边界。</p><p>越接近0，模型越认为该样本属于0类，越接近1，模型越认为该样本属于1类。</p><p>更具体地说：</p><p>如果 <code>y_pred_probs&gt; = 0.5</code>，<code>y=1</code>（第 1 类）<br>如果 <code>y_pred_probs &lt; 0.5</code>，<code>y=0</code>（第 0 类）</p><p>为了将我们的预测概率转化为预测标签，我们可以对 sigmoid  激活函数的输出进行四舍五入。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Find the predicted labels (round the prediction probabilities)</span></span><br><span class="line">y_preds = torch.<span class="built_in">round</span>(y_pred_probs)</span><br><span class="line"></span><br><span class="line"><span class="comment"># In full</span></span><br><span class="line">y_pred_labels = torch.<span class="built_in">round</span>(torch.sigmoid(model_0(X_test.to(device))[:<span class="number">5</span>]))</span><br><span class="line"></span><br><span class="line"><span class="comment"># Check for equality</span></span><br><span class="line"><span class="built_in">print</span>(torch.eq(y_preds.squeeze(), y_pred_labels.squeeze()))</span><br><span class="line"></span><br><span class="line"><span class="comment"># Get rid of extra dimension</span></span><br><span class="line">y_preds.squeeze()</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">tensor([True, True, True, True, True], device=&#x27;cuda:0&#x27;)</span><br><span class="line">tensor([0., 0., 1., 0., 1.], device=&#x27;cuda:0&#x27;, grad_fn=&lt;SqueezeBackward0&gt;)</span><br></pre></td></tr></table></figure><p>现在看起来我们的模型的预测与我们的真实标签 ( <code>y_test</code>) 的形式相同。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">y_test[:<span class="number">5</span>]</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tensor([1., 0., 1., 0., 1.])</span><br></pre></td></tr></table></figure><p>这意味着我们将能够将模型的预测与测试标签进行比较，以了解其表现如何。</p><p>回顾一下，我们使用 sigmoid 激活函数将模型的原始输出 (logits) 转换为预测概率。</p><p>然后通过四舍五入将预测概率转换为预测标签。</p><blockquote><p>注意：sigmoid 激活函数通常仅用于二分类 logits。对于多类分类，我们将考虑使用 <a href="https://pytorch.org/docs/stable/generated/torch.nn.Softmax.html">softmax 激活函数</a>。<br>将模型的原始输出传递给 nn.BCEWithLogitsLoss 时不需要使用 sigmoid激活函数（logits loss 中的“logits”是因为它适用于模型的原始 logits 输出），这是因为它内置了 sigmoid函数。</p></blockquote><h2 id="3-2-Building-a-training-and-testing-loop-建立训练和测试循环"><a href="#3-2-Building-a-training-and-testing-loop-建立训练和测试循环" class="headerlink" title="3.2 Building a training and testing loop 建立训练和测试循环"></a>3.2 Building a training and testing loop 建立训练和测试循环</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line">torch.manual_seed(<span class="number">42</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Set the number of epochs</span></span><br><span class="line">epochs = <span class="number">100</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Put data to target device</span></span><br><span class="line">X_train, y_train = X_train.to(device), y_train.to(device)</span><br><span class="line">X_test, y_test = X_test.to(device), y_test.to(device)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Build training and evaluation loop</span></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(epochs):</span><br><span class="line">    <span class="comment">### Training</span></span><br><span class="line">    model_0.train()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 1. Forward pass (model outputs raw logits)</span></span><br><span class="line">    y_logits = model_0(X_train).squeeze() <span class="comment"># squeeze to remove extra `1` dimensions, this won&#x27;t work unless model and data are on same device </span></span><br><span class="line">    y_pred = torch.<span class="built_in">round</span>(torch.sigmoid(y_logits)) <span class="comment"># turn logits -&gt; pred probs -&gt; pred labls</span></span><br><span class="line">  </span><br><span class="line">    <span class="comment"># 2. Calculate loss/accuracy</span></span><br><span class="line">    <span class="comment"># loss = loss_fn(torch.sigmoid(y_logits), # Using nn.BCELoss you need torch.sigmoid()</span></span><br><span class="line">    <span class="comment">#                y_train) </span></span><br><span class="line">    loss = loss_fn(y_logits, <span class="comment"># Using nn.BCEWithLogitsLoss works with raw logits</span></span><br><span class="line">                   y_train) </span><br><span class="line">    acc = accuracy_fn(y_true=y_train, </span><br><span class="line">                      y_pred=y_pred) </span><br><span class="line"></span><br><span class="line">    <span class="comment"># 3. Optimizer zero grad</span></span><br><span class="line">    optimizer.zero_grad()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 4. Loss backwards</span></span><br><span class="line">    loss.backward()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 5. Optimizer step</span></span><br><span class="line">    optimizer.step()</span><br><span class="line"></span><br><span class="line">    <span class="comment">### Testing</span></span><br><span class="line">    model_0.<span class="built_in">eval</span>()</span><br><span class="line">    <span class="keyword">with</span> torch.inference_mode():</span><br><span class="line">        <span class="comment"># 1. Forward pass</span></span><br><span class="line">        test_logits = model_0(X_test).squeeze() </span><br><span class="line">        test_pred = torch.<span class="built_in">round</span>(torch.sigmoid(test_logits))</span><br><span class="line">        <span class="comment"># 2. Caculate loss/accuracy</span></span><br><span class="line">        test_loss = loss_fn(test_logits,</span><br><span class="line">                            y_test)</span><br><span class="line">        test_acc = accuracy_fn(y_true=y_test,</span><br><span class="line">                               y_pred=test_pred)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Print out what&#x27;s happening every 10 epochs</span></span><br><span class="line">    <span class="keyword">if</span> epoch % <span class="number">10</span> == <span class="number">0</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;Epoch: <span class="subst">&#123;epoch&#125;</span> | Loss: <span class="subst">&#123;loss:<span class="number">.5</span>f&#125;</span>, Accuracy: <span class="subst">&#123;acc:<span class="number">.2</span>f&#125;</span>% | Test loss: <span class="subst">&#123;test_loss:<span class="number">.5</span>f&#125;</span>, Test acc: <span class="subst">&#123;test_acc:<span class="number">.2</span>f&#125;</span>%&quot;</span>)</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">Epoch: 0 | Loss: 0.71041, Accuracy: 49.50% | Test loss: 0.69582, Test acc: 53.00%</span><br><span class="line">Epoch: 10 | Loss: 0.70593, Accuracy: 49.12% | Test loss: 0.69352, Test acc: 54.00%</span><br><span class="line">Epoch: 20 | Loss: 0.70281, Accuracy: 49.25% | Test loss: 0.69213, Test acc: 54.00%</span><br><span class="line">Epoch: 30 | Loss: 0.70055, Accuracy: 49.12% | Test loss: 0.69132, Test acc: 54.50%</span><br><span class="line">Epoch: 40 | Loss: 0.69888, Accuracy: 49.12% | Test loss: 0.69087, Test acc: 54.00%</span><br><span class="line">Epoch: 50 | Loss: 0.69762, Accuracy: 48.75% | Test loss: 0.69066, Test acc: 53.00%</span><br><span class="line">Epoch: 60 | Loss: 0.69666, Accuracy: 48.75% | Test loss: 0.69061, Test acc: 53.50%</span><br><span class="line">Epoch: 70 | Loss: 0.69592, Accuracy: 48.88% | Test loss: 0.69067, Test acc: 54.50%</span><br><span class="line">Epoch: 80 | Loss: 0.69535, Accuracy: 49.00% | Test loss: 0.69079, Test acc: 54.00%</span><br><span class="line">Epoch: 90 | Loss: 0.69489, Accuracy: 49.00% | Test loss: 0.69096, Test acc: 54.00%</span><br></pre></td></tr></table></figure><p>每次数据分割的准确率几乎不超过 50%。</p><p>因为我们正在处理平衡的二元分类问题，所以这意味着我们的模型表现与随机猜测一样好（有 500 个 0 类和 1 类样本，每次预测 1 类的模型准确率都会达到 50%）。</p><h1 id="4-Make-predictions-and-evaluate-the-model-做出预测并评估模型"><a href="#4-Make-predictions-and-evaluate-the-model-做出预测并评估模型" class="headerlink" title="4. Make predictions and evaluate the model 做出预测并评估模型"></a>4. Make predictions and evaluate the model 做出预测并评估模型</h1><p>对于50%准确率的模型，几乎等于瞎猜。</p><p>我们将编写一些代码，从Learn PyTorch for Deep Learning仓库下载并导入 <code>helper_functions.py</code> 脚本。</p><p>它包含一个名为 <code>plot_decision_boundary()</code> 的有用函数，该函数创建了一个NumPy网格，以直观地绘制我们的模型预测某些类的不同点。</p><p>将结果可视化：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">from</span> pathlib <span class="keyword">import</span> Path </span><br><span class="line"></span><br><span class="line"><span class="comment"># Download helper functions from Learn PyTorch repo (if not already downloaded)</span></span><br><span class="line"><span class="keyword">if</span> Path(<span class="string">&quot;helper_functions.py&quot;</span>).is_file():</span><br><span class="line">  <span class="built_in">print</span>(<span class="string">&quot;helper_functions.py already exists, skipping download&quot;</span>)</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">  <span class="built_in">print</span>(<span class="string">&quot;Downloading helper_functions.py&quot;</span>)</span><br><span class="line">  request = requests.get(<span class="string">&quot;https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/helper_functions.py&quot;</span>)</span><br><span class="line">  <span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&quot;helper_functions.py&quot;</span>, <span class="string">&quot;wb&quot;</span>) <span class="keyword">as</span> f:</span><br><span class="line">    f.write(request.content)</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> helper_functions <span class="keyword">import</span> plot_predictions, plot_decision_boundary</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Plot decision boundaries for training and test sets</span></span><br><span class="line">plt.figure(figsize=(<span class="number">12</span>, <span class="number">6</span>))</span><br><span class="line">plt.subplot(<span class="number">1</span>, <span class="number">2</span>, <span class="number">1</span>)</span><br><span class="line">plt.title(<span class="string">&quot;Train&quot;</span>)</span><br><span class="line">plot_decision_boundary(model_0, X_train, y_train)</span><br><span class="line"></span><br><span class="line">plt.subplot(<span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>)</span><br><span class="line">plt.title(<span class="string">&quot;Test&quot;</span>)</span><br><span class="line">plot_decision_boundary(model_0, X_test, y_test)</span><br></pre></td></tr></table></figure><img src="/2024/08/16/PyTorch-26H-3/PyTorch-26H-3-4.png" class="" title="PyTorch-26H-3-4"><p>由于数据是圆形的，因此画一条直线最多只能将其从中间切开。</p><p>用机器学习术语来说，模型拟合不足<code>underfitting</code>，意味着它没有从数据中学习预测模式。</p><h1 id="5-Improving-a-model-from-a-model-perspective-改进模型（从模型角度）"><a href="#5-Improving-a-model-from-a-model-perspective-改进模型（从模型角度）" class="headerlink" title="5. Improving a model (from a model perspective) 改进模型（从模型角度）"></a>5. Improving a model (from a model perspective) 改进模型（从模型角度）</h1><p>修复模型的欠拟合问题。</p><p>特别关注模型（而不是数据），我们可以通过几种方式来做到这一点。</p><div class="table-container"><table><thead><tr><th style="text-align:center">模型改进技术</th><th style="text-align:center">作用</th></tr></thead><tbody><tr><td style="text-align:center">添加更多层 Add more layers</td><td style="text-align:center">每一层都可能增加模型的学习能力，因为每一层都能够学习数据中的某种新模式。更多层通常被称为使神经网络更深。</td></tr><tr><td style="text-align:center">添加更多隐藏单元 Add more hidden units</td><td style="text-align:center">与上述类似，每层隐藏单元越多，模型的学习能力就越强。更多隐藏单元通常被称为使神经网络更宽。</td></tr><tr><td style="text-align:center">更长训练时间（更多循环） Fitting for longer (more epochs)</td><td style="text-align:center">如果您的模型有更多机会查看数据，它可能会学到更多东西。</td></tr><tr><td style="text-align:center">改变激活函数 Changing the activation functions</td><td style="text-align:center">有些数据无法仅用直线来拟合（就像我们所看到的），使用非线性激活函数可以帮助解决这个问题（提示，提示）。</td></tr><tr><td style="text-align:center">改变学习率 Change the learning rate</td><td style="text-align:center">虽然与模型不太相关，但仍然相关，优化器的学习率决定了模型每一步应该改变多少参数，太多则模型过度修正，太少则学习不够。</td></tr><tr><td style="text-align:center">改变损失函数 Change the loss function</td><td style="text-align:center">同样，虽然模型特定性不强但仍然很重要，不同的问题需要不同的损失函数。例如，二元交叉熵损失函数不适用于多类分类问题。</td></tr><tr><td style="text-align:center">使用迁移学习 Use transfer learning</td><td style="text-align:center">从与您的问题领域类似的问题中获取预训练模型，并根据您自己的问题进行调整。</td></tr></tbody></table></div><blockquote><p>可以手动调整→超参数<br>机器学习为一半科学一半艺术，需要通过不断实验进行。</p></blockquote><img src="/2024/08/16/PyTorch-26H-3/PyTorch-26H-3-5_1.png" class="" title="PyTorch-26H-3-5_1"><p>让我们看看如果我们在模型中添加一个额外的层，适应更长的时间（<code>epochs=1000</code> 而不是 <code>epochs=100</code>），并将隐藏单元的数量从 <code>5</code> 增加到 <code>10</code>，会发生什么。</p><p>我们将遵循上述相同的步骤，但会更改一些超参数。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">CircleModelV1</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.layer_1 = nn.Linear(in_features=<span class="number">2</span>, out_features=<span class="number">10</span>)</span><br><span class="line">        self.layer_2 = nn.Linear(in_features=<span class="number">10</span>, out_features=<span class="number">10</span>) <span class="comment"># extra layer</span></span><br><span class="line">        self.layer_3 = nn.Linear(in_features=<span class="number">10</span>, out_features=<span class="number">1</span>)</span><br><span class="line">        </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>): <span class="comment"># note: always make sure forward is spelt correctly!</span></span><br><span class="line">        <span class="comment"># Creating a model like this is the same as below, though below</span></span><br><span class="line">        <span class="comment"># generally benefits from speedups where possible.</span></span><br><span class="line">        <span class="comment"># z = self.layer_1(x)</span></span><br><span class="line">        <span class="comment"># z = self.layer_2(z)</span></span><br><span class="line">        <span class="comment"># z = self.layer_3(z)</span></span><br><span class="line">        <span class="comment"># return z</span></span><br><span class="line">        <span class="keyword">return</span> self.layer_3(self.layer_2(self.layer_1(x)))</span><br><span class="line"></span><br><span class="line">model_1 = CircleModelV1().to(device)</span><br><span class="line">model_1</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">CircleModelV1(</span><br><span class="line">  (layer_1): Linear(in_features=2, out_features=10, bias=True)</span><br><span class="line">  (layer_2): Linear(in_features=10, out_features=10, bias=True)</span><br><span class="line">  (layer_3): Linear(in_features=10, out_features=1, bias=True)</span><br><span class="line">)</span><br></pre></td></tr></table></figure><p>现在我们有了一个模型，我们将使用与之前相同的设置重新创建一个损失函数和优化器实例。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># loss_fn = nn.BCELoss() # Requires sigmoid on input</span></span><br><span class="line">loss_fn = nn.BCEWithLogitsLoss() <span class="comment"># Does not require sigmoid on input</span></span><br><span class="line">optimizer = torch.optim.SGD(model_1.parameters(), lr=<span class="number">0.1</span>)</span><br></pre></td></tr></table></figure><p>这次我们将进行更长时间的训练（epochs=1000 vs epochs=100），看看它是否能改进我们的模型。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line">torch.manual_seed(<span class="number">42</span>)</span><br><span class="line">torch.cuda.manual_seed(<span class="number">42</span>)</span><br><span class="line"></span><br><span class="line">epochs = <span class="number">1000</span> <span class="comment"># Train for longer</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Put data to target device</span></span><br><span class="line">X_train, y_train = X_train.to(device), y_train.to(device)</span><br><span class="line">X_test, y_test = X_test.to(device), y_test.to(device)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(epochs):</span><br><span class="line">    <span class="comment">### Training</span></span><br><span class="line">    <span class="comment"># 1. Forward pass</span></span><br><span class="line">    y_logits = model_1(X_train).squeeze()</span><br><span class="line">    y_pred = torch.<span class="built_in">round</span>(torch.sigmoid(y_logits)) <span class="comment"># logits -&gt; prediction probabilities -&gt; prediction labels</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 2. Calculate loss/accuracy</span></span><br><span class="line">    loss = loss_fn(y_logits, y_train)</span><br><span class="line">    acc = accuracy_fn(y_true=y_train, </span><br><span class="line">                      y_pred=y_pred)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 3. Optimizer zero grad</span></span><br><span class="line">    optimizer.zero_grad()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 4. Loss backwards</span></span><br><span class="line">    loss.backward()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 5. Optimizer step</span></span><br><span class="line">    optimizer.step()</span><br><span class="line"></span><br><span class="line">    <span class="comment">### Testing</span></span><br><span class="line">    model_1.<span class="built_in">eval</span>()</span><br><span class="line">    <span class="keyword">with</span> torch.inference_mode():</span><br><span class="line">        <span class="comment"># 1. Forward pass</span></span><br><span class="line">        test_logits = model_1(X_test).squeeze() </span><br><span class="line">        test_pred = torch.<span class="built_in">round</span>(torch.sigmoid(test_logits))</span><br><span class="line">        <span class="comment"># 2. Caculate loss/accuracy</span></span><br><span class="line">        test_loss = loss_fn(test_logits,</span><br><span class="line">                            y_test)</span><br><span class="line">        test_acc = accuracy_fn(y_true=y_test,</span><br><span class="line">                               y_pred=test_pred)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Print out what&#x27;s happening every 10 epochs</span></span><br><span class="line">    <span class="keyword">if</span> epoch % <span class="number">100</span> == <span class="number">0</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;Epoch: <span class="subst">&#123;epoch&#125;</span> | Loss: <span class="subst">&#123;loss:<span class="number">.5</span>f&#125;</span>, Accuracy: <span class="subst">&#123;acc:<span class="number">.2</span>f&#125;</span>% | Test loss: <span class="subst">&#123;test_loss:<span class="number">.5</span>f&#125;</span>, Test acc: <span class="subst">&#123;test_acc:<span class="number">.2</span>f&#125;</span>%&quot;</span>)</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">Epoch: 0 | Loss: 0.69396, Accuracy: 50.88% | Test loss: 0.69261, Test acc: 51.00%</span><br><span class="line">Epoch: 100 | Loss: 0.69305, Accuracy: 50.38% | Test loss: 0.69379, Test acc: 48.00%</span><br><span class="line">Epoch: 200 | Loss: 0.69299, Accuracy: 51.12% | Test loss: 0.69437, Test acc: 46.00%</span><br><span class="line">Epoch: 300 | Loss: 0.69298, Accuracy: 51.62% | Test loss: 0.69458, Test acc: 45.00%</span><br><span class="line">Epoch: 400 | Loss: 0.69298, Accuracy: 51.12% | Test loss: 0.69465, Test acc: 46.00%</span><br><span class="line">Epoch: 500 | Loss: 0.69298, Accuracy: 51.00% | Test loss: 0.69467, Test acc: 46.00%</span><br><span class="line">Epoch: 600 | Loss: 0.69298, Accuracy: 51.00% | Test loss: 0.69468, Test acc: 46.00%</span><br><span class="line">Epoch: 700 | Loss: 0.69298, Accuracy: 51.00% | Test loss: 0.69468, Test acc: 46.00%</span><br><span class="line">Epoch: 800 | Loss: 0.69298, Accuracy: 51.00% | Test loss: 0.69468, Test acc: 46.00%</span><br><span class="line">Epoch: 900 | Loss: 0.69298, Accuracy: 51.00% | Test loss: 0.69468, Test acc: 46.00%</span><br></pre></td></tr></table></figure><p>我们的模型训练的时间更长，并且增加了一层，但它看起来仍然没有学到比随机猜测更好的模式。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Plot decision boundaries for training and test sets</span></span><br><span class="line">plt.figure(figsize=(<span class="number">12</span>, <span class="number">6</span>))</span><br><span class="line">plt.subplot(<span class="number">1</span>, <span class="number">2</span>, <span class="number">1</span>)</span><br><span class="line">plt.title(<span class="string">&quot;Train&quot;</span>)</span><br><span class="line">plot_decision_boundary(model_1, X_train, y_train)</span><br><span class="line">plt.subplot(<span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>)</span><br><span class="line">plt.title(<span class="string">&quot;Test&quot;</span>)</span><br><span class="line">plot_decision_boundary(model_1, X_test, y_test)</span><br></pre></td></tr></table></figure><img src="/2024/08/16/PyTorch-26H-3/PyTorch-26H-3-5.png" class="" title="PyTorch-26H-3-5"><p>我们的模型仍然在红点和蓝点之间画一条直线。</p><p>如果我们的模型画的是直线，那么它能模拟线性数据吗？</p><h2 id="5-1-Preparing-data-to-see-if-our-model-can-model-a-straight-line-准备数据，看看我们的模型是否能建模直线"><a href="#5-1-Preparing-data-to-see-if-our-model-can-model-a-straight-line-准备数据，看看我们的模型是否能建模直线" class="headerlink" title="5.1 Preparing data to see if our model can model a straight line 准备数据，看看我们的模型是否能建模直线"></a>5.1 Preparing data to see if our model can model a straight line 准备数据，看看我们的模型是否能建模直线</h2><p>创建一些线性数据来看看我们的模型是否能够对其进行建模，而不仅仅是使用一个无法学习任何东西的模型。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Create some data (same as notebook 01)</span></span><br><span class="line">weight = <span class="number">0.7</span></span><br><span class="line">bias = <span class="number">0.3</span></span><br><span class="line">start = <span class="number">0</span></span><br><span class="line">end = <span class="number">1</span></span><br><span class="line">step = <span class="number">0.01</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Create data</span></span><br><span class="line">X_regression = torch.arange(start, end, step).unsqueeze(dim=<span class="number">1</span>)</span><br><span class="line">y_regression = weight * X_regression + bias <span class="comment"># linear regression formula</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Check the data</span></span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">len</span>(X_regression))</span><br><span class="line">X_regression[:<span class="number">5</span>], y_regression[:<span class="number">5</span>]</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">100</span><br><span class="line">(tensor([[0.0000],</span><br><span class="line">         [0.0100],</span><br><span class="line">         [0.0200],</span><br><span class="line">         [0.0300],</span><br><span class="line">         [0.0400]]),</span><br><span class="line"> tensor([[0.3000],</span><br><span class="line">         [0.3070],</span><br><span class="line">         [0.3140],</span><br><span class="line">         [0.3210],</span><br><span class="line">         [0.3280]]))</span><br></pre></td></tr></table></figure><p>将数据分成训练集和测试集。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Create train and test splits</span></span><br><span class="line">train_split = <span class="built_in">int</span>(<span class="number">0.8</span> * <span class="built_in">len</span>(X_regression)) <span class="comment"># 80% of data used for training set</span></span><br><span class="line">X_train_regression, y_train_regression = X_regression[:train_split], y_regression[:train_split]</span><br><span class="line">X_test_regression, y_test_regression = X_regression[train_split:], y_regression[train_split:]</span><br><span class="line"></span><br><span class="line"><span class="comment"># Check the lengths of each split</span></span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">len</span>(X_train_regression), </span><br><span class="line">    <span class="built_in">len</span>(y_train_regression), </span><br><span class="line">    <span class="built_in">len</span>(X_test_regression), </span><br><span class="line">    <span class="built_in">len</span>(y_test_regression))</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">80 80 20 20</span><br></pre></td></tr></table></figure><p>漂亮，让我们看看数据是什么样子的。</p><p>为此，我们将使用我们在笔记本 01 中创建的 plot_predictions() 函数。</p><p>它包含在我们上面下载的 Learn PyTorch for Deep Learning 存储库中的 helper_functions.py 脚本中。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">plot_predictions(train_data=X_train_regression,</span><br><span class="line">    train_labels=y_train_regression,</span><br><span class="line">    test_data=X_test_regression,</span><br><span class="line">    test_labels=y_test_regression</span><br><span class="line">)</span><br></pre></td></tr></table></figure><img src="/2024/08/16/PyTorch-26H-3/PyTorch-26H-3-6.png" class="" title="PyTorch-26H-3-6"><h2 id="5-2-Adjusting-model-1-to-fit-a-straight-line-调整-model-1-以适合直线"><a href="#5-2-Adjusting-model-1-to-fit-a-straight-line-调整-model-1-以适合直线" class="headerlink" title="5.2 Adjusting model_1 to fit a straight line 调整 model_1 以适合直线"></a>5.2 Adjusting <code>model_1</code> to fit a straight line 调整 <code>model_1</code> 以适合直线</h2><p>重新创建<code>model_1</code>，但使用适合我们的回归数据的损失函数。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Same architecture as model_1 (but using nn.Sequential)</span></span><br><span class="line">model_2 = nn.Sequential(</span><br><span class="line">    nn.Linear(in_features=<span class="number">1</span>, out_features=<span class="number">10</span>),</span><br><span class="line">    nn.Linear(in_features=<span class="number">10</span>, out_features=<span class="number">10</span>),</span><br><span class="line">    nn.Linear(in_features=<span class="number">10</span>, out_features=<span class="number">1</span>)</span><br><span class="line">).to(device)</span><br><span class="line"></span><br><span class="line">model_2</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">Sequential(</span><br><span class="line">  (0): Linear(in_features=1, out_features=10, bias=True)</span><br><span class="line">  (1): Linear(in_features=10, out_features=10, bias=True)</span><br><span class="line">  (2): Linear(in_features=10, out_features=1, bias=True)</span><br><span class="line">)</span><br></pre></td></tr></table></figure><p>将损失函数设置为<code>nn.L1Loss()</code>（与平均绝对误差相同），并将优化器设置为<code>torch.optim.SGD()</code>。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Loss and optimizer</span></span><br><span class="line">loss_fn = nn.L1Loss()</span><br><span class="line">optimizer = torch.optim.SGD(model_2.parameters(), lr=<span class="number">0.1</span>)</span><br></pre></td></tr></table></figure><p>现在让我们使用常规训练循环步骤来训练模型，<code>epochs=1000</code>（就像<code>model_1</code>一样）。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Train the model</span></span><br><span class="line">torch.manual_seed(<span class="number">42</span>)</span><br><span class="line">torch.cuda.manual_seed(<span class="number">42</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Set the number of epochs</span></span><br><span class="line">epochs = <span class="number">1000</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Put data to target device</span></span><br><span class="line">X_train_regression, y_train_regression = X_train_regression.to(device), y_train_regression.to(device)</span><br><span class="line">X_test_regression, y_test_regression = X_test_regression.to(device), y_test_regression.to(device)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(epochs):</span><br><span class="line">    <span class="comment">### Training </span></span><br><span class="line">    <span class="comment"># 1. Forward pass</span></span><br><span class="line">    y_pred = model_2(X_train_regression)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 2. Calculate loss (no accuracy since it&#x27;s a regression problem, not classification)</span></span><br><span class="line">    loss = loss_fn(y_pred, y_train_regression)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 3. Optimizer zero grad</span></span><br><span class="line">    optimizer.zero_grad()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 4. Loss backwards</span></span><br><span class="line">    loss.backward()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 5. Optimizer step</span></span><br><span class="line">    optimizer.step()</span><br><span class="line"></span><br><span class="line">    <span class="comment">### Testing</span></span><br><span class="line">    model_2.<span class="built_in">eval</span>()</span><br><span class="line">    <span class="keyword">with</span> torch.inference_mode():</span><br><span class="line">      <span class="comment"># 1. Forward pass</span></span><br><span class="line">      test_pred = model_2(X_test_regression)</span><br><span class="line">      <span class="comment"># 2. Calculate the loss </span></span><br><span class="line">      test_loss = loss_fn(test_pred, y_test_regression)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Print out what&#x27;s happening</span></span><br><span class="line">    <span class="keyword">if</span> epoch % <span class="number">100</span> == <span class="number">0</span>: </span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;Epoch: <span class="subst">&#123;epoch&#125;</span> | Train loss: <span class="subst">&#123;loss:<span class="number">.5</span>f&#125;</span>, Test loss: <span class="subst">&#123;test_loss:<span class="number">.5</span>f&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">Epoch: 0 | Train loss: 0.75986, Test loss: 0.54143</span><br><span class="line">Epoch: 100 | Train loss: 0.09309, Test loss: 0.02901</span><br><span class="line">Epoch: 200 | Train loss: 0.07376, Test loss: 0.02850</span><br><span class="line">Epoch: 300 | Train loss: 0.06745, Test loss: 0.00615</span><br><span class="line">Epoch: 400 | Train loss: 0.06107, Test loss: 0.02004</span><br><span class="line">Epoch: 500 | Train loss: 0.05698, Test loss: 0.01061</span><br><span class="line">Epoch: 600 | Train loss: 0.04857, Test loss: 0.01326</span><br><span class="line">Epoch: 700 | Train loss: 0.06109, Test loss: 0.02127</span><br><span class="line">Epoch: 800 | Train loss: 0.05599, Test loss: 0.01426</span><br><span class="line">Epoch: 900 | Train loss: 0.05571, Test loss: 0.00603</span><br></pre></td></tr></table></figure><p>好的，与分类数据上的 <code>model_1</code> 不同，<code>model_2</code> 的损失似乎实际上在下降。</p><p>让我们绘制它的预测图，看看是否如此。</p><p>请记住，由于我们的模型和数据正在使用目标设备，并且该设备可能是 GPU，因此我们的绘图函数使用 <code>matplotlib</code>，而 <code>matplotlib</code> 无法处理 GPU 上的数据。</p><p>为了处理这个问题，当我们将所有数据传递给 <code>plot_predictions()</code> 时，我们将使用 <code>.cpu()</code> 将所有数据发送到 CPU。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Turn on evaluation mode</span></span><br><span class="line">model_2.<span class="built_in">eval</span>()</span><br><span class="line"></span><br><span class="line"><span class="comment"># Make predictions (inference)</span></span><br><span class="line"><span class="keyword">with</span> torch.inference_mode():</span><br><span class="line">    y_preds = model_2(X_test_regression)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Plot data and predictions with data on the CPU (matplotlib can&#x27;t handle data on the GPU)</span></span><br><span class="line"><span class="comment"># (try removing .cpu() from one of the below and see what happens)</span></span><br><span class="line">plot_predictions(train_data=X_train_regression.cpu(),</span><br><span class="line">                 train_labels=y_train_regression.cpu(),</span><br><span class="line">                 test_data=X_test_regression.cpu(),</span><br><span class="line">                 test_labels=y_test_regression.cpu(),</span><br><span class="line">                 predictions=y_preds.cpu());</span><br></pre></td></tr></table></figure><img src="/2024/08/16/PyTorch-26H-3/PyTorch-26H-3-7.png" class="" title="PyTorch-26H-3-7"><p>模型比在直线上随机猜测要好得多。这意味着我们的模型至少具有一定的学习能力。</p><blockquote><p>构建深度学习模型时，一个有用的故障排除步骤是先从尽可能小的模型开始，看看模型是否有效，然后再将其扩大。<br>这可能意味着从一个简单的神经网络（层数不多，隐藏神经元也不多）和一个小的数据集（就像我们制作的数据集）开始，然后在这个小例子上进行过度拟合overfitting（使模型表现得太好了），然后再增加数据量或模型 大小 / 设计 以减少过度拟合。</p></blockquote><h1 id="6-The-missing-piece-non-linearity-缺失的部分：非线性"><a href="#6-The-missing-piece-non-linearity-缺失的部分：非线性" class="headerlink" title="6. The missing piece: non-linearity 缺失的部分：非线性"></a>6. The missing piece: non-linearity 缺失的部分：非线性</h1><p>由于模型具有线性层，因此它可以绘制直线（线性）。</p><p>但是我们如何赋予它绘制非直线（非线性）线条的能力呢？</p><h2 id="6-1-Recreating-non-linear-data-red-and-blue-circles-重新创建非线性数据（红色和蓝色圆圈）"><a href="#6-1-Recreating-non-linear-data-red-and-blue-circles-重新创建非线性数据（红色和蓝色圆圈）" class="headerlink" title="6.1 Recreating non-linear data (red and blue circles) 重新创建非线性数据（红色和蓝色圆圈）"></a>6.1 Recreating non-linear data (red and blue circles) 重新创建非线性数据（红色和蓝色圆圈）</h2><p>重新创建数据以从头开始。我们将使用与之前相同的设置。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Make and plot data</span></span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> make_circles</span><br><span class="line"></span><br><span class="line">n_samples = <span class="number">1000</span></span><br><span class="line"></span><br><span class="line">X, y = make_circles(n_samples=<span class="number">1000</span>,</span><br><span class="line">    noise=<span class="number">0.03</span>,</span><br><span class="line">    random_state=<span class="number">42</span>,</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">plt.scatter(X[:, <span class="number">0</span>], X[:, <span class="number">1</span>], c=y, cmap=plt.cm.RdBu);</span><br></pre></td></tr></table></figure><img src="/2024/08/16/PyTorch-26H-3/PyTorch-26H-3-8.png" class="" title="PyTorch-26H-3-8"><p>太棒了！现在让我们将其分成训练集和测试集，其中 80% 的数据用于训练，20% 的数据用于测试。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Convert to tensors and split into train and test sets</span></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"></span><br><span class="line"><span class="comment"># Turn data into tensors</span></span><br><span class="line">X = torch.from_numpy(X).<span class="built_in">type</span>(torch.<span class="built_in">float</span>)</span><br><span class="line">y = torch.from_numpy(y).<span class="built_in">type</span>(torch.<span class="built_in">float</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Split into train and test sets</span></span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(X, </span><br><span class="line">                                                    y, </span><br><span class="line">                                                    test_size=<span class="number">0.2</span>,</span><br><span class="line">                                                    random_state=<span class="number">42</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">X_train[:<span class="number">5</span>], y_train[:<span class="number">5</span>]</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">(tensor([[ 0.6579, -0.4651],</span><br><span class="line">         [ 0.6319, -0.7347],</span><br><span class="line">         [-1.0086, -0.1240],</span><br><span class="line">         [-0.9666, -0.2256],</span><br><span class="line">         [-0.1666,  0.7994]]),</span><br><span class="line"> tensor([1., 0., 0., 0., 1.]))</span><br></pre></td></tr></table></figure><h2 id="6-2-Building-a-model-with-non-linearity-建立非线性模型"><a href="#6-2-Building-a-model-with-non-linearity-建立非线性模型" class="headerlink" title="6.2 Building a model with non-linearity 建立非线性模型"></a>6.2 Building a model with non-linearity 建立非线性模型</h2><p>可以用无限的直线（线性）和非直线（非线性）绘制什么样的图案？</p><p>到目前为止，我们的神经网络仅使用线性（直线）函数。</p><p>但我们处理的数据是非线性的（圆圈）。</p><p>当我们为模型引入使用非线性激活函数的能力时</p><p>PyTorch 有一堆<a href="https://pytorch.org/docs/stable/nn.html#non-linear-activations-weighted-sum-nonlinearity">现成的非线性激活函数</a>，它们可以执行类似但不同的事情。</p><p>最常见且性能最好的一种是<a href="https://en.wikipedia.org/wiki/Rectifier_(neural_networks">ReLU</a>)（整流线性单元，<a href="https://pytorch.org/docs/stable/generated/torch.nn.ReLU.html">torch.nn.ReLU()</a>）。</p><p>将它放在神经网络中前向传递的隐藏层之间，看看会发生什么。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Build model with non-linear activation function</span></span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"><span class="keyword">class</span> <span class="title class_">CircleModelV2</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.layer_1 = nn.Linear(in_features=<span class="number">2</span>, out_features=<span class="number">10</span>)</span><br><span class="line">        self.layer_2 = nn.Linear(in_features=<span class="number">10</span>, out_features=<span class="number">10</span>)</span><br><span class="line">        self.layer_3 = nn.Linear(in_features=<span class="number">10</span>, out_features=<span class="number">1</span>)</span><br><span class="line">        self.relu = nn.ReLU() <span class="comment"># &lt;- add in ReLU activation function</span></span><br><span class="line">        <span class="comment"># Can also put sigmoid in the model </span></span><br><span class="line">        <span class="comment"># This would mean you don&#x27;t need to use it on the predictions</span></span><br><span class="line">        <span class="comment"># self.sigmoid = nn.Sigmoid()</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">      <span class="comment"># Intersperse the ReLU activation function between layers</span></span><br><span class="line">       <span class="keyword">return</span> self.layer_3(self.relu(self.layer_2(self.relu(self.layer_1(x)))))</span><br><span class="line"></span><br><span class="line">model_3 = CircleModelV2().to(device)</span><br><span class="line"><span class="built_in">print</span>(model_3)</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">CircleModelV2(</span><br><span class="line">  (layer_1): Linear(in_features=2, out_features=10, bias=True)</span><br><span class="line">  (layer_2): Linear(in_features=10, out_features=10, bias=True)</span><br><span class="line">  (layer_3): Linear(in_features=10, out_features=1, bias=True)</span><br><span class="line">  (relu): ReLU()</span><br><span class="line">)</span><br></pre></td></tr></table></figure><p>与我们刚刚构建的分类神经网络（使用 ReLU 激活）类似的分类神经网络的视觉示例。尝试在 TensorFlow Playground 网站上创建一个您自己的神经网络。</p><blockquote><p>问题：构建神经网络时，我应该把非线性激活函数放在哪里？<br>经验法则是将它们放在隐藏层之间，紧接着输出层，但是，没有一成不变的选择。随着您对神经网络和深度学习的了解越来越多，您会发现很多不同的组合方法。与此同时，最好不断实验、实验、再实验。</p></blockquote><p>现在我们已经准备好了模型，让我们创建一个二元分类损失函数以及一个优化器。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Setup loss and optimizer </span></span><br><span class="line">loss_fn = nn.BCEWithLogitsLoss()</span><br><span class="line">optimizer = torch.optim.SGD(model_3.parameters(), lr=<span class="number">0.1</span>)</span><br></pre></td></tr></table></figure><h2 id="6-3-Training-a-model-with-non-linearity-训练非线性模型"><a href="#6-3-Training-a-model-with-non-linearity-训练非线性模型" class="headerlink" title="6.3 Training a model with non-linearity 训练非线性模型"></a>6.3 Training a model with non-linearity 训练非线性模型</h2><p>训练、模型、损失函数、优化器已准备就绪，让我们创建一个训练和测试循环。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Fit the model</span></span><br><span class="line">torch.manual_seed(<span class="number">42</span>)</span><br><span class="line">torch.cuda.manual_seed(<span class="number">42</span>)</span><br><span class="line">epochs = <span class="number">1000</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Put all data on target device</span></span><br><span class="line">X_train, y_train = X_train.to(device), y_train.to(device)</span><br><span class="line">X_test, y_test = X_test.to(device), y_test.to(device)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(epochs):</span><br><span class="line">    model_3.train()</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 1. Forward pass</span></span><br><span class="line">    y_logits = model_3(X_train).squeeze()</span><br><span class="line">    y_pred = torch.<span class="built_in">round</span>(torch.sigmoid(y_logits)) <span class="comment"># logits -&gt; prediction probabilities -&gt; prediction labels</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 2. Calculate loss and accuracy</span></span><br><span class="line">    loss = loss_fn(y_logits, y_train) <span class="comment"># BCEWithLogitsLoss calculates loss using logits</span></span><br><span class="line">    acc = accuracy_fn(y_true=y_train, </span><br><span class="line">                      y_pred=y_pred)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 3. Optimizer zero grad</span></span><br><span class="line">    optimizer.zero_grad()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 4. Loss backward</span></span><br><span class="line">    loss.backward()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 5. Optimizer step</span></span><br><span class="line">    optimizer.step()</span><br><span class="line"></span><br><span class="line">    <span class="comment">### Testing</span></span><br><span class="line">    model_3.<span class="built_in">eval</span>()</span><br><span class="line">    <span class="keyword">with</span> torch.inference_mode():</span><br><span class="line">      <span class="comment"># 1. Forward pass</span></span><br><span class="line">      test_logits = model_3(X_test).squeeze()</span><br><span class="line">      test_pred = torch.<span class="built_in">round</span>(torch.sigmoid(test_logits)) <span class="comment"># logits -&gt; prediction probabilities -&gt; prediction labels</span></span><br><span class="line">      <span class="comment"># 2. Calculate loss and accuracy</span></span><br><span class="line">      test_loss = loss_fn(test_logits, y_test)</span><br><span class="line">      test_acc = accuracy_fn(y_true=y_test,</span><br><span class="line">                             y_pred=test_pred)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Print out what&#x27;s happening</span></span><br><span class="line">    <span class="keyword">if</span> epoch % <span class="number">100</span> == <span class="number">0</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;Epoch: <span class="subst">&#123;epoch&#125;</span> | Loss: <span class="subst">&#123;loss:<span class="number">.5</span>f&#125;</span>, Accuracy: <span class="subst">&#123;acc:<span class="number">.2</span>f&#125;</span>% | Test Loss: <span class="subst">&#123;test_loss:<span class="number">.5</span>f&#125;</span>, Test Accuracy: <span class="subst">&#123;test_acc:<span class="number">.2</span>f&#125;</span>%&quot;</span>)</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">Epoch: 0 | Loss: 0.69295, Accuracy: 50.00% | Test Loss: 0.69319, Test Accuracy: 50.00%</span><br><span class="line">Epoch: 100 | Loss: 0.69115, Accuracy: 52.88% | Test Loss: 0.69102, Test Accuracy: 52.50%</span><br><span class="line">Epoch: 200 | Loss: 0.68977, Accuracy: 53.37% | Test Loss: 0.68940, Test Accuracy: 55.00%</span><br><span class="line">Epoch: 300 | Loss: 0.68795, Accuracy: 53.00% | Test Loss: 0.68723, Test Accuracy: 56.00%</span><br><span class="line">Epoch: 400 | Loss: 0.68517, Accuracy: 52.75% | Test Loss: 0.68411, Test Accuracy: 56.50%</span><br><span class="line">Epoch: 500 | Loss: 0.68102, Accuracy: 52.75% | Test Loss: 0.67941, Test Accuracy: 56.50%</span><br><span class="line">Epoch: 600 | Loss: 0.67515, Accuracy: 54.50% | Test Loss: 0.67285, Test Accuracy: 56.00%</span><br><span class="line">Epoch: 700 | Loss: 0.66659, Accuracy: 58.38% | Test Loss: 0.66322, Test Accuracy: 59.00%</span><br><span class="line">Epoch: 800 | Loss: 0.65160, Accuracy: 64.00% | Test Loss: 0.64757, Test Accuracy: 67.50%</span><br><span class="line">Epoch: 900 | Loss: 0.62362, Accuracy: 74.00% | Test Loss: 0.62145, Test Accuracy: 79.00%</span><br></pre></td></tr></table></figure><h2 id="6-4-Evaluating-a-model-trained-with-non-linear-activation-functions-评估用非线性激活函数训练的模型"><a href="#6-4-Evaluating-a-model-trained-with-non-linear-activation-functions-评估用非线性激活函数训练的模型" class="headerlink" title="6.4 Evaluating a model trained with non-linear activation functions 评估用非线性激活函数训练的模型"></a>6.4 Evaluating a model trained with non-linear activation functions 评估用非线性激活函数训练的模型</h2><p>还记得我们的圆形数据是非线性的吗？好吧，让我们看看现在模型的预测结果如何，该模型已经用非线性激活函数进行了训练。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Make predictions</span></span><br><span class="line">model_3.<span class="built_in">eval</span>()</span><br><span class="line"><span class="keyword">with</span> torch.inference_mode():</span><br><span class="line">    y_preds = torch.<span class="built_in">round</span>(torch.sigmoid(model_3(X_test))).squeeze()</span><br><span class="line">y_preds[:<span class="number">10</span>], y[:<span class="number">10</span>] <span class="comment"># want preds in same format as truth labels</span></span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">(tensor([1., 0., 1., 0., 0., 1., 0., 0., 1., 0.], device=&#x27;cuda:0&#x27;),</span><br><span class="line"> tensor([1., 1., 1., 1., 0., 1., 1., 1., 1., 0.]))</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Plot decision boundaries for training and test sets</span></span><br><span class="line">plt.figure(figsize=(<span class="number">12</span>, <span class="number">6</span>))</span><br><span class="line">plt.subplot(<span class="number">1</span>, <span class="number">2</span>, <span class="number">1</span>)</span><br><span class="line">plt.title(<span class="string">&quot;Train&quot;</span>)</span><br><span class="line">plot_decision_boundary(model_1, X_train, y_train) <span class="comment"># model_1 = no non-linearity</span></span><br><span class="line">plt.subplot(<span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>)</span><br><span class="line">plt.title(<span class="string">&quot;Test&quot;</span>)</span><br><span class="line">plot_decision_boundary(model_3, X_test, y_test) <span class="comment"># model_3 = has non-linearity</span></span><br></pre></td></tr></table></figure><img src="/2024/08/16/PyTorch-26H-3/PyTorch-26H-3-9.png" class="" title="PyTorch-26H-3-9"><h1 id="7-Replicating-non-linear-activation-functions-复制非线性激活函数"><a href="#7-Replicating-non-linear-activation-functions-复制非线性激活函数" class="headerlink" title="7. Replicating non-linear activation functions 复制非线性激活函数"></a>7. Replicating non-linear activation functions 复制非线性激活函数</h1><blockquote><p>您在自然中遇到的大部分数据都是非线性的（或线性和非线性的组合）。现在我们一直在处理二维图上的点。但想象一下，如果您有想要分类的植物图像，会有很多不同的植物形状。或者您想要总结的维基百科文本，有很多不同的单词组合方式（线性和非线性模式）。</p></blockquote><p>但是非线性激活是什么样的？我们如何复制一些并看看它们的作用如何？</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Create a toy tensor (similar to the data going into our model(s))</span></span><br><span class="line">A = torch.arange(-<span class="number">10</span>, <span class="number">10</span>, <span class="number">1</span>, dtype=torch.float32)</span><br><span class="line">A</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">tensor([-10.,  -9.,  -8.,  -7.,  -6.,  -5.,  -4.,  -3.,  -2.,  -1.,   0.,   1.,</span><br><span class="line">          2.,   3.,   4.,   5.,   6.,   7.,   8.,   9.])</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Visualize the toy tensor</span></span><br><span class="line">plt.plot(A);</span><br></pre></td></tr></table></figure><img src="/2024/08/16/PyTorch-26H-3/PyTorch-26H-3-10.png" class="" title="PyTorch-26H-3-10"><p>一条直线。</p><p>现在让我们看看 ReLU 激活函数如何影响它。</p><p>我们不会使用 PyTorch 的 ReLU (<code>torch.nn.ReLU</code>)，而是自己重新创建它。</p><p>ReLU 函数将所有负值变为 0，并保持正值不变。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Create ReLU function by hand </span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">relu</span>(<span class="params">x</span>):</span><br><span class="line">  <span class="keyword">return</span> torch.maximum(torch.tensor(<span class="number">0</span>), x) <span class="comment"># inputs must be tensors</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Pass toy tensor through ReLU function</span></span><br><span class="line">relu(A)</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 2., 3., 4., 5., 6., 7.,</span><br><span class="line">        8., 9.])</span><br></pre></td></tr></table></figure><p>看起来我们的 ReLU 函数起作用了，所有负值都是零。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Plot ReLU activated toy tensor</span></span><br><span class="line">plt.plot(relu(A));</span><br></pre></td></tr></table></figure><img src="/2024/08/16/PyTorch-26H-3/PyTorch-26H-3-11.png" class="" title="PyTorch-26H-3-11"><p>太棒了！这看起来和 ReLU <a href="https://en.wikipedia.org/wiki/Rectifier_(neural_networks">维基百科页面上的 ReLU 函数</a>) 形状一模一样。</p><p>我们试试我们一直在使用的 <a href="https://en.wikipedia.org/wiki/Sigmoid_function">sigmoid函数</a> 怎么样？</p><p>sigmoid 函数公式如下：</p><script type="math/tex; mode=display">out_i = \frac{1}{1+e^{-input_i}}</script><p>Or using $x$ as input:</p><script type="math/tex; mode=display">S(x) = \frac{1}{1+e^{-x_i}}</script><p>其中 $S$ 代表 sigmoid 函数，$e$ 代表<a href="">指数</a>（<a href="">torch.exp()</a>），$i$ 代表张量中的特定元素。</p><p>让我们用 PyTorch 构建一个函数来复制 sigmoid 函数。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Create a custom sigmoid function</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">sigmoid</span>(<span class="params">x</span>):</span><br><span class="line">  <span class="keyword">return</span> <span class="number">1</span> / (<span class="number">1</span> + torch.exp(-x))</span><br><span class="line"></span><br><span class="line"><span class="comment"># Test custom sigmoid on toy tensor</span></span><br><span class="line">sigmoid(A)</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">tensor([4.5398e-05, 1.2339e-04, 3.3535e-04, 9.1105e-04, 2.4726e-03, 6.6929e-03,</span><br><span class="line">        1.7986e-02, 4.7426e-02, 1.1920e-01, 2.6894e-01, 5.0000e-01, 7.3106e-01,</span><br><span class="line">        8.8080e-01, 9.5257e-01, 9.8201e-01, 9.9331e-01, 9.9753e-01, 9.9909e-01,</span><br><span class="line">        9.9966e-01, 9.9988e-01])</span><br></pre></td></tr></table></figure><p>这些值看起来很像我们之前看到的预测概率，让我们看看它们的可视化效果。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Plot sigmoid activated toy tensor</span></span><br><span class="line">plt.plot(sigmoid(A));</span><br></pre></td></tr></table></figure><img src="/2024/08/16/PyTorch-26H-3/PyTorch-26H-3-12.png" class="" title="PyTorch-26H-3-12"><p>看起来不错！我们已经从直线变成了曲线。</p><p>现在 PyTorch 中存在许多我们尚未尝试过的<a href="https://pytorch.org/docs/stable/nn.html#non-linear-activations-weighted-sum-nonlinearity">非线性激活函数</a>。</p><p>但这两个是最常见的两个。</p><p>问题仍然存在，您可以使用无限数量的线性（直线）和非线性（非直线）线来绘制什么图案？</p><p>几乎任何东西都可以，对吗？</p><p>当我们结合线性和非线性函数时，这正是我们的模型所做的事情。</p><p>我们不是告诉模型要做什么，而是给它工具来找出如何最好地发现数据中的模式。</p><p>这些工具是线性和非线性函数。</p><h1 id="8-Putting-things-together-by-building-a-multi-class-PyTorch-model-通过构建多类-PyTorch-模型将所有内容整合在一起"><a href="#8-Putting-things-together-by-building-a-multi-class-PyTorch-model-通过构建多类-PyTorch-模型将所有内容整合在一起" class="headerlink" title="8. Putting things together by building a multi-class PyTorch model 通过构建多类 PyTorch 模型将所有内容整合在一起"></a>8. Putting things together by building a multi-class PyTorch model 通过构建多类 PyTorch 模型将所有内容整合在一起</h1><p>使用多类分类问题将它们放在一起。</p><p><code>二元分类</code>问题是将某物归类为两个选项之一（例如，将一张照片归类为猫的照片或狗的照片）。而<code>多类分类</code>问题是从两个以上的选项列表中对某物进行分类（例如，将一张照片归类为猫、狗或鸡）。</p><h2 id="8-1-Creating-multi-class-classification-data-创建多类别分类数据"><a href="#8-1-Creating-multi-class-classification-data-创建多类别分类数据" class="headerlink" title="8.1 Creating multi-class classification data 创建多类别分类数据"></a>8.1 Creating multi-class classification data 创建多类别分类数据</h2><p>为了开始多类分类问题，让我们创建一些多类数据。</p><p>为此，我们可以利用 <code>Scikit-Learn</code> 的 <a href="https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_blobs.html">make_blobs()</a> 方法。</p><p>此方法将创建我们想要的任意数量的类（使用 <code>centers</code> 参数）。</p><p>具体来说，我们可以这样做：</p><p>1、使用 <code>make_blobs()</code> 创建一些多类数据。<br>2、将数据转换为张量（默认 <code>make_blobs()</code> 使用NumPy数组）。<br>3、使用 <code>train_test_split()</code> 将数据分为训练集和测试集 。<br>4、使数据可视化。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Import dependencies</span></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> make_blobs</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"></span><br><span class="line"><span class="comment"># Set the hyperparameters for data creation</span></span><br><span class="line">NUM_CLASSES = <span class="number">4</span></span><br><span class="line">NUM_FEATURES = <span class="number">2</span></span><br><span class="line">RANDOM_SEED = <span class="number">42</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 1. Create multi-class data</span></span><br><span class="line">X_blob, y_blob = make_blobs(n_samples=<span class="number">1000</span>,</span><br><span class="line">    n_features=NUM_FEATURES, <span class="comment"># X features</span></span><br><span class="line">    centers=NUM_CLASSES, <span class="comment"># y labels </span></span><br><span class="line">    cluster_std=<span class="number">1.5</span>, <span class="comment"># give the clusters a little shake up (try changing this to 1.0, the default)</span></span><br><span class="line">    random_state=RANDOM_SEED</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 2. Turn data into tensors</span></span><br><span class="line">X_blob = torch.from_numpy(X_blob).<span class="built_in">type</span>(torch.<span class="built_in">float</span>)</span><br><span class="line">y_blob = torch.from_numpy(y_blob).<span class="built_in">type</span>(torch.LongTensor)</span><br><span class="line"><span class="built_in">print</span>(X_blob[:<span class="number">5</span>], y_blob[:<span class="number">5</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 3. Split into train and test sets</span></span><br><span class="line">X_blob_train, X_blob_test, y_blob_train, y_blob_test = train_test_split(X_blob,</span><br><span class="line">    y_blob,</span><br><span class="line">    test_size=<span class="number">0.2</span>,</span><br><span class="line">    random_state=RANDOM_SEED</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 4. Plot data</span></span><br><span class="line">plt.figure(figsize=(<span class="number">10</span>, <span class="number">7</span>))</span><br><span class="line">plt.scatter(X_blob[:, <span class="number">0</span>], X_blob[:, <span class="number">1</span>], c=y_blob, cmap=plt.cm.RdYlBu);</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">tensor([[-8.4134,  6.9352],</span><br><span class="line">        [-5.7665, -6.4312],</span><br><span class="line">        [-6.0421, -6.7661],</span><br><span class="line">        [ 3.9508,  0.6984],</span><br><span class="line">        [ 4.2505, -0.2815]]) tensor([3, 2, 2, 1, 1])</span><br></pre></td></tr></table></figure><img src="/2024/08/16/PyTorch-26H-3/PyTorch-26H-3-13.png" class="" title="PyTorch-26H-3-13"><p>准备好了一些多类数据。建立一个模型来分离彩色斑点。</p><p>问题：这个数据集需要非线性吗？或者你可以画出一系列直线来分离它吗？</p><h2 id="8-2-Building-a-multi-class-classification-model-in-PyTorch-在-PyTorch-中构建多类分类模型"><a href="#8-2-Building-a-multi-class-classification-model-in-PyTorch-在-PyTorch-中构建多类分类模型" class="headerlink" title="8.2 Building a multi-class classification model in PyTorch 在 PyTorch 中构建多类分类模型"></a>8.2 Building a multi-class classification model in PyTorch 在 PyTorch 中构建多类分类模型</h2><p>到目前为止，我们已经在 PyTorch 中创建了一些模型。</p><p>您或许还开始了解神经网络的灵活性。</p><img src="/2024/08/16/PyTorch-26H-3/PyTorch-26H-3-13_1.png" class="" title="PyTorch-26H-3-13_1"><p>如何构建一个类似<code>model_3</code>但仍然能够处理多类数据的系统呢？</p><p>创建一个<code>nn.Module</code>包含三个超参数的子类：</p><ul><li><code>input_features</code> X 进入模型的特征数量。</li><li><code>output_features</code> 我们想要的输出特征的理想数量（这将等同于NUM_CLASSES或等于多类分类问题中的类数）。</li><li><code>hidden_units</code>  我们希望每个隐藏层使用的隐藏神经元的数量。</li></ul><p>然后我们将使用上面的超参数创建模型类。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Create device agnostic code</span></span><br><span class="line">device = <span class="string">&quot;cuda&quot;</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&quot;cpu&quot;</span></span><br><span class="line">device</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&#x27;cuda&#x27;</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"></span><br><span class="line"><span class="comment"># Build model</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">BlobModel</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, input_features, output_features, hidden_units=<span class="number">8</span></span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;Initializes all required hyperparameters for a multi-class classification model.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        Args:</span></span><br><span class="line"><span class="string">            input_features (int): Number of input features to the model.</span></span><br><span class="line"><span class="string">            out_features (int): Number of output features of the model</span></span><br><span class="line"><span class="string">              (how many classes there are).</span></span><br><span class="line"><span class="string">            hidden_units (int): Number of hidden units between layers, default 8.</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.linear_layer_stack = nn.Sequential(</span><br><span class="line">            nn.Linear(in_features=input_features, out_features=hidden_units),</span><br><span class="line">            <span class="comment"># nn.ReLU(), # &lt;- does our dataset require non-linear layers? (try uncommenting and see if the results change)</span></span><br><span class="line">            nn.Linear(in_features=hidden_units, out_features=hidden_units),</span><br><span class="line">            <span class="comment"># nn.ReLU(), # &lt;- does our dataset require non-linear layers? (try uncommenting and see if the results change)</span></span><br><span class="line">            nn.Linear(in_features=hidden_units, out_features=output_features), <span class="comment"># how many classes are there?</span></span><br><span class="line">        )</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        <span class="keyword">return</span> self.linear_layer_stack(x)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Create an instance of BlobModel and send it to the target device</span></span><br><span class="line">model_4 = BlobModel(input_features=NUM_FEATURES, </span><br><span class="line">                    output_features=NUM_CLASSES, </span><br><span class="line">                    hidden_units=<span class="number">8</span>).to(device)</span><br><span class="line">model_4</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">BlobModel(</span><br><span class="line">  (linear_layer_stack): Sequential(</span><br><span class="line">    (0): Linear(in_features=2, out_features=8, bias=True)</span><br><span class="line">    (1): Linear(in_features=8, out_features=8, bias=True)</span><br><span class="line">    (2): Linear(in_features=8, out_features=4, bias=True)</span><br><span class="line">  )</span><br><span class="line">)</span><br></pre></td></tr></table></figure><h2 id="8-3-Creating-a-loss-function-and-optimizer-for-a-multi-class-PyTorch-model-为多类-PyTorch-模型创建损失函数和优化器"><a href="#8-3-Creating-a-loss-function-and-optimizer-for-a-multi-class-PyTorch-model-为多类-PyTorch-模型创建损失函数和优化器" class="headerlink" title="8.3 Creating a loss function and optimizer for a multi-class PyTorch model 为多类 PyTorch 模型创建损失函数和优化器"></a>8.3 Creating a loss function and optimizer for a multi-class PyTorch model 为多类 PyTorch 模型创建损失函数和优化器</h2><p>由于我们正在研究多类分类问题，我们将使用该<code>nn.CrossEntropyLoss()</code>方法作为我们的损失函数。</p><p>我们将坚持使用学习率为 0.1 的 SGD 来优化我们的<code>model_4</code>参数。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Create loss and optimizer</span></span><br><span class="line">loss_fn = nn.CrossEntropyLoss()</span><br><span class="line">optimizer = torch.optim.SGD(model_4.parameters(), </span><br><span class="line">                            lr=<span class="number">0.1</span>) <span class="comment"># exercise: try changing the learning rate here and seeing what happens to the model&#x27;s performance</span></span><br></pre></td></tr></table></figure><h2 id="8-4-Getting-prediction-probabilities-for-a-multi-class-PyTorch-model-获取多类-PyTorch-模型的预测概率"><a href="#8-4-Getting-prediction-probabilities-for-a-multi-class-PyTorch-model-获取多类-PyTorch-模型的预测概率" class="headerlink" title="8.4 Getting prediction probabilities for a multi-class PyTorch model 获取多类 PyTorch 模型的预测概率"></a>8.4 Getting prediction probabilities for a multi-class PyTorch model 获取多类 PyTorch 模型的预测概率</h2><p>准备好了损失函数和优化器，并且准备好训练我们的模型，但在此之前，让我们对我们的模型进行一次前向传递，看看它是否有效。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Perform a single forward pass on the data (we&#x27;ll need to put it to the target device for it to work)</span></span><br><span class="line">model_4(X_blob_train.to(device))[:<span class="number">5</span>]</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">tensor([[-1.0821,  0.2580, -0.6953,  0.7268],</span><br><span class="line">        [-0.4015,  2.0296,  2.3008,  1.7942],</span><br><span class="line">        [ 1.3277, -0.3837,  0.2508, -1.6811],</span><br><span class="line">        [ 0.7637,  0.1111,  0.5110, -0.8092],</span><br><span class="line">        [-0.1890,  1.7277,  2.0414,  1.3623]], device=&#x27;cuda:0&#x27;,</span><br><span class="line">       grad_fn=&lt;SliceBackward0&gt;)</span><br></pre></td></tr></table></figure><p>为每个样本的每个特征都获得了一个值。检查一下形状以确认。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># How many elements in a single prediction sample?</span></span><br><span class="line">model_4(X_blob_train.to(device))[<span class="number">0</span>].shape, NUM_CLASSES </span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">(torch.Size([4]), 4)</span><br></pre></td></tr></table></figure><p>模型正在为每个类别预测一个值。</p><p>你还记得我们模型的原始输出叫什么吗？</p><p>提示：它与“frog splits”押韵（在制作这些材料时没有伤害任何动物）。</p><p>如果你猜是 logits，那你就猜对了。</p><p>所以现在我们的模型正在输出 logits，但如果我们想弄清楚样本到底是哪个标签，该怎么办？</p><p>如何从 <code>logits</code>(raw output of model) -&gt; <code>prediction probabilities</code>(use torch.softmax) -&gt; <code>prediction labels</code>(take the argmax of the prediction probabilities)，就像我们处理二元分类问题一样？</p><p>这就是 <a href="https://en.wikipedia.org/wiki/Softmax_function">softmax 激活函数</a> 发挥作用的地方。</p><p>softmax 函数计算每个预测类相对于所有其他可能类成为实际预测类的概率。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Make prediction logits with model</span></span><br><span class="line"><span class="comment"># 使用模型进行预测逻辑</span></span><br><span class="line">y_logits = model_4(X_blob_test.to(device))</span><br><span class="line"></span><br><span class="line"><span class="comment"># Perform softmax calculation on logits across dimension 1 to get prediction probabilities</span></span><br><span class="line"><span class="comment"># 对 1 维上的 logits 执行 softmax 计算，得到预测概率</span></span><br><span class="line">y_pred_probs = torch.softmax(y_logits, dim=<span class="number">1</span>) </span><br><span class="line"><span class="built_in">print</span>(y_logits[:<span class="number">5</span>])</span><br><span class="line"><span class="built_in">print</span>(y_pred_probs[:<span class="number">5</span>])</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">tensor([[-1.2549, -0.8112, -1.4795, -0.5696],</span><br><span class="line">        [ 1.7168, -1.2270,  1.7367,  2.1010],</span><br><span class="line">        [ 2.2400,  0.7714,  2.6020,  1.0107],</span><br><span class="line">        [-0.7993, -0.3723, -0.9138, -0.5388],</span><br><span class="line">        [-0.4332, -1.6117, -0.6891,  0.6852]], device=&#x27;cuda:0&#x27;,</span><br><span class="line">       grad_fn=&lt;SliceBackward0&gt;)</span><br><span class="line">tensor([[0.1872, 0.2918, 0.1495, 0.3715],</span><br><span class="line">        [0.2824, 0.0149, 0.2881, 0.4147],</span><br><span class="line">        [0.3380, 0.0778, 0.4854, 0.0989],</span><br><span class="line">        [0.2118, 0.3246, 0.1889, 0.2748],</span><br><span class="line">        [0.1945, 0.0598, 0.1506, 0.5951]], device=&#x27;cuda:0&#x27;,</span><br><span class="line">       grad_fn=&lt;SliceBackward0&gt;)</span><br></pre></td></tr></table></figure><p>softmax 函数的输出可能看起来仍然是乱码（确实如此，因为我们的模型尚未经过训练，并且使用随机模式进行预测），但每个样本都有非常具体的区别。</p><p>将 logits 传递到 softmax 函数后，每个样本现在都加到 1（或非常接近）。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Sum the first sample output of the softmax activation function</span></span><br><span class="line"><span class="comment"># 对softmax激活函数的第一个样本输出求和</span></span><br><span class="line">torch.<span class="built_in">sum</span>(y_pred_probs[<span class="number">0</span>])</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tensor(1., device=&#x27;cuda:0&#x27;, grad_fn=&lt;SumBackward0&gt;)</span><br></pre></td></tr></table></figure><p>这些预测概率本质上说明了模型认为目标 X 样本（输入）映射到每个类的程度。</p><p>由于 <code>y_pred_probs</code> 中每个类都有一个值，因此最高值的索引就是模型认为特定数据样本最属于的类。</p><p>我们可以使用 <code>torch.argmax()</code> 检查哪个索引具有最高值。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Which class does the model think is *most* likely at the index 0 sample?</span></span><br><span class="line"><span class="comment"># 模型认为在索引 0 样本中哪个类最有可能？</span></span><br><span class="line"><span class="built_in">print</span>(y_pred_probs[<span class="number">0</span>])</span><br><span class="line"><span class="built_in">print</span>(torch.argmax(y_pred_probs[<span class="number">0</span>]))</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">tensor([0.1872, 0.2918, 0.1495, 0.3715], device=&#x27;cuda:0&#x27;,</span><br><span class="line">       grad_fn=&lt;SelectBackward0&gt;)</span><br><span class="line">tensor(3, device=&#x27;cuda:0&#x27;)</span><br></pre></td></tr></table></figure><p>您可以看到 <code>torch.argmax()</code> 的输出返回 3，因此对于索引 0 处的样本的特征 (<code>X</code>)，模型预测最可能的类值 (<code>y</code>) 是 3。</p><p>当然，现在这只是随机猜测，所以它有 25% 的正确率（因为有四个类）。但我们可以通过训练模型来提高这些机会。</p><blockquote><p>模型的原始输出称为 logits。<br>对于多类分类问题，要将 logits 转换为预测概率，请使用 softmax 激活函数 (torch.softmax)。<br>具有最高预测概率的值的索引是模型认为在给定该样本的输入特征的情况下最有可能的类号（虽然这是一个预测，但并不意味着它是正确的）。</p></blockquote><h2 id="8-5-Creating-a-training-and-testing-loop-for-a-multi-class-PyTorch-model-为多类-PyTorch-模型创建训练和测试循环"><a href="#8-5-Creating-a-training-and-testing-loop-for-a-multi-class-PyTorch-model-为多类-PyTorch-模型创建训练和测试循环" class="headerlink" title="8.5 Creating a training and testing loop for a multi-class PyTorch model 为多类 PyTorch 模型创建训练和测试循环"></a>8.5 Creating a training and testing loop for a multi-class PyTorch model 为多类 PyTorch 模型创建训练和测试循环</h2><p>好了，现在我们已经完成了所有准备步骤，让我们编写一个训练和测试循环来改进和评估我们的模型。</p><p>我们之前已经完成了很多这些步骤，所以其中很多都是练习。</p><p>唯一的区别是，我们将调整步骤，将模型输出（<code>logits</code>）转换为预测概率（使用softmax激活函数），然后转换为预测标签（通过取softmax激活函数输出的argmax）。</p><p>让我们训练模型<code>epochs=100</code>，并每10个epochs评估一次。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Fit the model</span></span><br><span class="line">torch.manual_seed(<span class="number">42</span>)</span><br><span class="line">torch.cuda.manual_seed(<span class="number">42</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Set number of epochs</span></span><br><span class="line">epochs = <span class="number">100</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Put data to target device</span></span><br><span class="line">X_blob_train, y_blob_train = X_blob_train.to(device), y_blob_train.to(device)</span><br><span class="line">X_blob_test, y_blob_test = X_blob_test.to(device), y_blob_test.to(device)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(epochs):</span><br><span class="line">    <span class="comment">### Training</span></span><br><span class="line">    model_4.train()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 1. Forward pass</span></span><br><span class="line">    y_logits = model_4(X_blob_train) <span class="comment"># model outputs raw logits </span></span><br><span class="line">    y_pred = torch.softmax(y_logits, dim=<span class="number">1</span>).argmax(dim=<span class="number">1</span>) <span class="comment"># go from logits -&gt; prediction probabilities -&gt; prediction labels</span></span><br><span class="line">    <span class="comment"># print(y_logits)</span></span><br><span class="line">    <span class="comment"># 2. Calculate loss and accuracy</span></span><br><span class="line">    loss = loss_fn(y_logits, y_blob_train) </span><br><span class="line">    acc = accuracy_fn(y_true=y_blob_train,</span><br><span class="line">                      y_pred=y_pred)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 3. Optimizer zero grad</span></span><br><span class="line">    optimizer.zero_grad()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 4. Loss backwards</span></span><br><span class="line">    loss.backward()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 5. Optimizer step</span></span><br><span class="line">    optimizer.step()</span><br><span class="line"></span><br><span class="line">    <span class="comment">### Testing</span></span><br><span class="line">    model_4.<span class="built_in">eval</span>()</span><br><span class="line">    <span class="keyword">with</span> torch.inference_mode():</span><br><span class="line">      <span class="comment"># 1. Forward pass</span></span><br><span class="line">      test_logits = model_4(X_blob_test)</span><br><span class="line">      test_pred = torch.softmax(test_logits, dim=<span class="number">1</span>).argmax(dim=<span class="number">1</span>)</span><br><span class="line">      <span class="comment"># 2. Calculate test loss and accuracy</span></span><br><span class="line">      test_loss = loss_fn(test_logits, y_blob_test)</span><br><span class="line">      test_acc = accuracy_fn(y_true=y_blob_test,</span><br><span class="line">                             y_pred=test_pred)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Print out what&#x27;s happening</span></span><br><span class="line">    <span class="keyword">if</span> epoch % <span class="number">10</span> == <span class="number">0</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;Epoch: <span class="subst">&#123;epoch&#125;</span> | Loss: <span class="subst">&#123;loss:<span class="number">.5</span>f&#125;</span>, Acc: <span class="subst">&#123;acc:<span class="number">.2</span>f&#125;</span>% | Test Loss: <span class="subst">&#123;test_loss:<span class="number">.5</span>f&#125;</span>, Test Acc: <span class="subst">&#123;test_acc:<span class="number">.2</span>f&#125;</span>%&quot;</span>) </span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">Epoch: 0 | Loss: 1.04324, Acc: 65.50% | Test Loss: 0.57861, Test Acc: 95.50%</span><br><span class="line">Epoch: 10 | Loss: 0.14398, Acc: 99.12% | Test Loss: 0.13037, Test Acc: 99.00%</span><br><span class="line">Epoch: 20 | Loss: 0.08062, Acc: 99.12% | Test Loss: 0.07216, Test Acc: 99.50%</span><br><span class="line">Epoch: 30 | Loss: 0.05924, Acc: 99.12% | Test Loss: 0.05133, Test Acc: 99.50%</span><br><span class="line">Epoch: 40 | Loss: 0.04892, Acc: 99.00% | Test Loss: 0.04098, Test Acc: 99.50%</span><br><span class="line">Epoch: 50 | Loss: 0.04295, Acc: 99.00% | Test Loss: 0.03486, Test Acc: 99.50%</span><br><span class="line">Epoch: 60 | Loss: 0.03910, Acc: 99.00% | Test Loss: 0.03083, Test Acc: 99.50%</span><br><span class="line">Epoch: 70 | Loss: 0.03643, Acc: 99.00% | Test Loss: 0.02799, Test Acc: 99.50%Epoch: 0 | Loss: 1.04324, Acc: 65.50% | Test Loss: 0.57861, Test Acc: 95.50%</span><br><span class="line">Epoch: 10 | Loss: 0.14398, Acc: 99.12% | Test Loss: 0.13037, Test Acc: 99.00%</span><br><span class="line">Epoch: 20 | Loss: 0.08062, Acc: 99.12% | Test Loss: 0.07216, Test Acc: 99.50%</span><br><span class="line">Epoch: 30 | Loss: 0.05924, Acc: 99.12% | Test Loss: 0.05133, Test Acc: 99.50%</span><br><span class="line">Epoch: 40 | Loss: 0.04892, Acc: 99.00% | Test Loss: 0.04098, Test Acc: 99.50%</span><br><span class="line">Epoch: 50 | Loss: 0.04295, Acc: 99.00% | Test Loss: 0.03486, Test Acc: 99.50%</span><br><span class="line">Epoch: 60 | Loss: 0.03910, Acc: 99.00% | Test Loss: 0.03083, Test Acc: 99.50%</span><br><span class="line">Epoch: 70 | Loss: 0.03643, Acc: 99.00% | Test Loss: 0.02799, Test Acc: 99.50%</span><br><span class="line">Epoch: 80 | Loss: 0.03448, Acc: 99.00% | Test Loss: 0.02587, Test Acc: 99.50%</span><br><span class="line">Epoch: 90 | Loss: 0.03300, Acc: 99.12% | Test Loss: 0.02423, Test Acc: 99.50%</span><br></pre></td></tr></table></figure><h2 id="8-6-Making-and-evaluating-predictions-with-a-PyTorch-multi-class-model-使用-PyTorch-多类模型进行预测并评估预测"><a href="#8-6-Making-and-evaluating-predictions-with-a-PyTorch-multi-class-model-使用-PyTorch-多类模型进行预测并评估预测" class="headerlink" title="8.6 Making and evaluating predictions with a PyTorch multi-class model 使用 PyTorch 多类模型进行预测并评估预测"></a>8.6 Making and evaluating predictions with a PyTorch multi-class model 使用 PyTorch 多类模型进行预测并评估预测</h2><p>看起来我们训练过的模型表现得相当不错。</p><p>但为了确保这一点，让我们做一些预测并将它们可视化。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Make predictions</span></span><br><span class="line">model_4.<span class="built_in">eval</span>()</span><br><span class="line"><span class="keyword">with</span> torch.inference_mode():</span><br><span class="line">    y_logits = model_4(X_blob_test)</span><br><span class="line"></span><br><span class="line"><span class="comment"># View the first 10 predictions</span></span><br><span class="line">y_logits[:<span class="number">10</span>]</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">tensor([[  4.3377,  10.3539, -14.8948,  -9.7642],</span><br><span class="line">        [  5.0142, -12.0371,   3.3860,  10.6699],</span><br><span class="line">        [ -5.5885, -13.3448,  20.9894,  12.7711],</span><br><span class="line">        [  1.8400,   7.5599,  -8.6016,  -6.9942],</span><br><span class="line">        [  8.0726,   3.2906, -14.5998,  -3.6186],</span><br><span class="line">        [  5.5844, -14.9521,   5.0168,  13.2890],</span><br><span class="line">        [ -5.9739, -10.1913,  18.8655,   9.9179],</span><br><span class="line">        [  7.0755,  -0.7601,  -9.5531,   0.1736],</span><br><span class="line">        [ -5.5918, -18.5990,  25.5309,  17.5799],</span><br><span class="line">        [  7.3142,   0.7197, -11.2017,  -1.2011]], device=&#x27;cuda:0&#x27;)</span><br></pre></td></tr></table></figure><p>看起来我们模型的预测仍然是 <code>logit</code> 形式。</p><p>但为了评估它们，它们必须与我们的标签 (<code>y_blob_test</code>) 具有相同的形式，后者是整数形式。</p><p>让我们将模型的预测 <code>logit</code> 转换为预测概率（使用 <code>torch.softmax()</code>），然后转换为预测标签（通过获取每个样本的 <code>argmax()</code>）。</p><blockquote><p>可以跳过 <code>torch.softmax()</code> 函数，直接在 <code>logits</code> 上调用 <code>torch.argmax()</code>，从预测 <code>logits</code> -&gt; <code>predicted labels</code> 直接进入。<br>例如，<code>y_preds = torch.argmax(y_logits, dim=1)</code>，这节省了一个计算步骤（没有 <code>torch.softmax()</code>），但导致没有可用的预测概率。</p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Turn predicted logits in prediction probabilities</span></span><br><span class="line"><span class="comment"># 将预测的逻辑转换为预测概率</span></span><br><span class="line">y_pred_probs = torch.softmax(y_logits, dim=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Turn prediction probabilities into prediction labels</span></span><br><span class="line"><span class="comment"># 将预测概率转化为预测标签</span></span><br><span class="line">y_preds = y_pred_probs.argmax(dim=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Compare first 10 model preds and test labels</span></span><br><span class="line"><span class="comment"># 比较前 10 个模型预测和测试标签</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Predictions: <span class="subst">&#123;y_preds[:<span class="number">10</span>]&#125;</span>\nLabels: <span class="subst">&#123;y_blob_test[:<span class="number">10</span>]&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Test accuracy: <span class="subst">&#123;accuracy_fn(y_true=y_blob_test, y_pred=y_preds)&#125;</span>%&quot;</span>)</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Predictions: tensor([1, 3, 2, 1, 0, 3, 2, 0, 2, 0], device=&#x27;cuda:0&#x27;)</span><br><span class="line">Labels: tensor([1, 3, 2, 1, 0, 3, 2, 0, 2, 0], device=&#x27;cuda:0&#x27;)</span><br><span class="line">Test accuracy: 99.5%</span><br></pre></td></tr></table></figure><p>模型预测现在与测试标签的形式相同。</p><p>使用 <code>plot_decision_boundary()</code> 将它们可视化，请记住，因为我们的数据在 GPU 上，所以我们必须将其移动到 CPU 以便与 matplotlib 一起使用（<code>plot_decision_boundary()</code> 会自动为我们执行此操作）。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">plt.figure(figsize=(<span class="number">12</span>, <span class="number">6</span>))</span><br><span class="line">plt.subplot(<span class="number">1</span>, <span class="number">2</span>, <span class="number">1</span>)</span><br><span class="line">plt.title(<span class="string">&quot;Train&quot;</span>)</span><br><span class="line">plot_decision_boundary(model_4, X_blob_train, y_blob_train)</span><br><span class="line">plt.subplot(<span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>)</span><br><span class="line">plt.title(<span class="string">&quot;Test&quot;</span>)</span><br><span class="line">plot_decision_boundary(model_4, X_blob_test, y_blob_test)</span><br></pre></td></tr></table></figure><img src="/2024/08/16/PyTorch-26H-3/PyTorch-26H-3-14.png" class="" title="PyTorch-26H-3-14"><h1 id="9-More-classification-evaluation-metrics-更多分类评估指标"><a href="#9-More-classification-evaluation-metrics-更多分类评估指标" class="headerlink" title="9. More classification evaluation metrics 更多分类评估指标"></a>9. More classification evaluation metrics 更多分类评估指标</h1><p>到目前为止，我们仅介绍了评估分类模型的几种方法（准确性、损失和可视化预测）。</p><p>这些是您会遇到的一些最常见的方法，并且是一个很好的起点。</p><p>可能希望使用更多指标来评估分类模型，例如：</p><div class="table-container"><table><thead><tr><th style="text-align:center">指标名称/评估方法</th><th style="text-align:center">定义</th><th style="text-align:center">代码</th></tr></thead><tbody><tr><td style="text-align:center">预测精度Accuracy</td><td style="text-align:center">在 100 个预测中，您的模型有多少个预测正确？例如，95% 的准确率意味着 100 个预测中有 95 个正确。</td><td style="text-align:center"><a href="https://torchmetrics.readthedocs.io/en/stable/classification/accuracy.html#id3">torchmetrics.Accuracy()</a> or <a href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html">sklearn.metrics.accuracy_score()</a></td></tr><tr><td style="text-align:center">准确率Precision</td><td style="text-align:center">真阳性与样本总数的比例。精度越高，假阳性越少（模型预测为 1，但实际应该是 0）。</td><td style="text-align:center"><a href="https://torchmetrics.readthedocs.io/en/stable/classification/precision.html#id4">torchmetrics.Precision()</a> or <a href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.precision_score.html">sklearn.metrics.precision_score()</a></td></tr><tr><td style="text-align:center">召回 Recall</td><td style="text-align:center">真阳性占真阳性和假阴性总数的比例（模型预测为 0，但实际应为 1）。召回率越高，假阴性越少。</td><td style="text-align:center"><a href="https://torchmetrics.readthedocs.io/en/stable/classification/recall.html#id5">torchmetrics.Recall()</a> or <a href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.recall_score.html">sklearn.metrics.recall_score()</a></td></tr><tr><td style="text-align:center">F1分数 F1-score</td><td style="text-align:center">将精度和召回率结合为一个指标。1 表示最好，0 表示最差。</td><td style="text-align:center"><a href="https://torchmetrics.readthedocs.io/en/stable/classification/f1_score.html#f1score">torchmetrics.F1Score()</a> or <a href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html">sklearn.metrics.f1_score()</a></td></tr><tr><td style="text-align:center">混淆矩阵 <a href="https://www.dataschool.io/simple-guide-to-confusion-matrix-terminology/">Confusion matrix</a></td><td style="text-align:center">以表格方式将预测值与真实值进行比较，如果 100% 正确，矩阵中的所有值将从左上角到右下角（对角线）。</td><td style="text-align:center"><a href="https://torchmetrics.readthedocs.io/en/stable/classification/confusion_matrix.html#confusionmatrix">torchmetrics.ConfusionMatrix</a> or <a href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.ConfusionMatrixDisplay.html#sklearn.metrics.ConfusionMatrixDisplay.from_predictions">sklearn.metrics.plot_confusion_matrix()</a></td></tr><tr><td style="text-align:center">分类报告 Classification report</td><td style="text-align:center">收集一些主要的分类指标，例如精确度、召回率和 f1 分数。</td><td style="text-align:center"><a href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html">sklearn.metrics.classification_report()</a></td></tr></tbody></table></div><p>Scikit-Learn（一个流行的、世界一流的机器学习库）对上述指标有许多实现，如果你正在寻找一个类似 PyTorch 的版本，请查看 <a href="https://torchmetrics.readthedocs.io/en/latest/">TorchMetrics</a>，尤其是 <a href="https://torchmetrics.readthedocs.io/en/stable/pages/classification.html">TorchMetrics 分类部分</a>。</p><p>Precision 和 Recall 往往是相反的。</p><p><a href="https://towardsdatascience.com/beyond-accuracy-precision-and-recall-3da06bea9f6c">Beyond Accuracy: Precision and Recall</a></p><img src="/2024/08/16/PyTorch-26H-3/PyTorch-26H-3-15.png" class="" title="PyTorch-26H-3-15"><img src="/2024/08/16/PyTorch-26H-3/PyTorch-26H-3-16.png" class="" title="PyTorch-26H-3-16"><p>尝试一下 <code>torchmetrics.Accuracy</code> 指标。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">try</span>:</span><br><span class="line">    <span class="keyword">from</span> torchmetrics <span class="keyword">import</span> Accuracy</span><br><span class="line"><span class="keyword">except</span>:</span><br><span class="line">    !pip install torchmetrics==<span class="number">0.9</span><span class="number">.3</span> <span class="comment"># this is the version we&#x27;re using in this notebook (later versions exist here: https://torchmetrics.readthedocs.io/en/stable/generated/CHANGELOG.html#changelog)</span></span><br><span class="line">    <span class="keyword">from</span> torchmetrics <span class="keyword">import</span> Accuracy</span><br><span class="line"></span><br><span class="line"><span class="comment"># Setup metric and make sure it&#x27;s on the target device</span></span><br><span class="line">torchmetrics_accuracy = Accuracy(task=<span class="string">&#x27;multiclass&#x27;</span>, num_classes=<span class="number">4</span>).to(device)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Calculate accuracy</span></span><br><span class="line">torchmetrics_accuracy(y_preds, y_blob_test)</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tensor(0.9950, device=&#x27;cuda:0&#x27;)</span><br></pre></td></tr></table></figure><h1 id="非线性激活函数"><a href="#非线性激活函数" class="headerlink" title="非线性激活函数"></a>非线性激活函数</h1><img src="/2024/08/16/PyTorch-26H-3/PyTorch-26H-3-17.png" class="" title="PyTorch-26H-3-17"><h1 id="Exercises"><a href="#Exercises" class="headerlink" title="Exercises"></a>Exercises</h1><p>所有练习都集中于练习以上部分中的代码。</p><p>您应该能够通过参考每个部分或按照链接的资源来完成它们。</p><p>所有练习都应使用<a href="https://pytorch.org/docs/stable/notes/cuda.html#device-agnostic-code">设备激动代码</a>来完成。</p><p>资源：</p><ul><li><a href="https://github.com/mrdbourke/pytorch-deep-learning/blob/main/extras/exercises/02_pytorch_classification_exercises.ipynb">练习模板笔记本02</a></li><li><a href="https://github.com/mrdbourke/pytorch-deep-learning/blob/main/extras/solutions/02_pytorch_classification_exercise_solutions.ipynb">02 的示例解决方案笔记本</a>（在查看<em>之前先</em>尝试练习）</li></ul><ol><li><p>使用 Scikit-Learn 的函数创建二元分类数据集  <code>make_moons()</code>。</p><ul><li>为了一致性，数据集应该有 1000 个样本和一个<code>random_state=42</code>。</li><li>将数据转换为 PyTorch 张量。将数据分为训练集和测试集，<code>train_test_split</code>其中 80% 用于训练，20% 用于测试。</li></ul></li><li><p>通过子类化构建一个模型<code>nn.Module</code>，该模型包含非线性激活函数，并且能够拟合您在 1 中创建的数据。</p><ul><li>请随意使用您想要的 PyTorch 层（线性和非线性）的任意组合。</li></ul></li><li><p>设置二元分类兼容的损失函数和优化器，以便在训练模型时使用。</p></li><li><p>创建一个训练和测试循环，以使您在 2 中创建的模型适合您在 1 中创建的数据。</p><ul><li><a href="https://torchmetrics.readthedocs.io/en/latest/">为了测量模型准确性，您可以创建自己的准确性函数或使用TorchMetrics</a>中的准确性函数。</li><li>对模型进行足够长时间的训练，以达到 96% 以上的准确率。</li><li>训练循环应该每 10 个时期输出一次模型训练和测试集损失和准确率的进度。</li></ul></li><li><p>使用训练好的模型进行预测，并使用<code>plot_decision_boundary()</code>此笔记本中创建的函数绘制它们。</p></li><li><p>在纯 PyTorch 中复制 Tanh（双曲正切）激活函数。</p><ul><li>请随意参考<a href="https://ml-cheatsheet.readthedocs.io/en/latest/activation_functions.html#tanh">ML 备忘单网站</a>来获取该公式。</li></ul></li><li><p>使用<a href="https://cs231n.github.io/neural-networks-case-study/">CS231n 中的螺旋数据创建功能</a> 创建多类数据集（代码见下文）。</p><ul><li>构建一个能够拟合数据的模型（您可能需要线性和非线性层的组合）。</li><li>构建一个能够处理多类数据的损失函数和优化器（可选扩展：使用 Adam 优化器而不是 SGD，您可能必须尝试不同的学习率值才能使其发挥作用）。</li><li>对多类数据进行训练和测试循环，并在其上训练模型以达到 95% 以上的测试准确率（您可以在此处使用任何您喜欢的准确率测量函数）。</li><li>根据模型预测在螺旋数据集上绘制决策边界，该<code>plot_decision_boundary()</code>函数也适用于该数据集。</li></ul></li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Code for creating a spiral dataset from CS231n</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">N = <span class="number">100</span> <span class="comment"># number of points per class</span></span><br><span class="line">D = <span class="number">2</span> <span class="comment"># dimensionality</span></span><br><span class="line">K = <span class="number">3</span> <span class="comment"># number of classes</span></span><br><span class="line">X = np.zeros((N*K,D)) <span class="comment"># data matrix (each row = single example)</span></span><br><span class="line">y = np.zeros(N*K, dtype=<span class="string">&#x27;uint8&#x27;</span>) <span class="comment"># class labels</span></span><br><span class="line"><span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(K):</span><br><span class="line">  ix = <span class="built_in">range</span>(N*j,N*(j+<span class="number">1</span>))</span><br><span class="line">  r = np.linspace(<span class="number">0.0</span>,<span class="number">1</span>,N) <span class="comment"># radius</span></span><br><span class="line">  t = np.linspace(j*<span class="number">4</span>,(j+<span class="number">1</span>)*<span class="number">4</span>,N) + np.random.randn(N)*<span class="number">0.2</span> <span class="comment"># theta</span></span><br><span class="line">  X[ix] = np.c_[r*np.sin(t), r*np.cos(t)]</span><br><span class="line">  y[ix] = j</span><br><span class="line"><span class="comment"># lets visualize the data</span></span><br><span class="line">plt.scatter(X[:, <span class="number">0</span>], X[:, <span class="number">1</span>], c=y, s=<span class="number">40</span>, cmap=plt.cm.Spectral)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><h1 id="Extra-curriculum-课外活动"><a href="#Extra-curriculum-课外活动" class="headerlink" title="Extra-curriculum 课外活动"></a>Extra-curriculum 课外活动</h1><ul><li>写下 3 个您认为机器分类可能有用的问题（可以是任何问题，您可以发挥创造力，例如，根据购买金额和购买地点特征将信用卡交易分类为欺诈或非欺诈）。</li><li>研究基于梯度的优化器（如 SGD 或 Adam）中的“动量”概念，它是什么意思？</li><li>花 10 分钟阅读<a href="https://en.wikipedia.org/wiki/Activation_function#Table_of_activation_functions">Wikipedia 上关于不同激活函数的页面</a>，其中有多少个你能与<a href="https://pytorch.org/docs/stable/nn.html#non-linear-activations-weighted-sum-nonlinearity">PyTorch 的激活函数</a>相媲美？</li><li>研究何时准确度可能不是一个好的衡量标准（提示：阅读<a href="https://willkoehrsen.github.io/statistics/learning/beyond-accuracy-precision-and-recall/">Will Koehrsen 的《超越准确度》</a>来获取想法）。</li><li><strong>观看：</strong>要了解我们的神经网络内部发生的情况以及它们如何学习，请观看<a href="https://youtu.be/7sB052Pz0sQ">麻省理工学院的深度学习简介视频</a>。</li></ul>]]></content>
    
    
    <summary type="html">PyTorch-26H-3</summary>
    
    
    
    <category term="PyTorch" scheme="http://hibiscidai.com/categories/PyTorch/"/>
    
    
    <category term="学习笔记" scheme="http://hibiscidai.com/tags/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
    <category term="PyTorch" scheme="http://hibiscidai.com/tags/PyTorch/"/>
    
  </entry>
  
  <entry>
    <title>PyTorch-26H-2</title>
    <link href="http://hibiscidai.com/2024/08/15/PyTorch-26H-2/"/>
    <id>http://hibiscidai.com/2024/08/15/PyTorch-26H-2/</id>
    <published>2024-08-15T12:00:00.000Z</published>
    <updated>2024-10-17T13:14:12.000Z</updated>
    
    <content type="html"><![CDATA[<img src="/2024/08/15/PyTorch-26H-2/PyTorch-26H-2.png" class="" title="PyTorch-26H-2"><p>PyTorch-26H-2</p><span id="more"></span><h1 id="PyTorch-26H-2"><a href="#PyTorch-26H-2" class="headerlink" title="PyTorch-26H-2"></a>PyTorch-26H-2</h1><p>主页：<a href="https://www.freecodecamp.org/news/learn-pytorch-for-deep-learning-in-day/">https://www.freecodecamp.org/news/learn-pytorch-for-deep-learning-in-day/</a></p><p>youtub：<a href="https://youtu.be/V_xro1bcAuA">https://youtu.be/V_xro1bcAuA</a></p><p>github：<a href="https://github.com/mrdbourke/pytorch-deep-learning">https://github.com/mrdbourke/pytorch-deep-learning</a></p><p>Learn PyTorch for Deep Learning: Zero to Mastery book：<a href="https://www.learnpytorch.io/">https://www.learnpytorch.io/</a></p><p>PyTorch documentation：<a href="https://pytorch.org/docs/stable/index.html">https://pytorch.org/docs/stable/index.html</a></p><h1 id="Chapter-1-–-PyTorch-Workflow-Fundamentals"><a href="#Chapter-1-–-PyTorch-Workflow-Fundamentals" class="headerlink" title="Chapter 1 – PyTorch Workflow Fundamentals"></a>Chapter 1 – PyTorch Workflow Fundamentals</h1><p>机器学习和深度学习的本质是从过去获取一些数据，建立一种算法（如神经网络）来发现其中的模式，并利用发现的模式来预测未来。</p><p>从一条直线开始，构建一个 PyTorch 模型来学习直线的模式并进行匹配。</p><h2 id="What-we’re-going-to-cover"><a href="#What-we’re-going-to-cover" class="headerlink" title="What we’re going to cover"></a>What we’re going to cover</h2><img src="/2024/08/15/PyTorch-26H-2/PyTorch-26H-2-1.png" class="" title="PyTorch-26H-2-1"><div class="table-container"><table><thead><tr><th style="text-align:center">话题</th><th style="text-align:center">内容</th></tr></thead><tbody><tr><td style="text-align:center">1. 准备数据</td><td style="text-align:center">数据可以是任何东西，但首先我们要创建一条简单的直线</td></tr><tr><td style="text-align:center">2. 建立模型</td><td style="text-align:center">在这里我们将创建一个模型来学习数据中的模式，我们还将选择一个损失函数、优化器并建立一个训练循环。</td></tr><tr><td style="text-align:center">3. 将模型拟合到数据（训练）</td><td style="text-align:center">我们有数据和模型，现在让我们让模型（尝试）在（训练）数据中寻找模式。</td></tr><tr><td style="text-align:center">4. 做出预测并评估模型（推理）</td><td style="text-align:center">我们的模型在数据中发现了模式，让我们将它的发现与实际（测试）数据进行比较。</td></tr><tr><td style="text-align:center">5. 保存和加载模型</td><td style="text-align:center">在其他地方使用模型，或者稍后再回来。</td></tr><tr><td style="text-align:center">6. 综合起来</td><td style="text-align:center">让我们把以上所有内容结合起来。</td></tr></tbody></table></div><h2 id="Where-can-you-get-help"><a href="#Where-can-you-get-help" class="headerlink" title="Where can you get help?"></a>Where can you get help?</h2><p>本课程的所有材料均可在 <a href="https://github.com/mrdbourke/pytorch-deep-learning">GitHub</a> 上找到。</p><p>如果您遇到麻烦，您也可以在<a href="https://github.com/mrdbourke/pytorch-deep-learning/discussions">讨论页面</a>上提问。</p><p>还有<a href="https://discuss.pytorch.org/">PyTorch 开发者论坛</a>，这是一个对所有 PyTorch 相关事宜非常有用的地方。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">what_were_covering = &#123;<span class="number">1</span>: <span class="string">&quot;data (prepare and load)&quot;</span>,</span><br><span class="line">    <span class="number">2</span>: <span class="string">&quot;build model&quot;</span>,</span><br><span class="line">    <span class="number">3</span>: <span class="string">&quot;fitting the model to data (training)&quot;</span>,</span><br><span class="line">    <span class="number">4</span>: <span class="string">&quot;making predictions and evaluating a model (inference)&quot;</span>,</span><br><span class="line">    <span class="number">5</span>: <span class="string">&quot;saving and loading a model&quot;</span>,</span><br><span class="line">    <span class="number">6</span>: <span class="string">&quot;putting it all together&quot;</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">what_were_covering = &#123;<span class="number">1</span>: <span class="string">&quot;数据（准备和加载）&quot;</span>,</span><br><span class="line"><span class="number">2</span>: <span class="string">&quot;构建模型&quot;</span>,</span><br><span class="line"><span class="number">3</span>: <span class="string">&quot;将模型与数据拟合（训练）&quot;</span>,</span><br><span class="line"><span class="number">4</span>: <span class="string">&quot;进行预测和评估模型（推理）&quot;</span>,</span><br><span class="line"><span class="number">5</span>: <span class="string">&quot;保存和加载模型&quot;</span>,</span><br><span class="line"><span class="number">6</span>: <span class="string">&quot;将所有内容整合在一起&quot;</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>模块导入</p><p>我们将获得<code>torch</code>，<code>torch.nn</code>（nn代表神经网络，这个包包含在 PyTorch 中创建神经网络的构建块）和<code>matplotlib</code>。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn <span class="comment"># nn contains all of PyTorch&#x27;s building blocks for neural networks</span></span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="comment"># Check PyTorch version</span></span><br><span class="line">torch.__version__</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&#x27;2.4.1&#x27;</span><br></pre></td></tr></table></figure><h2 id="1-Data-preparing-and-loading"><a href="#1-Data-preparing-and-loading" class="headerlink" title="1. Data (preparing and loading)"></a>1. Data (preparing and loading)</h2><p>机器学习中的“数据”几乎可以是任何你能想象到的东西。数字表（比如一个大的 Excel 电子表格）、任何类型的图像、视频（YouTube 上有大量数据！）、歌曲或播客等音频文件、蛋白质结构、文本等等。</p><img src="/2024/08/15/PyTorch-26H-2/PyTorch-26H-2-2.png" class="" title="PyTorch-26H-2-2"><img src="/2024/08/15/PyTorch-26H-2/PyTorch-26H-2-3.png" class="" title="PyTorch-26H-2-3"><p>机器学习是一个由两部分组成的游戏：</p><p>1、<strong>数据（无论它是什么）转换为数字（一种表示）。</strong><br>2、<strong>选择或建立一个模型来尽可能好地学习表示。</strong></p><p>有时一项和两项可以同时进行。但是如果没有数据怎么办？嗯，这就是我们现在的情况。没有数据。但我们可以创造一些。我们将数据创建为一条直线。</p><p>我们将使用 <a href="https://en.wikipedia.org/wiki/Linear_regression">线性回归</a> 来创建具有已知参数（模型可以学习的东西）的数据，然后我们将使用 PyTorch 来查看是否可以构建模型来使用 <a href="https://en.wikipedia.org/wiki/Gradient_descent">梯度下降</a> 来估计这些参数。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Create *known* parameters</span></span><br><span class="line">weight = <span class="number">0.7</span></span><br><span class="line">bias = <span class="number">0.3</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Create data</span></span><br><span class="line">start = <span class="number">0</span></span><br><span class="line">end = <span class="number">1</span></span><br><span class="line">step = <span class="number">0.02</span></span><br><span class="line">X = torch.arange(start, end, step).unsqueeze(dim=<span class="number">1</span>)</span><br><span class="line">y = weight * X + bias</span><br><span class="line"></span><br><span class="line">X[:<span class="number">10</span>], y[:<span class="number">10</span>]</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">(tensor([[0.0000],</span><br><span class="line">         [0.0200],</span><br><span class="line">         [0.0400],</span><br><span class="line">         [0.0600],</span><br><span class="line">         [0.0800],</span><br><span class="line">         [0.1000],</span><br><span class="line">         [0.1200],</span><br><span class="line">         [0.1400],</span><br><span class="line">         [0.1600],</span><br><span class="line">         [0.1800]]),</span><br><span class="line"> tensor([[0.3000],</span><br><span class="line">         [0.3140],</span><br><span class="line">         [0.3280],</span><br><span class="line">         [0.3420],</span><br><span class="line">         [0.3560],</span><br><span class="line">         [0.3700],</span><br><span class="line">         [0.3840],</span><br><span class="line">         [0.3980],</span><br><span class="line">         [0.4120],</span><br><span class="line">         [0.4260]]))</span><br></pre></td></tr></table></figure><p>开始构建一个可以学习X（特征）和y（标签）之间关系的模型。</p><h3 id="Split-data-into-training-and-test-sets"><a href="#Split-data-into-training-and-test-sets" class="headerlink" title="Split data into training and test sets"></a>Split data into training and test sets</h3><p>在建立模型之前，我们需要将其拆分。</p><p>机器学习项目中最重要的步骤之一是创建训练和测试集（必要时还要创建验证集）。</p><img src="/2024/08/15/PyTorch-26H-2/PyTorch-26H-2-3_2.png" class="" title="PyTorch-26H-2-3_2"><div class="table-container"><table><thead><tr><th style="text-align:center">分类</th><th style="text-align:center">目的</th><th style="text-align:center">总数据量</th><th style="text-align:center">使用频率</th></tr></thead><tbody><tr><td style="text-align:center">训练集</td><td style="text-align:center">模型从这些数据中学习（例如您在学期期间学习的课程材料）。</td><td style="text-align:center">~60-80％</td><td style="text-align:center">Always</td></tr><tr><td style="text-align:center">验证集</td><td style="text-align:center">模型会根据这些数据进行调整（就像期末考试之前进行的模拟考试一样）。</td><td style="text-align:center">~10-20%</td><td style="text-align:center">Often but not always</td></tr><tr><td style="text-align:center">测试集</td><td style="text-align:center">模型会根据这些数据进行评估，以测试其所学到的知识（就像学期末参加的期末考试一样）。</td><td style="text-align:center">~10-20%</td><td style="text-align:center">Always</td></tr></tbody></table></div><p>只使用训练和测试集，这意味着我们将拥有一个数据集供我们的模型学习和评估。</p><p>通过分割X和Y张量来创建它们。</p><blockquote><p>处理真实数据时，此步骤通常在项目开始时完成（测试集应始终与所有其他数据分开）。我们希望我们的模型从训练数据中学习，然后在测试数据上对其进行评估，以了解它对未见过的示例的推广效果如何。</p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Create train/test split</span></span><br><span class="line">train_split = <span class="built_in">int</span>(<span class="number">0.8</span> * <span class="built_in">len</span>(X)) <span class="comment"># 80% of data used for training set, 20% for testing </span></span><br><span class="line">X_train, y_train = X[:train_split], y[:train_split]</span><br><span class="line">X_test, y_test = X[train_split:], y[train_split:]</span><br><span class="line"></span><br><span class="line"><span class="built_in">len</span>(X_train), <span class="built_in">len</span>(y_train), <span class="built_in">len</span>(X_test), <span class="built_in">len</span>(y_test)</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">len(X_train), len(y_train), len(X_test), len(y_test)</span><br></pre></td></tr></table></figure><p>40 个样本用于训练（X_train &amp; y_train）和 10 个样本用于测试（X_test &amp; y_test）。</p><p>创建的模型将尝试学习X_train &amp; y_train之间的关系，然后我们将评估它在 X_test 和 y_test 上的学习内容。</p><p>创建函数可视化数字：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">plot_predictions</span>(<span class="params">train_data=X_train, </span></span><br><span class="line"><span class="params">                     train_labels=y_train, </span></span><br><span class="line"><span class="params">                     test_data=X_test, </span></span><br><span class="line"><span class="params">                     test_labels=y_test, </span></span><br><span class="line"><span class="params">                     predictions=<span class="literal">None</span></span>):</span><br><span class="line">  <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">  Plots training data, test data and compares predictions.</span></span><br><span class="line"><span class="string">  &quot;&quot;&quot;</span></span><br><span class="line">  plt.figure(figsize=(<span class="number">10</span>, <span class="number">7</span>))</span><br><span class="line"></span><br><span class="line">  <span class="comment"># Plot training data in blue</span></span><br><span class="line">  plt.scatter(train_data, train_labels, c=<span class="string">&quot;b&quot;</span>, s=<span class="number">4</span>, label=<span class="string">&quot;Training data&quot;</span>)</span><br><span class="line">  </span><br><span class="line">  <span class="comment"># Plot test data in green</span></span><br><span class="line">  plt.scatter(test_data, test_labels, c=<span class="string">&quot;g&quot;</span>, s=<span class="number">4</span>, label=<span class="string">&quot;Testing data&quot;</span>)</span><br><span class="line"></span><br><span class="line">  <span class="keyword">if</span> predictions <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">    <span class="comment"># Plot the predictions in red (predictions were made on the test data)</span></span><br><span class="line">    plt.scatter(test_data, predictions, c=<span class="string">&quot;r&quot;</span>, s=<span class="number">4</span>, label=<span class="string">&quot;Predictions&quot;</span>)</span><br><span class="line"></span><br><span class="line">  <span class="comment"># Show the legend</span></span><br><span class="line">  plt.legend(prop=&#123;<span class="string">&quot;size&quot;</span>: <span class="number">14</span>&#125;)</span><br><span class="line"></span><br><span class="line">plot_predictions()</span><br></pre></td></tr></table></figure><img src="/2024/08/15/PyTorch-26H-2/PyTorch-26H-2-4.png" class="" title="PyTorch-26H-2-4"><h2 id="2-Build-model"><a href="#2-Build-model" class="headerlink" title="2. Build model"></a>2. Build model</h2><p>建立一个模型，使用蓝点来预测绿点。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Create a Linear Regression model class</span></span><br><span class="line"><span class="comment"># 创建线性回归模型类</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">LinearRegressionModel</span>(nn.Module): <span class="comment"># &lt;- almost everything in PyTorch is a nn.Module (think of this as neural network lego blocks)PyTorch 中的几乎所有东西都是 nn.Module（可以将其视为神经网络乐高积木）</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__() </span><br><span class="line">        self.weights = nn.Parameter(torch.randn(<span class="number">1</span>, <span class="comment"># &lt;- start with random weights (this will get adjusted as the model learns)从随机权重开始（这将随着模型的学习而进行调整）</span></span><br><span class="line">                                                dtype=torch.<span class="built_in">float</span>), <span class="comment"># &lt;- PyTorch loves float32 by defaultPyTorch 默认喜欢 float32</span></span><br><span class="line">                                   requires_grad=<span class="literal">True</span>) <span class="comment"># &lt;- can we update this value with gradient descent?)我们可以用梯度下降来更新这个值吗？）</span></span><br><span class="line"></span><br><span class="line">        self.bias = nn.Parameter(torch.randn(<span class="number">1</span>, <span class="comment"># &lt;- start with random bias (this will get adjusted as the model learns)从随机偏差开始（这将随着模型的学习而进行调整）</span></span><br><span class="line">                                            dtype=torch.<span class="built_in">float</span>), <span class="comment"># &lt;- PyTorch loves float32 by default</span></span><br><span class="line">                                requires_grad=<span class="literal">True</span>) <span class="comment"># &lt;- can we update this value with gradient descent?))我们可以用梯度下降来更新这个值吗？）</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># Forward defines the computation in the model Forward 定义模型中的计算</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x: torch.Tensor</span>) -&gt; torch.Tensor: <span class="comment"># &lt;- &quot;x&quot; is the input data (e.g. training/testing features) “x”是输入数据（例如训练/测试特征）</span></span><br><span class="line">        <span class="keyword">return</span> self.weights * x + self.bias <span class="comment"># &lt;- this is the linear regression formula (y = m*x + b) 这是线性回归公式 (y = m*x + b)</span></span><br></pre></td></tr></table></figure><p>Start with random values (weight &amp; bias)<br>从随机值开始（权重和偏差）</p><p>Look at training data and adjust the random values to better represent (or get closer to) the ideal values (the weight &amp; bias values we used to create the data)<br>查看训练数据并调整随机值以更好地表示（或更接近）理想值（我们用于创建数据的权重和偏差值）</p><p>Through two main algorithms:<br>通过两种主要算法：</p><ol><li>Gradient descent：<a href="https://youtu.be/IHZwWFHWa-w">https://youtu.be/IHZwWFHWa-w</a></li><li>梯度下降：<a href="https://youtu.be/IHZwWFHWa-w">https://youtu.be/IHZwWFHWa-w</a></li><li>Backpropagation：<a href="https://youtu.be/llg3gGewQ5U">https://youtu.be/llg3gGewQ5U</a></li><li>反向传播：<a href="https://youtu.be/llg3gGewQ5U">https://youtu.be/llg3gGewQ5U</a></li></ol><p><a href="https://realpython.com/python3-object-oriented-programming/">python3面向对象编程指南</a></p><img src="/2024/08/15/PyTorch-26H-2/PyTorch-26H-2-4_2.png" class="" title="PyTorch-26H-2-4_2"><p>Subclass nn.Module(this contains all the building blocks for neural networks)子类 nn.Module（包含神经网络的所有构建块）</p><p>Initialise model parameters to be used in various computations (these could be diMerent layers from torch.nn, single parameters, hard-coded values or functions)初始化用于各种计算的模型参数（这些参数可能是来自 torch.nn 的不同层、单个参数、硬编码值或函数）</p><p><code>requires_grad =True</code> means PyTorch will track the gradients of this speciLc parameter for use with torch.autograd and gradient descent (for many torch.nn modules, <code>requires_grad =True</code> is set by default)<code>require_grad =True</code> 表示 PyTorch 将跟踪此特定参数的梯度，以便与 torch.autograd 和梯度下降一起使用（对于许多 torch.nn 模块，<code>requires_grad =True</code> 是默认设置的）</p><p>Any subclass of nn.Module needs to override <code>forward()</code> (this deLnes the forward computation of the model)nn.Module 的任何子类都需要重写 <code>forward()</code>（这定义了模型的前向计算）</p><h3 id="PyTorch-model-building-essentials-PyTorch-模型构建要点"><a href="#PyTorch-model-building-essentials-PyTorch-模型构建要点" class="headerlink" title="PyTorch model building essentials PyTorch 模型构建要点"></a>PyTorch model building essentials PyTorch 模型构建要点</h3><p>PyTorch 有四个（大约）基本模块，<a href="https://pytorch.org/docs/stable/nn.html"><code>torch.nn</code></a>、<a href="https://pytorch.org/docs/stable/optim.html"><code>torch.optim</code></a>、<a href="https://pytorch.org/docs/stable/data.html#torch.utils.data.Dataset"><code>torch.utils.data.Dataset</code></a>、<a href="https://pytorch.org/docs/stable/data.html"><code>torch.utils.data.DataLoader</code></a>你可以用它们来创建几乎任何你能想到的神经网络。</p><div class="table-container"><table><thead><tr><th style="text-align:center">PyTorch模块</th><th style="text-align:center">作用</th></tr></thead><tbody><tr><td style="text-align:center"><a href="https://pytorch.org/docs/stable/nn.html">torch.nn</a></td><td style="text-align:center">包含计算图的所有构建块（本质上是以特定方式执行的一系列计算）。</td></tr><tr><td style="text-align:center"><a href="https://pytorch.org/docs/stable/generated/torch.nn.parameter.Parameter.html#parameter">torch.nn.Parameter</a></td><td style="text-align:center">存储可以与 一起使用的张量nn.Module。如果requires_grad=True梯度（用于通过<a href="https://ml-cheatsheet.readthedocs.io/en/latest/gradient_descent.html">梯度下降</a>更新模型参数）是自动计算的，这通常被称为“autograd”。</td></tr><tr><td style="text-align:center"><a href="https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module">torch.nn.Module</a></td><td style="text-align:center">所有神经网络模块的基类，神经网络的所有构建块都是子类。如果你在 PyTorch 中构建神经网络，你的模型应该是子类nn.Module。需要forward()实现一个方法。</td></tr><tr><td style="text-align:center"><a href="https://pytorch.org/docs/stable/optim.html">torch.optim</a></td><td style="text-align:center">包含各种优化算法（这些算法告诉存储的模型参数nn.Parameter如何最好地改变以改善梯度下降并进而减少损失）。</td></tr><tr><td style="text-align:center">def forward()</td><td style="text-align:center">所有nn.Module子类都需要一种方法，它定义了传递给特定的数据（例如上面的线性回归公式）forward()将进行的计算。nn.Module</td></tr></tbody></table></div><img src="/2024/08/15/PyTorch-26H-2/PyTorch-26H-2-4_3.png" class="" title="PyTorch-26H-2-4_3"><p>PyTorch 神经网络中的几乎所有内容都来自<code>torch.nn</code>。</p><p><code>nn.Module</code>包含较大的构建块（层）<br><code>nn.Parameter</code>包含较小的参数，如权重和偏差（将它们放在一起形成<code>nn.Module(s)</code>）<br><code>forward()</code>告诉较大的块如何在 <code>nn.Module(s)</code> 内对输入（充满数据的张量）进行计算<br><code>torch.optim</code>包含关于如何改进参数<code>nn.Parameter</code>以更好地表示输入数据的优化方法</p><img src="/2024/08/15/PyTorch-26H-2/PyTorch-26H-2-5.png" class="" title="PyTorch-26H-2-5"><p>子类 <code>nn.Module</code>（包含神经网络的所有构建块）<br>初始化用于各种计算的<code>模型参数</code>（这些参数可能是来自torch.nn 的不同层、单个参数、硬编码值或函数）<br><code>require_grad=True</code> 表示 PyTorch 将跟踪此特定参数的梯度，以便与 <code>torch.autograd</code> 和梯度下降一起使用（对于许多 <code>torch.nn</code> 模块，<code>requires_grad=True</code> 是默认设置）<br><code>nn.Module</code> 的任何子类都需要重写 <code>forward()</code>（这定义了模型的前向计算）</p><p>通过子类化创建 PyTorch 模型的基本构建块<code>nn.Module</code>。对于子类化的对象<code>nn.Module</code>，<code>forward()</code>必须定义方法。</p><p>在 <a href="https://pytorch.org/tutorials/beginner/ptcheat.html">PyTorch Cheat Sheet</a> 中查看更多这些基本模块及其用例。</p><h3 id="Checking-the-contents-of-a-PyTorch-model-检查-PyTorch-模型的内容"><a href="#Checking-the-contents-of-a-PyTorch-model-检查-PyTorch-模型的内容" class="headerlink" title="Checking the contents of a PyTorch model 检查 PyTorch 模型的内容"></a>Checking the contents of a PyTorch model 检查 PyTorch 模型的内容</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Set manual seed since nn.Parameter are randomly initialized由于 nn.Parameter 是随机初始化的，因此请设置手动种子</span></span><br><span class="line">torch.manual_seed(<span class="number">42</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Create an instance of the model (this is a subclass of nn.Module that contains nn.Parameter(s))创建模型的实例（这是包含 nn.Parameter(s) 的 nn.Module 的子类）</span></span><br><span class="line">model_0 = LinearRegressionModel()</span><br><span class="line"></span><br><span class="line"><span class="comment"># Check the nn.Parameter(s) within the nn.Module subclass we created检查我们创建的 nn.Module 子类中的 nn.Parameter(s)</span></span><br><span class="line"><span class="built_in">list</span>(model_0.parameters())</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[Parameter containing:</span><br><span class="line"> tensor([0.3367], requires_grad=True),</span><br><span class="line"> Parameter containing:</span><br><span class="line"> tensor([0.1288], requires_grad=True)]</span><br></pre></td></tr></table></figure><p>我们还可以使用 获取模型的状态（模型包含的内容）<code>.state_dict()</code></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># List named parameters </span></span><br><span class="line">model_0.state_dict()</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">OrderedDict([(&#x27;weights&#x27;, tensor([0.3367])), (&#x27;bias&#x27;, tensor([0.1288]))])</span><br></pre></td></tr></table></figure><p>注意 <code>model_0.state_dict()</code> 中的权重和偏差的值是如何作为随机浮点张量出现的吗？<br>这是因为我们上面使用 <code>torch.randn()</code> 初始化了它们。<br>本质上，我们希望从随机参数开始，并让模型将它们更新为最适合我们数据的参数（我们在创建直线数据时设置的硬编码 <code>weight</code> 和 <code>bias</code>）。</p><p>尝试改变上面两个单元格的 <code>torch.manual_seed()</code> 值，看看权重和偏差值会发生什么变化。<br>因为我们的模型从随机值开始，所以现在它的预测能力较差。</p><h3 id="Making-predictions-using-torch-inference-mode"><a href="#Making-predictions-using-torch-inference-mode" class="headerlink" title="Making predictions using torch.inference_mode()"></a>Making predictions using <code>torch.inference_mode()</code></h3><p>将测试数据传递给它，<code>X_test</code> 看看它的预测有多接近 <code>y_test</code>。</p><p>将数据传递给模型时，它将通过模型的 <code>forward()</code> 方法并使用我们定义的计算产生结果。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Make predictions with model</span></span><br><span class="line"><span class="keyword">with</span> torch.inference_mode(): </span><br><span class="line">    y_preds = model_0(X_test)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Note: in older PyTorch code you might also see torch.no_grad()</span></span><br><span class="line"><span class="comment"># with torch.no_grad():</span></span><br><span class="line"><span class="comment">#   y_preds = model_0(X_test)</span></span><br></pre></td></tr></table></figure><p>使用 <code>torch.inference_mode()</code> 作为<a href="https://realpython.com/python-with-statement/">上下文管理器</a>（这就是 <code>torch.inference_mode()</code>: 的作用）来进行预测。</p><p>顾名思义，<code>torch.inference_mode()</code> 用于使用模型进行推理（做出预测）。</p><p><code>torch.inference_mode()</code> 关闭了许多功能（例如梯度跟踪，这对于训练是必需的，但对于推理不是必需的），以使前向传递（数据通过 forward() 方法）更快。</p><p>在较旧的 PyTorch 代码中，您可能还会看到 <code>torch.no_grad()</code> 用于推理。虽然 <code>torch.inference_mode()</code> 和 <code>torch.no_grad()</code> 的作用类似，但 <code>torch.inference_mode()</code> 较新，可能更快且更受欢迎。有关更多信息，请参阅 <a href="https://twitter.com/PyTorch/status/1437838231505096708?s=20">Tweet from PyTorch</a> 。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Check the predictions</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Number of testing samples: <span class="subst">&#123;<span class="built_in">len</span>(X_test)&#125;</span>&quot;</span>) </span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Number of predictions made: <span class="subst">&#123;<span class="built_in">len</span>(y_preds)&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Predicted values:\n<span class="subst">&#123;y_preds&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">Number of testing samples: 10</span><br><span class="line">Number of predictions made: 10</span><br><span class="line">Predicted values:</span><br><span class="line">tensor([[0.3982],</span><br><span class="line">        [0.4049],</span><br><span class="line">        [0.4116],</span><br><span class="line">        [0.4184],</span><br><span class="line">        [0.4251],</span><br><span class="line">        [0.4318],</span><br><span class="line">        [0.4386],</span><br><span class="line">        [0.4453],</span><br><span class="line">        [0.4520],</span><br><span class="line">        [0.4588]])</span><br></pre></td></tr></table></figure><p>请注意每个测试样本有一个预测值。</p><p>这是因为我们使用的数据类型。对于我们的直线，一个X值对应一个y值。</p><p>然而，机器学习模型非常灵活。可以将 100 个X值映射到一个、两个、三个或 10 个y值。这完全取决于正在处理的内容。</p><p>预测仍然是页面上的数字，使用<code>plot_predictions()</code>上面创建的函数将它们可视化。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">plot_predictions(predictions=y_preds)</span><br></pre></td></tr></table></figure><img src="/2024/08/15/PyTorch-26H-2/PyTorch-26H-2-6.png" class="" title="PyTorch-26H-2-6"><p>对比预测结果：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">y_test - y_preds</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">tensor([[0.4618],</span><br><span class="line">        [0.4691],</span><br><span class="line">        [0.4764],</span><br><span class="line">        [0.4836],</span><br><span class="line">        [0.4909],</span><br><span class="line">        [0.4982],</span><br><span class="line">        [0.5054],</span><br><span class="line">        [0.5127],</span><br><span class="line">        [0.5200],</span><br><span class="line">        [0.5272]])</span><br></pre></td></tr></table></figure><p>使用随机参数做出预测，没有进行观察的结果，差距很大。</p><h2 id="3-Train-model-训练模型"><a href="#3-Train-model-训练模型" class="headerlink" title="3. Train model 训练模型"></a>3. Train model 训练模型</h2><p>模型正在使用随机参数进行计算进行预测，这基本上是猜测（随机）。</p><p>更新其内部参数（将参数称为模式），使用<code>weights</code>和<code>bias</code>随机设置的值<code>nn.Parameter()</code>，<code>torch.randn()</code>以便更好地表示数据。</p><p>可以对此进行硬编码（默认值weight=0.7和bias=0.3）</p><h3 id="Creating-a-loss-function-and-optimizer-in-PyTorch-在-PyTorch-中创建损失函数和优化器"><a href="#Creating-a-loss-function-and-optimizer-in-PyTorch-在-PyTorch-中创建损失函数和优化器" class="headerlink" title="Creating a loss function and optimizer in PyTorch 在 PyTorch 中创建损失函数和优化器"></a>Creating a loss function and optimizer in PyTorch 在 PyTorch 中创建损失函数和优化器</h3><div class="table-container"><table><thead><tr><th style="text-align:center">功能</th><th style="text-align:center">作用</th><th style="text-align:center">位置</th><th style="text-align:center">价值</th></tr></thead><tbody><tr><td style="text-align:center">损失函数</td><td style="text-align:center">衡量模型预测与真实标签相比的误差程度。误差越低越好。</td><td style="text-align:center">内置损失函数<code>torch.nn</code></td><td style="text-align:center">回归问题平均绝对误差(MAE)<code>torch.nn.L1Loss()</code>,二元分类问题的二元交叉熵<code>torch.nn.BCELoss()</code></td></tr><tr><td style="text-align:center">优化器</td><td style="text-align:center">告诉模型如何更新其内部参数以最好的降低损失。</td><td style="text-align:center">优化函数实现 <code>torch.optim</code></td><td style="text-align:center">随机梯度下降 <code>torch.optim.SGD()</code> , Adam优化器<code>torch.optim.Adam()</code></td></tr></tbody></table></div><p>据处理的问题类型，将决定使用的损失函数和优化器。</p><p>经验：SGD（随机梯度下降）或 Adam 优化器，效果很好。用于回归问题（预测数字）的 MAE（平均绝对误差）损失函数或用于分类问题（预测一件事或另一件事）的二元交叉熵损失函数。</p><p>对于我们的问题，因为我们正在预测一个数字，所以我们使用 PyTorch 中的 MAE（位于 <code>torch.nn.L1Loss()</code> 下）作为我们的损失函数。</p><p>平均绝对误差 (MAE，在 PyTorch 中为：<code>torch.nn.L1Loss</code>) 测量两点（预测和标签）之间的绝对差异，然后对所有示例取平均值。</p><img src="/2024/08/15/PyTorch-26H-2/PyTorch-26H-2-7.png" class="" title="PyTorch-26H-2-7"><p>我们将使用 SGD，<code>torch.optim.SGD(params, lr)</code>，其中：</p><p><code>params</code> 是您想要优化的目标模型参数（例如我们之前随机设置的<code>weights</code>和<code>bias</code>）。<br><code>lr</code> 是您希望优化器更新参数的学习率，越高意味着优化器将尝试更大的更新（这些更新有时可能太大，优化器将无法工作），越低意味着优化器将尝试较小的更新（这些更新有时可能太小，优化器将花费太长时间才能找到理想值）。学习率被视为超参数（因为它是由机器学习工程师设置的）。学习率的常见起始值为 0.01、0.001、0.0001，但是，这些值也可以随着时间的推移进行调整（这称为<a href="https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate">学习率调度</a>）。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Create the loss function 创建损失函数</span></span><br><span class="line">loss_fn = nn.L1Loss() <span class="comment"># MAE loss is same as L1Loss MAE 损失与 L1Loss 相同</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Create the optimizer 创建优化器</span></span><br><span class="line">optimizer = torch.optim.SGD(params=model_0.parameters(), <span class="comment"># parameters of target model to optimize 待优化目标模型参数</span></span><br><span class="line">                            lr=<span class="number">0.01</span>) <span class="comment"># learning rate (how much the optimizer should change parameters at each step, higher=more (less stable), lower=less (might take a long time))学习率（优化器在每一步应该改变多少参数，越高=越多（越不稳定），越低=越少（可能需要很长时间））</span></span><br></pre></td></tr></table></figure><h3 id="Creating-an-optimization-loop-in-PyTorch-在-PyTorch-中创建优化循环"><a href="#Creating-an-optimization-loop-in-PyTorch-在-PyTorch-中创建优化循环" class="headerlink" title="Creating an optimization loop in PyTorch 在 PyTorch 中创建优化循环"></a>Creating an optimization loop in PyTorch 在 PyTorch 中创建优化循环</h3><p>训练循环涉及模型 遍历训练数据并学习<code>features</code>和<code>labels</code>之间的关系。</p><p>测试循环涉及检查测试数据并评估模型在训练数据上学习到的模式的优劣（模型在训练期间永远不会看到测试数据）。</p><p>每个都称为一个“循环”，因为我们希望我们的模型查看（循环）每个数据集中的每个样本。</p><h3 id="PyTorch-training-loop-PyTorch-训练循环"><a href="#PyTorch-training-loop-PyTorch-训练循环" class="headerlink" title="PyTorch training loop PyTorch 训练循环"></a>PyTorch training loop PyTorch 训练循环</h3><p>训练步骤：</p><div class="table-container"><table><thead><tr><th style="text-align:center">序号</th><th style="text-align:center">步骤</th><th style="text-align:center">作用</th><th style="text-align:center">示例</th></tr></thead><tbody><tr><td style="text-align:center">1</td><td style="text-align:center">Forward pass</td><td style="text-align:center">该模型会遍历所有训练数据一次，并执行其 <code>forward()</code> 函数计算。</td><td style="text-align:center"><code>model(x_train)</code></td></tr><tr><td style="text-align:center">2</td><td style="text-align:center">Calculate the loss</td><td style="text-align:center">将模型的输出（预测）与基本事实进行比较，并进行评估以查看其错误程度。</td><td style="text-align:center"><code>loss = loss_fn(y_pred, y_train)</code></td></tr><tr><td style="text-align:center">3</td><td style="text-align:center">Zero gradients</td><td style="text-align:center">优化器的梯度设置为零（默认情况下是累积的），因此可以针对特定的训练步骤重新计算它们。</td><td style="text-align:center"><code>optimizer.zero_grad()</code></td></tr><tr><td style="text-align:center">4</td><td style="text-align:center">Perform backpropagation on the loss（Loss backward）</td><td style="text-align:center">计算每个要更新的模型参数的损失梯度（每个参数的 <code>require_grad=True</code>）。这称为反向传播，因此是“向后”的。</td><td style="text-align:center"><code>loss.backward()</code></td></tr><tr><td style="text-align:center">5</td><td style="text-align:center">Update the optimizer (gradient descent)</td><td style="text-align:center">使用 <code>require_grad=True</code> 来根据损失梯度更新参数，以改进它们。</td><td style="text-align:center"><code>optimizer.step()</code></td></tr></tbody></table></div><img src="/2024/08/15/PyTorch-26H-2/PyTorch-26H-2-8.png" class="" title="PyTorch-26H-2-8"><p>Pass the data through the model for a number of epochs (e.g. 100 for 100 passes of the data)<br>将数据通过模型传递若干个时期（例如，100 次数据传递为 100 个时期）</p><p>Pass the data through the model, this will perform the <code>forward()</code> method located within the model object<br>通过模型传递数据，这将执行位于模型对象内的 <code>forward()</code> 方法</p><p>Calculate the loss value (how wrong the model’s predictions are)<br>计算损失值（模型预测的错误程度）</p><p>Zero the optimizer gradients (they accumulate every epoch, zero them to start fresh each forward pass)<br>将优化器梯度归零（它们在每个时期都会累积，在每次前向传递时将它们归零以重新开始）</p><p>Perform backpropagation on the loss function (compute the gradient of every parameter with <code>requires_grad=True</code>)<br>对损失函数进行反向传播（使用 <code>require_grad=True</code> 计算每个参数的梯度）</p><p>Step the optimizer to update the model’s parameters with respect to the gradients calculated by <code>loss.backward()</code><br>让优化器根据 <code>loss.backward()</code> 计算出的梯度来更新模型的参数</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">epochs = <span class="number">1</span></span><br><span class="line"><span class="comment"># Pass the data through the model for a number of epochs (e.g. 100)</span></span><br><span class="line"><span class="comment"># 将数据通过模型传递若干个时期（例如 100）</span></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(epochs) :</span><br><span class="line">    <span class="comment"># Put model in training mode (this is the default state of a model)</span></span><br><span class="line">    <span class="comment"># 将模型置于训练模式（这是模型的默认状态）</span></span><br><span class="line">    model.train()</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 1. Forward pass on train data using the forward() method inside</span></span><br><span class="line">    <span class="comment"># 1. 使用内部的 forward() 方法向前传递训练数据</span></span><br><span class="line">    y_pred = model(X_train)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 2. Calculate the Loss (how different are the model&#x27;s predictions to the true values</span></span><br><span class="line">    <span class="comment"># 2. 计算损失（模型的预测与真实值有多大差异</span></span><br><span class="line">    Loss = Loss_fn(y_pred, y_true)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 3. Zero the gradients of the optimizer (they accumulate by default)</span></span><br><span class="line">    <span class="comment"># 3. 将优化器的梯度归零（默认情况下它们会累积）</span></span><br><span class="line">    optimizer.zero_grad()</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 4. Perform backpropagation on the loss</span></span><br><span class="line">    <span class="comment"># 4. 对损失进行反向传播</span></span><br><span class="line">    loss.backward()</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 5. Progress/step the optimizer ( gradient descent)</span></span><br><span class="line">    <span class="comment"># 5. 推进/步进优化器（梯度下降）</span></span><br><span class="line">    optimizer.step()</span><br></pre></td></tr></table></figure><blockquote><p>以上只是步骤排序或描述的一个例子。随着经验的积累，你会发现制作 PyTorch 训练循环可以非常灵活。</p></blockquote><p>训练循环歌曲:<br><a href="https://www.youtube.com/watch?v=Nutpusq_AFw">The Unofficial PyTorch Optimization Loop Song</a></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">It&#x27;s train time!</span><br><span class="line">do the forward pass,</span><br><span class="line">calculate the loss,</span><br><span class="line">optimizer zero grad,</span><br><span class="line">losssss backwards!</span><br><span class="line"></span><br><span class="line">Optimizer step step step</span><br><span class="line"></span><br><span class="line">Let&#x27;s test now!</span><br><span class="line">with torch no grad:</span><br><span class="line">do the forward pass,</span><br><span class="line">calculate the loss,</span><br><span class="line">watch it go down down down!</span><br></pre></td></tr></table></figure><p>至于事物的顺序，以上是一个很好的默认顺序，但你可能会看到略有不同的顺序。一些经验法则：</p><ul><li>在对损失执行反向传播 <code>(loss.backward())</code> 之前，先计算损失 <code>(loss = ...)</code>。</li><li>在针对每个模型参数 <code>(loss.backward())</code> 计算损失的梯度之前，先将梯度归零 <code>(optimizer.zero_grad())</code>。</li><li>在对损失执行反向传播 <code>(loss.backward())</code> 之后，逐步执行优化器 <code>(optimizer.step())</code>。</li></ul><p>有关帮助理解反向传播和梯度下降幕后情况的资源，请参阅课外部分。</p><h3 id="PyTorch-testing-loop-PyTorch-测试循环"><a href="#PyTorch-testing-loop-PyTorch-测试循环" class="headerlink" title="PyTorch testing loop PyTorch 测试循环"></a>PyTorch testing loop PyTorch 测试循环</h3><div class="table-container"><table><thead><tr><th style="text-align:center">序号</th><th style="text-align:center">步骤</th><th style="text-align:center">作用</th><th style="text-align:center">例子</th></tr></thead><tbody><tr><td style="text-align:center">1</td><td style="text-align:center">Forward pass</td><td style="text-align:center">该模型会遍历所有测试数据一次，并执行其 <code>forward()</code> 函数计算。</td><td style="text-align:center"><code>model(x_test)</code></td></tr><tr><td style="text-align:center">2</td><td style="text-align:center">Calculate the loss</td><td style="text-align:center">将模型的输出（预测）与基本事实进行比较，并进行评估以查看其错误程度。</td><td style="text-align:center"><code>loss = loss_fn(y_pred, y_test)</code></td></tr><tr><td style="text-align:center">3</td><td style="text-align:center">Calulate evaluation metrics (optional)</td><td style="text-align:center">除了损失值之外，您可能还想计算其他评估指标，例如测试集的准确性。</td><td style="text-align:center">Custom functions</td></tr></tbody></table></div><p>请注意，测试循环不包含执行反向传播（<code>loss.backward()</code>）或步进优化器（<code>optimizer.step()</code>），这是因为在测试期间模型中的任何参数都不会改变，它们已经被计算出来了。对于测试，我们只对通过模型的前向传递的输出感兴趣。</p><img src="/2024/08/15/PyTorch-26H-2/PyTorch-26H-2-9.png" class="" title="PyTorch-26H-2-9"><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Setup empty lists to keep track of model progress</span></span><br><span class="line"><span class="comment"># 设置空列表来跟踪模型进度</span></span><br><span class="line">epoch_count = []</span><br><span class="line">train_loss_values = []</span><br><span class="line">test_loss_values = []</span><br><span class="line"></span><br><span class="line"><span class="comment"># Pass the data through the model for a number of epochs (e.g. 100) pochs):</span></span><br><span class="line"><span class="comment"># 将数据通过模型传递若干个时期（例如 100 个时期）：</span></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span> (epochs):</span><br><span class="line">    <span class="comment">### Training Loop code here ###</span></span><br><span class="line">    <span class="comment">### Testing starts ###</span></span><br><span class="line">    <span class="comment"># Put the model in evaluation mode </span></span><br><span class="line">    model.<span class="built_in">eval</span>()</span><br><span class="line">    <span class="comment"># Turn on inference mode context manager :</span></span><br><span class="line">    <span class="keyword">with</span> torch.inference_mode():</span><br><span class="line">        <span class="comment"># 1. Forward pass on test data</span></span><br><span class="line">        test_pred = model(X_test)</span><br><span class="line">        <span class="comment"># 2. Caculate loss on test data</span></span><br><span class="line">        test_loss = Loss_fn(test_pred, y_test) </span><br><span class="line"><span class="comment"># Print out what&#x27;s happening every 10 epochs</span></span><br><span class="line"><span class="keyword">if</span> epoch % <span class="number">10</span> == <span class="number">0</span>:</span><br><span class="line">    epoch_count.append(epoch)</span><br><span class="line">    train_Loss_values.append(loss)</span><br><span class="line">    test_loss_values.append(test_loss)</span><br><span class="line">    <span class="built_in">print</span>( <span class="string">f&quot; Epoch: <span class="subst">&#123;epoch&#125;</span>| MAE Train Loss: <span class="subst">&#123;loss&#125;</span>I MAE Test Loss: <span class="subst">&#123;test_loss&#125;</span></span></span><br></pre></td></tr></table></figure><p>Create empty lists for storing useful values (helpful for tracking model progress)<br>创建空列表来存储有用的值（有助于跟踪模型进度）</p><p>Tell the model we want to evaluate rather than train (this turns off functionality used for training but not evaluation)<br>告诉模型我们想要评估而不是训练（这会关闭用于训练但不用于评估的功能）</p><p>Turn on <code>torch.inference_mode()</code> context manager to disable functionality such as gradient tracking for inference (gradient tracking not needed for inference)<br>打开 <code>torch.inference_mode()</code> 上下文管理器以禁用推理的梯度跟踪等功能（推理不需要梯度跟踪）</p><p>Pass the test data through the model (this will call the model’s implemented <code>forward()</code> method)<br>通过模型传递测试数据（这将调用模型实现的 <code>forward()</code> 方法）</p><p>Calculate the test loss value (how wrong the model’s predictions are on the test dataset, lower is better)<br>计算测试损失值（模型对测试数据集的预测错误程度，越低越好）</p><p>Display information outputs for how the model is doing during training/testing every ~10 epochs (note: what gets printed out here can be adjusted for speciLc problems)<br>每~10 个时期显示模型在训练/测试过程中的运行情况的信息输出（注意：此处打印的内容可针对具体问题进行调整）</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line">torch.manual_seed(<span class="number">42</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Set the number of epochs (how many times the model will pass over the training data)</span></span><br><span class="line">epochs = <span class="number">100</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Create empty loss lists to track values</span></span><br><span class="line">train_loss_values = []</span><br><span class="line">test_loss_values = []</span><br><span class="line">epoch_count = []</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(epochs):</span><br><span class="line">    <span class="comment">### Training</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># Put model in training mode (this is the default state of a model)</span></span><br><span class="line">    model_0.train()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 1. Forward pass on train data using the forward() method inside </span></span><br><span class="line">    y_pred = model_0(X_train)</span><br><span class="line">    <span class="comment"># print(y_pred)</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 2. Calculate the loss (how different are our models predictions to the ground truth)</span></span><br><span class="line">    loss = loss_fn(y_pred, y_train)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 3. Zero grad of the optimizer</span></span><br><span class="line">    optimizer.zero_grad()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 4. Loss backwards</span></span><br><span class="line">    loss.backward()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 5. Progress the optimizer</span></span><br><span class="line">    optimizer.step()</span><br><span class="line"></span><br><span class="line">    <span class="comment">### Testing</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># Put the model in evaluation mode</span></span><br><span class="line">    model_0.<span class="built_in">eval</span>()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">with</span> torch.inference_mode():</span><br><span class="line">      <span class="comment"># 1. Forward pass on test data</span></span><br><span class="line">      test_pred = model_0(X_test)</span><br><span class="line"></span><br><span class="line">      <span class="comment"># 2. Caculate loss on test data</span></span><br><span class="line">      test_loss = loss_fn(test_pred, y_test.<span class="built_in">type</span>(torch.<span class="built_in">float</span>)) <span class="comment"># predictions come in torch.float datatype, so comparisons need to be done with tensors of the same type</span></span><br><span class="line"></span><br><span class="line">      <span class="comment"># Print out what&#x27;s happening</span></span><br><span class="line">      <span class="keyword">if</span> epoch % <span class="number">10</span> == <span class="number">0</span>:</span><br><span class="line">            epoch_count.append(epoch)</span><br><span class="line">            train_loss_values.append(loss.detach().numpy())</span><br><span class="line">            test_loss_values.append(test_loss.detach().numpy())</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&quot;Epoch: <span class="subst">&#123;epoch&#125;</span> | MAE Train Loss: <span class="subst">&#123;loss&#125;</span> | MAE Test Loss: <span class="subst">&#123;test_loss&#125;</span> &quot;</span>)</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">Epoch: 0 | MAE Train Loss: 0.31288138031959534 | MAE Test Loss: 0.48106518387794495 </span><br><span class="line">Epoch: 10 | MAE Train Loss: 0.1976713240146637 | MAE Test Loss: 0.3463551998138428 </span><br><span class="line">Epoch: 20 | MAE Train Loss: 0.08908725529909134 | MAE Test Loss: 0.21729660034179688 </span><br><span class="line">Epoch: 30 | MAE Train Loss: 0.053148526698350906 | MAE Test Loss: 0.14464017748832703 </span><br><span class="line">Epoch: 40 | MAE Train Loss: 0.04543796554207802 | MAE Test Loss: 0.11360953003168106 </span><br><span class="line">Epoch: 50 | MAE Train Loss: 0.04167863354086876 | MAE Test Loss: 0.09919948130846024 </span><br><span class="line">Epoch: 60 | MAE Train Loss: 0.03818932920694351 | MAE Test Loss: 0.08886633068323135 </span><br><span class="line">Epoch: 70 | MAE Train Loss: 0.03476089984178543 | MAE Test Loss: 0.0805937647819519 </span><br><span class="line">Epoch: 80 | MAE Train Loss: 0.03132382780313492 | MAE Test Loss: 0.07232122868299484 </span><br><span class="line">Epoch: 90 | MAE Train Loss: 0.02788739837706089 | MAE Test Loss: 0.06473556160926819</span><br></pre></td></tr></table></figure><p>查看损失函数：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Plot the loss curves</span></span><br><span class="line">plt.plot(epoch_count, train_loss_values, label = <span class="string">&quot;Train loss&quot;</span>)</span><br><span class="line">plt.plot(epoch_count, test_loss_values, label = <span class="string">&quot;Test loss&quot;</span>)</span><br><span class="line">plt.title(<span class="string">&quot;Training and test loss curves&quot;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&quot;Loss&quot;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&quot;Epochs&quot;</span>)</span><br><span class="line">plt.legend();</span><br></pre></td></tr></table></figure><img src="/2024/08/15/PyTorch-26H-2/PyTorch-26H-2-10.png" class="" title="PyTorch-26H-2-10"><p>损失曲线显示损失随时间下降。请记住，损失是衡量模型错误程度的指标，因此损失越低越好。</p><p>由于损失函数和优化器，模型的内部参数（<code>weights</code> 和 <code>bias</code>）得到了更新，以更好地反映数据中的底层模式。</p><p>让我们检查模型的 <code>.state_dict()</code> 来查看模型与我们为权重和偏差设置的原始值有多接近。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Find our model&#x27;s learned parameters</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;The model learned the following values for weights and bias:&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(model_0.state_dict())</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;\nAnd the original values for weights and bias are:&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;weights: <span class="subst">&#123;weight&#125;</span>, bias: <span class="subst">&#123;bias&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">The model learned the following values for weights and bias:</span><br><span class="line">OrderedDict([(&#x27;weights&#x27;, tensor([0.5784])), (&#x27;bias&#x27;, tensor([0.3513]))])</span><br><span class="line"></span><br><span class="line">And the original values for weights and bias are:</span><br><span class="line">weights: 0.7, bias: 0.3</span><br></pre></td></tr></table></figure><p>我们的模型非常接近计算<code>weight</code>和的精确原始值<code>bias</code>（如果我们训练更长时间，它可能会更加接近）。</p><p>当epochs=200：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">Epoch: 0 | MAE Train Loss: 0.024458957836031914 | MAE Test Loss: 0.05646304413676262 </span><br><span class="line">Epoch: 10 | MAE Train Loss: 0.021020207554101944 | MAE Test Loss: 0.04819049686193466 </span><br><span class="line">Epoch: 20 | MAE Train Loss: 0.01758546568453312 | MAE Test Loss: 0.04060482233762741 </span><br><span class="line">Epoch: 30 | MAE Train Loss: 0.014155393466353416 | MAE Test Loss: 0.03233227878808975 </span><br><span class="line">Epoch: 40 | MAE Train Loss: 0.010716589167714119 | MAE Test Loss: 0.024059748277068138 </span><br><span class="line">Epoch: 50 | MAE Train Loss: 0.0072835334576666355 | MAE Test Loss: 0.016474086791276932 </span><br><span class="line">Epoch: 60 | MAE Train Loss: 0.0038517764769494534 | MAE Test Loss: 0.008201557211577892 </span><br><span class="line">Epoch: 70 | MAE Train Loss: 0.008932482451200485 | MAE Test Loss: 0.005023092031478882 </span><br><span class="line">Epoch: 80 | MAE Train Loss: 0.008932482451200485 | MAE Test Loss: 0.005023092031478882 </span><br><span class="line">Epoch: 90 | MAE Train Loss: 0.008932482451200485 | MAE Test Loss: 0.005023092031478882 </span><br><span class="line">Epoch: 100 | MAE Train Loss: 0.008932482451200485 | MAE Test Loss: 0.005023092031478882 </span><br><span class="line">Epoch: 110 | MAE Train Loss: 0.008932482451200485 | MAE Test Loss: 0.005023092031478882 </span><br><span class="line">Epoch: 120 | MAE Train Loss: 0.008932482451200485 | MAE Test Loss: 0.005023092031478882 </span><br><span class="line">Epoch: 130 | MAE Train Loss: 0.008932482451200485 | MAE Test Loss: 0.005023092031478882 </span><br><span class="line">Epoch: 140 | MAE Train Loss: 0.008932482451200485 | MAE Test Loss: 0.005023092031478882 </span><br><span class="line">Epoch: 150 | MAE Train Loss: 0.008932482451200485 | MAE Test Loss: 0.005023092031478882 </span><br><span class="line">Epoch: 160 | MAE Train Loss: 0.008932482451200485 | MAE Test Loss: 0.005023092031478882 </span><br><span class="line">Epoch: 170 | MAE Train Loss: 0.008932482451200485 | MAE Test Loss: 0.005023092031478882 </span><br><span class="line">Epoch: 180 | MAE Train Loss: 0.008932482451200485 | MAE Test Loss: 0.005023092031478882 </span><br><span class="line">Epoch: 190 | MAE Train Loss: 0.008932482451200485 | MAE Test Loss: 0.005023092031478882</span><br></pre></td></tr></table></figure><img src="/2024/08/15/PyTorch-26H-2/PyTorch-26H-2-11.png" class="" title="PyTorch-26H-2-11"><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">The model learned the following values for weights and bias:</span><br><span class="line">OrderedDict([(&#x27;weights&#x27;, tensor([0.6990])), (&#x27;bias&#x27;, tensor([0.3093]))])</span><br><span class="line"></span><br><span class="line">And the original values for weights and bias are:</span><br><span class="line">weights: 0.7, bias: 0.3</span><br></pre></td></tr></table></figure><h2 id="4-Making-predictions-with-a-trained-PyTorch-model-inference-使用训练好的-PyTorch-模型进行预测（推理）"><a href="#4-Making-predictions-with-a-trained-PyTorch-model-inference-使用训练好的-PyTorch-模型进行预测（推理）" class="headerlink" title="4. Making predictions with a trained PyTorch model (inference) 使用训练好的 PyTorch 模型进行预测（推理）"></a>4. Making predictions with a trained PyTorch model (inference) 使用训练好的 PyTorch 模型进行预测（推理）</h2><p>使用 <code>PyTorch</code> 模型进行预测（也称为执行推理）时，需要记住三件事：</p><ul><li>将模型设置为评估模式 (<code>model.eval()</code>)。</li><li>使用推理模式上下文管理器进行预测（使用 <code>torch.inference_mode(): ...</code>）。</li><li>所有预测都应使用同一设备上的对象进行（例如，仅在 GPU 上的数据和模型或仅在 CPU 上的数据和模型）。</li></ul><p>前两项确保 PyTorch 在训练期间在后台使用但对推理不必要的所有有用计算和设置均已关闭（这可加快计算速度）。第三项确保您不会遇到跨设备错误。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 1. Set the model in evaluation mode</span></span><br><span class="line">model_0.<span class="built_in">eval</span>()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 2. Setup the inference mode context manager</span></span><br><span class="line"><span class="keyword">with</span> torch.inference_mode():</span><br><span class="line">  <span class="comment"># 3. Make sure the calculations are done with the model and data on the same device</span></span><br><span class="line">  <span class="comment"># in our case, we haven&#x27;t setup device-agnostic code yet so our data and model are</span></span><br><span class="line">  <span class="comment"># on the CPU by default.</span></span><br><span class="line">  <span class="comment"># model_0.to(device)</span></span><br><span class="line">  <span class="comment"># X_test = X_test.to(device)</span></span><br><span class="line">  y_preds = model_0(X_test)</span><br><span class="line">y_preds</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">tensor([[0.8141],</span><br><span class="line">        [0.8256],</span><br><span class="line">        [0.8372],</span><br><span class="line">        [0.8488],</span><br><span class="line">        [0.8603],</span><br><span class="line">        [0.8719],</span><br><span class="line">        [0.8835],</span><br><span class="line">        [0.8950],</span><br><span class="line">        [0.9066],</span><br><span class="line">        [0.9182]])</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">plot_predictions(predictions=y_preds)</span><br></pre></td></tr></table></figure><img src="/2024/08/15/PyTorch-26H-2/PyTorch-26H-2-12.png" class="" title="PyTorch-26H-2-12"><h2 id="5-Saving-and-loading-a-PyTorch-model-保存和加载-PyTorch-模型"><a href="#5-Saving-and-loading-a-PyTorch-model-保存和加载-PyTorch-模型" class="headerlink" title="5. Saving and loading a PyTorch model 保存和加载 PyTorch 模型"></a>5. Saving and loading a PyTorch model 保存和加载 PyTorch 模型</h2><p>如果您已经训练了 PyTorch 模型，那么您可能会想要保存它并将其导出到某个地方。</p><p>例如，您可能在 Google Colab 或使用 GPU 的本地机器上训练它，但现在您想将其导出到其他人可以使用的某种应用程序中。</p><p>或者您可能想保存模型的进度，稍后再回来加载它。</p><p>对于在 PyTorch 中保存和加载模型，您应该了解三种主要方法（以下所有内容均取自 <a href="https://pytorch.org/tutorials/beginner/saving_loading_models.html#saving-loading-model-for-inference">PyTorch 保存和加载模型指南</a>）：</p><div class="table-container"><table><thead><tr><th style="text-align:center">方法</th><th style="text-align:center">作用</th></tr></thead><tbody><tr><td style="text-align:center"><code>torch.save</code></td><td style="text-align:center">使用 Python 的 <code>pickle</code> 实用程序将序列化对象保存到磁盘。可以使用 <code>torch.save</code> 保存模型、张量和各种其他 <code>Python</code> 对象（如字典）。</td></tr><tr><td style="text-align:center"><code>torch.load</code></td><td style="text-align:center">使用 pickle 的 <code>unpickling</code> 功能对 <code>pickle</code> 的 Python 对象文件（如模型、张量或字典）进行反序列化并将其加载到内存中。您还可以设置将对象加载到哪个设备（CPU、GPU 等）。</td></tr><tr><td style="text-align:center"><code>torch.nn.Module.load_state_dict</code></td><td style="text-align:center">使用已保存的 <code>state_dict()</code> 对象加载模型的参数字典 (<code>model.state_dict()</code>)。</td></tr></tbody></table></div><p>正如 <a href="https://docs.python.org/3/library/pickle.html">Python 的 pickle 文档</a>所述，pickle模块实现了用于序列化和反序列化 Python 对象结构的二进制协议，pickle 模块并不安全。这意味着您只应解开（加载）您信任的数据。这也适用于加载 PyTorch 模型。只使用您信任的来源保存的 PyTorch 模型。</p><h3 id="Saving-a-PyTorch-model’s-state-dict-保存-PyTorch-模型的state-dict"><a href="#Saving-a-PyTorch-model’s-state-dict-保存-PyTorch-模型的state-dict" class="headerlink" title="Saving a PyTorch model’s state_dict() 保存 PyTorch 模型的state_dict()"></a>Saving a PyTorch model’s <code>state_dict()</code> 保存 PyTorch 模型的<code>state_dict()</code></h3><p>什么是<code>state_dict()</code>？</p><p>在 PyTorch 中，模型的可学习参数（即权重和偏差） <code>torch.nn.Module</code>包含在模型的参数中（通过 访问<code>model.parameters()</code>）。 <code>Astate_dict</code>只是一个 Python 字典对象，它将每个层映射到其参数张量。<br><code>state_dict</code> 对象是 Python 字典，因此可以轻松保存、更新、更改和恢复它们，从而为 PyTorch 模型和优化器增加大量模块化。请注意，只有具有可学习参数（卷积层、线性层等）和已注册缓冲区（<code>batchnorm</code> 的 <code>running_mean</code>）的层才会在模型的 <code>state_dict</code> 中拥有条目。优化器对象 (<code>torch.optim</code>) 也有一个 <code>state_dict</code>，其中包含有关优化器状态以及所用超参数的信息。</p><p>保存和加载模型进行推理（进行预测）的<a href="https://pytorch.org/tutorials/beginner/saving_loading_models.html#saving-loading-model-for-inference">推荐方法</a>是保存和加载模型的 <code>state_dict()</code>。</p><p>让我们看看如何通过几个步骤做到这一点：</p><ul><li>我们将使用 Python 的 <code>pathlib</code> 模块创建一个目录，用于将模型保存到调用的模型中。</li><li>我们将创建一个文件路径来保存模型。</li><li>我们将调用 <code>torch.save(obj, f)</code>，其中 <code>obj</code> 是目标模型的 <code>state_dict()</code>，<code>f</code> 是保存模型的文件名。</li></ul><p>注意：PyTorch 保存的模型或对象通常以 <code>.pt</code> 或 <code>.pth</code> 结尾，例如 <code>saved_model_01.pth</code>。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pathlib <span class="keyword">import</span> Path</span><br><span class="line"></span><br><span class="line"><span class="comment"># 1. Create models directory </span></span><br><span class="line">MODEL_PATH = Path(<span class="string">&quot;models&quot;</span>)</span><br><span class="line">MODEL_PATH.mkdir(parents=<span class="literal">True</span>, exist_ok=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 2. Create model save path </span></span><br><span class="line">MODEL_NAME = <span class="string">&quot;01_pytorch_workflow_model_0.pth&quot;</span></span><br><span class="line">MODEL_SAVE_PATH = MODEL_PATH / MODEL_NAME</span><br><span class="line"></span><br><span class="line"><span class="comment"># 3. Save the model state dict </span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Saving model to: <span class="subst">&#123;MODEL_SAVE_PATH&#125;</span>&quot;</span>)</span><br><span class="line">torch.save(obj=model_0.state_dict(), <span class="comment"># only saving the state_dict() only saves the models learned parameters</span></span><br><span class="line">           f=MODEL_SAVE_PATH) </span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Saving model to: models\01_pytorch_workflow_model_0.pth</span><br></pre></td></tr></table></figure><h3 id="Loading-a-saved-PyTorch-model’s-state-dict-加载已保存的-PyTorch-模型的-state-dict"><a href="#Loading-a-saved-PyTorch-model’s-state-dict-加载已保存的-PyTorch-模型的-state-dict" class="headerlink" title="Loading a saved PyTorch model’s state_dict() 加载已保存的 PyTorch 模型的 state_dict()"></a>Loading a saved PyTorch model’s <code>state_dict()</code> 加载已保存的 PyTorch 模型的 <code>state_dict()</code></h3><p>由于我们现在在 <code>models/01_pytorch_workflow_model_0.pth</code> 处有一个保存的模型 <code>state_dict()</code>，我们现在可以使用 <code>torch.nn.Module.load_state_dict(torch.load(f))</code> 加载它，其中 <code>f</code> 是我们保存的模型 <code>state_dict()</code> 的文件路径。</p><p>为什么在 <code>torch.nn.Module.load_state_dict()</code> 里面调用 <code>torch.load()</code>？</p><p>因为我们只保存了模型的 <code>state_dict()</code>（它是学习参数的字典）而不是整个模型，所以我们首先必须使用 <code>torch.load()</code> 加载 <code>state_dict()</code>，然后将该 <code>state_dict()</code> 传递给我们模型的新实例（它是 <code>nn.Module</code> 的一个子类）。</p><p>为什么不保存整个模型？</p><p><a href="https://pytorch.org/tutorials/beginner/saving_loading_models.html#save-load-entire-model">保存整个模型</a>而不是仅仅保存 <code>state_dict()</code> 更为直观，但是，引用 PyTorch 文档：</p><p>保存整个模型的缺点是序列化数据与保存模型时使用的特定类和确切的目录结构绑定在一起……<br>因此，在其他项目中使用或重构后，您的代码可能会以各种方式中断。</p><p>因此，我们使用灵活的方法来保存和加载 <code>state_dict()</code>，它基本上是一个模型参数的字典。</p><p>让我们通过创建另一个 <code>LinearRegressionModel()</code> 实例来测试它，它是 <code>torch.nn.Module</code> 的一个子类，因此具有内置方法 <code>load_state_dict()</code>。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Instantiate a new instance of our model (this will be instantiated with random weights)</span></span><br><span class="line"><span class="comment"># 实例化我们模型的新实例（这将使用随机权重实例化）</span></span><br><span class="line">loaded_model_0 = LinearRegressionModel()</span><br><span class="line"></span><br><span class="line"><span class="comment"># Load the state_dict of our saved model (this will update the new instance of our model with trained weights)</span></span><br><span class="line"><span class="comment"># 加载我们保存的模型的 state_dict （这将使用训练后的权重更新我们模型的新实例）</span></span><br><span class="line">loaded_model_0.load_state_dict(torch.load(f=MODEL_SAVE_PATH))</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&lt;All keys matched successfully&gt;</span><br></pre></td></tr></table></figure><p>PyTorch 推理规则：</p><ul><li>将模型设置为评估模式 (<code>model.eval()</code>)。</li><li>使用推理模式上下文管理器进行预测（使用 <code>torch.inference_mode(): ...</code>）。</li><li>所有预测都应使用同一设备上的对象进行（例如，仅在 GPU 上的数据和模型或仅在 CPU 上的数据和模型）。</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 1. Put the loaded model into evaluation mode</span></span><br><span class="line"><span class="comment"># 1. 将加载的模型置于评估模式</span></span><br><span class="line">loaded_model_0.<span class="built_in">eval</span>()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 2. Use the inference mode context manager to make predictions</span></span><br><span class="line"><span class="comment"># 2. 使用推理模式上下文管理器进行预测</span></span><br><span class="line"><span class="keyword">with</span> torch.inference_mode():</span><br><span class="line">    loaded_model_preds = loaded_model_0(X_test) <span class="comment"># perform a forward pass on the test data with the loaded model# 使用加载的模型对测试数据执行前向传递</span></span><br></pre></td></tr></table></figure><p>现在我们已经使用加载的模型做出了一些预测，让我们看看它们是否与之前的预测相同。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># Compare previous model predictions with loaded model predictions (these should be the same)</span><br><span class="line">y_preds == loaded_model_preds</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">tensor([[True],</span><br><span class="line">        [True],</span><br><span class="line">        [True],</span><br><span class="line">        [True],</span><br><span class="line">        [True],</span><br><span class="line">        [True],</span><br><span class="line">        [True],</span><br><span class="line">        [True],</span><br><span class="line">        [True],</span><br><span class="line">        [True]])</span><br></pre></td></tr></table></figure><p>看起来加载的模型预测与之前的模型预测（保存前所做的预测）相同。这表明我们的模型正在按预期保存和加载。</p><p>还有更多方法可以保存和加载 PyTorch 模型，但我将把这些方法留到课外和进一步阅读中。有关更多信息，请参阅 <a href="https://pytorch.org/tutorials/beginner/saving_loading_models.html#saving-and-loading-models">PyTorch 保存和加载模型指南</a>。</p><h2 id="6-Putting-it-all-together"><a href="#6-Putting-it-all-together" class="headerlink" title="6. Putting it all together"></a>6. Putting it all together</h2><p>首先导入所需的标准库。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Import PyTorch and matplotlib</span></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn <span class="comment"># nn contains all of PyTorch&#x27;s building blocks for neural networks</span></span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="comment"># Check PyTorch version</span></span><br><span class="line">torch.__version__</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&#x27;2.4.1&#x27;</span><br></pre></td></tr></table></figure><p>通过设置来使我们的代码与设备无关，device=”cuda”如果它可用，否则它将默认为device=”cpu”。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Setup device agnostic code</span></span><br><span class="line">device = <span class="string">&quot;cuda&quot;</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&quot;cpu&quot;</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Using device: <span class="subst">&#123;device&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Using device: cuda</span><br></pre></td></tr></table></figure><h3 id="6-1-Data"><a href="#6-1-Data" class="headerlink" title="6.1 Data"></a>6.1 Data</h3><p>首先，我们将对一些权重和偏差值进行硬编码。</p><p>然后，我们将在 0 到 1 之间设置一个数字范围，这些数字将是我们的 X 值。</p><p>最后，我们将使用 X 值以及权重和偏差值，通过线性回归公式 (y = 权重 * X + 偏差) 创建 y。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Create weight and bias</span></span><br><span class="line">weight = <span class="number">0.7</span></span><br><span class="line">bias = <span class="number">0.3</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Create range values</span></span><br><span class="line">start = <span class="number">0</span></span><br><span class="line">end = <span class="number">1</span></span><br><span class="line">step = <span class="number">0.02</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Create X and y (features and labels)</span></span><br><span class="line">X = torch.arange(start, end, step).unsqueeze(dim=<span class="number">1</span>) <span class="comment"># without unsqueeze, errors will happen later on (shapes within linear layers)</span></span><br><span class="line">y = weight * X + bias</span><br><span class="line">X[:<span class="number">10</span>], y[:<span class="number">10</span>]</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">(tensor([[0.0000],</span><br><span class="line">         [0.0200],</span><br><span class="line">         [0.0400],</span><br><span class="line">         [0.0600],</span><br><span class="line">         [0.0800],</span><br><span class="line">         [0.1000],</span><br><span class="line">         [0.1200],</span><br><span class="line">         [0.1400],</span><br><span class="line">         [0.1600],</span><br><span class="line">         [0.1800]]),</span><br><span class="line"> tensor([[0.3000],</span><br><span class="line">         [0.3140],</span><br><span class="line">         [0.3280],</span><br><span class="line">         [0.3420],</span><br><span class="line">         [0.3560],</span><br><span class="line">         [0.3700],</span><br><span class="line">         [0.3840],</span><br><span class="line">         [0.3980],</span><br><span class="line">         [0.4120],</span><br><span class="line">         [0.4260]]))</span><br></pre></td></tr></table></figure><p>现在我们有了一些数据，让我们将其分成训练集和测试集。</p><p>我们将使用 80/20 的分割方式，即 80% 的训练数据和 20% 的测试数据。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Split data</span></span><br><span class="line">train_split = <span class="built_in">int</span>(<span class="number">0.8</span> * <span class="built_in">len</span>(X))</span><br><span class="line">X_train, y_train = X[:train_split], y[:train_split]</span><br><span class="line">X_test, y_test = X[train_split:], y[train_split:]</span><br><span class="line"></span><br><span class="line"><span class="built_in">len</span>(X_train), <span class="built_in">len</span>(y_train), <span class="built_in">len</span>(X_test), <span class="built_in">len</span>(y_test)</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">(40, 40, 10, 10)</span><br></pre></td></tr></table></figure><p>太好了，让我们将它们可视化以确保它们看起来不错。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Note: If you&#x27;ve reset your runtime, this function won&#x27;t work, </span></span><br><span class="line"><span class="comment"># you&#x27;ll have to rerun the cell above where it&#x27;s instantiated.</span></span><br><span class="line">plot_predictions(X_train, y_train, X_test, y_test)</span><br></pre></td></tr></table></figure><h3 id="6-2-Building-a-PyTorch-linear-model"><a href="#6-2-Building-a-PyTorch-linear-model" class="headerlink" title="6.2 Building a PyTorch linear model"></a>6.2 Building a PyTorch linear model</h3><p>太棒了，让我们来看一下。我们已经有了一些数据，现在是时候创建一个模型了。</p><p>我们将创建与以前相同风格的模型，只是这次，我们不再使用 <code>nn.Parameter()</code> 手动定义模型的权重和偏差参数，而是使用 <a href="https://pytorch.org/docs/stable/generated/torch.nn.Linear.html">nn.Linear(in_features, out_features)</a> 来为我们完成这项工作。</p><p>其中 <code>in_features</code> 是输入数据的维度数，<code>out_features</code> 是您希望输出到的维度数。</p><p>在我们的例子中，这两个都是 <code>1</code>，因为我们的数据每个标签 (<code>y</code>) 有 1 个输入特征 (<code>X</code>)。对它们进行大小调整以确保它们看起来不错。</p><img src="/2024/08/15/PyTorch-26H-2/PyTorch-26H-2-13.png" class="" title="PyTorch-26H-2-13"><p>使用 <code>nn.Parameter</code> 创建线性回归模型，而不是使用 <code>nn.Linear</code>。<code>torch.nn</code> 模块具有预构建计算的示例还有很多，包括许多流行且有用的神经网络层。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Subclass nn.Module to make our model</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">LinearRegressionModelV2</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        <span class="comment"># Use nn.Linear() for creating the model parameters</span></span><br><span class="line">        self.linear_layer = nn.Linear(in_features=<span class="number">1</span>, </span><br><span class="line">                                      out_features=<span class="number">1</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Define the forward computation (input data x flows through nn.Linear())</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x: torch.Tensor</span>) -&gt; torch.Tensor:</span><br><span class="line">        <span class="keyword">return</span> self.linear_layer(x)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Set the manual seed when creating the model (this isn&#x27;t always needed but is used for demonstrative purposes, try commenting it out and seeing what happens)</span></span><br><span class="line">torch.manual_seed(<span class="number">42</span>)</span><br><span class="line">model_1 = LinearRegressionModelV2()</span><br><span class="line">model_1, model_1.state_dict()</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">(LinearRegressionModelV2(</span><br><span class="line">   (linear_layer): Linear(in_features=1, out_features=1, bias=True)</span><br><span class="line"> ),</span><br><span class="line"> OrderedDict([(&#x27;linear_layer.weight&#x27;, tensor([[0.7645]])),</span><br><span class="line">              (&#x27;linear_layer.bias&#x27;, tensor([0.8300]))]))</span><br></pre></td></tr></table></figure><p>注意model_1.state_dict()的输出，nn.Linear()层为我们创建了一个随机权重和偏差参数。</p><p>现在让我们将模型放到 GPU 上（如果可用）。</p><p>我们可以使用 .to(device) 更改 PyTorch 对象所在的设备。</p><p>首先让我们检查模型的当前设备。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Check model device</span></span><br><span class="line"><span class="built_in">next</span>(model_1.parameters()).device</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">device(type=&#x27;cpu&#x27;)</span><br></pre></td></tr></table></figure><p>太棒了，看起来模型默认在 CPU 上运行。</p><p>让我们将其改为在 GPU 上运行（如果可用的话）。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Set model to GPU if it&#x27;s available, otherwise it&#x27;ll default to CPU</span></span><br><span class="line">model_1.to(device) <span class="comment"># the device variable was set above to be &quot;cuda&quot; if available or &quot;cpu&quot; if not</span></span><br><span class="line"><span class="built_in">next</span>(model_1.parameters()).device</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">device(type=&#x27;cuda&#x27;, index=0)</span><br></pre></td></tr></table></figure><p>太棒了！由于我们的代码与设备无关，因此无论 GPU 是否可用，上述单元都可以工作。</p><h3 id="6-3-Training"><a href="#6-3-Training" class="headerlink" title="6.3 Training"></a>6.3 Training</h3><p>是时候构建训练和测试循环了。</p><p>首先，我们需要一个损失函数loss function和一个优化器optimizer。</p><p>让我们使用之前使用的相同函数，<code>nn.L1Loss()</code> 和 <code>torch.optim.SGD()</code>。</p><p>我们必须将新模型的参数 (<code>model.parameters()</code>) 传递给优化器，以便它在训练期间进行调整。</p><p><code>0.01</code> 的学习率之前也很好用，所以让我们再次使用它。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Create loss function</span></span><br><span class="line">loss_fn = nn.L1Loss()</span><br><span class="line"></span><br><span class="line"><span class="comment"># Create optimizer</span></span><br><span class="line">optimizer = torch.optim.SGD(params=model_1.parameters(), <span class="comment"># optimize newly created model&#x27;s parameters</span></span><br><span class="line">                            lr=<span class="number">0.01</span>)</span><br></pre></td></tr></table></figure><p>损失函数和优化器已准备就绪，现在让我们使用训练和测试循环来训练和评估我们的模型。</p><p>与之前的训练循环相比，我们在此步骤中要做的唯一不同的事情是将数据放在目标设备上。</p><p>我们已经使用 <code>model_1.to(device)</code> 将我们的模型放在目标设备上。</p><p>我们可以对数据执行相同的操作。</p><p>这样，如果模型在 GPU 上，数据就在 GPU 上（反之亦然）。</p><p>这次让我们更进一步，设置 <code>epochs=1000</code>。</p><p>如果您需要 PyTorch 训练循环步骤的提醒，请参见下文。</p><p>PyTorch 训练循环步骤</p><ul><li>前向传递 - 模型对所有训练数据进行一次遍历，执行其 forward() 函数计算 (model(x_train))。</li><li>计算损失 - 将模型的输出 (预测) 与基本事实进行比较，并进行评估以查看它们的错误程度 (loss = loss_fn(y_pred, y_train)。</li><li>零梯度 - 优化器梯度设置为零 (默认情况下是累积的)，因此可以为特定的训练步骤重新计算它们 (optimizer.zero_grad())。</li><li>对损失执行反向传播 - 针对要更新的每个模型参数 (每个参数的 require_grad=True) 计算损失的梯度。这称为反向传播，因此是“向后”(loss.backward())。</li><li>步进优化器 (梯度下降) - 使用 require_grad=True 更新参数，以根据损失梯度来改进它们 (optimizer.step())。</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line">torch.manual_seed(<span class="number">42</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Set the number of epochs </span></span><br><span class="line">epochs = <span class="number">1000</span> </span><br><span class="line"></span><br><span class="line"><span class="comment"># Put data on the available device</span></span><br><span class="line"><span class="comment"># Without this, error will happen (not all model/data on device)</span></span><br><span class="line">X_train = X_train.to(device)</span><br><span class="line">X_test = X_test.to(device)</span><br><span class="line">y_train = y_train.to(device)</span><br><span class="line">y_test = y_test.to(device)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(epochs):</span><br><span class="line">    <span class="comment">### Training</span></span><br><span class="line">    model_1.train() <span class="comment"># train mode is on by default after construction</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 1. Forward pass</span></span><br><span class="line">    y_pred = model_1(X_train)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 2. Calculate loss</span></span><br><span class="line">    loss = loss_fn(y_pred, y_train)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 3. Zero grad optimizer</span></span><br><span class="line">    optimizer.zero_grad()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 4. Loss backward</span></span><br><span class="line">    loss.backward()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 5. Step the optimizer</span></span><br><span class="line">    optimizer.step()</span><br><span class="line"></span><br><span class="line">    <span class="comment">### Testing</span></span><br><span class="line">    model_1.<span class="built_in">eval</span>() <span class="comment"># put the model in evaluation mode for testing (inference)</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 1. Forward pass</span></span><br><span class="line">    <span class="keyword">with</span> torch.inference_mode():</span><br><span class="line">        test_pred = model_1(X_test)</span><br><span class="line">    </span><br><span class="line">        <span class="comment"># 2. Calculate the loss</span></span><br><span class="line">        test_loss = loss_fn(test_pred, y_test)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> epoch % <span class="number">100</span> == <span class="number">0</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;Epoch: <span class="subst">&#123;epoch&#125;</span> | Train loss: <span class="subst">&#123;loss&#125;</span> | Test loss: <span class="subst">&#123;test_loss&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">Epoch: 0 | Train loss: 0.5551779866218567 | Test loss: 0.5739762187004089</span><br><span class="line">Epoch: 100 | Train loss: 0.006215683650225401 | Test loss: 0.014086711220443249</span><br><span class="line">Epoch: 200 | Train loss: 0.0012645035749301314 | Test loss: 0.013801801018416882</span><br><span class="line">Epoch: 300 | Train loss: 0.0012645035749301314 | Test loss: 0.013801801018416882</span><br><span class="line">Epoch: 400 | Train loss: 0.0012645035749301314 | Test loss: 0.013801801018416882</span><br><span class="line">Epoch: 500 | Train loss: 0.0012645035749301314 | Test loss: 0.013801801018416882</span><br><span class="line">Epoch: 600 | Train loss: 0.0012645035749301314 | Test loss: 0.013801801018416882</span><br><span class="line">Epoch: 700 | Train loss: 0.0012645035749301314 | Test loss: 0.013801801018416882</span><br><span class="line">Epoch: 800 | Train loss: 0.0012645035749301314 | Test loss: 0.013801801018416882</span><br><span class="line">Epoch: 900 | Train loss: 0.0012645035749301314 | Test loss: 0.013801801018416882</span><br></pre></td></tr></table></figure><blockquote><p>注意：由于机器学习的随机性，您可能会得到略有不同的结果（不同的损失和预测值），具体取决于您的模型是在 CPU 还是 GPU 上训练的。即使您在任一设备上使用相同的随机种子，情况也是如此。如果差异很大，您可能需要查找错误，但是，如果差异很小（理想情况下很小），您可以忽略它。</p></blockquote><p>检查一下模型学习到的参数，并将它们与我们硬编码的原始参数进行比较。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Find our model&#x27;s learned parameters</span></span><br><span class="line"><span class="keyword">from</span> pprint <span class="keyword">import</span> pprint <span class="comment"># pprint = pretty print, see: https://docs.python.org/3/library/pprint.html </span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;The model learned the following values for weights and bias:&quot;</span>)</span><br><span class="line">pprint(model_1.state_dict())</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;\nAnd the original values for weights and bias are:&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;weights: <span class="subst">&#123;weight&#125;</span>, bias: <span class="subst">&#123;bias&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">The model learned the following values for weights and bias:</span><br><span class="line">OrderedDict([(&#x27;linear_layer.weight&#x27;, tensor([[0.6968]], device=&#x27;cuda:0&#x27;)),</span><br><span class="line">             (&#x27;linear_layer.bias&#x27;, tensor([0.3025], device=&#x27;cuda:0&#x27;))])</span><br><span class="line"></span><br><span class="line">And the original values for weights and bias are:</span><br><span class="line">weights: 0.7, bias: 0.3</span><br></pre></td></tr></table></figure><p>请记住，在实践中，你很少会提前知道完美的参数。</p><p>如果你提前知道了模型必须学习的参数，机器学习还有什么乐趣呢？</p><p>此外，在许多现实世界的机器学习问题中，参数的数量可能超过数千万。</p><h3 id="6-4-Making-predictions"><a href="#6-4-Making-predictions" class="headerlink" title="6.4 Making predictions"></a>6.4 Making predictions</h3><p>现在我们已经有一个训练好的模型，让我们打开它的评估模式并做出一些预测。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Turn model into evaluation mode</span></span><br><span class="line">model_1.<span class="built_in">eval</span>()</span><br><span class="line"></span><br><span class="line"><span class="comment"># Make predictions on the test data</span></span><br><span class="line"><span class="keyword">with</span> torch.inference_mode():</span><br><span class="line">    y_preds = model_1(X_test)</span><br><span class="line">y_preds</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">tensor([[0.8600],</span><br><span class="line">        [0.8739],</span><br><span class="line">        [0.8878],</span><br><span class="line">        [0.9018],</span><br><span class="line">        [0.9157],</span><br><span class="line">        [0.9296],</span><br><span class="line">        [0.9436],</span><br><span class="line">        [0.9575],</span><br><span class="line">        [0.9714],</span><br><span class="line">        [0.9854]], device=&#x27;cuda:0&#x27;)</span><br></pre></td></tr></table></figure><p>如果您使用 GPU 上的数据进行预测，您可能会注意到上面的输出在末尾有 device=’cuda:0’。这意味着数据位于 CUDA 设备 0 上（由于零索引，您的系统可以访问的第一个 GPU），如果您将来最终使用多个 GPU，这个数字可能会更高。</p><p>现在让我们绘制模型的预测。</p><blockquote><p>注意：许多数据科学库（例如 pandas、matplotlib 和 NumPy）无法使用存储在 GPU 上的数据。因此，当您尝试使用其中一个库中的函数处理未存储在 CPU 上的张量数据时，可能会遇到一些问题。要解决此问题，您可以在目标张量上调用 .cpu() 以返回 CPU 上的目标张量的副本。</p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># plot_predictions(predictions=y_preds) # -&gt; won&#x27;t work... data not on CPU</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Put data on the CPU and plot it</span></span><br><span class="line">plot_predictions(predictions=y_preds.cpu())</span><br></pre></td></tr></table></figure><img src="/2024/08/15/PyTorch-26H-2/PyTorch-26H-2-14.png" class="" title="PyTorch-26H-2-14"><h3 id="6-5-Saving-and-loading-a-model-保存和加载模型"><a href="#6-5-Saving-and-loading-a-model-保存和加载模型" class="headerlink" title="6.5 Saving and loading a model 保存和加载模型"></a>6.5 Saving and loading a model 保存和加载模型</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pathlib <span class="keyword">import</span> Path</span><br><span class="line"></span><br><span class="line"><span class="comment"># 1. Create models directory </span></span><br><span class="line">MODEL_PATH = Path(<span class="string">&quot;models&quot;</span>)</span><br><span class="line">MODEL_PATH.mkdir(parents=<span class="literal">True</span>, exist_ok=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 2. Create model save path </span></span><br><span class="line">MODEL_NAME = <span class="string">&quot;01_pytorch_workflow_model_1.pth&quot;</span></span><br><span class="line">MODEL_SAVE_PATH = MODEL_PATH / MODEL_NAME</span><br><span class="line"></span><br><span class="line"><span class="comment"># 3. Save the model state dict </span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Saving model to: <span class="subst">&#123;MODEL_SAVE_PATH&#125;</span>&quot;</span>)</span><br><span class="line">torch.save(obj=model_1.state_dict(), <span class="comment"># only saving the state_dict() only saves the models learned parameters</span></span><br><span class="line">           f=MODEL_SAVE_PATH) </span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Saving model to: models\01_pytorch_workflow_model_1.pth</span><br></pre></td></tr></table></figure><p>为了确保一切正常，我们将其重新加载。</p><ul><li>创建 <code>LinearRegressionModelV2()</code> 类的新实例</li><li>使用 <code>torch.nn.Module.load_state_dict()</code> 加载模型状态字典</li><li>将模型的新实例发送到目标设备（以确保我们的代码与设备无关）</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Instantiate a fresh instance of LinearRegressionModelV2</span></span><br><span class="line">loaded_model_1 = LinearRegressionModelV2()</span><br><span class="line"></span><br><span class="line"><span class="comment"># Load model state dict </span></span><br><span class="line">loaded_model_1.load_state_dict(torch.load(MODEL_SAVE_PATH))</span><br><span class="line"></span><br><span class="line"><span class="comment"># Put model to target device (if your data is on GPU, model will have to be on GPU to make predictions)</span></span><br><span class="line">loaded_model_1.to(device)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Loaded model:\n<span class="subst">&#123;loaded_model_1&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Model on device:\n<span class="subst">&#123;<span class="built_in">next</span>(loaded_model_1.parameters()).device&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">Loaded model:</span><br><span class="line">LinearRegressionModelV2(</span><br><span class="line">  (linear_layer): Linear(in_features=1, out_features=1, bias=True)</span><br><span class="line">)</span><br><span class="line">Model on device:</span><br><span class="line">cuda:0</span><br></pre></td></tr></table></figure><p>现在我们可以评估加载的模型，看看它的预测是否与保存之前的预测一致。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Evaluate loaded model</span></span><br><span class="line">loaded_model_1.<span class="built_in">eval</span>()</span><br><span class="line"><span class="keyword">with</span> torch.inference_mode():</span><br><span class="line">    loaded_model_1_preds = loaded_model_1(X_test)</span><br><span class="line">y_preds == loaded_model_1_preds</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">tensor([[True],</span><br><span class="line">        [True],</span><br><span class="line">        [True],</span><br><span class="line">        [True],</span><br><span class="line">        [True],</span><br><span class="line">        [True],</span><br><span class="line">        [True],</span><br><span class="line">        [True],</span><br><span class="line">        [True],</span><br><span class="line">        [True]], device=&#x27;cuda:0&#x27;)</span><br></pre></td></tr></table></figure><h2 id="Exercises"><a href="#Exercises" class="headerlink" title="Exercises"></a>Exercises</h2><p>1、使用线性回归公式 () 创建直线数据集<code>weight * X + bias</code>。</p><ul><li>设置<code>weight=0.3</code>并且<code>bias=0.9</code>总共应该至少有 100 个数据点。</li><li>将数据分成 80％ 用于训练，20％ 用于测试。</li><li>绘制训练和测试数据，使其变得可视化。</li></ul><p>2、通过子类化构建 PyTorch 模型<code>nn.Module</code>。</p><ul><li>里面应该有一个随机初始化<code>nn.Parameter()</code>的<code>requires_grad=True</code>，一个为<code>weights</code>，一个为<code>bias</code>。</li><li>实现<code>forward()</code>在1中创建数据集时使用的计算线性回归函数的方法。</li><li>一旦构建了模型，就创建它的一个实例并检查它的<code>state_dict()</code>。</li><li>注意：如果您愿意，<code>nn.Linear()</code>也<code>nn.Parameter()</code>可以使用。</li></ul><p>3、<code>nn.L1Loss()</code>分别使用和创建损失函数和优化器<code>torch.optim.SGD(params, lr)</code>。</p><ul><li>将优化器的学习率设置为 0.01，要优化的参数应该是您在 2 中创建的模型的模型参数。</li><li>编写一个训练循环来执行 300 个时期的适当训练步骤。</li><li>训练循环应该每 20 个时期在测试数据集上测试模型。</li></ul><p>4、使用训练好的模型对测试数据进行预测。</p><ul><li>根据原始训练和测试数据对这些预测进行可视化（注意：如果您想使用不支持 CUDA 的库（例如 matplotlib 来绘图，则可能需要确保预测不在GPU 上）。</li></ul><p>5、将您训练的模型保存<code>state_dict()</code>到文件中。</p><ul><li>创建您在 2 中创建的模型类的新实例，并加载<code>state_dict()</code>您刚刚保存的内容。</li><li>使用加载的模型对测试数据执行预测，并确认它们与 4 中的原始模型预测相匹配。</li></ul><h2 id="Extra-curriculum"><a href="#Extra-curriculum" class="headerlink" title="Extra-curriculum"></a>Extra-curriculum</h2><ul><li>阅读Jeremy Howard 的《到底<a href="https://pytorch.org/tutorials/beginner/nn_tutorial.html">是什么<code>torch.nn</code>？》，</a>以更深入地了解 PyTorch 中最重要的模块之一的工作原理。</li><li>花 10 分钟浏览并查看<a href="https://pytorch.org/tutorials/beginner/ptcheat.html">PyTorch 文档备忘单，</a>了解您可能会遇到的所有不同 PyTorch 模块。</li><li>花 10 分钟阅读<a href="https://pytorch.org/tutorials/beginner/saving_loading_models.html">PyTorch 网站上的加载和保存文档，</a>以熟悉 PyTorch 中的不同保存和加载选项。</li><li>花费 1-2 小时阅读/观看以下内容，了解梯度下降和反向传播的内部原理，这两种主要算法一直在后台运行，帮助我们的模型学习。</li><li><a href="https://en.wikipedia.org/wiki/Gradient_descent">梯度下降的维基百科页面</a></li><li>梯度下降算法——Robert Kwiatkowski 的<a href="https://towardsdatascience.com/gradient-descent-algorithm-a-deep-dive-cf04e8115f21">深入探讨</a></li><li><a href="https://youtu.be/IHZwWFHWa-w">梯度下降，神经网络如何学习视频</a>（3Blue1Brown 拍摄）</li><li><a href="https://youtu.be/Ilg3gGewQ5U">反向传播到底在做什么？</a>视频由 3Blue1Brown 提供</li><li><a href="https://en.wikipedia.org/wiki/Backpropagation">反向传播维基百科页面</a></li></ul>]]></content>
    
    
    <summary type="html">PyTorch-26H-2</summary>
    
    
    
    <category term="PyTorch" scheme="http://hibiscidai.com/categories/PyTorch/"/>
    
    
    <category term="学习笔记" scheme="http://hibiscidai.com/tags/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
    <category term="PyTorch" scheme="http://hibiscidai.com/tags/PyTorch/"/>
    
  </entry>
  
  <entry>
    <title>PyTorch-26H-1</title>
    <link href="http://hibiscidai.com/2024/08/14/PyTorch-26H-1/"/>
    <id>http://hibiscidai.com/2024/08/14/PyTorch-26H-1/</id>
    <published>2024-08-14T12:00:00.000Z</published>
    <updated>2024-10-11T13:34:53.000Z</updated>
    
    <content type="html"><![CDATA[<img src="/2024/08/14/PyTorch-26H-1/PyTorch-26H-1.png" class="" title="PyTorch-26H-1"><p>PyTorch-26H-1</p><span id="more"></span><h1 id="PyTorch-26H-1"><a href="#PyTorch-26H-1" class="headerlink" title="PyTorch-26H-1"></a>PyTorch-26H-1</h1><p>主页：<a href="https://www.freecodecamp.org/news/learn-pytorch-for-deep-learning-in-day/">https://www.freecodecamp.org/news/learn-pytorch-for-deep-learning-in-day/</a></p><p>youtub：<a href="https://youtu.be/V_xro1bcAuA">https://youtu.be/V_xro1bcAuA</a></p><p>github：<a href="https://github.com/mrdbourke/pytorch-deep-learning">https://github.com/mrdbourke/pytorch-deep-learning</a></p><p>Learn PyTorch for Deep Learning: Zero to Mastery book：<a href="https://www.learnpytorch.io/">https://www.learnpytorch.io/</a></p><p>PyTorch documentation：<a href="https://pytorch.org/docs/stable/index.html">https://pytorch.org/docs/stable/index.html</a></p><h1 id="Chapter-0-–-PyTorch-Fundamentals"><a href="#Chapter-0-–-PyTorch-Fundamentals" class="headerlink" title="Chapter 0 – PyTorch Fundamentals"></a>Chapter 0 – PyTorch Fundamentals</h1><h2 id="what-is-deep-learning"><a href="#what-is-deep-learning" class="headerlink" title="what is deep learning?"></a>what is deep learning?</h2><p>Machine learning is turning things (data) into numbers and finding patterns in those numbers.</p><p>Deep Learning ∈ Machine Learning ∈ Aritfical Intelligence</p><p>传统程序：输入+规则→输出<br>机器学些：输入+输出→规则</p><img src="/2024/08/14/PyTorch-26H-1/PyTorch-26H-1-1.png" class="" title="PyTorch-26H-1-1"><h2 id="Why-use-machine-deep-learning"><a href="#Why-use-machine-deep-learning" class="headerlink" title="Why use machine/deep learning?"></a>Why use machine/deep learning?</h2><p>对于复杂的问题，无法找到所有的规则。</p><h2 id="The-number-one-rule-of-ML"><a href="#The-number-one-rule-of-ML" class="headerlink" title="The number one rule of ML"></a>The number one rule of ML</h2><p>“If you can build a simple rule-based system that doesn’t require machine learning, do that.”</p><ul><li><p>A wise software engineer… (actually rule 1 of Google’s Machine Learning Handbook)</p></li><li><p>What deep learning is good for</p></li></ul><p>Problems with long lists of rules- when the traditional approach fails, machine learning/deep learning may help.<br>规则列表过长的问题——当传统方法失败时，机器学习/深度学习可能会有所帮助。</p><p>Continually changing environments- deep learning can adapt (learn’) to new scenarios.<br>不断变化的环境——深度学习可以适应（学习）新场景。</p><p>Discovering insights within large collections of data- can you imagine trying to hand-craft rules for what 101 different kinds of food look like?<br>在大量数据中发现见解——你能想象尝试手工制定 101 种不同食物的规则吗？</p><ul><li>What deep learning is not good for</li></ul><p>When you need explainability- -the patterns learned by a deep learning model are typically uninterpretable by a human.<br>当你需要可解释性时——深度学习模型学习到的模式通常无法被人类解释。</p><p>When the traditional approach is a better option一if you can accomplish what you need with a simple rule-based system.<br>当传统方法是更好的选择时——如果你可以使用简单的基于规则的系统完成所需的工作。</p><p>When errors are unacceptable一since the outputs of deep learning model aren’t always predictable.<br>当错误不可接受时——因为深度学习模型的输出并不总是可预测的。</p><p>When you don’t have much data一deep learning models usually require a fairly large amount of data to produce great results.<br>当你没有太多数据时——深度学习模型通常需要相当大量的数据才能产生很好的结果。</p><h2 id="Machine-learning-vs-deep-learning"><a href="#Machine-learning-vs-deep-learning" class="headerlink" title="Machine learning vs deep learning"></a>Machine learning vs deep learning</h2><img src="/2024/08/14/PyTorch-26H-1/PyTorch-26H-1-2.png" class="" title="PyTorch-26H-1-2"><ul><li>Machine learning</li></ul><p>适合处理结构化数据</p><p>常见算法：<br>Random forest 随机森林<br>Gradient boosted models 梯度提升模型<br>Naive Bayes 朴素贝叶斯<br>Nearest neighbour 最近邻<br>Support vector machine 支持向量机</p><ul><li>Deep learning</li></ul><p>适合处理非结构化数据</p><p>常见算法：<br>Neural networks 神经网络<br>Fully connected neural network 全连接神经网络<br>Convolutional neural network 卷积神经网络<br>Recurrent neuralnetwork 循环神经网络<br>Transformer</p><h2 id="Anatomy-of-neural-networks"><a href="#Anatomy-of-neural-networks" class="headerlink" title="Anatomy of neural networks"></a>Anatomy of neural networks</h2><img src="/2024/08/14/PyTorch-26H-1/PyTorch-26H-1-3.png" class="" title="PyTorch-26H-1-3"><p>数据→数字→神经网络→权重→输出</p><img src="/2024/08/14/PyTorch-26H-1/PyTorch-26H-1-4.png" class="" title="PyTorch-26H-1-4"><h2 id="Different-learning-paradigms"><a href="#Different-learning-paradigms" class="headerlink" title="Different learning paradigms"></a>Different learning paradigms</h2><img src="/2024/08/14/PyTorch-26H-1/PyTorch-26H-1-5.png" class="" title="PyTorch-26H-1-5"><p>监督学习：大量已知数据标注。</p><p>无监督学习：自动分析数据。</p><p>迁移学习：将学习到的模式嵌入到新的模型中。</p><p>强化学习reinforcement learning：奖励想要的结果。</p><img src="/2024/08/14/PyTorch-26H-1/PyTorch-26H-1-6.png" class="" title="PyTorch-26H-1-6"><h2 id="What-can-deep-learning-be-used-for"><a href="#What-can-deep-learning-be-used-for" class="headerlink" title="What can deep learning be used for?"></a>What can deep learning be used for?</h2><img src="/2024/08/14/PyTorch-26H-1/PyTorch-26H-1-7.png" class="" title="PyTorch-26H-1-7"><p>CV</p><p>NATURAL LANGUAGE PROGRESS</p><p>SEQUENCE IN AND SEQUENCE OUT</p><h2 id="What-is-why-PyTorch"><a href="#What-is-why-PyTorch" class="headerlink" title="What is/why PyTorch?"></a>What is/why PyTorch?</h2><img src="/2024/08/14/PyTorch-26H-1/PyTorch-26H-1-8.png" class="" title="PyTorch-26H-1-8"><p>Most popular research deep learning framework<br>最流行的深度学习研究框架</p><p>Write fast deep learning code in Python (able to run on a GPU/many GPUs)<br>用 Python 编写快速的深度学习代码（可在 GPU/多个 GPU 上运行）</p><p>Able to access many pre-built deep learning models (Torch Hub/torchvision.models)<br>能够访问许多预构建的深度学习模型（Torch Hub/torchvision.models）</p><p>Whole stack: preprocess data, model data, deploy model in your application/cloud<br>整个堆栈：预处理数据、建立数据模型、在应用程序/云中部署模型</p><p>Originally designed and used in-house by Facebook/Meta (now opensource and used by companies such as Tesla, Microsoft, OpenAI)<br>最初由 Facebook/Meta 内部设计和使用（现已开源，并被特斯拉、微软、OpenAI 等公司使用）</p><p><a href="www.paperswithcode.com/trends">paperswithcode</a></p><img src="/2024/08/14/PyTorch-26H-1/PyTorch-26H-1-9.png" class="" title="PyTorch-26H-1-9"><p>GPU(Graphics Processing Unit)</p><p>TPU(Tensor Processing Unit)</p><h2 id="What-are-tensors"><a href="#What-are-tensors" class="headerlink" title="What are tensors?"></a>What are tensors?</h2><img src="/2024/08/14/PyTorch-26H-1/PyTorch-26H-1-10.png" class="" title="PyTorch-26H-1-10"><img src="/2024/08/14/PyTorch-26H-1/PyTorch-26H-1-11.png" class="" title="PyTorch-26H-1-11"><h2 id="Outline"><a href="#Outline" class="headerlink" title="Outline"></a>Outline</h2><p>Now:</p><ul><li>PyTorch basics &amp; fundamentals (dealing with tensors and tensor operations)</li><li>PyTorch 基础和基本原理（处理张量和张量运算）</li></ul><p>Later:</p><ul><li>Preprocessing data (getting it into tensors)</li><li>预处理数据（将数据转化为张量）</li><li>Building and using pretrained deep learning models</li><li>构建和使用预训练的深度学习模型</li><li>Fitting a model to the data (learning patterns)</li><li>根据数据拟合模型（学习模式）</li><li>Making predictions with a model (using patterns)</li><li>使用模型进行预测（使用模式）</li><li>Evaluating model predictions</li><li>评估模型预测</li><li>Saving and loading models</li><li>保存和加载模型</li><li>Using a trained model to make predictions on custom data</li><li>使用训练好的模型对自定义数据进行预测</li></ul><p>一点科学，一点艺术。</p><img src="/2024/08/14/PyTorch-26H-1/PyTorch-26H-1-12.png" class="" title="PyTorch-26H-1-12"><h2 id="How-to-and-how-not-to-approach-this-course"><a href="#How-to-and-how-not-to-approach-this-course" class="headerlink" title="How to (and how not to) approach this course"></a>How to (and how not to) approach this course</h2><img src="/2024/08/14/PyTorch-26H-1/PyTorch-26H-1-13.png" class="" title="PyTorch-26H-1-13"><p>1、code alone</p><p>2、explore and experiment</p><p>3、visuallize what you don’t understand</p><p>4、ask questions</p><p>5、do the exercises</p><p>6、share your work</p><h2 id="Important-resources"><a href="#Important-resources" class="headerlink" title="Important resources"></a>Important resources</h2><img src="/2024/08/14/PyTorch-26H-1/PyTorch-26H-1-14.png" class="" title="PyTorch-26H-1-14"><p>课程资料：<br><a href="https://www.github.com/mrdbourke/pytorch-deep-learning">Course materials</a></p><p>问答：<br><a href="https://www.github.com/mrdbourke/pytorch-deep-learning/discussions">Course Q&amp;A</a></p><p>书籍：<br><a href="https://learnpytorch.io">Course online book</a></p><p><a href="https://pytorch.org/">pytorch_org</a></p><p><a href="https://pytorch.org/docs/stable/index.html">PyTorch documentation</a></p><p>出问题去讨论区</p><img src="/2024/08/14/PyTorch-26H-1/PyTorch-26H-1-15.png" class="" title="PyTorch-26H-1-15"><h2 id="Getting-setup"><a href="#Getting-setup" class="headerlink" title="Getting setup"></a>Getting setup</h2><p><a href="https://colab.research.google.com/">Google colab</a></p><img src="/2024/08/14/PyTorch-26H-1/PyTorch-26H-1-16.png" class="" title="PyTorch-26H-1-16"><img src="/2024/08/14/PyTorch-26H-1/PyTorch-26H-1-17.png" class="" title="PyTorch-26H-1-17"><img src="/2024/08/14/PyTorch-26H-1/PyTorch-26H-1-18.png" class="" title="PyTorch-26H-1-18"><p><code>00_pytorch_fundamentals_vedio.ipynb</code></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Hello I&#x27;m excited to learn PyTorch!&quot;</span>)</span><br><span class="line"></span><br><span class="line">&gt;Hello I<span class="string">&#x27;m excited to learn PyTorch!</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">!nvidia-smi</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Mon Aug 26 11:28:50 2024       </span></span><br><span class="line"><span class="string">+---------------------------------------------------------------------------------------+</span></span><br><span class="line"><span class="string">| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |</span></span><br><span class="line"><span class="string">|-----------------------------------------+----------------------+----------------------+</span></span><br><span class="line"><span class="string">| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |</span></span><br><span class="line"><span class="string">| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |</span></span><br><span class="line"><span class="string">|                                         |                      |               MIG M. |</span></span><br><span class="line"><span class="string">|=========================================+======================+======================|</span></span><br><span class="line"><span class="string">|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |</span></span><br><span class="line"><span class="string">| N/A   49C    P8              10W /  70W |      0MiB / 15360MiB |      0%      Default |</span></span><br><span class="line"><span class="string">|                                         |                      |                  N/A |</span></span><br><span class="line"><span class="string">+-----------------------------------------+----------------------+----------------------+</span></span><br><span class="line"><span class="string">                                                                                         </span></span><br><span class="line"><span class="string">+---------------------------------------------------------------------------------------+</span></span><br><span class="line"><span class="string">| Processes:                                                                            |</span></span><br><span class="line"><span class="string">|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |</span></span><br><span class="line"><span class="string">|        ID   ID                                                             Usage      |</span></span><br><span class="line"><span class="string">|=======================================================================================|</span></span><br><span class="line"><span class="string">|  No running processes found                                                           |</span></span><br><span class="line"><span class="string">+---------------------------------------------------------------------------------------+</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">import torch</span></span><br><span class="line"><span class="string">import pandas as pd</span></span><br><span class="line"><span class="string">import numpy as np</span></span><br><span class="line"><span class="string">import matplotlib.pyplot as plt</span></span><br><span class="line"><span class="string">print(torch.__version__)</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">&gt;2.3.1+cu121</span></span><br></pre></td></tr></table></figure><h2 id="Introduction-to-tensors"><a href="#Introduction-to-tensors" class="headerlink" title="Introduction to tensors"></a>Introduction to tensors</h2><p><a href="https://pytorch.org/docs/stable/tensors.html">torch.Tensor</a></p><p>A torch.Tensor is a multi-dimensional matrix containing elements of a single data type.<br>张量是包含单一数据类型元素的多维矩阵。</p><h3 id="scalar→标量"><a href="#scalar→标量" class="headerlink" title="scalar→标量"></a><strong>scalar→标量</strong></h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># scalar</span></span><br><span class="line">scalar = torch.tensor(<span class="number">7</span>)</span><br><span class="line">scalar</span><br><span class="line"><span class="comment">#&gt;tensor(7)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看张量的维度</span></span><br><span class="line">scalar.ndim</span><br><span class="line"><span class="comment">#&gt;0</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#取回张量→int</span></span><br><span class="line">scalar.item()</span><br><span class="line"><span class="comment">#&gt;7</span></span><br></pre></td></tr></table></figure><h3 id="vecotr→向量"><a href="#vecotr→向量" class="headerlink" title="vecotr→向量"></a><strong>vecotr→向量</strong></h3><p>拥有大小和方向</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#Vector</span></span><br><span class="line">vector = torch.tensor([<span class="number">7</span>,<span class="number">7</span>])</span><br><span class="line">vector</span><br><span class="line"><span class="comment">#&gt;tensor([7, 7])</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#查看向量的维度</span></span><br><span class="line">vector.ndim</span><br><span class="line"><span class="comment">#&gt;1</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#查看向量的形状</span></span><br><span class="line">vector.shape</span><br><span class="line"><span class="comment">#&gt;torch.Size([2])</span></span><br></pre></td></tr></table></figure><h3 id="MATRIX→矩阵"><a href="#MATRIX→矩阵" class="headerlink" title="MATRIX→矩阵"></a><strong>MATRIX→矩阵</strong></h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">MATRIX = torch.tensor([[<span class="number">7</span>,<span class="number">8</span>],</span><br><span class="line">[<span class="number">9</span>,<span class="number">10</span>]])</span><br><span class="line">MATRIX</span><br><span class="line"></span><br><span class="line"><span class="comment">#&gt;tensor([[ 7,  8],</span></span><br><span class="line"><span class="comment">#&gt;        [ 9, 10]])</span></span><br><span class="line"></span><br><span class="line">MATRIX.ndim</span><br><span class="line"><span class="comment">#&gt;2</span></span><br><span class="line"></span><br><span class="line">MATRIX[<span class="number">0</span>]</span><br><span class="line"><span class="comment">#&gt;tensor([7, 8])</span></span><br><span class="line"></span><br><span class="line">MATRIX[<span class="number">1</span>]</span><br><span class="line"><span class="comment">#&gt;tensor([ 9, 10])</span></span><br><span class="line"></span><br><span class="line">MATRIX.shape</span><br><span class="line"><span class="comment">#&gt;torch.Size([2, 2])</span></span><br></pre></td></tr></table></figure><h3 id="TENSOR→张量"><a href="#TENSOR→张量" class="headerlink" title="TENSOR→张量"></a><strong>TENSOR→张量</strong></h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">TENSOR = torch.tensor([[[<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>],</span><br><span class="line">[<span class="number">3</span>, <span class="number">6</span>, <span class="number">9</span>],</span><br><span class="line">[<span class="number">2</span>, <span class="number">4</span>, <span class="number">6</span>]]])</span><br><span class="line">TENSOR</span><br><span class="line"><span class="comment">#&gt;tensor([[[1, 2, 3],</span></span><br><span class="line"><span class="comment">#&gt;         [3, 6, 9],</span></span><br><span class="line"><span class="comment">#&gt;         [2, 4, 6]]])</span></span><br><span class="line"></span><br><span class="line">TENSOR.ndim</span><br><span class="line"><span class="comment">#&gt;3</span></span><br><span class="line"></span><br><span class="line">TENSOR.shape</span><br><span class="line"><span class="comment">#&gt;torch.Size([1, 3, 3])</span></span><br><span class="line"><span class="comment">## 一维 3x3形状的张量</span></span><br><span class="line"></span><br><span class="line">TENSOR[<span class="number">0</span>]</span><br><span class="line"><span class="comment">#&gt;tensor([[1, 2, 3],</span></span><br><span class="line"><span class="comment">#&gt;        [3, 6, 9],</span></span><br><span class="line"><span class="comment">#&gt;        [2, 4, 6]])</span></span><br></pre></td></tr></table></figure><img src="/2024/08/14/PyTorch-26H-1/PyTorch-26H-1-19.png" class="" title="PyTorch-26H-1-19"><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">TENSOR = torch.tensor([[[<span class="number">1</span>, <span class="number">2</span>],</span><br><span class="line">[<span class="number">3</span>, <span class="number">6</span>],</span><br><span class="line">[<span class="number">2</span>, <span class="number">4</span>]]])</span><br><span class="line">TENSOR.ndim</span><br><span class="line"><span class="comment">#&gt;3</span></span><br><span class="line"></span><br><span class="line">TENSOR.shape</span><br><span class="line"><span class="comment">#&gt;torch.Size([1, 3, 2])</span></span><br><span class="line"></span><br><span class="line">TENSOR[<span class="number">0</span>]</span><br><span class="line"><span class="comment">#&gt;tensor([[1, 2],</span></span><br><span class="line"><span class="comment">#&gt;        [3, 6],</span></span><br><span class="line"><span class="comment">#&gt;        [2, 4]])</span></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">TENSOR = torch.tensor([[[<span class="number">1</span>, <span class="number">2</span>],</span><br><span class="line">[<span class="number">3</span>, <span class="number">6</span>],</span><br><span class="line">[<span class="number">2</span>, <span class="number">4</span>]],</span><br><span class="line">   [[<span class="number">1</span>, <span class="number">2</span>],</span><br><span class="line">    [<span class="number">3</span>, <span class="number">6</span>],</span><br><span class="line">    [<span class="number">2</span>, <span class="number">4</span>]]])</span><br><span class="line">TENSOR.ndim</span><br><span class="line"><span class="comment">#&gt;3</span></span><br><span class="line"></span><br><span class="line">TENSOR.shape</span><br><span class="line"><span class="comment">#&gt;torch.Size([2, 3, 2])</span></span><br><span class="line"></span><br><span class="line">TENSOR[<span class="number">0</span>]</span><br><span class="line"><span class="comment">#&gt;tensor([[1, 2],</span></span><br><span class="line"><span class="comment">#&gt;        [3, 6],</span></span><br><span class="line"><span class="comment">#&gt;        [2, 4]])</span></span><br><span class="line"></span><br><span class="line">TENSOR[<span class="number">1</span>]</span><br><span class="line"><span class="comment">#&gt;tensor([[1, 2],</span></span><br><span class="line"><span class="comment">#&gt;        [3, 6],</span></span><br><span class="line"><span class="comment">#&gt;        [2, 4]])</span></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">TENSOR = torch.tensor([[[<span class="number">1</span>, <span class="number">2</span>],</span><br><span class="line">[<span class="number">3</span>, <span class="number">6</span>],</span><br><span class="line">[<span class="number">2</span>, <span class="number">4</span>]],</span><br><span class="line">   [[<span class="number">1</span>, <span class="number">2</span>],</span><br><span class="line">    [<span class="number">3</span>, <span class="number">6</span>],</span><br><span class="line">    [<span class="number">2</span>, <span class="number">4</span>],</span><br><span class="line">    [<span class="number">2</span>, <span class="number">4</span>]]])</span><br><span class="line"><span class="comment"># ValueError: expected sequence of length 3 at dim 1 (got 4)</span></span><br></pre></td></tr></table></figure><div class="table-container"><table><thead><tr><th style="text-align:center">Name</th><th style="text-align:center">解释</th><th style="text-align:center">维度</th><th style="text-align:center"></th></tr></thead><tbody><tr><td style="text-align:center">scalar标量</td><td style="text-align:center">一个数字</td><td style="text-align:center">0</td><td style="text-align:center">Lower(a)</td></tr><tr><td style="text-align:center">vector向量</td><td style="text-align:center">带有方向的数字（例如带有方向的风速），但也可以有许多其他数字</td><td style="text-align:center">1</td><td style="text-align:center">Lower(y)</td></tr><tr><td style="text-align:center">matrix矩阵</td><td style="text-align:center">二维数字数组</td><td style="text-align:center">2</td><td style="text-align:center">Upper(Q)</td></tr><tr><td style="text-align:center">tensor张量</td><td style="text-align:center">n 维数字数组</td><td style="text-align:center">n,0 维张量是标量，1 维张量是矢量</td><td style="text-align:center">Upper(X)</td></tr></tbody></table></div><img src="/2024/08/14/PyTorch-26H-1/PyTorch-26H-1-20.png" class="" title="PyTorch-26H-1-20"><h2 id="Creating-tensors"><a href="#Creating-tensors" class="headerlink" title="Creating tensors"></a>Creating tensors</h2><p>Why random tensors?<br>Random tensors are important because the way many neural networks learn is that they start with tensors full of random numbers and then adjust those random numbers to better represent the data .<br>随机张量很重要，因为许多神经网络的学习方式是从充满随机数的张量开始，然后调整这些随机数以更好地表示数据。</p><p>start with random numbersy → look at data → update random numbers → look at data → update random numbers</p><ul><li>创建随机张量</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Create a random tensor of size (3, 4)</span></span><br><span class="line">random_tensor = torch.rand(size=(<span class="number">3</span>, <span class="number">4</span>))</span><br><span class="line">random_tensor, random_tensor.dtype</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">(tensor([[0.6541, 0.4807, 0.2162, 0.6168],</span><br><span class="line">         [0.4428, 0.6608, 0.6194, 0.8620],</span><br><span class="line">         [0.2795, 0.6055, 0.4958, 0.5483]]),</span><br><span class="line"> torch.float32)</span><br></pre></td></tr></table></figure><ul><li>创建随机图像张量</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Create a random tensor with similar shape to an image tensor</span></span><br><span class="line">random_image_size_tensor = torch.rand(size=(<span class="number">224</span>, <span class="number">224</span>, <span class="number">3</span>)) <span class="comment"># height, width, colour channels (R, G, B)</span></span><br><span class="line">random_image_size_tensor.shape, random_image_size_tensor.ndim</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">(torch.Size([224, 224, 3]), 3)</span><br></pre></td></tr></table></figure><p>图像表示为具有形状的张量，[3, 224, 224]这意味着[colour_channels, height, width]，图像具有3颜色通道（红色、绿色、蓝色）、像素高度224和像素宽度224。</p><img src="/2024/08/14/PyTorch-26H-1/PyTorch-26H-1-21.png" class="" title="PyTorch-26H-1-21"><h3 id="Zeros-and-ones"><a href="#Zeros-and-ones" class="headerlink" title="Zeros and ones"></a>Zeros and ones</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Create a tensor of all zeros</span></span><br><span class="line">zeros = torch.zeros(size=(<span class="number">3</span>, <span class="number">4</span>))</span><br><span class="line">zeros</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">tensor([[0., 0., 0., 0.],</span><br><span class="line">        [0., 0., 0., 0.],</span><br><span class="line">        [0., 0., 0., 0.]])</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Create a tensor of all ones</span></span><br><span class="line">ones = torch.ones(size=(<span class="number">3</span>, <span class="number">4</span>))</span><br><span class="line">ones</span><br><span class="line">ones.dtype</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">tensor([[1., 1., 1., 1.],</span><br><span class="line">        [1., 1., 1., 1.],</span><br><span class="line">        [1., 1., 1., 1.]])</span><br><span class="line">torch.float32</span><br></pre></td></tr></table></figure><h3 id="Creating-a-range-of-tensors-and-tensors-like"><a href="#Creating-a-range-of-tensors-and-tensors-like" class="headerlink" title="Creating a range of tensors and tensors-like"></a>Creating a range of tensors and tensors-like</h3><ul><li>数字范围</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Use torch.range() and get deprecated message, use torch.arange()</span></span><br><span class="line">one_to_ten = torch.arange(start=<span class="number">1</span>, end=<span class="number">11</span>, step=<span class="number">1</span>)</span><br><span class="line">one_to_ten</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tensor([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10])</span><br></pre></td></tr></table></figure><ul><li>相同形状填充零或一的张量</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Creating tensors like</span></span><br><span class="line">ten_zeros = torch.zeros_like(<span class="built_in">input</span>=one_to_ten)</span><br><span class="line">ten_zeros</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Creating tensors like</span></span><br><span class="line">ten_zeros = torch.oness_like(<span class="built_in">input</span>=one_to_ten)</span><br><span class="line">ten_zeros</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1])</span><br></pre></td></tr></table></figure><h2 id="Tensor-datatypes"><a href="#Tensor-datatypes" class="headerlink" title="Tensor datatypes"></a>Tensor datatypes</h2><p><a href="https://pytorch.org/docs/stable/tensors.html#data-types">torch.Tensor-Data tpyes</a></p><p><a href="https://en.wikipedia.org/wiki/Precision_(computer_science">Precision in computing</a>#:~:text=In%20computer%20science%2C%20the%20precision,used%20to%20express%20a%20value)</p><p>张量数据类型是使用 PyTorch 和深度学习时会遇到的 3 个大错误之一：</p><ol><li>张量数据类型不正确datatype</li><li>张量形状不正确shape</li><li>张量不在正确的设备上device</li></ol><ul><li>默认为float32</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Float 32 tensor</span></span><br><span class="line">float_32_tensor = torch.tensor([<span class="number">3.0</span>, <span class="number">6.0</span>, <span class="number">9.0</span>],</span><br><span class="line">                               dtype=<span class="literal">None</span>)</span><br><span class="line">float_32_tensor</span><br><span class="line">float_32_tensor.dtype</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">tensor([3., 6., 9.])</span><br><span class="line">torch.float32</span><br></pre></td></tr></table></figure><ul><li>修改默认数据类型</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Float 32 tensor</span></span><br><span class="line">float_32_tensor = torch.tensor([<span class="number">3.0</span>, <span class="number">6.0</span>, <span class="number">9.0</span>],</span><br><span class="line">                               dtype=torch.float16)</span><br><span class="line">float_32_tensor</span><br><span class="line">float_32_tensor.dtype</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">tensor([3., 6., 9.]), dtype=torch.float16</span><br><span class="line">torch.float16</span><br></pre></td></tr></table></figure><ul><li>设备和记录操作</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Float 32 tensor</span></span><br><span class="line">float_32_tensor = torch.tensor([<span class="number">3.0</span>, <span class="number">6.0</span>, <span class="number">9.0</span>],</span><br><span class="line">                               dtype=<span class="literal">None</span>,<span class="comment">#张量数据类型</span></span><br><span class="line">                               device=<span class="literal">None</span>,<span class="comment">#cpu or cuda</span></span><br><span class="line">                               requires_grad=<span class="literal">False</span>)<span class="comment">#是否使用此张量操作跟踪</span></span><br><span class="line">float_32_tensor</span><br><span class="line">float_32_tensor.dtype</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">tensor([3., 6., 9.])</span><br><span class="line">torch.float32</span><br></pre></td></tr></table></figure><ul><li>张量转换32 → 16</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">float_16_tensor = float_32_tensor.<span class="built_in">type</span>(torch.float16)</span><br><span class="line">float_16_tensor</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tensor([3., 6., 9.], dtype=torch.float16)</span><br></pre></td></tr></table></figure><ul><li>不同数据类型张量相乘</li></ul><p>进行了自动类型转换，向上转换</p><p>float16 × float32 → float32</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">test = float_16_tensor * float_32_tensor</span><br><span class="line">test, test.dtype</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">(tensor([ 9., 36., 81.]), torch.float32)</span><br></pre></td></tr></table></figure><p>int64 × float32 → float32</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">int_32_tensor = torch.tensor([<span class="number">3</span>, <span class="number">6</span>, <span class="number">9</span>], dtype=torch.int64)</span><br><span class="line">int_32_tensor, int_32_tensor.dtype</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">(tensor([3, 6, 9]), torch.int64)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">test = float_32_tensor * int_32_tensor</span><br><span class="line">test, test.dtype</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">(tensor([ 9., 36., 81.]), torch.float32)</span><br></pre></td></tr></table></figure><p>long × float32 → float32</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">int_32_tensor = torch.tensor([<span class="number">3</span>, <span class="number">6</span>, <span class="number">9</span>], dtype=torch.long)</span><br><span class="line">int_32_tensor, int_32_tensor.dtpye</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">(tensor([3, 6, 9]), torch.int64)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">test = float_32_tensor * int_32_tensor</span><br><span class="line">test, test.dtype</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">(tensor([ 9., 36., 81.]), torch.float32)</span><br></pre></td></tr></table></figure><h2 id="Tensor-attributes-information-about-tensors"><a href="#Tensor-attributes-information-about-tensors" class="headerlink" title="Tensor attributes (information about tensors)"></a>Tensor attributes (information about tensors)</h2><ul><li>shape/size()：形状</li><li>dtpye：数据类型</li><li>device：设备</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Create a tensor</span></span><br><span class="line">some_tensor = torch.rand(<span class="number">3</span>, <span class="number">4</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Find out details about it</span></span><br><span class="line"><span class="built_in">print</span>(some_tensor)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Shape of tensor: <span class="subst">&#123;some_tensor.shape&#125;</span>&quot;</span>)<span class="comment">#some_tensor.shape=some_tensor.size()</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Datatype of tensor: <span class="subst">&#123;some_tensor.dtype&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Device tensor is stored on: <span class="subst">&#123;some_tensor.device&#125;</span>&quot;</span>) <span class="comment"># default to CPU</span></span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">tensor([[0.4688, 0.0055, 0.8551, 0.0646],</span><br><span class="line">        [0.6538, 0.5157, 0.4071, 0.2109],</span><br><span class="line">        [0.9960, 0.3061, 0.9369, 0.7008]])</span><br><span class="line">Shape of tensor: torch.Size([3, 4])</span><br><span class="line">Datatype of tensor: torch.float32</span><br><span class="line">Device tensor is stored on: cpu</span><br></pre></td></tr></table></figure><h2 id="Manipulating-tensors"><a href="#Manipulating-tensors" class="headerlink" title="Manipulating tensors"></a>Manipulating tensors</h2><ul><li>Addition：加法</li><li>Substraction：减法</li><li>Multiplication (element-wise)：乘法</li><li>Division：除法</li><li>Matrix multiplication：矩阵乘法</li></ul><h3 id="basic-operations"><a href="#basic-operations" class="headerlink" title="basic operations"></a>basic operations</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Create a tensor of values and add a number to it</span></span><br><span class="line">tensor = torch.tensor([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>])</span><br><span class="line">tensor + <span class="number">10</span></span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tensor([11, 12, 13])</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Multiply it by 10</span></span><br><span class="line">tensor * <span class="number">10</span></span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tensor([10, 20, 30])</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># Tensors don&#x27;t change unless reassigned</span><br><span class="line">tensor</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tensor([1, 2, 3])</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Subtract and reassign</span></span><br><span class="line">tensor = tensor - <span class="number">10</span></span><br><span class="line">tensor</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tensor([-9, -8, -7])</span><br></pre></td></tr></table></figure><p>PyTorch也有一些内置函数，如<code>torch.mul()</code>(乘法的缩写)和<code>torch.add()</code>来执行基本操作。</p><h3 id="Matrix-multiplication"><a href="#Matrix-multiplication" class="headerlink" title="Matrix multiplication"></a>Matrix multiplication</h3><p><a href="https://www.mathsisfun.com/algebra/matrix-multiplying.html">How to Multiply Matrices</a></p><p>矩阵乘法需要记住的两个主要规则是：</p><ol><li><p><strong>内部尺寸必须匹配</strong>：<br>(3, 2) @ (3, 2)不起作用<br>(2, 3) @ (3, 2)会起作用<br>(3, 2) @ (2, 3)会起作用</p></li><li><p><strong>得到的矩阵具有外部尺寸的形状</strong>：<br>(2, 3) @ (3, 2)-&gt;(2, 2)<br>(3, 2) @ (2, 3)-&gt;(3, 3)</p></li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line">tensor = torch.tensor([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>])</span><br><span class="line">tensor.shape</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.Size([3])</span><br></pre></td></tr></table></figure><ul><li>元素乘法：</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tensor * tensor</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tensor([1, 4, 9])</span><br></pre></td></tr></table></figure><ul><li>矩阵乘法：</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">torch.matmul(tensor, tensor)</span><br><span class="line"><span class="comment"># 1 * 1 + 2 * 2 + 3 * 3</span></span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tensor(14)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">torch.mm(tensor, tensor)</span><br><span class="line"><span class="comment"># 1 * 1 + 2 * 2 + 3 * 3</span></span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tensor(14)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">tensor @ tensor</span><br><span class="line"><span class="comment"># 1 * 1 + 2 * 2 + 3 * 3</span></span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tensor(14)</span><br></pre></td></tr></table></figure><ul><li>内置<code>torch.matmul()</code>方法更快。</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">%%time</span><br><span class="line"><span class="comment"># Matrix multiplication by hand </span></span><br><span class="line"><span class="comment"># (avoid doing operations with for loops at all cost, they are computationally expensive)</span></span><br><span class="line">value = <span class="number">0</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(tensor)):</span><br><span class="line">  value += tensor[i] * tensor[i]</span><br><span class="line">value</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">CPU times: user 773 µs, sys: 0 ns, total: 773 µs</span><br><span class="line">Wall time: 499 µs</span><br><span class="line">tensor(14)</span><br><span class="line">````</span><br><span class="line"></span><br><span class="line">```python</span><br><span class="line"><span class="meta prompt_">%</span><span class="language-bash">%time</span></span><br><span class="line">torch.matmul(tensor, tensor)</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">CPU times: user 146 µs, sys: 83 µs, total: 229 µs</span><br><span class="line">Wall time: 171 µs</span><br><span class="line">tensor(14)</span><br></pre></td></tr></table></figure><h3 id="深度学习中最常见的错误之一（形状错误）"><a href="#深度学习中最常见的错误之一（形状错误）" class="headerlink" title="深度学习中最常见的错误之一（形状错误）"></a>深度学习中最常见的错误之一（形状错误）</h3><p><a href="http://matrixmultiplication.xyz/">matrixmultiplication矩阵可视化</a></p><p>由于深度学习的大部分内容是对矩阵进行乘法和执行运算，并且矩阵对于可以组合的形状和大小有严格的规则，因此在深度学习中遇到的最常见错误之一就是形状不匹配。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Shapes need to be in the right way  </span></span><br><span class="line">tensor_A = torch.tensor([[<span class="number">1</span>, <span class="number">2</span>],</span><br><span class="line">                         [<span class="number">3</span>, <span class="number">4</span>],</span><br><span class="line">                         [<span class="number">5</span>, <span class="number">6</span>]], dtype=torch.float32)</span><br><span class="line"></span><br><span class="line">tensor_B = torch.tensor([[<span class="number">7</span>, <span class="number">10</span>],</span><br><span class="line">                         [<span class="number">8</span>, <span class="number">11</span>], </span><br><span class="line">                         [<span class="number">9</span>, <span class="number">12</span>]], dtype=torch.float32)</span><br><span class="line"></span><br><span class="line">torch.matmul(tensor_A, tensor_B) <span class="comment"># (this will error)</span></span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">...</span><br><span class="line">RuntimeError: mat1 and mat2 shapes cannot be multiplied (3x2 and 3x2)</span><br></pre></td></tr></table></figure><p>通过矩阵的内部维度匹配来使矩阵乘法在tensor_A和之间进行tensor_B。</p><p><strong>使用转置（切换给定张量的维度）。</strong></p><p>您可以使用以下任一方式在 PyTorch 中执行转置：</p><ul><li><code>torch.transpose(input, dim0, dim1)</code>， 其中 <code>input</code> 是需要转置的张量， 和 <code>dim0</code> 是 <code>dim1</code> 需要交换的维度。</li><li><code>tensor.T</code>，<code>tensor</code> 是需要转置的张量。</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#tensor([[1., 2.],</span></span><br><span class="line"><span class="comment">#        [3., 4.],</span></span><br><span class="line"><span class="comment">#        [5., 6.]])</span></span><br><span class="line"><span class="comment">#tensor([[ 7., 10.],</span></span><br><span class="line"><span class="comment">#        [ 8., 11.],</span></span><br><span class="line"><span class="comment">#        [ 9., 12.]])</span></span><br><span class="line"><span class="built_in">print</span>(tensor_A)</span><br><span class="line"><span class="built_in">print</span>(tensor_B.T)</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">tensor([[1., 2.],</span><br><span class="line">        [3., 4.],</span><br><span class="line">        [5., 6.]])</span><br><span class="line">tensor([[ 7.,  8.,  9.],</span><br><span class="line">        [10., 11., 12.]])</span><br><span class="line">````</span><br><span class="line"></span><br><span class="line">```python</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">The operation works when tensor_B is transposed</span></span><br><span class="line">print(f&quot;Original shapes: tensor_A = &#123;tensor_A.shape&#125;, tensor_B = &#123;tensor_B.shape&#125;\n&quot;)</span><br><span class="line">print(f&quot;New shapes: tensor_A = &#123;tensor_A.shape&#125; (same as above), tensor_B.T = &#123;tensor_B.T.shape&#125;\n&quot;)</span><br><span class="line">print(f&quot;Multiplying: &#123;tensor_A.shape&#125; * &#123;tensor_B.T.shape&#125; &lt;- inner dimensions match\n&quot;)</span><br><span class="line">print(&quot;Output:\n&quot;)</span><br><span class="line">output = torch.matmul(tensor_A, tensor_B.T)</span><br><span class="line">print(output) </span><br><span class="line">print(f&quot;\nOutput shape: &#123;output.shape&#125;&quot;)</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">Original shapes: tensor_A = torch.Size([3, 2]), tensor_B = torch.Size([3, 2])</span><br><span class="line"></span><br><span class="line">New shapes: tensor_A = torch.Size([3, 2]) (same as above), tensor_B.T = torch.Size([2, 3])</span><br><span class="line"></span><br><span class="line">Multiplying: torch.Size([3, 2]) * torch.Size([2, 3]) &lt;- inner dimensions match</span><br><span class="line"></span><br><span class="line">Output:</span><br><span class="line"></span><br><span class="line">tensor([[ 27.,  30.,  33.],</span><br><span class="line">        [ 61.,  68.,  75.],</span><br><span class="line">        [ 95., 106., 117.]])</span><br><span class="line"></span><br><span class="line">Output shape: torch.Size([3, 3])</span><br></pre></td></tr></table></figure><img src="/2024/08/14/PyTorch-26H-1/PyTorch-26H-1-22.gif" class="" title="PyTorch-26H-1-22"><h3 id="像这样的矩阵乘法也称为两个矩阵的点积。"><a href="#像这样的矩阵乘法也称为两个矩阵的点积。" class="headerlink" title="像这样的矩阵乘法也称为两个矩阵的点积。"></a>像这样的矩阵乘法也称为两个矩阵的点积。</h3><p>神经网络充满了矩阵乘法和点积。</p><p>该<code>torch.nn.Linear()</code>模块（我们稍后会看到它的实际作用），也称为前馈层或全连接层，实现输入<code>x</code>和权重矩阵之间的矩阵乘法<code>A</code>。</p><script type="math/tex; mode=display">y = x\cdot{A^T} + b</script><ul><li>x是该层的输入（深度学习是将多个层<code>torch.nn.Linear()</code>和其他层堆叠在一起）。</li><li>A是由该层创建的权重矩阵，它开始是随机数，随着神经网络学习更好地表示数据中的模式，这些随机数会进行调整（请注意“ T”，这是因为权重矩阵被转置了）。</li><li>注意：您可能还经常看到<code>W</code>或另一个字母，<code>X</code>用于展示权重矩阵。</li><li><code>b</code>是用于稍微偏移权重和输入的偏差项。</li><li><code>y</code>是输出（对输入进行操作以期发现其中的模式）。</li></ul><p>这是一个线性函数（你可能在高中或其他地方见过类似 $y = mx+b$ 的函数），可以用来画一条直线！</p><p>让我们尝试一下线性层。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Since the linear layer starts with a random weights matrix, let&#x27;s make it reproducible (more on this later)由于线性层以随机权重矩阵开始，因此让我们使其可重现</span></span><br><span class="line">torch.manual_seed(<span class="number">42</span>)</span><br><span class="line"><span class="comment"># This uses matrix multiplication使用矩阵乘法</span></span><br><span class="line">linear = torch.nn.Linear(in_features=<span class="number">2</span>, <span class="comment"># in_features = matches inner dimension of input 匹配输入的内维度</span></span><br><span class="line">                         out_features=<span class="number">6</span>) <span class="comment"># out_features = describes outer value 描述外部值</span></span><br><span class="line">x = tensor_A</span><br><span class="line">output = linear(x)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Input shape: <span class="subst">&#123;x.shape&#125;</span>\n&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Output:\n<span class="subst">&#123;output&#125;</span>\n\nOutput shape: <span class="subst">&#123;output.shape&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">Input shape: torch.Size([3, 2])</span><br><span class="line"></span><br><span class="line">Output:</span><br><span class="line">tensor([[2.2368, 1.2292, 0.4714, 0.3864, 0.1309, 0.9838],</span><br><span class="line">        [4.4919, 2.1970, 0.4469, 0.5285, 0.3401, 2.4777],</span><br><span class="line">        [6.7469, 3.1648, 0.4224, 0.6705, 0.5493, 3.9716]],</span><br><span class="line">       grad_fn=&lt;AddmmBackward0&gt;)</span><br><span class="line"></span><br><span class="line">Output shape: torch.Size([3, 6])</span><br></pre></td></tr></table></figure><h2 id="Finding-the-min-max-mean-amp-sum"><a href="#Finding-the-min-max-mean-amp-sum" class="headerlink" title="Finding the min, max, mean &amp; sum"></a>Finding the min, max, mean &amp; sum</h2><h3 id="最小最大平均求和"><a href="#最小最大平均求和" class="headerlink" title="最小最大平均求和"></a>最小最大平均求和</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Create a tensor</span></span><br><span class="line">x = torch.arange(<span class="number">0</span>, <span class="number">100</span>, <span class="number">10</span>)</span><br><span class="line">x</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tensor([ 0, 10, 20, 30, 40, 50, 60, 70, 80, 90])</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Minimum: <span class="subst">&#123;x.<span class="built_in">min</span>()&#125;</span>&quot;</span>)<span class="comment">#torch.min(x)</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Maximum: <span class="subst">&#123;x.<span class="built_in">max</span>()&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># print(f&quot;Mean: &#123;x.mean()&#125;&quot;) # this will error</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Mean: <span class="subst">&#123;x.<span class="built_in">type</span>(torch.float32).mean()&#125;</span>&quot;</span>) <span class="comment"># won&#x27;t work without float datatype</span></span><br><span class="line"><span class="comment"># torch.mean(x.type(torch.float32))</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Sum: <span class="subst">&#123;x.<span class="built_in">sum</span>()&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">Minimum: 0</span><br><span class="line">Maximum: 90</span><br><span class="line">Mean: 45.0</span><br><span class="line">Sum: 450</span><br></pre></td></tr></table></figure><h3 id="查找最大最小索引位置"><a href="#查找最大最小索引位置" class="headerlink" title="查找最大最小索引位置"></a>查找最大最小索引位置</h3><p><code>torch.argmax()</code>，<code>torch.argmin()</code>。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Create a tensor</span></span><br><span class="line">tensor = torch.arange(<span class="number">10</span>, <span class="number">100</span>, <span class="number">10</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Tensor: <span class="subst">&#123;tensor&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Returns index of max and min values</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Index where max value occurs: <span class="subst">&#123;tensor.argmax()&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Index where min value occurs: <span class="subst">&#123;tensor.argmin()&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Tensor: tensor([10, 20, 30, 40, 50, 60, 70, 80, 90])</span><br><span class="line">Index where max value occurs: 8</span><br><span class="line">Index where min value occurs: 0</span><br></pre></td></tr></table></figure><h3 id="更改数据类型"><a href="#更改数据类型" class="headerlink" title="更改数据类型"></a>更改数据类型</h3><p><code>torch.Tensor.type(dtype=None)</code></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Create a tensor and check its datatype</span></span><br><span class="line">tensor = torch.arange(<span class="number">10.</span>, <span class="number">100.</span>, <span class="number">10.</span>)</span><br><span class="line">tensor.dtype</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.float32</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Create a float16 tensor</span></span><br><span class="line">tensor_float16 = tensor.<span class="built_in">type</span>(torch.float16)</span><br><span class="line">tensor_float16</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tensor([10., 20., 30., 40., 50., 60., 70., 80., 90.], dtype=torch.float16)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Create an int8 tensor</span></span><br><span class="line">tensor_int8 = tensor.<span class="built_in">type</span>(torch.int8)</span><br><span class="line">tensor_int8</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tensor([10, 20, 30, 40, 50, 60, 70, 80, 90], dtype=torch.int8)</span><br></pre></td></tr></table></figure><blockquote><p>数字越小（例如 32、16、8），计算机存储的值就越不精确。存储量越少，通常计算速度越快，整体模型就越小。基于移动端的神经网络通常使用 8 位整数，与 float32 相比，它们更小、运行速度更快，但准确度较低。</p></blockquote><p><a href="https://pytorch.org/docs/stable/tensors.html">torch.Tensor-doc</a></p><h2 id="重塑、视图、堆叠、压缩、解压、置换"><a href="#重塑、视图、堆叠、压缩、解压、置换" class="headerlink" title="重塑、视图、堆叠、压缩、解压、置换"></a>重塑、视图、堆叠、压缩、解压、置换</h2><ul><li>Reshaping - reshapes an input tensor to a defined shape</li><li>View - return a view of a input tensor of certain shape but keep the same memory as the original tensor</li><li>Stacking - combine multiple tnesors on top of each other (vstack) or side by side(hstack)</li><li>Squeeze - removes all 1 dimensions from a tensor</li><li>Unsqueeze - add a 1 dimensions to a target tensor</li><li><p>Permute - Return a view of the input with dimensions permuted(swapped) in a certain way</p></li><li><p>重塑 - 将输入张量重塑为定义的形状</p></li><li>视图 - 返回特定形状的输入张量的视图，但保留与原始张量相同的内存</li><li>堆叠 - 将多个张量组合在一起（vstack）或并排组合（hstack）</li><li>压缩 - 从张量中删除所有 1 维</li><li>解压 - 向目标张量添加 1 维</li><li>置换 - 返回以特定方式置换（交换）维度的输入视图</li></ul><div class="table-container"><table><thead><tr><th style="text-align:center">方法</th><th style="text-align:center">描述</th></tr></thead><tbody><tr><td style="text-align:center">torch.reshape(input, shape)</td><td style="text-align:center">重塑input为shape（如果兼容），也可以使用torch.Tensor.reshape()。</td></tr><tr><td style="text-align:center">Tensor.view(shape)</td><td style="text-align:center">shape返回与原始张量不同的但共享相同数据的原始张量的视图。</td></tr><tr><td style="text-align:center">torch.stack(tensors, dim=0)</td><td style="text-align:center">沿新维度（dim）连接一系列张量（tensor），所有tensors必须大小相同。</td></tr><tr><td style="text-align:center">torch.squeeze(input)</td><td style="text-align:center">挤压input以删除所有具有值的维度1。</td></tr><tr><td style="text-align:center">torch.unsqueeze(input, dim)</td><td style="text-align:center">返回在 处添加input的维度值。1dim</td></tr><tr><td style="text-align:center">torch.permute(input, dims)</td><td style="text-align:center">返回原始输入的视图，其尺寸已置换（重新排列）为 dims。</td></tr></tbody></table></div><h3 id="Reshaping-重塑"><a href="#Reshaping-重塑" class="headerlink" title="Reshaping-重塑"></a>Reshaping-重塑</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Create a tensor</span></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line">x = torch.arange(<span class="number">1.</span>, <span class="number">8.</span>)</span><br><span class="line">x, x.shape</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">(tensor([1., 2., 3., 4., 5., 6., 7.]), torch.Size([7]))</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Add an extra dimension</span></span><br><span class="line">x_reshaped = x.reshape(<span class="number">1</span>, <span class="number">7</span>)</span><br><span class="line">x_reshaped, x_reshaped.shape</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">(tensor([[1., 2., 3., 4., 5., 6., 7.]]), torch.Size([1, 7]))</span><br></pre></td></tr></table></figure><p><code>x.reshape(1, 8)</code> → error，因为元素数和原来数组不相同。</p><p><code>x.reshape(2, 7)</code> → error，因为在不增加元素数量的情况情况下将元素数量增加一倍。</p><p><code>x.reshape(7, 1)</code> → 可以运行，行列转换。</p><h3 id="View-视图"><a href="#View-视图" class="headerlink" title="View-视图"></a>View-视图</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Change view (keeps same data as original but changes view)</span></span><br><span class="line"><span class="comment"># See more: https://stackoverflow.com/a/54507446/7900723</span></span><br><span class="line">z = x.view(<span class="number">1</span>, <span class="number">7</span>)</span><br><span class="line">z, z.shape</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">(tensor([[1., 2., 3., 4., 5., 6., 7.]]), torch.Size([1, 7]))</span><br></pre></td></tr></table></figure><p>改变张量的视图实际上只会创建同<code>torch.view()</code>一张量的新视图。</p><p>因此<strong>改变视图也会改变原始张量。</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Changing z changes x</span></span><br><span class="line">z[:, <span class="number">0</span>] = <span class="number">5</span></span><br><span class="line">z, x</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">(tensor([[5., 2., 3., 4., 5., 6., 7.]]), tensor([5., 2., 3., 4., 5., 6., 7.]))</span><br></pre></td></tr></table></figure><h3 id="Stacking-堆叠"><a href="#Stacking-堆叠" class="headerlink" title="Stacking-堆叠"></a>Stacking-堆叠</h3><p>新的张量堆叠在其自身之上五次，<code>torch.stack()</code>。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Stack tensors on top of each other</span></span><br><span class="line">x_stacked = torch.stack([x, x, x, x], dim=<span class="number">0</span>)</span><br><span class="line">x_stacked</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">tensor([[5., 2., 3., 4., 5., 6., 7.],</span><br><span class="line">        [5., 2., 3., 4., 5., 6., 7.],</span><br><span class="line">        [5., 2., 3., 4., 5., 6., 7.],</span><br><span class="line">        [5., 2., 3., 4., 5., 6., 7.]])</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Stack tensors on top of each other</span></span><br><span class="line">x_stacked = torch.stack([x, x, x, x], dim=<span class="number">1</span>)</span><br><span class="line">x_stacked</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">tensor([[5., 5., 5., 5.],</span><br><span class="line">        [2., 2., 2., 2.],</span><br><span class="line">        [3., 3., 3., 3.],</span><br><span class="line">        [4., 4., 4., 4.],</span><br><span class="line">        [5., 5., 5., 5.],</span><br><span class="line">        [6., 6., 6., 6.],</span><br><span class="line">        [7., 7., 7., 7.]])</span><br></pre></td></tr></table></figure><p><code>x_stacked = torch.stack([x, x, x, x], dim=2)</code> 维度为2不行，因为原来的形状与二维不兼容。</p><h4 id="torch-stack-和-torch-vstack-和-torch-hstack"><a href="#torch-stack-和-torch-vstack-和-torch-hstack" class="headerlink" title="torch.stack 和 torch.vstack 和 torch.hstack"></a>torch.stack 和 torch.vstack 和 torch.hstack</h4><ul><li>stack</li></ul><p><a href="https://pytorch.org/docs/main/generated/torch.stack.html">torch.stack</a></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.stack(tensors, dim=0, *, out=None) → Tensor</span><br></pre></td></tr></table></figure><p>沿新维度连接一系列张量。</p><p>所有张量都需要具有相同的大小。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">x = torch.randn(<span class="number">2</span>, <span class="number">3</span>)</span><br><span class="line">x, x.size()</span><br><span class="line"></span><br><span class="line">x1 = torch.stack((x, x)) <span class="comment"># same as torch.stack((x, x), dim=0)</span></span><br><span class="line">x1, x1.size()</span><br><span class="line"></span><br><span class="line">x2 = torch.stack((x, x), dim=<span class="number">1</span>)</span><br><span class="line">x2, x2.size()</span><br><span class="line"></span><br><span class="line">x3 = torch.stack((x, x), dim=<span class="number">2</span>)</span><br><span class="line">x3, x3.size()</span><br><span class="line"></span><br><span class="line">x4 = torch.stack((x, x), dim=-<span class="number">1</span>)</span><br><span class="line">x4, x4.size()</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line">(tensor([[ 0.1801,  0.1566, -2.0349],</span><br><span class="line">         [ 0.0183, -0.0088, -0.6409]]),</span><br><span class="line"> torch.Size([2, 3]))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">(tensor([[[ 1.3646, -0.4994, -0.6540],</span><br><span class="line">          [-0.3804, -0.2373,  1.8952]],</span><br><span class="line"> </span><br><span class="line">         [[ 1.3646, -0.4994, -0.6540],</span><br><span class="line">          [-0.3804, -0.2373,  1.8952]]]),</span><br><span class="line"> torch.Size([2, 2, 3]))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">(tensor([[[ 1.3646, -0.4994, -0.6540],</span><br><span class="line">          [ 1.3646, -0.4994, -0.6540]],</span><br><span class="line"> </span><br><span class="line">         [[-0.3804, -0.2373,  1.8952],</span><br><span class="line">          [-0.3804, -0.2373,  1.8952]]]),</span><br><span class="line"> torch.Size([2, 2, 3]))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">(tensor([[[ 1.3646,  1.3646],</span><br><span class="line">          [-0.4994, -0.4994],</span><br><span class="line">          [-0.6540, -0.6540]],</span><br><span class="line"> </span><br><span class="line">         [[-0.3804, -0.3804],</span><br><span class="line">          [-0.2373, -0.2373],</span><br><span class="line">          [ 1.8952,  1.8952]]]),</span><br><span class="line"> torch.Size([2, 3, 2]))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">(tensor([[[ 1.3646,  1.3646],</span><br><span class="line">          [-0.4994, -0.4994],</span><br><span class="line">          [-0.6540, -0.6540]],</span><br><span class="line"> </span><br><span class="line">         [[-0.3804, -0.3804],</span><br><span class="line">          [-0.2373, -0.2373],</span><br><span class="line">          [ 1.8952,  1.8952]]]),</span><br><span class="line"> torch.Size([2, 3, 2]))</span><br></pre></td></tr></table></figure><ul><li>vstack</li></ul><p><a href="https://pytorch.org/docs/stable/generated/torch.vstack.html">torch.vstack</a></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.vstack(tensors, *, out=<span class="literal">None</span>) → Tensor</span><br></pre></td></tr></table></figure><p>按垂直顺序（按行）堆叠张量。</p><p>这相当于在所有一维张量被重塑后沿第一个轴进行连接<code>torch.atleast_2d()</code>。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">a = torch.tensor([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>])</span><br><span class="line">b = torch.tensor([<span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>])</span><br><span class="line">torch.vstack((a,b))</span><br><span class="line"></span><br><span class="line">a = torch.tensor([[<span class="number">1</span>],[<span class="number">2</span>],[<span class="number">3</span>]])</span><br><span class="line">b = torch.tensor([[<span class="number">4</span>],[<span class="number">5</span>],[<span class="number">6</span>]])</span><br><span class="line">torch.vstack((a,b))</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">tensor([[1, 2, 3],</span><br><span class="line">        [4, 5, 6]])</span><br><span class="line"></span><br><span class="line">tensor([[1],</span><br><span class="line">        [2],</span><br><span class="line">        [3],</span><br><span class="line">        [4],</span><br><span class="line">        [5],</span><br><span class="line">        [6]])</span><br></pre></td></tr></table></figure><ul><li>hstack</li></ul><p><a href="https://pytorch.org/docs/stable/generated/torch.hstack.html">torch.hstack</a></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.hstack(tensors, *, out=<span class="literal">None</span>) → Tensor</span><br></pre></td></tr></table></figure><p>按水平顺序（按列）堆叠张量。</p><p>这相当于沿第一个轴对一维张量进行连接，并沿第二个轴对所有其他张量进行连接。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">a = torch.tensor([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>])</span><br><span class="line">b = torch.tensor([<span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>])</span><br><span class="line">torch.hstack((a,b))</span><br><span class="line"></span><br><span class="line">a = torch.tensor([[<span class="number">1</span>],[<span class="number">2</span>],[<span class="number">3</span>]])</span><br><span class="line">b = torch.tensor([[<span class="number">4</span>],[<span class="number">5</span>],[<span class="number">6</span>]])</span><br><span class="line">torch.hstack((a,b))</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">tensor([1, 2, 3, 4, 5, 6])</span><br><span class="line"></span><br><span class="line">tensor([[1, 4],</span><br><span class="line">        [2, 5],</span><br><span class="line">        [3, 6]])</span><br></pre></td></tr></table></figure><h3 id="Squeeze-压缩"><a href="#Squeeze-压缩" class="headerlink" title="Squeeze-压缩"></a>Squeeze-压缩</h3><p>从张量中删除所有单一维度（将张量压缩为仅具有超过 1 的维度）</p><p><a href="https://pytorch.org/docs/main/generated/torch.squeeze.html">torch.squeeze</a></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.squeeze(<span class="built_in">input</span>: Tensor, dim: <span class="type">Optional</span>[<span class="type">Union</span>[<span class="built_in">int</span>, <span class="type">List</span>[<span class="built_in">int</span>]]]) → Tensor</span><br></pre></td></tr></table></figure><p>返回已删除所有指定尺寸为input1的张量。</p><p>input：(A × 1 × B × C × 1 × D)<br>method：input.squeeze()<br>output：(A × B × C × D)</p><p>input：(A × 1 × B)<br>method：squeeze(input, 0)<br>output：(A × 1 × B)</p><p>input：(A × 1 × B)<br>method：squeeze(input, 1)<br>output：(A × B)</p><blockquote><p>返回的张量与输入张量共享存储，因此改变一个张量的内容也会改变另一个张量的内容。<br>果张量的批处理维度为 1，则squeeze(input) 也会删除批处理维度，这可能会导致意外错误。</p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Previous tensor: <span class="subst">&#123;x_reshaped&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Previous shape: <span class="subst">&#123;x_reshaped.shape&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Remove extra dimension from x_reshaped</span></span><br><span class="line">x_squeezed = x_reshaped.squeeze()</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;\nNew tensor: <span class="subst">&#123;x_squeezed&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;New shape: <span class="subst">&#123;x_squeezed.shape&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">Previous tensor: tensor([[5., 2., 3., 4., 5., 6., 7.]])</span><br><span class="line">Previous shape: torch.Size([1, 7])</span><br><span class="line"></span><br><span class="line">New tensor: tensor([5., 2., 3., 4., 5., 6., 7.])</span><br><span class="line">New shape: torch.Size([7])</span><br></pre></td></tr></table></figure><h3 id="Unsqueeze-解压"><a href="#Unsqueeze-解压" class="headerlink" title="Unsqueeze-解压"></a>Unsqueeze-解压</h3><p>在特定索引处添加维度值 1</p><p><a href="https://pytorch.org/docs/main/generated/torch.unsqueeze.html">torch.unsqueeze</a></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.unsqueeze(<span class="built_in">input</span>, dim) → Tensor</span><br></pre></td></tr></table></figure><p>返回在指定位置插入一个维度为一的新张量。</p><p>返回的张量与该张量共享相同的底层数据。</p><p>可以使用dim范围内的值。负数将对应于= 处的应用。[-input.dim() - 1, input.dim() + 1)dimunsqueeze()dimdim + input.dim() + 1</p><p>可以使用 <code>[-input.dim() - 1, input.dim() + 1)</code> 范围内的 dim 值。负 dim 将对应于在 <code>dim = dim + input.dim() + 1</code> 处应用的 unsqueeze()。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Previous tensor: <span class="subst">&#123;x_squeezed&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Previous shape: <span class="subst">&#123;x_squeezed.shape&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">## Add an extra dimension with unsqueeze</span></span><br><span class="line">x_unsqueezed = x_squeezed.unsqueeze(dim=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;\nNew tensor: <span class="subst">&#123;x_unsqueezed&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;New shape: <span class="subst">&#123;x_unsqueezed.shape&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line">x_unsqueezed = x_squeezed.unsqueeze(dim=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;\nNew tensor: <span class="subst">&#123;x_unsqueezed&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;New shape: <span class="subst">&#123;x_unsqueezed.shape&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">Previous tensor: tensor([5., 2., 3., 4., 5., 6., 7.])</span><br><span class="line">Previous shape: torch.Size([7])</span><br><span class="line"></span><br><span class="line">New tensor: tensor([[5., 2., 3., 4., 5., 6., 7.]])</span><br><span class="line">New shape: torch.Size([1, 7])</span><br><span class="line"></span><br><span class="line">New tensor: tensor([[5.],</span><br><span class="line">[2.],</span><br><span class="line">                    [3.],</span><br><span class="line">                    [4.],</span><br><span class="line">                    [5.],</span><br><span class="line">                    [6.],</span><br><span class="line">                    [7.]])</span><br><span class="line">New shape: torch.Size([7, 1])</span><br></pre></td></tr></table></figure><h3 id="Permute-置换"><a href="#Permute-置换" class="headerlink" title="Permute-置换"></a>Permute-置换</h3><p>重新排列轴值的顺序</p><p><a href="https://pytorch.org/docs/stable/generated/torch.permute.html">torch.permute</a></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.permute(<span class="built_in">input</span>, dims) → Tensor</span><br></pre></td></tr></table></figure><p>返回维度已排列的原始张量输入的视图。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>x = torch.randn(<span class="number">2</span>, <span class="number">3</span>, <span class="number">5</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>x.size()</span><br><span class="line">torch.Size([<span class="number">2</span>, <span class="number">3</span>, <span class="number">5</span>])</span><br><span class="line"></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>torch.permute(x, (<span class="number">2</span>, <span class="number">0</span>, <span class="number">1</span>)).size()</span><br><span class="line">torch.Size([<span class="number">5</span>, <span class="number">2</span>, <span class="number">3</span>])</span><br></pre></td></tr></table></figure></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Create tensor with specific shape</span></span><br><span class="line">x_original = torch.rand(size=(<span class="number">224</span>, <span class="number">224</span>, <span class="number">3</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># Permute the original tensor to rearrange the axis order</span></span><br><span class="line">x_permuted = x_original.permute(<span class="number">2</span>, <span class="number">0</span>, <span class="number">1</span>) <span class="comment"># shifts axis 0-&gt;1, 1-&gt;2, 2-&gt;0</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Previous shape: <span class="subst">&#123;x_original.shape&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;New shape: <span class="subst">&#123;x_permuted.shape&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Previous shape: torch.Size([224, 224, 3])</span><br><span class="line">New shape: torch.Size([3, 224, 224])</span><br></pre></td></tr></table></figure><blockquote><p>因为排列返回一个视图（与原始共享相同的数据），所以排列张量中的值将与原始张量相同，如果更改视图中的值，它将更改原始的值。</p></blockquote><h2 id="Selecting-data-indexing"><a href="#Selecting-data-indexing" class="headerlink" title="Selecting data (indexing)"></a>Selecting data (indexing)</h2><p>从张量中选择特定数据（例如，仅第一列或第二行）。可以使用索引。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Create a tensor </span></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line">x = torch.arange(<span class="number">1</span>, <span class="number">10</span>).reshape(<span class="number">1</span>, <span class="number">3</span>, <span class="number">3</span>)</span><br><span class="line">x, x.shape</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">(tensor([[[1, 2, 3],</span><br><span class="line">          [4, 5, 6],</span><br><span class="line">          [7, 8, 9]]]),</span><br><span class="line"> torch.Size([1, 3, 3]))</span><br></pre></td></tr></table></figure><p>索引值从外部维度 -&gt; 内部维度（检查方括号）</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Let&#x27;s index bracket by bracket</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;First square bracket:\n<span class="subst">&#123;x[<span class="number">0</span>]&#125;</span>&quot;</span>) </span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Second square bracket: <span class="subst">&#123;x[<span class="number">0</span>][<span class="number">0</span>]&#125;</span>&quot;</span>) </span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Third square bracket: <span class="subst">&#123;x[<span class="number">0</span>][<span class="number">0</span>][<span class="number">0</span>]&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">First square bracket:</span><br><span class="line">tensor([[1, 2, 3],</span><br><span class="line">        [4, 5, 6],</span><br><span class="line">        [7, 8, 9]])</span><br><span class="line">Second square bracket: tensor([1, 2, 3])</span><br><span class="line">Third square bracket: 1</span><br></pre></td></tr></table></figure><p><code>:</code>指定“此维度中的所有值”，然后使用逗号 ( <code>,</code>) 添加另一个维度。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Get all values of 0th dimension and the 0 index of 1st dimension, 获取第 0 维的所有值以及第 1 维的 0 索引</span></span><br><span class="line">x[:, <span class="number">0</span>]</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tensor([[1, 2, 3]])</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Get all values of 0th &amp; 1st dimensions but only index 1 of 2nd dimension, 获取第 0 维和第 1 维的所有值，但仅获取第 2 维的索引 1</span></span><br><span class="line">x[:, :, <span class="number">1</span>]</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tensor([[2, 5, 8]])</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Get all values of the 0 dimension but only the 1 index value of the 1st and 2nd dimension,获取 0 维的所有值，但仅获取第 1 维和第 2 维的 1 索引值</span></span><br><span class="line">x[:, <span class="number">1</span>, <span class="number">1</span>]</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tensor([5])</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Get index 0 of 0th and 1st dimension and all values of 2nd dimension,获取第 0 维和第 1 维的索引 0 以及第 2 维的所有值</span></span><br><span class="line">x[<span class="number">0</span>, <span class="number">0</span>, :] <span class="comment"># same as x[0][0]</span></span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tensor([1, 2, 3])</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Index on x to return 9</span></span><br><span class="line"><span class="built_in">print</span>(x[<span class="number">0</span>][<span class="number">2</span>][<span class="number">2</span>])</span><br><span class="line"><span class="comment">#x[0, 2, 2]</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Index on x to return 3, 6, 9</span></span><br><span class="line"><span class="built_in">print</span>(x[:, :, <span class="number">2</span>])</span><br><span class="line"><span class="comment"># x[0, :, 2]</span></span><br></pre></td></tr></table></figure><h2 id="PyTorch-tensors-and-NumPy"><a href="#PyTorch-tensors-and-NumPy" class="headerlink" title="PyTorch tensors and NumPy"></a>PyTorch tensors and NumPy</h2><p>NumPy 是一个流行的 Python 数值计算库，因此 PyTorch 具有与其良好交互的功能。</p><p>从 NumPy 到 PyTorch（以及返回）需要使用的两种主要方法是：</p><ul><li><code>torch.from_numpy(ndarray)</code> ： NumPy 数组 -&gt; PyTorch 张量。</li><li><code>torch.Tensor.numpy()</code> ： PyTorch 张量 -&gt; NumPy 数组。</li></ul><h3 id="NumPy-array-to-tensor"><a href="#NumPy-array-to-tensor" class="headerlink" title="NumPy array to tensor"></a>NumPy array to tensor</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># NumPy array to tensor</span></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">array = np.arange(<span class="number">1.0</span>, <span class="number">8.0</span>)</span><br><span class="line">tensor = torch.from_numpy(array)</span><br><span class="line"></span><br><span class="line">array, tensor</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">(array([1., 2., 3., 4., 5., 6., 7.]),</span><br><span class="line"> tensor([1., 2., 3., 4., 5., 6., 7.], dtype=torch.float64))</span><br></pre></td></tr></table></figure><p>默认情况下，NumPy 数组是使用数据类型创建的float64，如果将其转换为 PyTorch 张量，将保留相同的数据类型（如上）。</p><p>许多 PyTorch 计算默认使用float32。</p><p>转换 NumPy 数组 (float64) -&gt; PyTorch 张量 (float64) -&gt; PyTorch 张量 (float32)，使用<code>tensor = torch.from_numpy(array).type(torch.float32)</code>。</p><h3 id="改变数组，张量不变"><a href="#改变数组，张量不变" class="headerlink" title="改变数组，张量不变"></a>改变数组，张量不变</h3><p>tensor上面重新分配了</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 改变数组，保留张量数组</span></span><br><span class="line"><span class="comment"># Change the array, keep the tensor</span></span><br><span class="line">array = array + <span class="number">1</span></span><br><span class="line">array, tensor</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">(array([2., 3., 4., 5., 6., 7., 8.]),</span><br><span class="line"> tensor([1., 2., 3., 4., 5., 6., 7.], dtype=torch.float64))</span><br></pre></td></tr></table></figure><h3 id="Tensor-to-NumPy-array"><a href="#Tensor-to-NumPy-array" class="headerlink" title="Tensor to NumPy array"></a>Tensor to NumPy array</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Tensor to NumPy array</span></span><br><span class="line">tensor = torch.ones(<span class="number">7</span>) <span class="comment"># create a tensor of ones with dtype=float32</span></span><br><span class="line">numpy_tensor = tensor.numpy() <span class="comment"># will be dtype=float32 unless changed</span></span><br><span class="line">tensor, numpy_tensor</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">(tensor([1., 1., 1., 1., 1., 1., 1.]),</span><br><span class="line"> array([1., 1., 1., 1., 1., 1., 1.], dtype=float32))</span><br></pre></td></tr></table></figure><h3 id="改变张量，数组不变"><a href="#改变张量，数组不变" class="headerlink" title="改变张量，数组不变"></a>改变张量，数组不变</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Change the tensor, keep the array the same</span></span><br><span class="line">tensor = tensor + <span class="number">1</span></span><br><span class="line">tensor, numpy_tensor</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">(tensor([2., 2., 2., 2., 2., 2., 2.]),</span><br><span class="line"> array([1., 1., 1., 1., 1., 1., 1.], dtype=float32))</span><br></pre></td></tr></table></figure><h2 id="Reproducibility"><a href="#Reproducibility" class="headerlink" title="Reproducibility"></a>Reproducibility</h2><p><a href="https://pytorch.org/docs/stable/notes/randomness.html">PyTorch-Reproducibility</a></p><p><a href="https://en.wikipedia.org/wiki/Random_seed">Random seed-WiKi</a></p><p>伪随机性。</p><p>计算机的设计从根本上来说就是确定性的（每个步骤都是可预测的），所以它们产生的随机性是模拟随机性。</p><p>神经网络从随机数开始描述数据中的模式（这些数字是糟糕的描述），并尝试使用张量运算（以及一些我们尚未讨论的其他内容）来改进这些随机数，以更好地描述数据中的模式。</p><p>流程：start with random numbers -&gt; tensor operations -&gt; try to make better (again and again and again)</p><p>尽管随机性很好而且很强大，但有时还是希望随机性少一点，因此可以进行可重复的实验。</p><p>A计算机上运行与B计算机上运行相同的代码是否可以获得相同（或非常相似）的结果。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line"><span class="comment"># Create two random tensors</span></span><br><span class="line">random_tensor_A = torch.rand(<span class="number">3</span>, <span class="number">4</span>)</span><br><span class="line">random_tensor_B = torch.rand(<span class="number">3</span>, <span class="number">4</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Tensor A:\n<span class="subst">&#123;random_tensor_A&#125;</span>\n&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Tensor B:\n<span class="subst">&#123;random_tensor_B&#125;</span>\n&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Does Tensor A equal Tensor B? (anywhere)&quot;</span>)</span><br><span class="line">random_tensor_A == random_tensor_B</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">Tensor A:</span><br><span class="line">tensor([[0.8016, 0.3649, 0.6286, 0.9663],</span><br><span class="line">        [0.7687, 0.4566, 0.5745, 0.9200],</span><br><span class="line">        [0.3230, 0.8613, 0.0919, 0.3102]])</span><br><span class="line"></span><br><span class="line">Tensor B:</span><br><span class="line">tensor([[0.9536, 0.6002, 0.0351, 0.6826],</span><br><span class="line">        [0.3743, 0.5220, 0.1336, 0.9666],</span><br><span class="line">        [0.9754, 0.8474, 0.8988, 0.1105]])</span><br><span class="line"></span><br><span class="line">Does Tensor A equal Tensor B? (anywhere)</span><br><span class="line">tensor([[False, False, False, False],</span><br><span class="line">        [False, False, False, False],</span><br><span class="line">        [False, False, False, False]])</span><br></pre></td></tr></table></figure><p>创建两个具有相同值的随机张量。</p><p>张量仍然包含随机值，但它们具有相同的特性。</p><p>这就是<code>torch.manual_seed(seed)</code>出现的位置，其中seed是一个整数（类似于42但可以是任何东西），它决定了随机性。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"></span><br><span class="line"><span class="comment"># # Set the random seed</span></span><br><span class="line">RANDOM_SEED=<span class="number">42</span> <span class="comment"># try changing this to different values and see what happens to the numbers below</span></span><br><span class="line">torch.manual_seed(seed=RANDOM_SEED) </span><br><span class="line">random_tensor_C = torch.rand(<span class="number">3</span>, <span class="number">4</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Have to reset the seed every time a new rand() is called </span></span><br><span class="line"><span class="comment"># Without this, tensor_D would be different to tensor_C </span></span><br><span class="line">torch.random.manual_seed(seed=RANDOM_SEED) <span class="comment"># try commenting this line out and seeing what happens</span></span><br><span class="line">random_tensor_D = torch.rand(<span class="number">3</span>, <span class="number">4</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Tensor C:\n<span class="subst">&#123;random_tensor_C&#125;</span>\n&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Tensor D:\n<span class="subst">&#123;random_tensor_D&#125;</span>\n&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Does Tensor C equal Tensor D? (anywhere)&quot;</span>)</span><br><span class="line">random_tensor_C == random_tensor_D</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">Tensor C:</span><br><span class="line">tensor([[0.8823, 0.9150, 0.3829, 0.9593],</span><br><span class="line">        [0.3904, 0.6009, 0.2566, 0.7936],</span><br><span class="line">        [0.9408, 0.1332, 0.9346, 0.5936]])</span><br><span class="line"></span><br><span class="line">Tensor D:</span><br><span class="line">tensor([[0.8823, 0.9150, 0.3829, 0.9593],</span><br><span class="line">        [0.3904, 0.6009, 0.2566, 0.7936],</span><br><span class="line">        [0.9408, 0.1332, 0.9346, 0.5936]])</span><br><span class="line"></span><br><span class="line">Does Tensor C equal Tensor D? (anywhere)</span><br><span class="line">tensor([[True, True, True, True],</span><br><span class="line">        [True, True, True, True],</span><br><span class="line">        [True, True, True, True]])</span><br></pre></td></tr></table></figure><h2 id="在-GPU-上运行张量（并进行更快的计算）"><a href="#在-GPU-上运行张量（并进行更快的计算）" class="headerlink" title="在 GPU 上运行张量（并进行更快的计算）"></a>在 GPU 上运行张量（并进行更快的计算）</h2><p>深度学习算法需要大量的数值运算。</p><p>默认情况下这些操作通常在 CPU（计算机处理单元）上完成。</p><p>然而，还有另一种常见的硬件，称为 GPU（图形处理单元），它在执行神经网络所需的特定类型的操作（矩阵乘法）时通常比 CPU 快得多。</p><h3 id="获取GPU"><a href="#获取GPU" class="headerlink" title="获取GPU"></a>获取GPU</h3><p><a href="https://timdettmers.com/2023/01/30/which-gpu-for-deep-learning/">Which GPU(s) to Get for Deep Learning: My Experience and Advice for Using GPUs in Deep Learning</a></p><div class="table-container"><table><thead><tr><th style="text-align:center"><strong>Method</strong></th><th style="text-align:center"><strong>Difficulty to setup</strong></th><th style="text-align:center"><strong>Pros</strong></th><th style="text-align:center"><strong>Cons</strong></th><th style="text-align:center"><strong>How to setup</strong></th></tr></thead><tbody><tr><td style="text-align:center">Google Colab</td><td style="text-align:center">Easy</td><td style="text-align:center">Free to use, almost zero setup required, can share work with others as easy as a link</td><td style="text-align:center">Doesn’t save your data outputs, limited compute, subject to timeouts</td><td style="text-align:center"><a href="https://colab.research.google.com/notebooks/gpu.ipynb">Follow the Google Colab Guide</a></td></tr><tr><td style="text-align:center">Use your own</td><td style="text-align:center">Medium</td><td style="text-align:center">Run everything locally on your own machine</td><td style="text-align:center">GPUs aren’t free, require upfront cost</td><td style="text-align:center">Follow the <a href="https://pytorch.org/get-started/locally/">PyTorch   installation guidelines</a></td></tr><tr><td style="text-align:center">Cloud computing (AWS, GCP, Azure)</td><td style="text-align:center">Medium-Hard</td><td style="text-align:center">Small upfront cost, access to almost infinite compute</td><td style="text-align:center">Can get expensive if running continually, takes some time to setup right</td><td style="text-align:center">Follow the <a href="https://pytorch.org/get-started/cloud-partners/">PyTorch installation guidelines</a></td></tr></tbody></table></div><p>检查本机GPU</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">C:\Users\windows11&gt;nvidia-smi</span><br><span class="line">Fri Oct 11 20:12:11 2024</span><br><span class="line">+-----------------------------------------------------------------------------------------+</span><br><span class="line">| NVIDIA-SMI 551.68                 Driver Version: 551.68         CUDA Version: 12.4     |</span><br><span class="line">|-----------------------------------------+------------------------+----------------------+</span><br><span class="line">| GPU  Name                     TCC/WDDM  | Bus-Id          Disp.A | Volatile Uncorr. ECC |</span><br><span class="line">| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |</span><br><span class="line">|                                         |                        |               MIG M. |</span><br><span class="line">|=========================================+========================+======================|</span><br><span class="line">|   0  NVIDIA GeForce RTX 3090      WDDM  |   00000000:73:00.0  On |                  N/A |</span><br><span class="line">| 30%   44C    P8             30W /  350W |    2290MiB /  24576MiB |      3%      Default |</span><br><span class="line">|                                         |                        |                  N/A |</span><br><span class="line">+-----------------------------------------+------------------------+----------------------+</span><br></pre></td></tr></table></figure><h3 id="让-PyTorch-在-GPU-上运行"><a href="#让-PyTorch-在-GPU-上运行" class="headerlink" title="让 PyTorch 在 GPU 上运行"></a>让 PyTorch 在 GPU 上运行</h3><h4 id="检查cuda包"><a href="#检查cuda包" class="headerlink" title="检查cuda包"></a>检查cuda包</h4><p>一旦您准备好访问 GPU，下一步就是使用 PyTorch 来存储数据（张量）和计算数据（对张量执行操作）。</p><p>为此，您可以使用该<code>torch.cuda</code>包。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Check for GPU</span></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line">torch.cuda.is_available()</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">!nvidia-smi</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">Fri Oct 11 12:55:41 2024       </span><br><span class="line">+---------------------------------------------------------------------------------------+</span><br><span class="line">| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |</span><br><span class="line">|-----------------------------------------+----------------------+----------------------+</span><br><span class="line">| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |</span><br><span class="line">| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |</span><br><span class="line">|                                         |                      |               MIG M. |</span><br><span class="line">|=========================================+======================+======================|</span><br><span class="line">|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |</span><br><span class="line">| N/A   37C    P8               9W /  70W |      3MiB / 15360MiB |      0%      Default |</span><br><span class="line">|                                         |                      |                  N/A |</span><br><span class="line">+-----------------------------------------+----------------------+----------------------+</span><br><span class="line">                                                                                         </span><br><span class="line">+---------------------------------------------------------------------------------------+</span><br><span class="line">| Processes:                                                                            |</span><br><span class="line">|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |</span><br><span class="line">|        ID   ID                                                             Usage      |</span><br><span class="line">|=======================================================================================|</span><br><span class="line">|  No running processes found                                                           |</span><br><span class="line">+---------------------------------------------------------------------------------------+</span><br></pre></td></tr></table></figure><p>如果上述输出为True，则 PyTorch 可以看到并使用 GPU；如果输出False，则它看不到 GPU，在这种情况下，您必须返回安装步骤。</p><h4 id="设置device"><a href="#设置device" class="headerlink" title="设置device"></a>设置device</h4><p>让我们创建一个device变量来存储可用的设备类型。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Set device type</span></span><br><span class="line">device = <span class="string">&quot;cuda&quot;</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&quot;cpu&quot;</span></span><br><span class="line">device</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&#x27;cuda&#x27;</span><br></pre></td></tr></table></figure><p>如果输出上述内容，”cuda”则意味着我们可以将所有 PyTorch 代码设置为使用可用的 CUDA 设备（GPU），如果输出”cpu”，则我们的 PyTorch 代码将坚持使用 CPU。</p><blockquote><p>在 PyTorch 中，最佳做法是编写与设备无关的代码。这意味着代码将在 CPU（始终可用）或 GPU（如果可用）上运行。</p></blockquote><p>best-practices：<a href="https://pytorch.org/docs/main/notes/cuda.html">PyTroch CUDA semantics</a></p><h4 id="多个GPU计算"><a href="#多个GPU计算" class="headerlink" title="多个GPU计算"></a>多个GPU计算</h4><p>如果您想要进行更快的计算，则可以使用 GPU，但如果您想进行更快的计算，则可以使用多个 GPU。</p><p>您可以计算 PyTorch 可以使用的 GPU 数量<code>torch.cuda.device_count()</code>。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Count number of devices</span></span><br><span class="line">torch.cuda.device_count()</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">1</span><br></pre></td></tr></table></figure><p>了解 PyTorch 可以访问的 GPU 数量很有帮助，以防您想在一个 GPU 上运行特定进程，而在另一个 GPU 上运行另一个进程（PyTorch 还具有允许您在所有GPU 上运行进程的功能）。</p><h3 id="将张量（和模型）放在-GPU-上"><a href="#将张量（和模型）放在-GPU-上" class="headerlink" title="将张量（和模型）放在 GPU 上"></a>将张量（和模型）放在 GPU 上</h3><p>您可以通过对张量（和模型，我们稍后会看到）调用 <code>to(device)</code> 来将其放置在特定设备上。其中 <code>device</code> 是您希望张量（或模型）转到的目标设备。</p><p>为什么要这么做？</p><p>GPU 提供的数值计算速度比 CPU 快得多，并且如果 GPU 不可用，由于我们的设备无关代码（参见上文），它将在 CPU 上运行。</p><p>使用 <code>to(device)</code> 将张量放在 GPU 上（例如 <code>some_tensor.to(device)</code>）将返回该张量的副本，例如，相同的张量将存在于 CPU 和 GPU 上。要覆盖张量，请重新分配它们：<code>some_tensor = some_tensor.to(device)</code></p><h4 id="创建一个张量并将其放在-GPU-上"><a href="#创建一个张量并将其放在-GPU-上" class="headerlink" title="创建一个张量并将其放在 GPU 上"></a>创建一个张量并将其放在 GPU 上</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">device = <span class="string">&quot;cuda&quot;</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&quot;cpu&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Create tensor (default on CPU)</span></span><br><span class="line">tensor = torch.tensor([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># Tensor not on GPU</span></span><br><span class="line"><span class="built_in">print</span>(tensor, tensor.device)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Move tensor to GPU (if available)</span></span><br><span class="line">tensor_on_gpu = tensor.to(device)</span><br><span class="line">tensor_on_gpu</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">tensor([1, 2, 3]) cpu</span><br><span class="line">tensor([1, 2, 3], device=&#x27;cuda:0&#x27;)</span><br></pre></td></tr></table></figure><p>二个张量有device=’cuda:0’，这意味着它存储在第 0 个可用的 GPU 上（GPU 的索引为 0，如果有两个可用的 GPU，则它们分别为’cuda:0’和’cuda:1’，最多为’cuda:n’）。</p><h3 id="将张量移回-CPU"><a href="#将张量移回-CPU" class="headerlink" title="将张量移回 CPU"></a>将张量移回 CPU</h3><p>使用 NumPy 与张量进行交互（NumPy 不利用 GPU），您需要执行此操作。</p><p><code>torch.Tensor.numpy()</code>使用方法<code>tensor_on_gpu</code>。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># If tensor is on GPU, can&#x27;t transform it to NumPy (this will error)</span></span><br><span class="line">tensor_on_gpu.numpy()</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">TypeError: can&#x27;t convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first.</span><br></pre></td></tr></table></figure><p>相反，为了将张量返回到 CPU 并可供 NumPy 使用，使用<code>Tensor.cpu()</code>。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Instead, copy the tensor back to cpu</span></span><br><span class="line">tensor_back_on_cpu = tensor_on_gpu.cpu().numpy()</span><br><span class="line">tensor_back_on_cpu</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">array([1, 2, 3])</span><br></pre></td></tr></table></figure><p>上面返回了 CPU 内存中 GPU 张量的副本，原始张量仍然在 GPU 上。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tensor_on_gpu</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tensor([1, 2, 3], device=&#x27;cuda:0&#x27;)</span><br></pre></td></tr></table></figure><h3 id="GPU上的随机种子"><a href="#GPU上的随机种子" class="headerlink" title="GPU上的随机种子"></a>GPU上的随机种子</h3><p>在cpu上的随机种子，使用<code>torch.manual_seed()</code></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line">torch.manual_seed(<span class="number">42</span>)  <span class="comment"># 设置CPU种子</span></span><br><span class="line">torch.cuda.manual_seed(<span class="number">42</span>)  <span class="comment"># 设置当前GPU的种子</span></span><br><span class="line">torch.cuda.manual_seed_all(<span class="number">42</span>)  <span class="comment"># 如果使用多个GPU，则为所有GPU设置种子</span></span><br><span class="line"></span><br><span class="line">torch.backends.cudnn.deterministic = <span class="literal">True</span><span class="comment">#确保卷积操作的确定性，强制使用确定性的算法。</span></span><br><span class="line">torch.backends.cudnn.benchmark = <span class="literal">False</span><span class="comment">#禁用动态算法选择，这样算法的选择不会因为输入数据的变化而改变。</span></span><br></pre></td></tr></table></figure><p>通过上述设置，可以确保在 CPU 和 GPU 上运行的 PyTorch 代码具有可重复性。</p><h2 id="练习"><a href="#练习" class="headerlink" title="练习"></a>练习</h2><p><code>pytorch-deep-learning/extras/exercises</code></p><p>…\pytorch-deep-learning\extras\exercises\00_pytorch_fundamentals_exercises.ipynb<br>…\pytorch-deep-learning\extras\solutions\00_pytorch_fundamentals_exercise_solutions.ipynb</p><h2 id="配置pytroch环境"><a href="#配置pytroch环境" class="headerlink" title="配置pytroch环境"></a>配置pytroch环境</h2><p><a href="https://pytorch.org/get-started/locally/#windows-anaconda">PyTorch Get Started</a></p><p>pytorch 2.4.1<br>windows<br>conda<br>python<br>CUDA12.4</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">conda create -n pytorch241 python=3.8</span><br><span class="line"></span><br><span class="line">conda activate pytorch241</span><br><span class="line"></span><br><span class="line">conda install pytorch torchvision torchaudio pytorch-cuda=12.4 -c pytorch -c nvidia</span><br><span class="line"></span><br><span class="line">conda env remove -n pytorch241</span><br><span class="line">conda clean -i</span><br></pre></td></tr></table></figure>]]></content>
    
    
    <summary type="html">PyTorch-26H-1</summary>
    
    
    
    <category term="PyTorch" scheme="http://hibiscidai.com/categories/PyTorch/"/>
    
    
    <category term="学习笔记" scheme="http://hibiscidai.com/tags/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
    <category term="PyTorch" scheme="http://hibiscidai.com/tags/PyTorch/"/>
    
  </entry>
  
  <entry>
    <title>Linux登录提示语</title>
    <link href="http://hibiscidai.com/2024/08/13/Linux%E7%99%BB%E5%BD%95%E6%8F%90%E7%A4%BA%E8%AF%AD/"/>
    <id>http://hibiscidai.com/2024/08/13/Linux%E7%99%BB%E5%BD%95%E6%8F%90%E7%A4%BA%E8%AF%AD/</id>
    <published>2024-08-13T02:00:00.000Z</published>
    <updated>2024-08-13T06:52:11.000Z</updated>
    
    <content type="html"><![CDATA[<img src="/2024/08/13/Linux%E7%99%BB%E5%BD%95%E6%8F%90%E7%A4%BA%E8%AF%AD/Linux%E7%99%BB%E5%BD%95%E6%8F%90%E7%A4%BA%E8%AF%AD.png" class="" title="Linux登录提示语"><p>Linux登录提示语</p><span id="more"></span><h1 id="Linux登录提示语"><a href="#Linux登录提示语" class="headerlink" title="Linux登录提示语"></a>Linux登录提示语</h1><p><code>/etc/issue</code> 本地（虚拟控制台KVM等）登录前提示语，支持转义字符</p><p><code>/etc/issue.net</code> 远程（telnet，ssh）登录前提示语，不支持转义字符</p><p><code>/etc/motd</code> 登录后提示语</p><p><code>/etc/issue</code> 和 <code>/etc/issue.net</code> ：这2个文件是你在登录之前显示的，区别一个负责本地登录前显示，一个负责网络登录前显示。也即 <code>/etc/issue</code> 是显示在控制台登录前（非图形界面），而 <code>/etc/issue.net</code> 是显示在 Telnet (SSH默认不开启）远程登录前，另外 <code>/etc/issue.net</code> 不支持转义字符。</p><p><code>/etc/motd</code> ：这个文件是在你登录之后显示的，不管你是 TTY 还是 PTS 登录，也不管是  Telnet 或 SSH 都显示这个文件里面的信息。</p><p>配置更改后，需要重启SSH服务。</p><ul><li><code>\d</code> : 插入目前日期。</li><li><code>\t</code> : 插入当前时间</li><li><code>\s</code> : 插入系统名称，操作系统名称</li><li><code>\r</code> : 插入操作系统版本号，例如1.1.9.</li><li><code>\v</code> : 插入操作系统的版本</li><li><code>\m</code> : 展示设备的架构标记符，例如i486</li><li><code>\n</code> : 插入设备主机名</li><li><code>\o</code> : 插入设备域名</li><li><code>\l</code> : 插入当前tty终端名称</li><li><code>\u</code> : 插入当前登录用户数</li><li><code>\U</code> : 插入当前登录用户数，以 “1 user” or “ users” 形式</li></ul><h1 id="Ubuntu-系统登录提示"><a href="#Ubuntu-系统登录提示" class="headerlink" title="Ubuntu 系统登录提示"></a>Ubuntu 系统登录提示</h1><p>一般的静态MOTD在<code>/etc/motd</code>中存放，而动态的MOTD在<code>/run/motd.dynamic</code>中存放。</p><p><code>update-motd.d</code>中的东西会存放在<code>motd.dynamic</code>中，然后<code>motd.dynamic</code>再通过<code>pam_motd</code>执行。</p><p>这里的<code>pam_motd</code>其实就是<code>pam_motd.so</code>用于执行<code>update-motd.d</code>文件夹中可执行文件的。</p><p>文件夹：<code>/etc/update-motd.d</code></p><p><code>00-header</code><br><code>10-help-text</code><br><code>50-landscape-sysinfo</code><br><code>50-motd-news</code><br><code>85-fvupd</code><br><code>90-updates-available</code><br><code>91-contract-ua-esm-status</code><br><code>91-release-upgrade</code><br><code>92-nattended-upgrades</code><br><code>95-hwe-eol</code><br><code>97-overlayroot</code><br><code>98-fsck-at-reboot</code><br><code>98-reboot-required</code></p><p>这几个脚本文件，前面的 数字决定了执行顺序，数字越小执行顺序越靠前。</p><p>修改文件内容即可</p><h1 id="命令行美化"><a href="#命令行美化" class="headerlink" title="命令行美化"></a>命令行美化</h1><ul><li><p>figlet: 将英文字母转换为ASCII字符画</p></li><li><p>jp2a: 将图片转换为ASCII字符画</p></li><li><p>asciitable 输出好看的ASCII表格</p></li><li><p><a href="https://motd.bakaya.ro/?ref=xavier.wang">图片转Linux Shell彩色文本</a></p></li><li><p><a href="https://rivers.chaitin.cn/tools/figlet">在线figlet</a></p></li></ul><h1 id="案例"><a href="#案例" class="headerlink" title="案例"></a>案例</h1><p>文件位置：<code>/etc/update-motd.d/xx.txt</code></p><figure class="highlight txt"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">  _  _  _        ____   _____     _     ____       _____  _   _  ___  ____         _  _  _ </span><br><span class="line"> | || || |      |  _ \ | ____|   / \   |  _ \     |_   _|| | | ||_ _|/ ___|       | || || |</span><br><span class="line"> | || || |      | |_) ||  _|    / _ \  | | | |      | |  | |_| | | | \___ \       | || || |</span><br><span class="line"> |_||_||_|      |  _ &lt; | |___  / ___ \ | |_| |      | |  |  _  | | |  ___) |      |_||_||_|</span><br><span class="line"> (_)(_)(_)      |_| \_\|_____|/_/   \_\|____/       |_|  |_| |_||___||____/       (_)(_)(_)</span><br><span class="line">                                                                                                                                                                 </span><br><span class="line">                                                                      </span><br><span class="line">！！！    不按要求操作，删除账号    ！！！</span><br><span class="line">！！！    If you do not follow the instructions, your account will be deleted    ！！！</span><br><span class="line"></span><br><span class="line">https://docs.qq.com/doc/xxxx</span><br><span class="line"></span><br><span class="line">  _  _  _        ____   _____     _     ____       _____  _   _  ___  ____         _  _  _ </span><br><span class="line"> | || || |      |  _ \ | ____|   / \   |  _ \     |_   _|| | | ||_ _|/ ___|       | || || |</span><br><span class="line"> | || || |      | |_) ||  _|    / _ \  | | | |      | |  | |_| | | | \___ \       | || || |</span><br><span class="line"> |_||_||_|      |  _ &lt; | |___  / ___ \ | |_| |      | |  |  _  | | |  ___) |      |_||_||_|</span><br><span class="line"> (_)(_)(_)      |_| \_\|_____|/_/   \_\|____/       |_|  |_| |_||___||____/       (_)(_)(_)</span><br><span class="line">                                                                                          </span><br><span class="line">···</span><br><span class="line"></span><br><span class="line">printf &quot;******************************************************************\n&quot;</span><br><span class="line">printf &quot;******************************************************************\n&quot;</span><br><span class="line">printf &quot; * 使用前必读-YOU MUST READ IT: https://docs.qq.com/doc/DRWNzTWNsSlRtY0lV\n&quot;</span><br><span class="line">printf &quot;******************************************************************\n&quot;</span><br><span class="line">printf &quot;******************************************************************\n&quot;</span><br></pre></td></tr></table></figure><p>修改<code>/etc/update-motd.d/92-unattended-upgrades</code></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cat /etc/update-motd.d/xxx.txt</span><br></pre></td></tr></table></figure><p>查询效果：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">run-parts /etc/update-motd.d</span><br></pre></td></tr></table></figure>]]></content>
    
    
    <summary type="html">Linux登录提示语</summary>
    
    
    
    <category term="Linux" scheme="http://hibiscidai.com/categories/Linux/"/>
    
    
    <category term="Linux" scheme="http://hibiscidai.com/tags/Linux/"/>
    
  </entry>
  
  <entry>
    <title>drd-Digital_Rocks_Data</title>
    <link href="http://hibiscidai.com/2024/08/12/drd-Digital_Rocks_Data/"/>
    <id>http://hibiscidai.com/2024/08/12/drd-Digital_Rocks_Data/</id>
    <published>2024-08-12T07:00:00.000Z</published>
    <updated>2024-08-12T07:46:12.000Z</updated>
    
    <content type="html"><![CDATA[<img src="/2024/08/12/drd-Digital_Rocks_Data/drd-Digital_Rocks_Data.png" class="" title="drd-Digital_Rocks_Data"><p>drd-Digital_Rocks_Data</p><span id="more"></span><h1 id="drd-Digital-Rocks-Data"><a href="#drd-Digital-Rocks-Data" class="headerlink" title="drd-Digital_Rocks_Data"></a>drd-Digital_Rocks_Data</h1><p><a href="https://pypi.org/project/drd/">drd-pypi</a></p><p><a href="https://github.com/lukasmosser/digital_rocks_data">digital_rocks_data_github</a></p><h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h1><p>Digital Rock Images are three-dimensional datasets of rocks and other porous media.<br>数字岩石图像是岩石和其他多孔介质的三维数据集。</p><p>These are typically acquired using three-dimensional imaging techniques such as Micro-Computer Tomography (MicroCT).<br>这些图像通常使用三维成像技术（例如微型计算机断层扫描 (MicroCT)）获取。</p><p>They represent a rich dataset that form a basis for characterization of physical processes involving porous media.<br>它们代表了丰富的数据集，为表征涉及多孔介质的物理过程奠定了基础。</p><p>Digital Rock Images are scattered throughout the web on various hosting sites such as the Digital Rocks Portal, Zenodo, or university specific sites. This library aims to make downloading these datasets easy through a python interface so they can be used in automated image processing workflows, reproducible research, or data science and machine learning worfklows.<br>数字岩石图像分散在网络上的各种托管网站上，例如 Digital Rocks Portal、Zenodo 或大学专用网站。该库旨在通过 Python 界面轻松下载这些数据集，以便它们可用于自动图像处理工作流程、可重复研究或数据科学和机器学习工作流程。</p><p>Furthermore, these images are associated with metadata about their spatial dimensions which should be considered when loading these image datasets.<br>The library therefore requires these metadata to be available and creates an xarray DataArray which can keep spatial scale information when loading an image dataset.<br>此外，这些图像与有关其空间维度的元数据相关联，在加载这些图像数据集时应考虑这些元数据。<br>因此，该库要求这些元数据可用，并创建一个 xarray DataArray，它可以在加载图像数据集时保留空间尺度信息。</p><p>Each dataset is linked in this library i.e. no hosting is done by the library itself.<br>每个数据集都链接到此库中，即库本身不进行任何托管。</p><p><a href="https://www.digitalrocksportal.org/">Digital Rocks Portal</a>：<br><a href="https://www.digitalrocksportal.org/projects/317">Eleven Sandstones Dataset</a></p><ul><li>Berea</li><li>Bandera Brown</li><li>Bandera Gray</li><li>Bentheimer</li><li>Berea Sister Gray</li><li>Berea Upper Gray</li><li>Buff Berea</li><li>Castle Gate</li><li>Kirby</li><li>Leopard</li><li>Parker</li></ul><p><a href="https://www.imperial.ac.uk/earth-science/research/research-groups/pore-scale-modelling/micro-ct-images-and-networks/">Imperial College London</a>：</p><ul><li>MicroCT Images of Sandstones and Carbonates 2015</li><li><a href="https://figshare.com/projects/micro-CT_Images_-_2009/2275">icroCT Images of Sandstones and Carbonates 2009</a></li></ul><h1 id="使用说明"><a href="#使用说明" class="headerlink" title="使用说明"></a>使用说明</h1><ul><li>安装使用</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install drd</span><br></pre></td></tr></table></figure><ul><li><code>plot_eleven_sandstones_dataset_example.py</code></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">Eleven Sandstones Plotting Example</span></span><br><span class="line"><span class="string">=========================</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">This example shows how we can load an image from the eleven sandstones dataset.</span></span><br><span class="line"><span class="string">这个例子展示了如何从十一块砂岩数据集中加载图像。</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="keyword">from</span> drd.datasets.eleven_sandstones <span class="keyword">import</span> load_eleven_sandstones</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="comment"># %%</span></span><br><span class="line"><span class="comment"># Loading the Image</span></span><br><span class="line"><span class="comment"># ------------------------</span></span><br><span class="line"><span class="comment"># 我们将使用名为“load_eleven_sandstones”的实用函数来生成 xarray DataArray</span></span><br><span class="line"><span class="comment"># We will use one of the utility functions called `load_eleven_sandstones` to generate an xarray DataArray </span></span><br><span class="line"><span class="comment"># 它已经包含所有预先配置的空间轴信息和缩放比例。</span></span><br><span class="line"><span class="comment"># which already contains all the spatial axis information and scaling preconfigured.</span></span><br><span class="line"><span class="comment"># 这样，我们将根据空间坐标系对图像数据有一个适当的定义。</span></span><br><span class="line"><span class="comment"># This way we will have a proper definition of the image data in terms of a spatial coordinate system.</span></span><br><span class="line"></span><br><span class="line">img = load_eleven_sandstones(<span class="string">&quot;Berea&quot;</span>, <span class="string">&quot;Berea_2d25um_grayscale.raw&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 这是“代码块”的结尾（如果使用上述 IDE）。</span></span><br><span class="line"><span class="comment"># This is the end of the &#x27;code block&#x27; (if using an above IDE). All code within</span></span><br><span class="line"><span class="comment"># 此块可轻松一次性执行。</span></span><br><span class="line"><span class="comment"># this block can be easily executed all at once.</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># %%</span></span><br><span class="line"><span class="comment"># 使用 xarray 绘制图像数据</span></span><br><span class="line"><span class="comment"># Plotting the Image Data using xarray</span></span><br><span class="line"><span class="comment"># ------------------------</span></span><br><span class="line"><span class="comment"># 我们将使用 xarray 的功能来汇总或选择我们的数据以绘制 z 维度的平均值。</span></span><br><span class="line"><span class="comment"># We will use xarray&#x27;s ability to summarize or select our data to plot an average over the z dimension.</span></span><br><span class="line"></span><br><span class="line">img.mean(dim=<span class="string">&#x27;z&#x27;</span>).plot()</span><br><span class="line">plt.tight_layout()</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line"><span class="comment"># %%</span></span><br><span class="line"><span class="comment"># 我们可以清楚地看到我们如何首先从网络下载图像数据，然后计算微型 CT 图像数据集的平均值。</span></span><br><span class="line"><span class="comment"># We can clearly see how we first downloaded the image data from the web and subsequently compute an average over the micro-ct image dataset.</span></span><br></pre></td></tr></table></figure><ul><li><code>plot_icl_sandstones_carbonates_2009_example.py</code></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">Imperial College London Sandstones &amp; Carbonates 2009 Dataset</span></span><br><span class="line"><span class="string">=========================</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">This example shows how we can load an image from the Imperial College London Sandstones &amp; Carbonates 2009 dataset.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="keyword">from</span> drd.datasets.icl_sandstones_carbonates_2009 <span class="keyword">import</span> load_icl_sandstones_carbonates_2009</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="comment"># %%</span></span><br><span class="line"><span class="comment"># Loading the Image</span></span><br><span class="line"><span class="comment"># ------------------------</span></span><br><span class="line"><span class="comment"># 我们将使用名为“load_icl_sandstones_carbonates_2009”的实用函数来生成 xarray DataArray</span></span><br><span class="line"><span class="comment"># We will use one of the utility functions called `load_icl_sandstones_carbonates_2009` to generate an xarray DataArray </span></span><br><span class="line"><span class="comment"># 它已经包含所有预先配置的空间轴信息和缩放比例。</span></span><br><span class="line"><span class="comment"># which already contains all the spatial axis information and scaling preconfigured.</span></span><br><span class="line"><span class="comment"># 这样，我们将根据空间坐标系对图像数据有一个适当的定义。</span></span><br><span class="line"><span class="comment"># This way we will have a proper definition of the image data in terms of a spatial coordinate system.</span></span><br><span class="line"></span><br><span class="line">img = load_icl_sandstones_carbonates_2009(<span class="string">&quot;Berea&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 这是“代码块”的结尾（如果使用上述 IDE）。</span></span><br><span class="line"><span class="comment"># This is the end of the &#x27;code block&#x27; (if using an above IDE). All code within</span></span><br><span class="line"><span class="comment"># 此块可轻松一次性执行。</span></span><br><span class="line"><span class="comment"># this block can be easily executed all at once.</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># %%</span></span><br><span class="line"><span class="comment"># Plotting the Image Data using xarray</span></span><br><span class="line"><span class="comment"># ------------------------</span></span><br><span class="line"><span class="comment"># We will use xarray&#x27;s ability to summarize or select our data to plot an average over the z dimension.</span></span><br><span class="line"></span><br><span class="line">img.mean(dim=<span class="string">&#x27;z&#x27;</span>).plot()</span><br><span class="line">plt.tight_layout()</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line"><span class="comment"># %%</span></span><br><span class="line"><span class="comment"># We can clearly see how we first downloaded the image data from the web and subsequently compute an average over the micro-ct image dataset.</span></span><br></pre></td></tr></table></figure><h1 id="数据集"><a href="#数据集" class="headerlink" title="数据集"></a>数据集</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br><span class="line">248</span><br><span class="line">249</span><br><span class="line">250</span><br><span class="line">251</span><br><span class="line">252</span><br><span class="line">253</span><br><span class="line">254</span><br><span class="line">255</span><br><span class="line">256</span><br><span class="line">257</span><br><span class="line">258</span><br><span class="line">259</span><br><span class="line">260</span><br><span class="line">261</span><br><span class="line">262</span><br><span class="line">263</span><br><span class="line">264</span><br><span class="line">265</span><br><span class="line">266</span><br><span class="line">267</span><br><span class="line">268</span><br><span class="line">269</span><br><span class="line">270</span><br><span class="line">271</span><br><span class="line">272</span><br><span class="line">273</span><br><span class="line">274</span><br><span class="line">275</span><br><span class="line">276</span><br><span class="line">277</span><br><span class="line">278</span><br><span class="line">279</span><br><span class="line">280</span><br><span class="line">281</span><br><span class="line">282</span><br><span class="line">283</span><br><span class="line">284</span><br><span class="line">285</span><br><span class="line">286</span><br><span class="line">287</span><br><span class="line">288</span><br><span class="line">289</span><br><span class="line">290</span><br><span class="line">291</span><br><span class="line">292</span><br><span class="line">293</span><br><span class="line">294</span><br><span class="line">295</span><br><span class="line">296</span><br><span class="line">297</span><br><span class="line">298</span><br><span class="line">299</span><br><span class="line">300</span><br><span class="line">301</span><br><span class="line">302</span><br><span class="line">303</span><br><span class="line">304</span><br><span class="line">305</span><br><span class="line">306</span><br><span class="line">307</span><br><span class="line">308</span><br><span class="line">309</span><br><span class="line">310</span><br><span class="line">311</span><br><span class="line">312</span><br><span class="line">313</span><br><span class="line">314</span><br><span class="line">315</span><br><span class="line">316</span><br><span class="line">317</span><br><span class="line">318</span><br><span class="line">319</span><br><span class="line">320</span><br><span class="line">321</span><br><span class="line">322</span><br><span class="line">323</span><br><span class="line">324</span><br><span class="line">325</span><br><span class="line">326</span><br><span class="line">327</span><br><span class="line">328</span><br><span class="line">329</span><br><span class="line">330</span><br><span class="line">331</span><br><span class="line">332</span><br><span class="line">333</span><br><span class="line">334</span><br><span class="line">335</span><br><span class="line">336</span><br><span class="line">337</span><br><span class="line">338</span><br><span class="line">339</span><br><span class="line">340</span><br><span class="line">341</span><br><span class="line">342</span><br><span class="line">343</span><br><span class="line">344</span><br><span class="line">345</span><br><span class="line">346</span><br><span class="line">347</span><br><span class="line">348</span><br><span class="line">349</span><br><span class="line">350</span><br><span class="line">351</span><br><span class="line">352</span><br><span class="line">353</span><br><span class="line">354</span><br></pre></td><td class="code"><pre><span class="line">DATASET_METADATA = &#123;</span><br><span class="line">    <span class="string">&quot;Berea&quot;</span>: &#123;</span><br><span class="line">        <span class="string">&quot;Berea_2d25um_grayscale.raw&quot;</span>: &#123;</span><br><span class="line">            <span class="string">&quot;url&quot;</span>: <span class="string">&quot;https://www.digitalrocksportal.org/projects/317/images/223451/download/&quot;</span>,</span><br><span class="line">            <span class="string">&quot;voxel_length&quot;</span>: [<span class="number">2.25</span>, <span class="number">2.25</span>, <span class="number">2.25</span>],</span><br><span class="line">            <span class="string">&quot;metric_voxel_length_unit&quot;</span>:  <span class="number">1e-6</span>,</span><br><span class="line">            <span class="string">&quot;width&quot;</span>: <span class="number">1000</span>, </span><br><span class="line">            <span class="string">&quot;height&quot;</span>: <span class="number">1000</span>, </span><br><span class="line">            <span class="string">&quot;number_of_slices&quot;</span>: <span class="number">1000</span>,</span><br><span class="line">            <span class="string">&quot;byte_order&quot;</span>: <span class="string">&quot;little-endian&quot;</span>,</span><br><span class="line">            <span class="string">&quot;image_type&quot;</span>: np.uint8</span><br><span class="line">        &#125;,</span><br><span class="line">        <span class="string">&quot;Berea_2d25um_grayscale_filtered.raw&quot;</span>: &#123;</span><br><span class="line">            <span class="string">&quot;url&quot;</span>: <span class="string">&quot;https://www.digitalrocksportal.org/projects/317/images/223452/download/&quot;</span>,</span><br><span class="line">            <span class="string">&quot;voxel_length&quot;</span>: [<span class="number">2.25</span>, <span class="number">2.25</span>, <span class="number">2.25</span>],</span><br><span class="line">            <span class="string">&quot;metric_voxel_length_unit&quot;</span>:  <span class="number">1e-6</span>,</span><br><span class="line">            <span class="string">&quot;width&quot;</span>: <span class="number">1000</span>, </span><br><span class="line">            <span class="string">&quot;height&quot;</span>: <span class="number">1000</span>, </span><br><span class="line">            <span class="string">&quot;number_of_slices&quot;</span>: <span class="number">1000</span>,</span><br><span class="line">            <span class="string">&quot;byte_order&quot;</span>: <span class="string">&quot;little-endian&quot;</span>,</span><br><span class="line">            <span class="string">&quot;image_type&quot;</span>: np.uint8</span><br><span class="line">        &#125;,</span><br><span class="line">        <span class="string">&quot;Berea_2d25um_binary.raw&quot;</span>: &#123;</span><br><span class="line">            <span class="string">&quot;url&quot;</span>: <span class="string">&quot;https://www.digitalrocksportal.org/projects/317/images/223453/download/&quot;</span>,</span><br><span class="line">            <span class="string">&quot;voxel_length&quot;</span>: [<span class="number">2.25</span>, <span class="number">2.25</span>, <span class="number">2.25</span>],</span><br><span class="line">            <span class="string">&quot;metric_voxel_length_unit&quot;</span>: <span class="number">1e-6</span>,</span><br><span class="line">            <span class="string">&quot;width&quot;</span>: <span class="number">1000</span>, </span><br><span class="line">            <span class="string">&quot;height&quot;</span>: <span class="number">1000</span>, </span><br><span class="line">            <span class="string">&quot;number_of_slices&quot;</span>: <span class="number">1000</span>,</span><br><span class="line">            <span class="string">&quot;byte_order&quot;</span>: <span class="string">&quot;little-endian&quot;</span>,</span><br><span class="line">            <span class="string">&quot;image_type&quot;</span>: np.uint8</span><br><span class="line">        &#125;   </span><br><span class="line">    &#125;,</span><br><span class="line">    <span class="string">&quot;BanderaBrown&quot;</span>: &#123;</span><br><span class="line">        <span class="string">&quot;BanderaBrown_2d25um_grayscale.raw&quot;</span>: &#123;</span><br><span class="line">            <span class="string">&quot;url&quot;</span>: <span class="string">&quot;https://www.digitalrocksportal.org/projects/317/images/223448/download/&quot;</span>,</span><br><span class="line">            <span class="string">&quot;voxel_length&quot;</span>: [<span class="number">2.25</span>, <span class="number">2.25</span>, <span class="number">2.25</span>],</span><br><span class="line">            <span class="string">&quot;metric_voxel_length_unit&quot;</span>:  <span class="number">1e-6</span>,</span><br><span class="line">            <span class="string">&quot;width&quot;</span>: <span class="number">1000</span>, </span><br><span class="line">            <span class="string">&quot;height&quot;</span>: <span class="number">1000</span>, </span><br><span class="line">            <span class="string">&quot;number_of_slices&quot;</span>: <span class="number">1000</span>,</span><br><span class="line">            <span class="string">&quot;byte_order&quot;</span>: <span class="string">&quot;little-endian&quot;</span>,</span><br><span class="line">            <span class="string">&quot;image_type&quot;</span>: np.uint8</span><br><span class="line">        &#125;,</span><br><span class="line">        <span class="string">&quot;BanderaBrown_2d25um_grayscale_filtered.raw&quot;</span>: &#123;</span><br><span class="line">            <span class="string">&quot;url&quot;</span>: <span class="string">&quot;https://www.digitalrocksportal.org/projects/317/images/223454/download/&quot;</span>,</span><br><span class="line">            <span class="string">&quot;voxel_length&quot;</span>: [<span class="number">2.25</span>, <span class="number">2.25</span>, <span class="number">2.25</span>],</span><br><span class="line">            <span class="string">&quot;metric_voxel_length_unit&quot;</span>:  <span class="number">1e-6</span>,</span><br><span class="line">            <span class="string">&quot;width&quot;</span>: <span class="number">1000</span>, </span><br><span class="line">            <span class="string">&quot;height&quot;</span>: <span class="number">1000</span>, </span><br><span class="line">            <span class="string">&quot;number_of_slices&quot;</span>: <span class="number">1000</span>,</span><br><span class="line">            <span class="string">&quot;byte_order&quot;</span>: <span class="string">&quot;little-endian&quot;</span>,</span><br><span class="line">            <span class="string">&quot;image_type&quot;</span>: np.uint8</span><br><span class="line">        &#125;,</span><br><span class="line">        <span class="string">&quot;BanderaBrown_2d25um_binary.raw&quot;</span>: &#123;</span><br><span class="line">            <span class="string">&quot;url&quot;</span>: <span class="string">&quot;https://www.digitalrocksportal.org/projects/317/images/223455/download/&quot;</span>,</span><br><span class="line">            <span class="string">&quot;voxel_length&quot;</span>: [<span class="number">2.25</span>, <span class="number">2.25</span>, <span class="number">2.25</span>],</span><br><span class="line">            <span class="string">&quot;metric_voxel_length_unit&quot;</span>: <span class="number">1e-6</span>,</span><br><span class="line">            <span class="string">&quot;width&quot;</span>: <span class="number">1000</span>, </span><br><span class="line">            <span class="string">&quot;height&quot;</span>: <span class="number">1000</span>, </span><br><span class="line">            <span class="string">&quot;number_of_slices&quot;</span>: <span class="number">1000</span>,</span><br><span class="line">            <span class="string">&quot;byte_order&quot;</span>: <span class="string">&quot;little-endian&quot;</span>,</span><br><span class="line">            <span class="string">&quot;image_type&quot;</span>: np.uint8</span><br><span class="line">        &#125;   </span><br><span class="line">    &#125;,</span><br><span class="line">    <span class="string">&quot;BanderaGray&quot;</span>: &#123;</span><br><span class="line">        <span class="string">&quot;BanderaGray_2d25um_grayscale.raw&quot;</span>: &#123;</span><br><span class="line">            <span class="string">&quot;url&quot;</span>: <span class="string">&quot;https://www.digitalrocksportal.org/projects/317/images/223459/download/&quot;</span>,</span><br><span class="line">            <span class="string">&quot;voxel_length&quot;</span>: [<span class="number">2.25</span>, <span class="number">2.25</span>, <span class="number">2.25</span>],</span><br><span class="line">            <span class="string">&quot;metric_voxel_length_unit&quot;</span>:  <span class="number">1e-6</span>,</span><br><span class="line">            <span class="string">&quot;width&quot;</span>: <span class="number">1000</span>, </span><br><span class="line">            <span class="string">&quot;height&quot;</span>: <span class="number">1000</span>, </span><br><span class="line">            <span class="string">&quot;number_of_slices&quot;</span>: <span class="number">1000</span>,</span><br><span class="line">            <span class="string">&quot;byte_order&quot;</span>: <span class="string">&quot;little-endian&quot;</span>,</span><br><span class="line">            <span class="string">&quot;image_type&quot;</span>: np.uint8</span><br><span class="line">        &#125;,</span><br><span class="line">        <span class="string">&quot;BanderaGray_2d25um_grayscale_filtered.raw&quot;</span>: &#123;</span><br><span class="line">            <span class="string">&quot;url&quot;</span>: <span class="string">&quot;https://www.digitalrocksportal.org/projects/317/images/223457/download/&quot;</span>,</span><br><span class="line">            <span class="string">&quot;voxel_length&quot;</span>: [<span class="number">2.25</span>, <span class="number">2.25</span>, <span class="number">2.25</span>],</span><br><span class="line">            <span class="string">&quot;metric_voxel_length_unit&quot;</span>:  <span class="number">1e-6</span>,</span><br><span class="line">            <span class="string">&quot;width&quot;</span>: <span class="number">1000</span>, </span><br><span class="line">            <span class="string">&quot;height&quot;</span>: <span class="number">1000</span>, </span><br><span class="line">            <span class="string">&quot;number_of_slices&quot;</span>: <span class="number">1000</span>,</span><br><span class="line">            <span class="string">&quot;byte_order&quot;</span>: <span class="string">&quot;little-endian&quot;</span>,</span><br><span class="line">            <span class="string">&quot;image_type&quot;</span>: np.uint8</span><br><span class="line">        &#125;,</span><br><span class="line">        <span class="string">&quot;BanderaGray_2d25um_binary.raw&quot;</span>: &#123;</span><br><span class="line">            <span class="string">&quot;url&quot;</span>: <span class="string">&quot;https://www.digitalrocksportal.org/projects/317/images/223458/download/&quot;</span>,</span><br><span class="line">            <span class="string">&quot;voxel_length&quot;</span>: [<span class="number">2.25</span>, <span class="number">2.25</span>, <span class="number">2.25</span>],</span><br><span class="line">            <span class="string">&quot;metric_voxel_length_unit&quot;</span>: <span class="number">1e-6</span>,</span><br><span class="line">            <span class="string">&quot;width&quot;</span>: <span class="number">1000</span>, </span><br><span class="line">            <span class="string">&quot;height&quot;</span>: <span class="number">1000</span>, </span><br><span class="line">            <span class="string">&quot;number_of_slices&quot;</span>: <span class="number">1000</span>,</span><br><span class="line">            <span class="string">&quot;byte_order&quot;</span>: <span class="string">&quot;little-endian&quot;</span>,</span><br><span class="line">            <span class="string">&quot;image_type&quot;</span>: np.uint8</span><br><span class="line">        &#125;   </span><br><span class="line">    &#125;,</span><br><span class="line">    <span class="string">&quot;Bentheimer&quot;</span>: &#123;</span><br><span class="line">        <span class="string">&quot;Bentheimer_2d25um_grayscale.raw&quot;</span>: &#123;</span><br><span class="line">            <span class="string">&quot;url&quot;</span>: <span class="string">&quot;https://www.digitalrocksportal.org/projects/317/images/223461/download/&quot;</span>,</span><br><span class="line">            <span class="string">&quot;voxel_length&quot;</span>: [<span class="number">2.25</span>, <span class="number">2.25</span>, <span class="number">2.25</span>],</span><br><span class="line">            <span class="string">&quot;metric_voxel_length_unit&quot;</span>:  <span class="number">1e-6</span>,</span><br><span class="line">            <span class="string">&quot;width&quot;</span>: <span class="number">1000</span>, </span><br><span class="line">            <span class="string">&quot;height&quot;</span>: <span class="number">1000</span>, </span><br><span class="line">            <span class="string">&quot;number_of_slices&quot;</span>: <span class="number">1000</span>,</span><br><span class="line">            <span class="string">&quot;byte_order&quot;</span>: <span class="string">&quot;little-endian&quot;</span>,</span><br><span class="line">            <span class="string">&quot;image_type&quot;</span>: np.uint8</span><br><span class="line">        &#125;,</span><br><span class="line">        <span class="string">&quot;Bentheimer_2d25um_grayscale_filtered.raw&quot;</span>: &#123;</span><br><span class="line">            <span class="string">&quot;url&quot;</span>: <span class="string">&quot;https://www.digitalrocksportal.org/projects/317/images/223462/download/&quot;</span>,</span><br><span class="line">            <span class="string">&quot;voxel_length&quot;</span>: [<span class="number">2.25</span>, <span class="number">2.25</span>, <span class="number">2.25</span>],</span><br><span class="line">            <span class="string">&quot;metric_voxel_length_unit&quot;</span>:  <span class="number">1e-6</span>,</span><br><span class="line">            <span class="string">&quot;width&quot;</span>: <span class="number">1000</span>, </span><br><span class="line">            <span class="string">&quot;height&quot;</span>: <span class="number">1000</span>, </span><br><span class="line">            <span class="string">&quot;number_of_slices&quot;</span>: <span class="number">1000</span>,</span><br><span class="line">            <span class="string">&quot;byte_order&quot;</span>: <span class="string">&quot;little-endian&quot;</span>,</span><br><span class="line">            <span class="string">&quot;image_type&quot;</span>: np.uint8</span><br><span class="line">        &#125;,</span><br><span class="line">        <span class="string">&quot;Bentheimer_2d25um_binary.raw&quot;</span>: &#123;</span><br><span class="line">            <span class="string">&quot;url&quot;</span>: <span class="string">&quot;https://www.digitalrocksportal.org/projects/317/images/223463/download/&quot;</span>,</span><br><span class="line">            <span class="string">&quot;voxel_length&quot;</span>: [<span class="number">2.25</span>, <span class="number">2.25</span>, <span class="number">2.25</span>],</span><br><span class="line">            <span class="string">&quot;metric_voxel_length_unit&quot;</span>: <span class="number">1e-6</span>,</span><br><span class="line">            <span class="string">&quot;width&quot;</span>: <span class="number">1000</span>, </span><br><span class="line">            <span class="string">&quot;height&quot;</span>: <span class="number">1000</span>, </span><br><span class="line">            <span class="string">&quot;number_of_slices&quot;</span>: <span class="number">1000</span>,</span><br><span class="line">            <span class="string">&quot;byte_order&quot;</span>: <span class="string">&quot;little-endian&quot;</span>,</span><br><span class="line">            <span class="string">&quot;image_type&quot;</span>: np.uint8</span><br><span class="line">        &#125;   </span><br><span class="line">    &#125;,</span><br><span class="line">    <span class="string">&quot;BSG&quot;</span>: &#123;</span><br><span class="line">        <span class="string">&quot;BSG_2d25um_grayscale.raw&quot;</span>: &#123;</span><br><span class="line">            <span class="string">&quot;url&quot;</span>: <span class="string">&quot;https://www.digitalrocksportal.org/projects/317/images/223464/download/&quot;</span>,</span><br><span class="line">            <span class="string">&quot;voxel_length&quot;</span>: [<span class="number">2.25</span>, <span class="number">2.25</span>, <span class="number">2.25</span>],</span><br><span class="line">            <span class="string">&quot;metric_voxel_length_unit&quot;</span>:  <span class="number">1e-6</span>,</span><br><span class="line">            <span class="string">&quot;width&quot;</span>: <span class="number">1000</span>, </span><br><span class="line">            <span class="string">&quot;height&quot;</span>: <span class="number">1000</span>, </span><br><span class="line">            <span class="string">&quot;number_of_slices&quot;</span>: <span class="number">1000</span>,</span><br><span class="line">            <span class="string">&quot;byte_order&quot;</span>: <span class="string">&quot;little-endian&quot;</span>,</span><br><span class="line">            <span class="string">&quot;image_type&quot;</span>: np.uint8</span><br><span class="line">        &#125;,</span><br><span class="line">        <span class="string">&quot;BSG_2d25um_grayscale_filtered.raw&quot;</span>: &#123;</span><br><span class="line">            <span class="string">&quot;url&quot;</span>: <span class="string">&quot;https://www.digitalrocksportal.org/projects/317/images/223465/download/&quot;</span>,</span><br><span class="line">            <span class="string">&quot;voxel_length&quot;</span>: [<span class="number">2.25</span>, <span class="number">2.25</span>, <span class="number">2.25</span>],</span><br><span class="line">            <span class="string">&quot;metric_voxel_length_unit&quot;</span>:  <span class="number">1e-6</span>,</span><br><span class="line">            <span class="string">&quot;width&quot;</span>: <span class="number">1000</span>, </span><br><span class="line">            <span class="string">&quot;height&quot;</span>: <span class="number">1000</span>, </span><br><span class="line">            <span class="string">&quot;number_of_slices&quot;</span>: <span class="number">1000</span>,</span><br><span class="line">            <span class="string">&quot;byte_order&quot;</span>: <span class="string">&quot;little-endian&quot;</span>,</span><br><span class="line">            <span class="string">&quot;image_type&quot;</span>: np.uint8</span><br><span class="line">        &#125;,</span><br><span class="line">        <span class="string">&quot;BSG_2d25um_binary.raw&quot;</span>: &#123;</span><br><span class="line">            <span class="string">&quot;url&quot;</span>: <span class="string">&quot;https://www.digitalrocksportal.org/projects/317/images/223466/download/&quot;</span>,</span><br><span class="line">            <span class="string">&quot;voxel_length&quot;</span>: [<span class="number">2.25</span>, <span class="number">2.25</span>, <span class="number">2.25</span>],</span><br><span class="line">            <span class="string">&quot;metric_voxel_length_unit&quot;</span>: <span class="number">1e-6</span>,</span><br><span class="line">            <span class="string">&quot;width&quot;</span>: <span class="number">1000</span>, </span><br><span class="line">            <span class="string">&quot;height&quot;</span>: <span class="number">1000</span>, </span><br><span class="line">            <span class="string">&quot;number_of_slices&quot;</span>: <span class="number">1000</span>,</span><br><span class="line">            <span class="string">&quot;byte_order&quot;</span>: <span class="string">&quot;little-endian&quot;</span>,</span><br><span class="line">            <span class="string">&quot;image_type&quot;</span>: np.uint8</span><br><span class="line">        &#125;   </span><br><span class="line">    &#125;,</span><br><span class="line">    <span class="string">&quot;BUG&quot;</span>: &#123;</span><br><span class="line">        <span class="string">&quot;BUG_2d25um_grayscale.raw&quot;</span>: &#123;</span><br><span class="line">            <span class="string">&quot;url&quot;</span>: <span class="string">&quot;https://www.digitalrocksportal.org/projects/317/images/223467/download/&quot;</span>,</span><br><span class="line">            <span class="string">&quot;voxel_length&quot;</span>: [<span class="number">2.25</span>, <span class="number">2.25</span>, <span class="number">2.25</span>],</span><br><span class="line">            <span class="string">&quot;metric_voxel_length_unit&quot;</span>:  <span class="number">1e-6</span>,</span><br><span class="line">            <span class="string">&quot;width&quot;</span>: <span class="number">1000</span>, </span><br><span class="line">            <span class="string">&quot;height&quot;</span>: <span class="number">1000</span>, </span><br><span class="line">            <span class="string">&quot;number_of_slices&quot;</span>: <span class="number">1000</span>,</span><br><span class="line">            <span class="string">&quot;byte_order&quot;</span>: <span class="string">&quot;little-endian&quot;</span>,</span><br><span class="line">            <span class="string">&quot;image_type&quot;</span>: np.uint8</span><br><span class="line">        &#125;,</span><br><span class="line">        <span class="string">&quot;BUG_2d25um_grayscale_filtered.raw&quot;</span>: &#123;</span><br><span class="line">            <span class="string">&quot;url&quot;</span>: <span class="string">&quot;https://www.digitalrocksportal.org/projects/317/images/223468/download/&quot;</span>,</span><br><span class="line">            <span class="string">&quot;voxel_length&quot;</span>: [<span class="number">2.25</span>, <span class="number">2.25</span>, <span class="number">2.25</span>],</span><br><span class="line">            <span class="string">&quot;metric_voxel_length_unit&quot;</span>:  <span class="number">1e-6</span>,</span><br><span class="line">            <span class="string">&quot;width&quot;</span>: <span class="number">1000</span>, </span><br><span class="line">            <span class="string">&quot;height&quot;</span>: <span class="number">1000</span>, </span><br><span class="line">            <span class="string">&quot;number_of_slices&quot;</span>: <span class="number">1000</span>,</span><br><span class="line">            <span class="string">&quot;byte_order&quot;</span>: <span class="string">&quot;little-endian&quot;</span>,</span><br><span class="line">            <span class="string">&quot;image_type&quot;</span>: np.uint8</span><br><span class="line">        &#125;,</span><br><span class="line">        <span class="string">&quot;BUG_2d25um_binary.raw&quot;</span>: &#123;</span><br><span class="line">            <span class="string">&quot;url&quot;</span>: <span class="string">&quot;https://www.digitalrocksportal.org/projects/317/images/223469/download/&quot;</span>,</span><br><span class="line">            <span class="string">&quot;voxel_length&quot;</span>: [<span class="number">2.25</span>, <span class="number">2.25</span>, <span class="number">2.25</span>],</span><br><span class="line">            <span class="string">&quot;metric_voxel_length_unit&quot;</span>: <span class="number">1e-6</span>,</span><br><span class="line">            <span class="string">&quot;width&quot;</span>: <span class="number">1000</span>, </span><br><span class="line">            <span class="string">&quot;height&quot;</span>: <span class="number">1000</span>, </span><br><span class="line">            <span class="string">&quot;number_of_slices&quot;</span>: <span class="number">1000</span>,</span><br><span class="line">            <span class="string">&quot;byte_order&quot;</span>: <span class="string">&quot;little-endian&quot;</span>,</span><br><span class="line">            <span class="string">&quot;image_type&quot;</span>: np.uint8</span><br><span class="line">        &#125;   </span><br><span class="line">    &#125;,</span><br><span class="line">    <span class="string">&quot;BB&quot;</span>: &#123;</span><br><span class="line">        <span class="string">&quot;BB_2d25um_grayscale.raw&quot;</span>: &#123;</span><br><span class="line">            <span class="string">&quot;url&quot;</span>: <span class="string">&quot;https://www.digitalrocksportal.org/projects/317/images/223470/download/&quot;</span>,</span><br><span class="line">            <span class="string">&quot;voxel_length&quot;</span>: [<span class="number">2.25</span>, <span class="number">2.25</span>, <span class="number">2.25</span>],</span><br><span class="line">            <span class="string">&quot;metric_voxel_length_unit&quot;</span>:  <span class="number">1e-6</span>,</span><br><span class="line">            <span class="string">&quot;width&quot;</span>: <span class="number">1000</span>, </span><br><span class="line">            <span class="string">&quot;height&quot;</span>: <span class="number">1000</span>, </span><br><span class="line">            <span class="string">&quot;number_of_slices&quot;</span>: <span class="number">1000</span>,</span><br><span class="line">            <span class="string">&quot;byte_order&quot;</span>: <span class="string">&quot;little-endian&quot;</span>,</span><br><span class="line">            <span class="string">&quot;image_type&quot;</span>: np.uint8</span><br><span class="line">        &#125;,</span><br><span class="line">        <span class="string">&quot;BB_2d25um_grayscale_filtered.raw&quot;</span>: &#123;</span><br><span class="line">            <span class="string">&quot;url&quot;</span>: <span class="string">&quot;https://www.digitalrocksportal.org/projects/317/images/223471/download/&quot;</span>,</span><br><span class="line">            <span class="string">&quot;voxel_length&quot;</span>: [<span class="number">2.25</span>, <span class="number">2.25</span>, <span class="number">2.25</span>],</span><br><span class="line">            <span class="string">&quot;metric_voxel_length_unit&quot;</span>:  <span class="number">1e-6</span>,</span><br><span class="line">            <span class="string">&quot;width&quot;</span>: <span class="number">1000</span>, </span><br><span class="line">            <span class="string">&quot;height&quot;</span>: <span class="number">1000</span>, </span><br><span class="line">            <span class="string">&quot;number_of_slices&quot;</span>: <span class="number">1000</span>,</span><br><span class="line">            <span class="string">&quot;byte_order&quot;</span>: <span class="string">&quot;little-endian&quot;</span>,</span><br><span class="line">            <span class="string">&quot;image_type&quot;</span>: np.uint8</span><br><span class="line">        &#125;,</span><br><span class="line">        <span class="string">&quot;BB_2d25um_binary.raw&quot;</span>: &#123;</span><br><span class="line">            <span class="string">&quot;url&quot;</span>: <span class="string">&quot;https://www.digitalrocksportal.org/projects/317/images/223472/download/&quot;</span>,</span><br><span class="line">            <span class="string">&quot;voxel_length&quot;</span>: [<span class="number">2.25</span>, <span class="number">2.25</span>, <span class="number">2.25</span>],</span><br><span class="line">            <span class="string">&quot;metric_voxel_length_unit&quot;</span>: <span class="number">1e-6</span>,</span><br><span class="line">            <span class="string">&quot;width&quot;</span>: <span class="number">1000</span>, </span><br><span class="line">            <span class="string">&quot;height&quot;</span>: <span class="number">1000</span>, </span><br><span class="line">            <span class="string">&quot;number_of_slices&quot;</span>: <span class="number">1000</span>,</span><br><span class="line">            <span class="string">&quot;byte_order&quot;</span>: <span class="string">&quot;little-endian&quot;</span>,</span><br><span class="line">            <span class="string">&quot;image_type&quot;</span>: np.uint8</span><br><span class="line">        &#125;   </span><br><span class="line">    &#125;,</span><br><span class="line">    <span class="string">&quot;CastleGate&quot;</span>: &#123;</span><br><span class="line">        <span class="string">&quot;CastleGate_2d25um_grayscale.raw&quot;</span>: &#123;</span><br><span class="line">            <span class="string">&quot;url&quot;</span>: <span class="string">&quot;https://www.digitalrocksportal.org/projects/317/images/223473/download/&quot;</span>,</span><br><span class="line">            <span class="string">&quot;voxel_length&quot;</span>: [<span class="number">2.25</span>, <span class="number">2.25</span>, <span class="number">2.25</span>],</span><br><span class="line">            <span class="string">&quot;metric_voxel_length_unit&quot;</span>:  <span class="number">1e-6</span>,</span><br><span class="line">            <span class="string">&quot;width&quot;</span>: <span class="number">1000</span>, </span><br><span class="line">            <span class="string">&quot;height&quot;</span>: <span class="number">1000</span>, </span><br><span class="line">            <span class="string">&quot;number_of_slices&quot;</span>: <span class="number">1000</span>,</span><br><span class="line">            <span class="string">&quot;byte_order&quot;</span>: <span class="string">&quot;little-endian&quot;</span>,</span><br><span class="line">            <span class="string">&quot;image_type&quot;</span>: np.uint8</span><br><span class="line">        &#125;,</span><br><span class="line">        <span class="string">&quot;CastleGate_2d25um_grayscale_filtered.raw&quot;</span>: &#123;</span><br><span class="line">            <span class="string">&quot;url&quot;</span>: <span class="string">&quot;https://www.digitalrocksportal.org/projects/317/images/223474/download/&quot;</span>,</span><br><span class="line">            <span class="string">&quot;voxel_length&quot;</span>: [<span class="number">2.25</span>, <span class="number">2.25</span>, <span class="number">2.25</span>],</span><br><span class="line">            <span class="string">&quot;metric_voxel_length_unit&quot;</span>:  <span class="number">1e-6</span>,</span><br><span class="line">            <span class="string">&quot;width&quot;</span>: <span class="number">1000</span>, </span><br><span class="line">            <span class="string">&quot;height&quot;</span>: <span class="number">1000</span>, </span><br><span class="line">            <span class="string">&quot;number_of_slices&quot;</span>: <span class="number">1000</span>,</span><br><span class="line">            <span class="string">&quot;byte_order&quot;</span>: <span class="string">&quot;little-endian&quot;</span>,</span><br><span class="line">            <span class="string">&quot;image_type&quot;</span>: np.uint8</span><br><span class="line">        &#125;,</span><br><span class="line">        <span class="string">&quot;CastleGate_2d25um_binary.raw&quot;</span>: &#123;</span><br><span class="line">            <span class="string">&quot;url&quot;</span>: <span class="string">&quot;https://www.digitalrocksportal.org/projects/317/images/223475/download/&quot;</span>,</span><br><span class="line">            <span class="string">&quot;voxel_length&quot;</span>: [<span class="number">2.25</span>, <span class="number">2.25</span>, <span class="number">2.25</span>],</span><br><span class="line">            <span class="string">&quot;metric_voxel_length_unit&quot;</span>: <span class="number">1e-6</span>,</span><br><span class="line">            <span class="string">&quot;width&quot;</span>: <span class="number">1000</span>, </span><br><span class="line">            <span class="string">&quot;height&quot;</span>: <span class="number">1000</span>, </span><br><span class="line">            <span class="string">&quot;number_of_slices&quot;</span>: <span class="number">1000</span>,</span><br><span class="line">            <span class="string">&quot;byte_order&quot;</span>: <span class="string">&quot;little-endian&quot;</span>,</span><br><span class="line">            <span class="string">&quot;image_type&quot;</span>: np.uint8</span><br><span class="line">        &#125;   </span><br><span class="line">    &#125;,</span><br><span class="line">    <span class="string">&quot;Kirby&quot;</span>: &#123;</span><br><span class="line">        <span class="string">&quot;Kirby_2d25um_grayscale.raw&quot;</span>: &#123;</span><br><span class="line">            <span class="string">&quot;url&quot;</span>: <span class="string">&quot;https://www.digitalrocksportal.org/projects/317/images/223476/download/&quot;</span>,</span><br><span class="line">            <span class="string">&quot;voxel_length&quot;</span>: [<span class="number">2.25</span>, <span class="number">2.25</span>, <span class="number">2.25</span>],</span><br><span class="line">            <span class="string">&quot;metric_voxel_length_unit&quot;</span>:  <span class="number">1e-6</span>,</span><br><span class="line">            <span class="string">&quot;width&quot;</span>: <span class="number">1000</span>, </span><br><span class="line">            <span class="string">&quot;height&quot;</span>: <span class="number">1000</span>, </span><br><span class="line">            <span class="string">&quot;number_of_slices&quot;</span>: <span class="number">1000</span>,</span><br><span class="line">            <span class="string">&quot;byte_order&quot;</span>: <span class="string">&quot;little-endian&quot;</span>,</span><br><span class="line">            <span class="string">&quot;image_type&quot;</span>: np.uint8</span><br><span class="line">        &#125;,</span><br><span class="line">        <span class="string">&quot;Kirby_2d25um_grayscale_filtered.raw&quot;</span>: &#123;</span><br><span class="line">            <span class="string">&quot;url&quot;</span>: <span class="string">&quot;https://www.digitalrocksportal.org/projects/317/images/223477/download/&quot;</span>,</span><br><span class="line">            <span class="string">&quot;voxel_length&quot;</span>: [<span class="number">2.25</span>, <span class="number">2.25</span>, <span class="number">2.25</span>],</span><br><span class="line">            <span class="string">&quot;metric_voxel_length_unit&quot;</span>:  <span class="number">1e-6</span>,</span><br><span class="line">            <span class="string">&quot;width&quot;</span>: <span class="number">1000</span>, </span><br><span class="line">            <span class="string">&quot;height&quot;</span>: <span class="number">1000</span>, </span><br><span class="line">            <span class="string">&quot;number_of_slices&quot;</span>: <span class="number">1000</span>,</span><br><span class="line">            <span class="string">&quot;byte_order&quot;</span>: <span class="string">&quot;little-endian&quot;</span>,</span><br><span class="line">            <span class="string">&quot;image_type&quot;</span>: np.uint8</span><br><span class="line">        &#125;,</span><br><span class="line">        <span class="string">&quot;Kirby_2d25um_binary.raw&quot;</span>: &#123;</span><br><span class="line">            <span class="string">&quot;url&quot;</span>: <span class="string">&quot;https://www.digitalrocksportal.org/projects/317/images/223478/download/&quot;</span>,</span><br><span class="line">            <span class="string">&quot;voxel_length&quot;</span>: [<span class="number">2.25</span>, <span class="number">2.25</span>, <span class="number">2.25</span>],</span><br><span class="line">            <span class="string">&quot;metric_voxel_length_unit&quot;</span>: <span class="number">1e-6</span>,</span><br><span class="line">            <span class="string">&quot;width&quot;</span>: <span class="number">1000</span>, </span><br><span class="line">            <span class="string">&quot;height&quot;</span>: <span class="number">1000</span>, </span><br><span class="line">            <span class="string">&quot;number_of_slices&quot;</span>: <span class="number">1000</span>,</span><br><span class="line">            <span class="string">&quot;byte_order&quot;</span>: <span class="string">&quot;little-endian&quot;</span>,</span><br><span class="line">            <span class="string">&quot;image_type&quot;</span>: np.uint8</span><br><span class="line">        &#125;   </span><br><span class="line">    &#125;,</span><br><span class="line">    <span class="string">&quot;Leopard&quot;</span>: &#123;</span><br><span class="line">        <span class="string">&quot;Leopard_2d25um_grayscale.raw&quot;</span>: &#123;</span><br><span class="line">            <span class="string">&quot;url&quot;</span>: <span class="string">&quot;https://www.digitalrocksportal.org/projects/317/images/223479/download/&quot;</span>,</span><br><span class="line">            <span class="string">&quot;voxel_length&quot;</span>: [<span class="number">2.25</span>, <span class="number">2.25</span>, <span class="number">2.25</span>],</span><br><span class="line">            <span class="string">&quot;metric_voxel_length_unit&quot;</span>:  <span class="number">1e-6</span>,</span><br><span class="line">            <span class="string">&quot;width&quot;</span>: <span class="number">1000</span>, </span><br><span class="line">            <span class="string">&quot;height&quot;</span>: <span class="number">1000</span>, </span><br><span class="line">            <span class="string">&quot;number_of_slices&quot;</span>: <span class="number">1000</span>,</span><br><span class="line">            <span class="string">&quot;byte_order&quot;</span>: <span class="string">&quot;little-endian&quot;</span>,</span><br><span class="line">            <span class="string">&quot;image_type&quot;</span>: np.uint8</span><br><span class="line">        &#125;,</span><br><span class="line">        <span class="string">&quot;Leopard_2d25um_grayscale_filtered.raw&quot;</span>: &#123;</span><br><span class="line">            <span class="string">&quot;url&quot;</span>: <span class="string">&quot;https://www.digitalrocksportal.org/projects/317/images/223480/download/&quot;</span>,</span><br><span class="line">            <span class="string">&quot;voxel_length&quot;</span>: [<span class="number">2.25</span>, <span class="number">2.25</span>, <span class="number">2.25</span>],</span><br><span class="line">            <span class="string">&quot;metric_voxel_length_unit&quot;</span>:  <span class="number">1e-6</span>,</span><br><span class="line">            <span class="string">&quot;width&quot;</span>: <span class="number">1000</span>, </span><br><span class="line">            <span class="string">&quot;height&quot;</span>: <span class="number">1000</span>, </span><br><span class="line">            <span class="string">&quot;number_of_slices&quot;</span>: <span class="number">1000</span>,</span><br><span class="line">            <span class="string">&quot;byte_order&quot;</span>: <span class="string">&quot;little-endian&quot;</span>,</span><br><span class="line">            <span class="string">&quot;image_type&quot;</span>: np.uint8</span><br><span class="line">        &#125;,</span><br><span class="line">        <span class="string">&quot;Leopard_2d25um_binary.raw&quot;</span>: &#123;</span><br><span class="line">            <span class="string">&quot;url&quot;</span>: <span class="string">&quot;https://www.digitalrocksportal.org/projects/317/images/223481/download/&quot;</span>,</span><br><span class="line">            <span class="string">&quot;voxel_length&quot;</span>: [<span class="number">2.25</span>, <span class="number">2.25</span>, <span class="number">2.25</span>],</span><br><span class="line">            <span class="string">&quot;metric_voxel_length_unit&quot;</span>: <span class="number">1e-6</span>,</span><br><span class="line">            <span class="string">&quot;width&quot;</span>: <span class="number">1000</span>, </span><br><span class="line">            <span class="string">&quot;height&quot;</span>: <span class="number">1000</span>, </span><br><span class="line">            <span class="string">&quot;number_of_slices&quot;</span>: <span class="number">1000</span>,</span><br><span class="line">            <span class="string">&quot;byte_order&quot;</span>: <span class="string">&quot;little-endian&quot;</span>,</span><br><span class="line">            <span class="string">&quot;image_type&quot;</span>: np.uint8</span><br><span class="line">        &#125;   </span><br><span class="line">    &#125;,</span><br><span class="line">    <span class="string">&quot;Parker&quot;</span>: &#123;</span><br><span class="line">        <span class="string">&quot;Parker_2d25um_grayscale.raw&quot;</span>: &#123;</span><br><span class="line">            <span class="string">&quot;url&quot;</span>: <span class="string">&quot;https://www.digitalrocksportal.org/projects/317/images/223482/download/&quot;</span>,</span><br><span class="line">            <span class="string">&quot;voxel_length&quot;</span>: [<span class="number">2.25</span>, <span class="number">2.25</span>, <span class="number">2.25</span>],</span><br><span class="line">            <span class="string">&quot;metric_voxel_length_unit&quot;</span>:  <span class="number">1e-6</span>,</span><br><span class="line">            <span class="string">&quot;width&quot;</span>: <span class="number">1000</span>, </span><br><span class="line">            <span class="string">&quot;height&quot;</span>: <span class="number">1000</span>, </span><br><span class="line">            <span class="string">&quot;number_of_slices&quot;</span>: <span class="number">1000</span>,</span><br><span class="line">            <span class="string">&quot;byte_order&quot;</span>: <span class="string">&quot;little-endian&quot;</span>,</span><br><span class="line">            <span class="string">&quot;image_type&quot;</span>: np.uint8</span><br><span class="line">        &#125;,</span><br><span class="line">        <span class="string">&quot;Parker_2d25um_grayscale_filtered.raw&quot;</span>: &#123;</span><br><span class="line">            <span class="string">&quot;url&quot;</span>: <span class="string">&quot;https://www.digitalrocksportal.org/projects/317/images/223483/download/&quot;</span>,</span><br><span class="line">            <span class="string">&quot;voxel_length&quot;</span>: [<span class="number">2.25</span>, <span class="number">2.25</span>, <span class="number">2.25</span>],</span><br><span class="line">            <span class="string">&quot;metric_voxel_length_unit&quot;</span>:  <span class="number">1e-6</span>,</span><br><span class="line">            <span class="string">&quot;width&quot;</span>: <span class="number">1000</span>, </span><br><span class="line">            <span class="string">&quot;height&quot;</span>: <span class="number">1000</span>, </span><br><span class="line">            <span class="string">&quot;number_of_slices&quot;</span>: <span class="number">1000</span>,</span><br><span class="line">            <span class="string">&quot;byte_order&quot;</span>: <span class="string">&quot;little-endian&quot;</span>,</span><br><span class="line">            <span class="string">&quot;image_type&quot;</span>: np.uint8</span><br><span class="line">        &#125;,</span><br><span class="line">        <span class="string">&quot;Parker_2d25um_binary.raw&quot;</span>: &#123;</span><br><span class="line">            <span class="string">&quot;url&quot;</span>: <span class="string">&quot;https://www.digitalrocksportal.org/projects/317/images/223484/download/&quot;</span>,</span><br><span class="line">            <span class="string">&quot;voxel_length&quot;</span>: [<span class="number">2.25</span>, <span class="number">2.25</span>, <span class="number">2.25</span>],</span><br><span class="line">            <span class="string">&quot;metric_voxel_length_unit&quot;</span>: <span class="number">1e-6</span>,</span><br><span class="line">            <span class="string">&quot;width&quot;</span>: <span class="number">1000</span>, </span><br><span class="line">            <span class="string">&quot;height&quot;</span>: <span class="number">1000</span>, </span><br><span class="line">            <span class="string">&quot;number_of_slices&quot;</span>: <span class="number">1000</span>,</span><br><span class="line">            <span class="string">&quot;byte_order&quot;</span>: <span class="string">&quot;little-endian&quot;</span>,</span><br><span class="line">            <span class="string">&quot;image_type&quot;</span>: np.uint8</span><br><span class="line">        &#125;   </span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h1 id="案例"><a href="#案例" class="headerlink" title="案例"></a>案例</h1><p>创建conda环境，通过pip安装drd</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> drd.datasets.eleven_sandstones <span class="keyword">import</span> load_eleven_sandstones</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="comment"># xarray DataArray with image data</span></span><br><span class="line">img = load_eleven_sandstones(<span class="string">&quot;Berea&quot;</span>, <span class="string">&quot;Berea_2d25um_grayscale.raw&quot;</span>, <span class="string">&quot;/home/daijin/data/drd_data/&quot;</span>)</span><br><span class="line"><span class="comment">#img = load_eleven_sandstones(&quot;Berea&quot;, &quot;Berea_2d25um_grayscale_filtered.raw&quot;, &quot;/home/daijin/data/drd_data/&quot;)</span></span><br><span class="line"><span class="comment">#img = load_eleven_sandstones(&quot;Berea&quot;, &quot;Berea_2d25um_binary.raw&quot;, &quot;/home/daijin/data/drd_data/&quot;)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Plot average over z dimension</span></span><br><span class="line">img.mean(dim=<span class="string">&#x27;z&#x27;</span>).plot()</span><br><span class="line"><span class="comment">#img.mean(dim=&#x27;x&#x27;).plot()</span></span><br><span class="line"><span class="comment">#img.mean(dim=&#x27;y&#x27;).plot()</span></span><br><span class="line"></span><br><span class="line">plt.tight_layout()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p>程序运行会检查文件是否下载，下载完成后进行文件校验，校验完成后进行数据读取。</p><img src="/2024/08/12/drd-Digital_Rocks_Data/Berea_2d25um_grayscale_z.png" class="" title="Berea_2d25um_grayscale_z"><img src="/2024/08/12/drd-Digital_Rocks_Data/Berea_2d25um_grayscale_filtered_z.png" class="" title="Berea_2d25um_grayscale_filtered_z"><img src="/2024/08/12/drd-Digital_Rocks_Data/Berea_2d25um_binary_z.png" class="" title="Berea_2d25um_binary_z"><img src="/2024/08/12/drd-Digital_Rocks_Data/Berea_2d25um_grayscale_x.png" class="" title="Berea_2d25um_grayscale_x"><img src="/2024/08/12/drd-Digital_Rocks_Data/Berea_2d25um_grayscale_filtered_x.png" class="" title="Berea_2d25um_grayscale_filtered_x"><img src="/2024/08/12/drd-Digital_Rocks_Data/Berea_2d25um_binary_x.png" class="" title="Berea_2d25um_binary_x"><img src="/2024/08/12/drd-Digital_Rocks_Data/Berea_2d25um_grayscale_y.png" class="" title="Berea_2d25um_grayscale_y"><img src="/2024/08/12/drd-Digital_Rocks_Data/Berea_2d25um_grayscale_filtered_y.png" class="" title="Berea_2d25um_grayscale_filtered_y"><img src="/2024/08/12/drd-Digital_Rocks_Data/Berea_2d25um_binary_y.png" class="" title="Berea_2d25um_binary_y">]]></content>
    
    
    <summary type="html">drd-Digital_Rocks_Data</summary>
    
    
    
    <category term="岩石物理" scheme="http://hibiscidai.com/categories/%E5%B2%A9%E7%9F%B3%E7%89%A9%E7%90%86/"/>
    
    
    <category term="数字岩心" scheme="http://hibiscidai.com/tags/%E6%95%B0%E5%AD%97%E5%B2%A9%E5%BF%83/"/>
    
    <category term="岩石物理" scheme="http://hibiscidai.com/tags/%E5%B2%A9%E7%9F%B3%E7%89%A9%E7%90%86/"/>
    
  </entry>
  
  <entry>
    <title>WebDAV-使用指南</title>
    <link href="http://hibiscidai.com/2024/08/12/WebDAV-%E4%BD%BF%E7%94%A8%E6%8C%87%E5%8D%97/"/>
    <id>http://hibiscidai.com/2024/08/12/WebDAV-%E4%BD%BF%E7%94%A8%E6%8C%87%E5%8D%97/</id>
    <published>2024-08-12T06:00:00.000Z</published>
    <updated>2024-08-12T06:10:29.000Z</updated>
    
    <content type="html"><![CDATA[<img src="/2024/08/12/WebDAV-%E4%BD%BF%E7%94%A8%E6%8C%87%E5%8D%97/WebDAV-%E4%BD%BF%E7%94%A8%E6%8C%87%E5%8D%97.png" class="" title="WebDAV-使用指南"><p>WebDAV-使用指南</p><span id="more"></span><h1 id="WebDAV-使用指南"><a href="#WebDAV-使用指南" class="headerlink" title="WebDAV-使用指南"></a>WebDAV-使用指南</h1><p><a href="https://kb.synology.cn/zh-cn/DSM/tutorial/How_to_access_files_on_Synology_NAS_with_WebDAV">如何使用 WebDAV 访问 Synology NAS 上的文件？</a></p><p><a href="https://kb.synology.cn/zh-cn/DSM/help/WebDAVServer/webdav_server?version=7">WebDAV Server</a></p><p><a href="https://www.raidrive.com/">RaiDriver</a></p><h1 id="WebDAV是啥"><a href="#WebDAV是啥" class="headerlink" title="WebDAV是啥"></a>WebDAV是啥</h1><p>基于Web的分布式编写和版本控制（英语：Web-based Distributed Authoring and Versioning，缩写：WebDAV）是超文本传输协议（HTTP）的扩展，有利于用户间协同编辑和管理存储在万维网服务器文档。</p><p>WebDAV协议为用户在服务器上创建、更改和移动文档提供了一个框架。WebDAV协议最重要的功能包括作者或修改日期等属性的维护、命名空间管理、集合和覆盖保护。为属性维护所提供的功能包括创建、删除和查询文件信息等；命名空间管理处理在服务器名称空间内复制和移动网页的能力；集合（Collections）处理各种资源的创建、删除和列举；覆盖保护处理与锁定文件相关的问题。WebDAV协议利用TLS、HTTP摘要认证、XML等技术来满足这些需求。</p><h1 id="Synology设置要求"><a href="#Synology设置要求" class="headerlink" title="Synology设置要求"></a>Synology设置要求</h1><p>参看前文连接</p><h1 id="RaiDriver配置"><a href="#RaiDriver配置" class="headerlink" title="RaiDriver配置"></a>RaiDriver配置</h1><p>下载RaiDriver<br>安装RaiDriver</p><img src="/2024/08/12/WebDAV-%E4%BD%BF%E7%94%A8%E6%8C%87%E5%8D%97/RaiDriver%E9%85%8D%E7%BD%AE-1.png" class="" title="RaiDriver配置-1"><p>此软件只保证在win上通过WebDAV协议进行访问，可以测试连通性。<br>测试成功后可以在本地电脑磁盘上看到映射的文件</p><h1 id="注意事项"><a href="#注意事项" class="headerlink" title="注意事项"></a>注意事项</h1><p>群辉自带内网穿透，http写：<br><a href="https://{内网ip}.{quickconnect}.quickconnect.cn:{端口}/{映射文件夹}">https://{内网ip}.{quickconnect}.quickconnect.cn:{端口}/{映射文件夹}</a></p><p>账户密码可以用一个，但建议创建新用户，防止密码泄密后访问所有文件。</p>]]></content>
    
    
    <summary type="html">WebDAV-使用指南</summary>
    
    
    
    <category term="软件" scheme="http://hibiscidai.com/categories/%E8%BD%AF%E4%BB%B6/"/>
    
    
    <category term="软件" scheme="http://hibiscidai.com/tags/%E8%BD%AF%E4%BB%B6/"/>
    
    <category term="WebDAV" scheme="http://hibiscidai.com/tags/WebDAV/"/>
    
  </entry>
  
  <entry>
    <title>Cesium-使用指南</title>
    <link href="http://hibiscidai.com/2024/08/06/Cesium-%E4%BD%BF%E7%94%A8%E6%8C%87%E5%8D%97/"/>
    <id>http://hibiscidai.com/2024/08/06/Cesium-%E4%BD%BF%E7%94%A8%E6%8C%87%E5%8D%97/</id>
    <published>2024-08-06T08:00:00.000Z</published>
    <updated>2024-08-08T09:22:57.000Z</updated>
    
    <content type="html"><![CDATA[<img src="/2024/08/06/Cesium-%E4%BD%BF%E7%94%A8%E6%8C%87%E5%8D%97/Cesium-%E4%BD%BF%E7%94%A8%E6%8C%87%E5%8D%97.png" class="" title="Cesium-使用指南"><p>Cesium-使用指南</p><span id="more"></span><h1 id="Cesium-使用指南"><a href="#Cesium-使用指南" class="headerlink" title="Cesium-使用指南"></a>Cesium-使用指南</h1><p><a href="https://cesium.com/">Cesium: The Platform for 3D Geospatial</a></p><p><a href="https://github.com/CesiumGS/cesium">Cesium-github</a></p><p><a href="https://cesium.com/learn/cesiumjs-sandcastle/">Cesium-doc</a></p><p><a href="https://sandcastle.cesium.com/">Cesium-沙盒</a></p><p><a href="https://ion.cesium.com/">Cesium-用户控制面板</a></p><p><a href="http://lbs.tianditu.gov.cn/">国家地理信息公共服务平台天地图</a></p><p><a href="http://lbs.tianditu.gov.cn/server/MapService.html">天地图-地图API</a></p><p><a href=""></a></p><h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h1><p>CesiumJS is a JavaScript library for creating 3D globes and 2D maps in a web browser without a plugin. It uses WebGL for hardware-accelerated graphics, and is cross-platform, cross-browser, and tuned for dynamic-data visualization.<br>CesiumJS 是一个 JavaScript 库，用于在 Web 浏览器中创建 3D 地球仪和 2D 地图，无需插件。它使用 WebGL 进行硬件加速图形处理，并且跨平台、跨浏览器，并针对动态数据可视化进行了调整。</p><p>Built on open formats, CesiumJS is designed for robust interoperability and scaling for massive datasets.<br>CesiumJS 基于开放格式构建，旨在实现强大的互操作性和对海量数据集的扩展。</p><h1 id="注册"><a href="#注册" class="headerlink" title="注册"></a>注册</h1><p>登陆cesium官网注册账号，然后前往用户控制面板查看自己的<code>Access Tokens</code>，最好新建一个token，打开全部权限。</p><p>登陆天地图官网进行注册，进入用户平台。创建新的应用，得到应用的key。</p><h1 id="安装CesiumJS"><a href="#安装CesiumJS" class="headerlink" title="安装CesiumJS"></a>安装CesiumJS</h1><h2 id="CDN安装-主要安装方式"><a href="#CDN安装-主要安装方式" class="headerlink" title="CDN安装-主要安装方式"></a>CDN安装-主要安装方式</h2><p>Below is a complete HTML page that will load the required JavaScript and CSS files and initialize the scene at San Francisco. If you don’t have a development environment, you can create a file containing this HTML and view it in a browser.<br>下面是一个完整的 HTML 页面，它将加载所需的 JavaScript 和 CSS 文件并初始化旧金山的场景。如果您没有开发环境，您可以创建一个包含此 HTML 的文件并在浏览器中查看它。</p><p>Just replace your_access_token with your Cesium ion access token.</p><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&lt;!DOCTYPE <span class="keyword">html</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">html</span> <span class="attr">lang</span>=<span class="string">&quot;en&quot;</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">head</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">meta</span> <span class="attr">charset</span>=<span class="string">&quot;utf-8&quot;</span>&gt;</span></span><br><span class="line">  <span class="comment">&lt;!-- Include the CesiumJS JavaScript and CSS files --&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">script</span> <span class="attr">src</span>=<span class="string">&quot;https://cesium.com/downloads/cesiumjs/releases/1.120/Build/Cesium/Cesium.js&quot;</span>&gt;</span><span class="tag">&lt;/<span class="name">script</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">link</span> <span class="attr">href</span>=<span class="string">&quot;https://cesium.com/downloads/cesiumjs/releases/1.120/Build/Cesium/Widgets/widgets.css&quot;</span> <span class="attr">rel</span>=<span class="string">&quot;stylesheet&quot;</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">head</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">body</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">div</span> <span class="attr">id</span>=<span class="string">&quot;cesiumContainer&quot;</span>&gt;</span><span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">script</span> <span class="attr">type</span>=<span class="string">&quot;module&quot;</span>&gt;</span><span class="language-javascript"></span></span><br><span class="line"><span class="language-javascript">    <span class="comment">// Your access token can be found at: https://ion.cesium.com/tokens.</span></span></span><br><span class="line"><span class="language-javascript">    <span class="comment">// Replace `your_access_token` with your Cesium ion access token.</span></span></span><br><span class="line"><span class="language-javascript"></span></span><br><span class="line"><span class="language-javascript">    <span class="title class_">Cesium</span>.<span class="property">Ion</span>.<span class="property">defaultAccessToken</span> = <span class="string">&#x27;your_access_token&#x27;</span>;</span></span><br><span class="line"><span class="language-javascript"></span></span><br><span class="line"><span class="language-javascript">    <span class="comment">// Initialize the Cesium Viewer in the HTML element with the `cesiumContainer` ID.</span></span></span><br><span class="line"><span class="language-javascript">    <span class="keyword">const</span> viewer = <span class="keyword">new</span> <span class="title class_">Cesium</span>.<span class="title class_">Viewer</span>(<span class="string">&#x27;cesiumContainer&#x27;</span>, &#123;</span></span><br><span class="line"><span class="language-javascript">      <span class="attr">terrain</span>: <span class="title class_">Cesium</span>.<span class="property">Terrain</span>.<span class="title function_">fromWorldTerrain</span>(),</span></span><br><span class="line"><span class="language-javascript">    &#125;);    </span></span><br><span class="line"><span class="language-javascript"></span></span><br><span class="line"><span class="language-javascript">    <span class="comment">// Fly the camera to San Francisco at the given longitude, latitude, and height.</span></span></span><br><span class="line"><span class="language-javascript">    viewer.<span class="property">camera</span>.<span class="title function_">flyTo</span>(&#123;</span></span><br><span class="line"><span class="language-javascript">      <span class="attr">destination</span>: <span class="title class_">Cesium</span>.<span class="property">Cartesian3</span>.<span class="title function_">fromDegrees</span>(-<span class="number">122.4175</span>, <span class="number">37.655</span>, <span class="number">400</span>),</span></span><br><span class="line"><span class="language-javascript">      <span class="attr">orientation</span>: &#123;</span></span><br><span class="line"><span class="language-javascript">        <span class="attr">heading</span>: <span class="title class_">Cesium</span>.<span class="property">Math</span>.<span class="title function_">toRadians</span>(<span class="number">0.0</span>),</span></span><br><span class="line"><span class="language-javascript">        <span class="attr">pitch</span>: <span class="title class_">Cesium</span>.<span class="property">Math</span>.<span class="title function_">toRadians</span>(-<span class="number">15.0</span>),</span></span><br><span class="line"><span class="language-javascript">      &#125;</span></span><br><span class="line"><span class="language-javascript">    &#125;);</span></span><br><span class="line"><span class="language-javascript"></span></span><br><span class="line"><span class="language-javascript">    <span class="comment">// Add Cesium OSM Buildings, a global 3D buildings layer.</span></span></span><br><span class="line"><span class="language-javascript">    <span class="keyword">const</span> buildingTileset = <span class="keyword">await</span> <span class="title class_">Cesium</span>.<span class="title function_">createOsmBuildingsAsync</span>();</span></span><br><span class="line"><span class="language-javascript">    viewer.<span class="property">scene</span>.<span class="property">primitives</span>.<span class="title function_">add</span>(buildingTileset);   </span></span><br><span class="line"><span class="language-javascript">  </span><span class="tag">&lt;/<span class="name">script</span>&gt;</span></span><br><span class="line"> <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">body</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">html</span>&gt;</span></span><br></pre></td></tr></table></figure><img src="/2024/08/06/Cesium-%E4%BD%BF%E7%94%A8%E6%8C%87%E5%8D%97/CesiumJSHelloWorld.png" class="" title="CesiumJSHelloWorld"><h2 id="挂载服务器"><a href="#挂载服务器" class="headerlink" title="挂载服务器"></a>挂载服务器</h2><p>在本地打开的html可以预览格式和js，但是调用cesium的地图服务需要采用http传输协议，所以在本地容易出现卡地图加载不出来的情况。</p><p>需要将静态页面部署到有公网ip的服务器上，进行静态页面访问即可。</p><h3 id="宝塔新建静态网页"><a href="#宝塔新建静态网页" class="headerlink" title="宝塔新建静态网页"></a>宝塔新建静态网页</h3><p>默认网页端口是80，如果想创建多个网站，可以使用多端口映射。</p><p>先去ecs控制台打开81（也可以自己定义）端口，然后宝塔界面安全组也打开。</p><p>网站→添加站点<br>域名：xxx.xxx.xxx.xxx:81<br>根目录：www/wwwroot/新建网站文件夹<br>FTP：无<br>数据库：无<br>PHP版本：纯静态<br>网站分类：默认分类</p><p>创建完成之后根目录中index.html即可<br>可以通过<code>xxx.xxx.xxxx.xxx:81</code>访问index<br>根目录中其他网页可以输入<code>xxx.xxx.xxxx.xxx:81/xxx.html</code>访问</p><h2 id="NPM安装-参考安装，本文不采用"><a href="#NPM安装-参考安装，本文不采用" class="headerlink" title="NPM安装-参考安装，本文不采用"></a>NPM安装-参考安装，本文不采用</h2><p>If you’re building your application using a module bundler such as Webpack, Parcel, or Rollup, you can install CesiumJS by running:<br>如果您使用模块捆绑器（例如 Webpack、Parcel 或 Rollup）构建应用程序，则可以通过运行以下命令安装 CesiumJS：</p><p>npm install cesium</p><p>The code below loads the required JavaScript and CSS files.<br>以下代码加载所需的 JavaScript 和 CSS 文件。</p><p>Just replace your_access_token with your Cesium ion access token.<br>只需将 your_access_token 替换为您的 Cesium ion 访问令牌即可。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">// The URL on your server where CesiumJS<span class="string">&#x27;s static files are hosted.</span></span><br><span class="line"><span class="string">window.CESIUM_BASE_URL = &#x27;</span>/<span class="string">&#x27;;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">import &#123; Cartesian3, createOsmBuildingsAsync, Ion, Math as CesiumMath, Terrain, Viewer &#125; from &#x27;</span>cesium<span class="string">&#x27;;</span></span><br><span class="line"><span class="string">import &quot;cesium/Build/Cesium/Widgets/widgets.css&quot;;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">// Your access token can be found at: https://ion.cesium.com/tokens.</span></span><br><span class="line"><span class="string">// Replace `your_access_token` with your Cesium ion access token.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Ion.defaultAccessToken = &#x27;</span>your_access_token<span class="string">&#x27;;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">// Initialize the Cesium Viewer in the HTML element with the `cesiumContainer` ID.</span></span><br><span class="line"><span class="string">const viewer = new Viewer(&#x27;</span>cesiumContaine<span class="string">r&#x27;, &#123;</span></span><br><span class="line"><span class="string">  terrain: Terrain.fromWorldTerrain(),</span></span><br><span class="line"><span class="string">&#125;);    </span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">// Fly the camera to San Francisco at the given longitude, latitude, and height.</span></span><br><span class="line"><span class="string">viewer.camera.flyTo(&#123;</span></span><br><span class="line"><span class="string">  destination: Cartesian3.fromDegrees(-122.4175, 37.655, 400),</span></span><br><span class="line"><span class="string">  orientation: &#123;</span></span><br><span class="line"><span class="string">    heading: CesiumMath.toRadians(0.0),</span></span><br><span class="line"><span class="string">    pitch: CesiumMath.toRadians(-15.0),</span></span><br><span class="line"><span class="string">  &#125;</span></span><br><span class="line"><span class="string">&#125;);</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">// Add Cesium OSM Buildings, a global 3D buildings layer.</span></span><br><span class="line"><span class="string">const buildingTileset = await createOsmBuildingsAsync();</span></span><br><span class="line"><span class="string">viewer.scene.primitives.add(buildingTileset);   </span></span><br></pre></td></tr></table></figure><h3 id="Configuring-CESIUM-BASE-URL"><a href="#Configuring-CESIUM-BASE-URL" class="headerlink" title="Configuring CESIUM_BASE_URL"></a>Configuring CESIUM_BASE_URL</h3><p>CesiumJS requires a few static files to be hosted on your server, like web workers and SVG icons. Configure your module bundler to copy the following four directories and serve them as static files:<br>CesiumJS 需要在您的服务器上托管一些静态文件，例如 Web Worker 和 SVG 图标。配置您的模块捆绑器以复制以下四个目录并将它们作为静态文件提供：</p><ul><li><code>node_modules/cesium/Build/Cesium/Workers</code></li><li><code>node_modules/cesium/Build/Cesium/ThirdParty</code></li><li><code>node_modules/cesium/Build/Cesium/Assets</code></li><li><code>node_modules/cesium/Build/Cesium/Widgets</code></li></ul><p>The <code>window.CESIUM_BASE_URL</code> global variable must be set before CesiumJS is imported. It must point to the URL where those four directories are served.</p><p>在导入 CesiumJS 之前必须设置 <code>window.CESIUM_BASE_URL</code> 全局变量。它必须指向提供这四个目录的 URL。</p><p>For example, if the image at <code>Assets/Images/cesium_credit.png</code> is served with a <code>static/Cesium/</code> prefix under <a href="http://localhost:8080/static/Cesium/Assets/Images/cesium_credit.png">http://localhost:8080/static/Cesium/Assets/Images/cesium_credit.png</a>, then you would set the base URL as follows:</p><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">window.CESIUM_BASE_URL = &#x27;/static/Cesium/&#x27;;</span><br></pre></td></tr></table></figure><p>See the Cesium Webpack Example for a complete Webpack config.<br>请参阅 Cesium Webpack 示例以了解完整的 Webpack 配置。</p><h1 id="地图"><a href="#地图" class="headerlink" title="地图"></a>地图</h1><h2 id="Cesium平台提供的地图"><a href="#Cesium平台提供的地图" class="headerlink" title="Cesium平台提供的地图"></a>Cesium平台提供的地图</h2><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&lt;!DOCTYPE <span class="keyword">html</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">html</span> <span class="attr">lang</span>=<span class="string">&quot;en&quot;</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">head</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">meta</span> <span class="attr">charset</span>=<span class="string">&quot;utf-8&quot;</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- Include the CesiumJS JavaScript and CSS files --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">script</span> <span class="attr">src</span>=<span class="string">&quot;https://cesium.com/downloads/cesiumjs/releases/1.120/Build/Cesium/Cesium.js&quot;</span>&gt;</span><span class="tag">&lt;/<span class="name">script</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">link</span> <span class="attr">href</span>=<span class="string">&quot;https://cesium.com/downloads/cesiumjs/releases/1.120/Build/Cesium/Widgets/widgets.css&quot;</span> <span class="attr">rel</span>=<span class="string">&quot;stylesheet&quot;</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">head</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">body</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">div</span> <span class="attr">id</span>=<span class="string">&quot;cesiumContainer&quot;</span>&gt;</span><span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">script</span>&gt;</span><span class="language-javascript"></span></span><br><span class="line"><span class="language-javascript">            <span class="comment">// Natural Earth II with Shaded Relief, Water, and Drainages from http://www.naturalearthdata.com</span></span></span><br><span class="line"><span class="language-javascript">            <span class="keyword">const</span> viewer = <span class="keyword">new</span> <span class="title class_">Cesium</span>.<span class="title class_">Viewer</span>(<span class="string">&quot;cesiumContainer&quot;</span>, &#123;</span></span><br><span class="line"><span class="language-javascript"><span class="attr">baseLayer</span>: <span class="title class_">Cesium</span>.<span class="property">ImageryLayer</span>.<span class="title function_">fromProviderAsync</span>(</span></span><br><span class="line"><span class="language-javascript"><span class="title class_">Cesium</span>.<span class="property">IonImageryProvider</span>.<span class="title function_">fromAssetId</span>(<span class="number">3813</span>)</span></span><br><span class="line"><span class="language-javascript">),</span></span><br><span class="line"><span class="language-javascript">            &#125;);</span></span><br><span class="line"><span class="language-javascript"></span><span class="tag">&lt;/<span class="name">script</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">div</span> <span class="attr">id</span>=<span class="string">&quot;csiumContain&quot;</span>&gt;</span><span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">body</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">html</span>&gt;</span></span><br></pre></td></tr></table></figure><blockquote><p>添加个人token会导致无法调用地图。</p></blockquote><p>其中<code>AssetId</code>为官方提供的id地址</p><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">script</span>&gt;</span><span class="language-javascript"></span></span><br><span class="line"><span class="language-javascript"><span class="keyword">const</span> viewer = <span class="keyword">new</span> <span class="title class_">Cesium</span>.<span class="title class_">Viewer</span>(<span class="string">&#x27;cesiumContainer&#x27;</span>, </span></span><br><span class="line"><span class="language-javascript">    &#123;</span></span><br><span class="line"><span class="language-javascript"><span class="attr">baseLayer</span>: <span class="title class_">Cesium</span>.<span class="property">ImageryLayer</span>.<span class="title function_">fromProviderAsync</span>(</span></span><br><span class="line"><span class="language-javascript"><span class="title class_">Cesium</span>.<span class="property">IonImageryProvider</span>.<span class="title function_">fromAssetId</span>(<span class="number">3</span>)</span></span><br><span class="line"><span class="language-javascript">),</span></span><br><span class="line"><span class="language-javascript">    &#125;</span></span><br><span class="line"><span class="language-javascript">&#125;);</span></span><br><span class="line"><span class="language-javascript"></span><span class="tag">&lt;/<span class="name">script</span>&gt;</span></span><br></pre></td></tr></table></figure><p>在cesium-用户控制台中<code>My Assets</code>可以找到对应的id</p><div class="table-container"><table><thead><tr><th style="text-align:center">ID</th><th style="text-align:center">Name</th><th style="text-align:center">Type</th><th style="text-align:center">Data added</th><th style="text-align:center">Size</th></tr></thead><tbody><tr><td style="text-align:center">2275207</td><td style="text-align:center">Google Photorealistic 3D Tiles</td><td style="text-align:center">3D Tiles</td><td style="text-align:center">2023-9-13</td><td style="text-align:center">-</td></tr><tr><td style="text-align:center">96188</td><td style="text-align:center">Cesium OSM Buildings</td><td style="text-align:center">3D Tiles</td><td style="text-align:center">2020-5-1</td><td style="text-align:center">-</td></tr><tr><td style="text-align:center">4</td><td style="text-align:center">Bing Maps Road</td><td style="text-align:center">Imagery</td><td style="text-align:center">2016-10-27</td><td style="text-align:center">-</td></tr><tr><td style="text-align:center">3</td><td style="text-align:center">Bing Maps Aerial with Labels</td><td style="text-align:center">Imagery</td><td style="text-align:center">2016-10-27</td><td style="text-align:center">-</td></tr><tr><td style="text-align:center">2</td><td style="text-align:center">Bing Maps Aerial</td><td style="text-align:center">Imagery</td><td style="text-align:center">2016-10-27</td><td style="text-align:center">-</td></tr><tr><td style="text-align:center">1</td><td style="text-align:center">Cesium World Terrain</td><td style="text-align:center">Terrain</td><td style="text-align:center">2016-10-18</td><td style="text-align:center">-</td></tr><tr><td style="text-align:center">3831</td><td style="text-align:center">Natural Earth II</td><td style="text-align:center">-</td><td style="text-align:center">-</td><td style="text-align:center">-</td></tr></tbody></table></div><img src="/2024/08/06/Cesium-%E4%BD%BF%E7%94%A8%E6%8C%87%E5%8D%97/Google%20Photorealistic%203D%20Tiles.png" class="" alt="Google Photorealistic 3D Tiles"><img src="/2024/08/06/Cesium-%E4%BD%BF%E7%94%A8%E6%8C%87%E5%8D%97/Cesium%20OSM%20Buildings.png" class="" alt="Cesium OSM Buildings"><img src="/2024/08/06/Cesium-%E4%BD%BF%E7%94%A8%E6%8C%87%E5%8D%97/Bing%20Maps%20Road.png" class="" alt="Bing Maps Road"><img src="/2024/08/06/Cesium-%E4%BD%BF%E7%94%A8%E6%8C%87%E5%8D%97/Bing%20Maps%20Aerial%20with%20Labels.png" class="" alt="Bing Maps Aerial with Labels"><img src="/2024/08/06/Cesium-%E4%BD%BF%E7%94%A8%E6%8C%87%E5%8D%97/Bing%20Maps%20Aerial.png" class="" alt="Bing Maps Aerial"><img src="/2024/08/06/Cesium-%E4%BD%BF%E7%94%A8%E6%8C%87%E5%8D%97/Cesium%20World%20Terrain.png" class="" alt="Cesium World Terrain"><img src="/2024/08/06/Cesium-%E4%BD%BF%E7%94%A8%E6%8C%87%E5%8D%97/Natural%20Earth%20II.png" class="" alt="Natural Earth II"><h2 id="天地图提供的地图"><a href="#天地图提供的地图" class="headerlink" title="天地图提供的地图"></a>天地图提供的地图</h2><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&lt;!DOCTYPE <span class="keyword">html</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">html</span> <span class="attr">lang</span>=<span class="string">&quot;en&quot;</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">head</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">meta</span> <span class="attr">charset</span>=<span class="string">&quot;utf-8&quot;</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- Include the CesiumJS JavaScript and CSS files --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">script</span> <span class="attr">src</span>=<span class="string">&quot;https://cesium.com/downloads/cesiumjs/releases/1.120/Build/Cesium/Cesium.js&quot;</span>&gt;</span><span class="tag">&lt;/<span class="name">script</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">link</span> <span class="attr">href</span>=<span class="string">&quot;https://cesium.com/downloads/cesiumjs/releases/1.120/Build/Cesium/Widgets/widgets.css&quot;</span> <span class="attr">rel</span>=<span class="string">&quot;stylesheet&quot;</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">head</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">body</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">div</span> <span class="attr">id</span>=<span class="string">&quot;cesiumContainer&quot;</span>&gt;</span><span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">script</span>&gt;</span><span class="language-javascript"></span></span><br><span class="line"><span class="language-javascript"><span class="comment">// 这个 tk 只能在本域名下使用</span></span></span><br><span class="line"><span class="language-javascript"><span class="keyword">var</span> token = <span class="string">&#x27;xxx&#x27;</span>;</span></span><br><span class="line"><span class="language-javascript"><span class="comment">// 服务域名</span></span></span><br><span class="line"><span class="language-javascript"><span class="comment">//var tdtUrl = &#x27;https://t&#123;s&#125;.tianditu.gov.cn/&#x27;;</span></span></span><br><span class="line"><span class="language-javascript"><span class="comment">// 服务负载子域</span></span></span><br><span class="line"><span class="language-javascript"><span class="keyword">var</span> subdomains=[<span class="string">&#x27;0&#x27;</span>,<span class="string">&#x27;1&#x27;</span>,<span class="string">&#x27;2&#x27;</span>,<span class="string">&#x27;3&#x27;</span>,<span class="string">&#x27;4&#x27;</span>,<span class="string">&#x27;5&#x27;</span>,<span class="string">&#x27;6&#x27;</span>,<span class="string">&#x27;7&#x27;</span>];</span></span><br><span class="line"><span class="language-javascript"><span class="keyword">var</span> viewer = <span class="keyword">new</span> <span class="title class_">Cesium</span>.<span class="title class_">Viewer</span>(<span class="string">&#x27;cesiumContainer&#x27;</span>,&#123;</span></span><br><span class="line"><span class="language-javascript"><span class="attr">shouldAnimate</span>: <span class="literal">true</span>,</span></span><br><span class="line"><span class="language-javascript"><span class="attr">selectionIndicator</span>:<span class="literal">true</span>,</span></span><br><span class="line"><span class="language-javascript"><span class="attr">animation</span>:<span class="literal">true</span>,       <span class="comment">//动画</span></span></span><br><span class="line"><span class="language-javascript"><span class="attr">homeButton</span>:<span class="literal">true</span>,       <span class="comment">//home键</span></span></span><br><span class="line"><span class="language-javascript"><span class="attr">geocoder</span>:<span class="literal">true</span>,         <span class="comment">//地址编码</span></span></span><br><span class="line"><span class="language-javascript"><span class="attr">baseLayerPicker</span>:<span class="literal">true</span>, <span class="comment">//图层选择控件</span></span></span><br><span class="line"><span class="language-javascript"><span class="attr">timeline</span>:<span class="literal">true</span>,        <span class="comment">//时间轴</span></span></span><br><span class="line"><span class="language-javascript"><span class="attr">fullscreenButton</span>:<span class="literal">true</span>, <span class="comment">//全屏显示</span></span></span><br><span class="line"><span class="language-javascript"><span class="attr">infoBox</span>:<span class="literal">true</span>,         <span class="comment">//点击要素之后浮窗</span></span></span><br><span class="line"><span class="language-javascript"><span class="attr">sceneModePicker</span>:<span class="literal">true</span>,  <span class="comment">//投影方式  三维/二维</span></span></span><br><span class="line"><span class="language-javascript"><span class="attr">navigationInstructionsInitiallyVisible</span>:<span class="literal">true</span>, <span class="comment">//导航指令</span></span></span><br><span class="line"><span class="language-javascript"><span class="attr">navigationHelpButton</span>:<span class="literal">true</span>,     <span class="comment">//帮助信息</span></span></span><br><span class="line"><span class="language-javascript"><span class="attr">selectionIndicator</span>:<span class="literal">true</span>, <span class="comment">// 选择</span></span></span><br><span class="line"><span class="language-javascript"><span class="attr">imageryProvider</span>: <span class="keyword">new</span> <span class="variable language_">window</span>.<span class="property">Cesium</span>.<span class="title class_">WebMapTileServiceImageryProvider</span>(&#123;</span></span><br><span class="line"><span class="language-javascript"><span class="comment">//影像底图,</span></span></span><br><span class="line"><span class="language-javascript"><span class="attr">url</span>: <span class="string">&quot;http://t0.tianditu.gov.cn/ter_c/wmts?tk=&quot;</span>+token,<span class="comment">//天地图的地图晕眩-经纬度</span></span></span><br><span class="line"><span class="language-javascript"><span class="comment">//url: &quot;http://t0.tianditu.gov.cn/ter_w/wmts?tk=&quot;+token,//天地图的地图晕眩-球面墨卡托</span></span></span><br><span class="line"><span class="language-javascript"><span class="attr">subdomains</span>: subdomains,</span></span><br><span class="line"><span class="language-javascript"><span class="attr">layer</span>: <span class="string">&quot;tdtImgLayer&quot;</span>,</span></span><br><span class="line"><span class="language-javascript"><span class="attr">style</span>: <span class="string">&quot;default&quot;</span>,</span></span><br><span class="line"><span class="language-javascript"><span class="attr">format</span>: <span class="string">&quot;image/jpeg&quot;</span>,</span></span><br><span class="line"><span class="language-javascript"><span class="attr">tileMatrixSetID</span>: <span class="string">&quot;GoogleMapsCompatible&quot;</span>,<span class="comment">//使用谷歌的瓦片切片方式</span></span></span><br><span class="line"><span class="language-javascript"><span class="attr">show</span>: <span class="literal">true</span></span></span><br><span class="line"><span class="language-javascript">&#125;)</span></span><br><span class="line"><span class="language-javascript">&#125;);</span></span><br><span class="line"><span class="language-javascript"></span></span><br><span class="line"><span class="language-javascript">viewer.<span class="property">imageryLayers</span>.<span class="title function_">addImageryProvider</span>(<span class="keyword">new</span> <span class="variable language_">window</span>.<span class="property">Cesium</span>.<span class="title class_">WebMapTileServiceImageryProvider</span>(&#123;</span></span><br><span class="line"><span class="language-javascript"><span class="comment">//影像注记</span></span></span><br><span class="line"><span class="language-javascript"><span class="comment">//url: &quot;http://t0.tianditu.gov.cn/cta_c/wmts?tk=&quot;+token,//天地图的地形标注-经纬度</span></span></span><br><span class="line"><span class="language-javascript"><span class="attr">url</span>: <span class="string">&quot;http://t0.tianditu.gov.cn/cta_w/wmts?tk=&quot;</span>+token,<span class="comment">//天地图的地形标注-球面墨卡托</span></span></span><br><span class="line"><span class="language-javascript"><span class="attr">subdomains</span>: subdomains,</span></span><br><span class="line"><span class="language-javascript"><span class="attr">layer</span>: <span class="string">&quot;tdtCiaLayer&quot;</span>,</span></span><br><span class="line"><span class="language-javascript"><span class="attr">style</span>: <span class="string">&quot;default&quot;</span>,</span></span><br><span class="line"><span class="language-javascript"><span class="attr">format</span>: <span class="string">&quot;image/jpeg&quot;</span>,</span></span><br><span class="line"><span class="language-javascript"><span class="attr">tileMatrixSetID</span>: <span class="string">&quot;GoogleMapsCompatible&quot;</span>,</span></span><br><span class="line"><span class="language-javascript"><span class="attr">show</span>: <span class="literal">true</span></span></span><br><span class="line"><span class="language-javascript">&#125;));</span></span><br><span class="line"><span class="language-javascript"></span></span><br><span class="line"><span class="language-javascript">viewer.<span class="property">camera</span>.<span class="title function_">setView</span>(&#123;</span></span><br><span class="line"><span class="language-javascript"><span class="comment">// fromDegrees()方法，将经纬度和高程转换为世界坐标</span></span></span><br><span class="line"><span class="language-javascript"><span class="attr">destination</span>:<span class="title class_">Cesium</span>.<span class="property">Cartesian3</span>.<span class="title function_">fromDegrees</span>(-<span class="number">121.9068641</span>,<span class="number">56.20149076</span>,<span class="number">20000000</span>),</span></span><br><span class="line"><span class="language-javascript"><span class="attr">orientation</span>:&#123;</span></span><br><span class="line"><span class="language-javascript"><span class="comment">// 指向</span></span></span><br><span class="line"><span class="language-javascript"><span class="attr">heading</span>:<span class="title class_">Cesium</span>.<span class="property">Math</span>.<span class="title function_">toRadians</span>(<span class="number">270</span>,<span class="number">0</span>),</span></span><br><span class="line"><span class="language-javascript"><span class="comment">// 视角</span></span></span><br><span class="line"><span class="language-javascript"><span class="attr">pitch</span>:<span class="title class_">Cesium</span>.<span class="property">Math</span>.<span class="title function_">toRadians</span>(-<span class="number">90</span>),</span></span><br><span class="line"><span class="language-javascript"><span class="attr">roll</span>:<span class="number">0.0</span></span></span><br><span class="line"><span class="language-javascript">&#125;</span></span><br><span class="line"><span class="language-javascript">&#125;);</span></span><br><span class="line"><span class="language-javascript"></span></span><br><span class="line"><span class="language-javascript">viewer.<span class="property">scene</span>.<span class="property">mode</span> = <span class="title class_">Cesium</span>.<span class="property">SceneMode</span>.<span class="property">SCENE2D</span>;<span class="comment">// 2D 模式</span></span></span><br><span class="line"><span class="language-javascript"></span></span><br><span class="line"><span class="language-javascript"></span><span class="tag">&lt;/<span class="name">script</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">body</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">html</span>&gt;</span></span><br></pre></td></tr></table></figure><ul><li>矢量底图</li></ul><img src="/2024/08/06/Cesium-%E4%BD%BF%E7%94%A8%E6%8C%87%E5%8D%97/%E5%A4%A9%E5%9C%B0%E5%9B%BE_%E7%9F%A2%E9%87%8F%E5%BA%95%E5%9B%BE.png" class="" title="天地图_矢量底图"><p>经纬度投影：<a href="http://t0.tianditu.gov.cn/vec_c/wmts?tk=您的密钥">http://t0.tianditu.gov.cn/vec_c/wmts?tk=您的密钥</a></p><p>球面墨卡托投影：<a href="http://t0.tianditu.gov.cn/vec_w/wmts?tk=您的密钥">http://t0.tianditu.gov.cn/vec_w/wmts?tk=您的密钥</a></p><ul><li>矢量注记</li></ul><img src="/2024/08/06/Cesium-%E4%BD%BF%E7%94%A8%E6%8C%87%E5%8D%97/%E5%A4%A9%E5%9C%B0%E5%9B%BE_%E7%9F%A2%E9%87%8F%E6%B3%A8%E8%AE%B0.png" class="" title="天地图_矢量注记"><p>经纬度投影：<a href="http://t0.tianditu.gov.cn/cva_c/wmts?tk=您的密钥">http://t0.tianditu.gov.cn/cva_c/wmts?tk=您的密钥</a></p><p>球面墨卡托投影：<a href="http://t0.tianditu.gov.cn/cva_w/wmts?tk=您的密钥">http://t0.tianditu.gov.cn/cva_w/wmts?tk=您的密钥</a></p><ul><li>影像底图</li></ul><img src="/2024/08/06/Cesium-%E4%BD%BF%E7%94%A8%E6%8C%87%E5%8D%97/%E5%A4%A9%E5%9C%B0%E5%9B%BE_%E5%BD%B1%E5%83%8F%E5%BA%95%E5%9B%BE.png" class="" title="天地图_影像底图"><p>经纬度投影：<a href="http://t0.tianditu.gov.cn/img_c/wmts?tk=您的密钥">http://t0.tianditu.gov.cn/img_c/wmts?tk=您的密钥</a></p><p>球面墨卡托投影：<a href="http://t0.tianditu.gov.cn/img_w/wmts?tk=您的密钥">http://t0.tianditu.gov.cn/img_w/wmts?tk=您的密钥</a></p><ul><li>影像注记</li></ul><img src="/2024/08/06/Cesium-%E4%BD%BF%E7%94%A8%E6%8C%87%E5%8D%97/%E5%A4%A9%E5%9C%B0%E5%9B%BE_%E5%BD%B1%E5%83%8F%E6%B3%A8%E8%AE%B0.png" class="" title="天地图_影像注记"><p>经纬度投影：<a href="http://t0.tianditu.gov.cn/cia_c/wmts?tk=您的密钥">http://t0.tianditu.gov.cn/cia_c/wmts?tk=您的密钥</a></p><p>球面墨卡托投影：<a href="http://t0.tianditu.gov.cn/cia_w/wmts?tk=您的密钥">http://t0.tianditu.gov.cn/cia_w/wmts?tk=您的密钥</a></p><ul><li>地形晕眩</li></ul><img src="/2024/08/06/Cesium-%E4%BD%BF%E7%94%A8%E6%8C%87%E5%8D%97/%E5%A4%A9%E5%9C%B0%E5%9B%BE_%E5%9C%B0%E5%BD%A2%E6%99%95%E7%9C%A9.png" class="" title="天地图_地形晕眩"><p>经纬度投影：<a href="http://t0.tianditu.gov.cn/ter_c/wmts?tk=您的密钥">http://t0.tianditu.gov.cn/ter_c/wmts?tk=您的密钥</a></p><p>球面墨卡托投影：<a href="http://t0.tianditu.gov.cn/ter_w/wmts?tk=您的密钥">http://t0.tianditu.gov.cn/ter_w/wmts?tk=您的密钥</a></p><ul><li>地形注记</li></ul><img src="/2024/08/06/Cesium-%E4%BD%BF%E7%94%A8%E6%8C%87%E5%8D%97/%E5%A4%A9%E5%9C%B0%E5%9B%BE_%E5%9C%B0%E5%BD%A2%E6%B3%A8%E8%AE%B0.png" class="" title="天地图_地形注记"><p>经纬度投影：<a href="http://t0.tianditu.gov.cn/cta_c/wmts?tk=您的密钥">http://t0.tianditu.gov.cn/cta_c/wmts?tk=您的密钥</a></p><p>球面墨卡托投影：<a href="http://t0.tianditu.gov.cn/cta_w/wmts?tk=您的密钥">http://t0.tianditu.gov.cn/cta_w/wmts?tk=您的密钥</a></p><ul><li>全球境界</li></ul><img src="/2024/08/06/Cesium-%E4%BD%BF%E7%94%A8%E6%8C%87%E5%8D%97/%E5%A4%A9%E5%9C%B0%E5%9B%BE_%E5%85%A8%E7%90%83%E5%A2%83%E7%95%8C.png" class="" title="天地图_全球境界"><p>经纬度投影：<a href="http://t0.tianditu.gov.cn/ibo_c/wmts?tk=您的密钥">http://t0.tianditu.gov.cn/ibo_c/wmts?tk=您的密钥</a></p><p>球面墨卡托投影：<a href="http://t0.tianditu.gov.cn/ibo_w/wmts?tk=您的密钥">http://t0.tianditu.gov.cn/ibo_w/wmts?tk=您的密钥</a></p><ul><li>三维地名</li></ul><img src="/2024/08/06/Cesium-%E4%BD%BF%E7%94%A8%E6%8C%87%E5%8D%97/%E5%A4%A9%E5%9C%B0%E5%9B%BE_%E4%B8%89%E7%BB%B4%E5%9C%B0%E5%90%8D.png" class="" title="天地图_三维地名"><p>调用说明：<a href="http://lbs.tianditu.gov.cn/docs/#/sanwei/">http://lbs.tianditu.gov.cn/docs/#/sanwei/</a></p><p>cesuim扩展包：<a href="http://lbs.tianditu.gov.cn/docs/#/sanwei/">http://lbs.tianditu.gov.cn/docs/#/sanwei/</a></p><p>服务地址：https://[ t0-t7 ].tianditu.gov.cn/mapservice/GetTiles?tk=您的密钥</p><ul><li>三维地形</li></ul><img src="/2024/08/06/Cesium-%E4%BD%BF%E7%94%A8%E6%8C%87%E5%8D%97/%E5%A4%A9%E5%9C%B0%E5%9B%BE_%E4%B8%89%E7%BB%B4%E5%9C%B0%E5%BD%A2.jpg" class="" title="天地图_三维地形"><p>调用说明：<a href="http://lbs.tianditu.gov.cn/docs/#/sanwei/">http://lbs.tianditu.gov.cn/docs/#/sanwei/</a></p><p>cesuim扩展包：<a href="http://lbs.tianditu.gov.cn/docs/#/sanwei/">http://lbs.tianditu.gov.cn/docs/#/sanwei/</a></p><p>服务地址：https://[ t0-t7 ].tianditu.gov.cn/mapservice/swdx?tk=您的密钥</p><ul><li>备注</li></ul><p>天地图地图服务二级域名包括t0-t7，您可以随机选择使用，如<a href="http://t2.tianditu.gov.cn/vec_c/wmts?tk=您的密钥">http://t2.tianditu.gov.cn/vec_c/wmts?tk=您的密钥</a></p><p>元数据查询：<br><a href="http://t0.tianditu.gov.cn/img_w/wmts?request=GetCapabilities&amp;service=wmts">http://t0.tianditu.gov.cn/img_w/wmts?request=GetCapabilities&amp;service=wmts</a></p><p>地图瓦片获取：<br><a href="http://t0.tianditu.gov.cn/img_w/wmts?SERVICE=WMTS&amp;REQUEST=GetTile&amp;VERSION=1.0.0&amp;LAYER=img&amp;STYLE=default&amp;TILEMATRIXSET=w&amp;FORMAT=tiles&amp;TILEMATRIX={z}&amp;TILEROW={y}&amp;TILECOL={x}&amp;tk=您的密钥">http://t0.tianditu.gov.cn/img_w/wmts?SERVICE=WMTS&amp;REQUEST=GetTile&amp;VERSION=1.0.0&amp;LAYER=img&amp;STYLE=default&amp;TILEMATRIXSET=w&amp;FORMAT=tiles&amp;TILEMATRIX={z}&amp;TILEROW={y}&amp;TILECOL={x}&amp;tk=您的密钥</a></p><h1 id="画点"><a href="#画点" class="headerlink" title="画点"></a>画点</h1><h2 id="月球点案例"><a href="#月球点案例" class="headerlink" title="月球点案例"></a>月球点案例</h2><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">script</span>&gt;</span><span class="language-javascript"></span></span><br><span class="line"><span class="language-javascript"><span class="keyword">const</span> pointsOfInterest = [</span></span><br><span class="line"><span class="language-javascript">  &#123;</span></span><br><span class="line"><span class="language-javascript">    <span class="attr">text</span>: <span class="string">&quot;Apollo 11&quot;</span>,</span></span><br><span class="line"><span class="language-javascript">    <span class="attr">latitude</span>: <span class="number">0.67416</span>,</span></span><br><span class="line"><span class="language-javascript">    <span class="attr">longitude</span>: <span class="number">23.47315</span>,</span></span><br><span class="line"><span class="language-javascript">  &#125;,</span></span><br><span class="line"><span class="language-javascript">  &#123;</span></span><br><span class="line"><span class="language-javascript">    <span class="attr">text</span>: <span class="string">&quot;Apollo 14&quot;</span>,</span></span><br><span class="line"><span class="language-javascript">    <span class="attr">latitude</span>: -<span class="number">3.64417</span>,</span></span><br><span class="line"><span class="language-javascript">    <span class="attr">longitude</span>: <span class="number">342.52135</span>,</span></span><br><span class="line"><span class="language-javascript">  &#125;,</span></span><br><span class="line"><span class="language-javascript">  &#123;</span></span><br><span class="line"><span class="language-javascript">    <span class="attr">text</span>: <span class="string">&quot;Apollo 15&quot;</span>,</span></span><br><span class="line"><span class="language-javascript">    <span class="attr">latitude</span>: <span class="number">26.13341</span>,</span></span><br><span class="line"><span class="language-javascript">    <span class="attr">longitude</span>: <span class="number">3.6285</span>,</span></span><br><span class="line"><span class="language-javascript">  &#125;,</span></span><br><span class="line"><span class="language-javascript">  &#123;</span></span><br><span class="line"><span class="language-javascript">    <span class="attr">text</span>: <span class="string">&quot;Lunokhod 1&quot;</span>,</span></span><br><span class="line"><span class="language-javascript">    <span class="attr">latitude</span>: <span class="number">38.2378</span>,</span></span><br><span class="line"><span class="language-javascript">    <span class="attr">longitude</span>: -<span class="number">35.0017</span>,</span></span><br><span class="line"><span class="language-javascript">  &#125;,</span></span><br><span class="line"><span class="language-javascript">  &#123;</span></span><br><span class="line"><span class="language-javascript">    <span class="attr">text</span>: <span class="string">&quot;Lunokhod 2&quot;</span>,</span></span><br><span class="line"><span class="language-javascript">    <span class="attr">latitude</span>: <span class="number">25.83232</span>,</span></span><br><span class="line"><span class="language-javascript">    <span class="attr">longitude</span>: <span class="number">30.92215</span>,</span></span><br><span class="line"><span class="language-javascript">  &#125;,</span></span><br><span class="line"><span class="language-javascript">];</span></span><br><span class="line"><span class="language-javascript"></span></span><br><span class="line"><span class="language-javascript"><span class="comment">// Natural Earth II with Shaded Relief, Water, and Drainages from http://www.naturalearthdata.com</span></span></span><br><span class="line"><span class="language-javascript"><span class="keyword">const</span> viewer = <span class="keyword">new</span> <span class="title class_">Cesium</span>.<span class="title class_">Viewer</span>(<span class="string">&quot;cesiumContainer&quot;</span>, &#123;</span></span><br><span class="line"><span class="language-javascript">  <span class="attr">baseLayer</span>: <span class="title class_">Cesium</span>.<span class="property">ImageryLayer</span>.<span class="title function_">fromProviderAsync</span>(</span></span><br><span class="line"><span class="language-javascript">    <span class="title class_">Cesium</span>.<span class="property">IonImageryProvider</span>.<span class="title function_">fromAssetId</span>(<span class="number">3813</span>)</span></span><br><span class="line"><span class="language-javascript">  ),</span></span><br><span class="line"><span class="language-javascript">&#125;);</span></span><br><span class="line"><span class="language-javascript"></span></span><br><span class="line"><span class="language-javascript">viewer.<span class="property">entities</span>.<span class="title function_">add</span>(&#123;</span></span><br><span class="line"><span class="language-javascript">  <span class="attr">position</span>: <span class="title class_">Cesium</span>.<span class="property">Cartesian3</span>.<span class="title function_">fromDegrees</span>(-<span class="number">121.9068641</span>,<span class="number">56.20149076</span>),</span></span><br><span class="line"><span class="language-javascript">  <span class="attr">point</span>: &#123;</span></span><br><span class="line"><span class="language-javascript">    <span class="attr">color</span>: <span class="title class_">Cesium</span>.<span class="property">Color</span>.<span class="property">YELLOW</span>,</span></span><br><span class="line"><span class="language-javascript">    <span class="attr">pixelSize</span>: <span class="number">10</span></span></span><br><span class="line"><span class="language-javascript">  &#125;</span></span><br><span class="line"><span class="language-javascript">&#125;);</span></span><br><span class="line"><span class="language-javascript"></span><span class="tag">&lt;/<span class="name">script</span>&gt;</span></span><br></pre></td></tr></table></figure><h2 id="添加多个点"><a href="#添加多个点" class="headerlink" title="添加多个点"></a>添加多个点</h2><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">script</span>&gt;</span><span class="language-javascript"></span></span><br><span class="line"><span class="language-javascript"><span class="comment">// 使用提供的坐标创建点位置数组</span></span></span><br><span class="line"><span class="language-javascript"><span class="keyword">const</span> positions = [</span></span><br><span class="line"><span class="language-javascript">  [<span class="number">56.20149</span>, -<span class="number">121.906864</span>],</span></span><br><span class="line"><span class="language-javascript">  [<span class="number">57.00581</span>, -<span class="number">122.605421</span>],</span></span><br><span class="line"><span class="language-javascript">  [<span class="number">57.00405</span>, -<span class="number">122.682536</span>],</span></span><br><span class="line"><span class="language-javascript">  [<span class="number">57.06126</span>, -<span class="number">122.344514</span>],</span></span><br><span class="line"><span class="language-javascript">  [<span class="number">57.54797</span>, -<span class="number">122.754017</span>],</span></span><br><span class="line"><span class="language-javascript">  [<span class="number">57.33774</span>, -<span class="number">122.300309</span>],</span></span><br><span class="line"><span class="language-javascript">  [<span class="number">57.58799</span>, -<span class="number">122.798906</span>],</span></span><br><span class="line"><span class="language-javascript">  [<span class="number">56.23782</span>, -<span class="number">122.059896</span>],</span></span><br><span class="line"><span class="language-javascript">  [<span class="number">56.66702</span>, -<span class="number">122.241126</span>],</span></span><br><span class="line"><span class="language-javascript">  [<span class="number">56.96679</span>, -<span class="number">122.183874</span>],</span></span><br><span class="line"><span class="language-javascript">  [<span class="number">56.99772</span>, -<span class="number">122.251137</span>],</span></span><br><span class="line"><span class="language-javascript">  [<span class="number">52.42144</span>, -<span class="number">122.44831</span>],</span></span><br><span class="line"><span class="language-javascript">  [<span class="number">56.38861</span>, -<span class="number">122.31356</span>],</span></span><br><span class="line"><span class="language-javascript">  [<span class="number">56.87023</span>, -<span class="number">122.12061</span>]</span></span><br><span class="line"><span class="language-javascript">];</span></span><br><span class="line"><span class="language-javascript"></span></span><br><span class="line"><span class="language-javascript"><span class="comment">// 为每个位置添加一个点实体</span></span></span><br><span class="line"><span class="language-javascript">positions.<span class="title function_">forEach</span>(<span class="function">(<span class="params">pos, index</span>) =&gt;</span> &#123;</span></span><br><span class="line"><span class="language-javascript">  viewer.<span class="property">entities</span>.<span class="title function_">add</span>(&#123;</span></span><br><span class="line"><span class="language-javascript">    <span class="attr">position</span>: <span class="title class_">Cesium</span>.<span class="property">Cartesian3</span>.<span class="title function_">fromDegrees</span>(pos[<span class="number">1</span>], pos[<span class="number">0</span>]),  <span class="comment">// 注意：经度在前，纬度在后</span></span></span><br><span class="line"><span class="language-javascript">    <span class="attr">point</span>: &#123;</span></span><br><span class="line"><span class="language-javascript">      <span class="attr">color</span>: <span class="title class_">Cesium</span>.<span class="property">Color</span>.<span class="title function_">fromRandom</span>(&#123;<span class="attr">alpha</span>: <span class="number">1.0</span>&#125;), <span class="comment">// 随机颜色</span></span></span><br><span class="line"><span class="language-javascript">      <span class="attr">pixelSize</span>: <span class="number">10</span>,</span></span><br><span class="line"><span class="language-javascript">    &#125;,</span></span><br><span class="line"><span class="language-javascript">    <span class="attr">label</span>: &#123;</span></span><br><span class="line"><span class="language-javascript">      <span class="attr">text</span>: <span class="string">`Point <span class="subst">$&#123;index + <span class="number">1</span>&#125;</span>`</span>,</span></span><br><span class="line"><span class="language-javascript">      <span class="attr">font</span>: <span class="string">&#x27;14pt sans-serif&#x27;</span>,</span></span><br><span class="line"><span class="language-javascript">      <span class="attr">horizontalOrigin</span>: <span class="title class_">Cesium</span>.<span class="property">HorizontalOrigin</span>.<span class="property">LEFT</span>,</span></span><br><span class="line"><span class="language-javascript">      <span class="attr">verticalOrigin</span>: <span class="title class_">Cesium</span>.<span class="property">VerticalOrigin</span>.<span class="property">BOTTOM</span>,</span></span><br><span class="line"><span class="language-javascript">      <span class="attr">pixelOffset</span>: <span class="keyword">new</span> <span class="title class_">Cesium</span>.<span class="title class_">Cartesian2</span>(<span class="number">5</span>, <span class="number">5</span>)</span></span><br><span class="line"><span class="language-javascript">    &#125;</span></span><br><span class="line"><span class="language-javascript">  &#125;);</span></span><br><span class="line"><span class="language-javascript">&#125;);</span></span><br><span class="line"><span class="language-javascript"></span></span><br><span class="line"><span class="language-javascript"><span class="comment">// 设置相机视角以适应所有点</span></span></span><br><span class="line"><span class="language-javascript">viewer.<span class="title function_">zoomTo</span>(viewer.<span class="property">entities</span>);</span></span><br><span class="line"><span class="language-javascript"></span><span class="tag">&lt;/<span class="name">script</span>&gt;</span></span><br></pre></td></tr></table></figure><h1 id="设置中心点"><a href="#设置中心点" class="headerlink" title="设置中心点"></a>设置中心点</h1><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">viewer.camera.setView(&#123;</span><br><span class="line">    // fromDegrees()方法，将经纬度和高程转换为世界坐标</span><br><span class="line">    destination:Cesium.Cartesian3.fromDegrees(117.48,30.67,15000.0),</span><br><span class="line">    orientation:&#123;</span><br><span class="line">    // 指向</span><br><span class="line">    heading:Cesium.Math.toRadians(90,0),</span><br><span class="line">    // 视角</span><br><span class="line">    pitch:Cesium.Math.toRadians(-90),</span><br><span class="line">    roll:0.0</span><br><span class="line">    &#125;</span><br><span class="line">&#125;);</span><br><span class="line"></span><br><span class="line">viewer.camera.flyTo(&#123;</span><br><span class="line">    // fromDegrees()方法，将经纬度和高程转换为世界坐标</span><br><span class="line">    destination:Cesium.Cartesian3.fromDegrees(117.48,30.67,15000.0),</span><br><span class="line">    orientation:&#123;</span><br><span class="line">    // 指向</span><br><span class="line">    heading:Cesium.Math.toRadians(90,0),</span><br><span class="line">    // 视角</span><br><span class="line">    pitch:Cesium.Math.toRadians(-90),</span><br><span class="line">    roll:0.0</span><br><span class="line">    &#125;</span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure><h1 id="设置默认显示模式"><a href="#设置默认显示模式" class="headerlink" title="设置默认显示模式"></a>设置默认显示模式</h1><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">// 2.5D 哥伦布模式</span><br><span class="line">viewer.scene.mode = Cesium.SceneMode.COLUMBUS_VIEW;</span><br><span class="line">// 2D 模式</span><br><span class="line">viewer.scene.mode = Cesium.SceneMode.SCENE2D;</span><br><span class="line">// 3D 模式</span><br><span class="line">viewer.scene.mode = Cesium.SceneMode.SCENE3D;</span><br><span class="line">// 变形模式</span><br><span class="line">viewer.scene.mode = Cesium.SceneMode.MORPHING;</span><br></pre></td></tr></table></figure><h1 id="截图"><a href="#截图" class="headerlink" title="截图"></a>截图</h1><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">script</span>&gt;</span><span class="language-javascript"></span></span><br><span class="line"><span class="language-javascript">    <span class="keyword">function</span> <span class="title function_">saveToFile</span>(<span class="params"></span>) &#123;</span></span><br><span class="line"><span class="language-javascript">        <span class="keyword">let</span> canvas = viewer.<span class="property">scene</span>.<span class="property">canvas</span>;</span></span><br><span class="line"><span class="language-javascript">        <span class="keyword">let</span> image = canvas.<span class="title function_">toDataURL</span>(<span class="string">&quot;image/png&quot;</span>).<span class="title function_">replace</span>(<span class="string">&quot;image/png&quot;</span>, <span class="string">&quot;image/octet-stream&quot;</span>);</span></span><br><span class="line"><span class="language-javascript"></span></span><br><span class="line"><span class="language-javascript">        <span class="keyword">let</span> link = <span class="variable language_">document</span>.<span class="title function_">createElement</span>(<span class="string">&quot;a&quot;</span>);</span></span><br><span class="line"><span class="language-javascript">        <span class="keyword">let</span> blob = <span class="title function_">dataURLtoBlob</span>(image);</span></span><br><span class="line"><span class="language-javascript">        <span class="keyword">let</span> objurl = <span class="variable constant_">URL</span>.<span class="title function_">createObjectURL</span>(blob);</span></span><br><span class="line"><span class="language-javascript">        link.<span class="property">download</span> = <span class="string">&quot;scene.png&quot;</span>;</span></span><br><span class="line"><span class="language-javascript">        link.<span class="property">href</span> = objurl;</span></span><br><span class="line"><span class="language-javascript">        link.<span class="title function_">click</span>();</span></span><br><span class="line"><span class="language-javascript">    &#125;</span></span><br><span class="line"><span class="language-javascript"></span></span><br><span class="line"><span class="language-javascript">    <span class="keyword">function</span> <span class="title function_">dataURLtoBlob</span>(<span class="params">dataurl</span>) &#123;</span></span><br><span class="line"><span class="language-javascript">        <span class="keyword">let</span> arr = dataurl.<span class="title function_">split</span>(<span class="string">&#x27;,&#x27;</span>),</span></span><br><span class="line"><span class="language-javascript">        mime = arr[<span class="number">0</span>].<span class="title function_">match</span>(<span class="regexp">/:(.*?);/</span>)[<span class="number">1</span>],</span></span><br><span class="line"><span class="language-javascript">        bstr = <span class="title function_">atob</span>(arr[<span class="number">1</span>]),</span></span><br><span class="line"><span class="language-javascript">        n = bstr.<span class="property">length</span>,</span></span><br><span class="line"><span class="language-javascript">        u8arr = <span class="keyword">new</span> <span class="title class_">Uint8Array</span>(n);</span></span><br><span class="line"><span class="language-javascript">        <span class="keyword">while</span> (n--) &#123;</span></span><br><span class="line"><span class="language-javascript">        u8arr[n] = bstr.<span class="title function_">charCodeAt</span>(n);</span></span><br><span class="line"><span class="language-javascript">        &#125;</span></span><br><span class="line"><span class="language-javascript">        <span class="keyword">return</span> <span class="keyword">new</span> <span class="title class_">Blob</span>([u8arr], &#123; <span class="attr">type</span>: mime &#125;);</span></span><br><span class="line"><span class="language-javascript">    &#125;</span></span><br><span class="line"><span class="language-javascript"></span><span class="tag">&lt;/<span class="name">script</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">div</span> <span class="attr">id</span>=<span class="string">&quot;toolbar&quot;</span> <span class="attr">class</span>=<span class="string">&quot;param-container tool-bar layui-form-item&quot;</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">button</span>  <span class="attr">onclick</span>=<span class="string">&quot;saveToFile()&quot;</span>&gt;</span>场景出图<span class="tag">&lt;/<span class="name">button</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br></pre></td></tr></table></figure><h1 id="沙盒代码"><a href="#沙盒代码" class="headerlink" title="沙盒代码"></a>沙盒代码</h1><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">// Natural Earth II 3831</span><br><span class="line">const viewer = new Cesium.Viewer(&quot;cesiumContainer&quot;, &#123;</span><br><span class="line">  baseLayer: Cesium.ImageryLayer.fromProviderAsync(</span><br><span class="line">    Cesium.IonImageryProvider.fromAssetId(3813)</span><br><span class="line">  ),</span><br><span class="line">&#125;);</span><br><span class="line"></span><br><span class="line">viewer.camera.setView(&#123;</span><br><span class="line">    // fromDegrees()方法，将经纬度和高程转换为世界坐标</span><br><span class="line">    destination:Cesium.Cartesian3.fromDegrees(-121.9068641,56.20149076,20000000),</span><br><span class="line">    orientation:&#123;</span><br><span class="line">    // 指向</span><br><span class="line">    heading:Cesium.Math.toRadians(270,0),</span><br><span class="line">    // 视角</span><br><span class="line">    pitch:Cesium.Math.toRadians(-90),</span><br><span class="line">    roll:0.0</span><br><span class="line">    &#125;</span><br><span class="line">&#125;);</span><br><span class="line"></span><br><span class="line">viewer.entities.add(&#123;</span><br><span class="line">  position: Cesium.Cartesian3.fromDegrees(-121.9068641,56.20149076),</span><br><span class="line">  point: &#123;</span><br><span class="line">    color: Cesium.Color.YELLOW,</span><br><span class="line">    pixelSize: 10</span><br><span class="line">  &#125;</span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br></pre></td><td class="code"><pre><span class="line">// Natural Earth II 3831</span><br><span class="line">const viewer = new Cesium.Viewer(&quot;cesiumContainer&quot;, &#123;</span><br><span class="line">  baseLayer: Cesium.ImageryLayer.fromProviderAsync(</span><br><span class="line">    Cesium.IonImageryProvider.fromAssetId(3813)</span><br><span class="line">  ),</span><br><span class="line">&#125;);</span><br><span class="line"></span><br><span class="line">// 设置相机视角以覆盖所有点</span><br><span class="line">viewer.camera.setView(&#123;</span><br><span class="line">  destination: Cesium.Cartesian3.fromDegrees(-122.5, 55, 1000000),</span><br><span class="line">  orientation: &#123;</span><br><span class="line">    heading: Cesium.Math.toRadians(0),</span><br><span class="line">    pitch: Cesium.Math.toRadians(-45),</span><br><span class="line">    roll: 0.0</span><br><span class="line">  &#125;</span><br><span class="line">&#125;);</span><br><span class="line"></span><br><span class="line">// 使用提供的坐标创建点位置数组</span><br><span class="line">const positions = [</span><br><span class="line">  [56.20149, -121.906864],</span><br><span class="line">  [57.00581, -122.605421],</span><br><span class="line">  [57.00405, -122.682536],</span><br><span class="line">  [57.06126, -122.344514],</span><br><span class="line">  [57.54797, -122.754017],</span><br><span class="line">  [57.33774, -122.300309],</span><br><span class="line">  [57.58799, -122.798906],</span><br><span class="line">  [56.23782, -122.059896],</span><br><span class="line">  [56.66702, -122.241126],</span><br><span class="line">  [56.96679, -122.183874],</span><br><span class="line">  [56.99772, -122.251137],</span><br><span class="line">  [52.42144, -122.44831],</span><br><span class="line">  [56.38861, -122.31356],</span><br><span class="line">  [56.87023, -122.12061]</span><br><span class="line">];</span><br><span class="line"></span><br><span class="line">// 为每个位置添加一个点实体</span><br><span class="line">positions.forEach((pos, index) =&gt; &#123;</span><br><span class="line">  viewer.entities.add(&#123;</span><br><span class="line">    position: Cesium.Cartesian3.fromDegrees(pos[1], pos[0]),  // 注意：经度在前，纬度在后</span><br><span class="line">    point: &#123;</span><br><span class="line">      color: Cesium.Color.fromRandom(&#123;alpha: 1.0&#125;), // 随机颜色</span><br><span class="line">      pixelSize: 10,</span><br><span class="line">    &#125;,</span><br><span class="line">    label: &#123;</span><br><span class="line">      text: `Point $&#123;index + 1&#125;`,</span><br><span class="line">      font: &#x27;14pt sans-serif&#x27;,</span><br><span class="line">      horizontalOrigin: Cesium.HorizontalOrigin.LEFT,</span><br><span class="line">      verticalOrigin: Cesium.VerticalOrigin.BOTTOM,</span><br><span class="line">      pixelOffset: new Cesium.Cartesian2(5, 5)</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;);</span><br><span class="line">&#125;);</span><br><span class="line"></span><br><span class="line">// 设置相机视角以适应所有点</span><br><span class="line">viewer.zoomTo(viewer.entities);</span><br></pre></td></tr></table></figure><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br></pre></td><td class="code"><pre><span class="line">// Natural Earth II 3831</span><br><span class="line">const viewer = new Cesium.Viewer(&quot;cesiumContainer&quot;, &#123;</span><br><span class="line">  baseLayer: Cesium.ImageryLayer.fromProviderAsync(</span><br><span class="line">    Cesium.IonImageryProvider.fromAssetId(3831)</span><br><span class="line">  ),</span><br><span class="line">&#125;);</span><br><span class="line"></span><br><span class="line">viewer.camera.setView(&#123;</span><br><span class="line">    // fromDegrees()方法，将经纬度和高程转换为世界坐标</span><br><span class="line">    destination:Cesium.Cartesian3.fromDegrees(-121.9068641,56.20149076,20000000),</span><br><span class="line">    orientation:&#123;</span><br><span class="line">    // 指向</span><br><span class="line">    heading:Cesium.Math.toRadians(0,0),</span><br><span class="line">    // 视角</span><br><span class="line">    pitch:Cesium.Math.toRadians(-90),</span><br><span class="line">    roll:0.0</span><br><span class="line">    &#125;</span><br><span class="line">&#125;);</span><br><span class="line"></span><br><span class="line">viewer.entities.add(&#123;</span><br><span class="line">  position: Cesium.Cartesian3.fromDegrees(-121.9068641,56.20149076),</span><br><span class="line">  point: &#123;</span><br><span class="line">    color: Cesium.Color.YELLOW,</span><br><span class="line">    pixelSize: 10</span><br><span class="line">  &#125;</span><br><span class="line">&#125;);</span><br><span class="line"></span><br><span class="line">// 定义多个点的数据</span><br><span class="line">const points = [</span><br><span class="line">    &#123; lon: -121.9068641, lat: 56.20149076, color: Cesium.Color.YELLOW, pixes: 10 &#125;,</span><br><span class="line">    &#123; lon: -122.6054214, lat: 57.00580928, color: Cesium.Color.YELLOW, pixes: 10 &#125;,</span><br><span class="line">    &#123; lon: -122.6825364, lat: 57.004054, color: Cesium.Color.YELLOW, pixes: 10 &#125;,</span><br><span class="line">    &#123; lon: -122.3445136, lat: 57.06126005, color: Cesium.Color.YELLOW, pixes: 10 &#125;,</span><br><span class="line">    &#123; lon: -122.7540172, lat: 57.54796791, color: Cesium.Color.YELLOW, pixes: 10 &#125;,</span><br><span class="line">    &#123; lon: -122.3003092, lat: 57.33774351, color: Cesium.Color.YELLOW, pixes: 10 &#125;,</span><br><span class="line">    &#123; lon: -122.7989062, lat: 57.58799072, color: Cesium.Color.YELLOW, pixes: 10 &#125;,</span><br><span class="line">    &#123; lon: -122.0598957, lat: 56.23781614, color: Cesium.Color.YELLOW, pixes: 10 &#125;,</span><br><span class="line">    &#123; lon: -122.2411258, lat: 56.66701811, color: Cesium.Color.YELLOW, pixes: 10 &#125;,</span><br><span class="line">    &#123; lon: -122.1838739, lat: 56.96678936, color: Cesium.Color.YELLOW, pixes: 10 &#125;,</span><br><span class="line">    &#123; lon: -122.251137, lat: 56.99771651, color: Cesium.Color.YELLOW, pixes: 10 &#125;,</span><br><span class="line">    &#123; lon: -122.44831, lat: 52.42144, color: Cesium.Color.YELLOW, pixes: 10 &#125;,</span><br><span class="line">    &#123; lon: -122.31356, lat: 56.38861, color: Cesium.Color.YELLOW, pixes: 10 &#125;,</span><br><span class="line">    &#123; lon: -122.12061, lat: 56.87023, color: Cesium.Color.YELLOW, pixes: 10 &#125;</span><br><span class="line">];</span><br><span class="line"></span><br><span class="line">// 遍历点数据并添加到地图上</span><br><span class="line">points.forEach(point =&gt; &#123;</span><br><span class="line">    viewer.entities.add(&#123;</span><br><span class="line">        position: Cesium.Cartesian3.fromDegrees(point.lon, point.lat),</span><br><span class="line">        point: &#123;</span><br><span class="line">            color: point.color,</span><br><span class="line">            pixelSize: point.pixes</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;);</span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure>]]></content>
    
    
    <summary type="html">Cesium-使用指南</summary>
    
    
    
    <category term="科研利器" scheme="http://hibiscidai.com/categories/%E7%A7%91%E7%A0%94%E5%88%A9%E5%99%A8/"/>
    
    
    <category term="学习笔记" scheme="http://hibiscidai.com/tags/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
    <category term="软件" scheme="http://hibiscidai.com/tags/%E8%BD%AF%E4%BB%B6/"/>
    
    <category term="石油地质" scheme="http://hibiscidai.com/tags/%E7%9F%B3%E6%B2%B9%E5%9C%B0%E8%B4%A8/"/>
    
  </entry>
  
  <entry>
    <title>CGAN-TensorFlow</title>
    <link href="http://hibiscidai.com/2024/07/10/CGAN-TensorFlow/"/>
    <id>http://hibiscidai.com/2024/07/10/CGAN-TensorFlow/</id>
    <published>2024-07-10T09:00:00.000Z</published>
    <updated>2024-07-11T09:24:39.000Z</updated>
    
    <content type="html"><![CDATA[<img src="/2024/07/10/CGAN-TensorFlow/CGAN-TensorFlow.png" class="" title="CGAN-TensorFlow"><p>CGAN-TensorFlow</p><span id="more"></span><p>[TOC]</p><h1 id="CGAN-TensorFlow"><a href="#CGAN-TensorFlow" class="headerlink" title="CGAN-TensorFlow"></a>CGAN-TensorFlow</h1><p>原文链接：<a href="https://agustinus.kristia.de/techblog/2016/12/24/conditional-gan-tensorflow/">Conditional Generative Adversarial Nets in TensorFlow</a></p><p>We have seen the Generative Adversarial Nets (GAN) model in the previous post. We have also seen the arch nemesis of GAN, the VAE and its conditional variation: Conditional VAE (CVAE). Hence, it is only proper for us to study conditional variation of GAN, called Conditional GAN or CGAN for short.<br>我们在上一篇文章中看到了生成对抗网络（GAN）模型。我们还看到了 GAN 的死对头，VAE 及其条件变体：条件 VAE（CVAE）。因此，我们研究 GAN 的条件变体（称为条件 GAN 或简称 CGAN）是再合适不过的了。</p><h1 id="CGAN-Formulation-and-Architecture"><a href="#CGAN-Formulation-and-Architecture" class="headerlink" title="CGAN: Formulation and Architecture"></a>CGAN: Formulation and Architecture</h1><p>Recall, in GAN, we have two neural nets: the generator <script type="math/tex">G(z)</script>  and the discriminator <script type="math/tex">D(X)</script>.<br>Now, as we want to condition those networks with some vector <script type="math/tex">y</script>, the easiest way to do it is to feed <script type="math/tex">y</script> into both networks. Hence, our generator and discriminator are now <script type="math/tex">G(z,y)</script>  and  <script type="math/tex">D(X,y)</script> respectively.<br>回想一下，在 GAN 中，我们有两个神经网络：生成器 <script type="math/tex">G(z)</script> 和鉴别器 <script type="math/tex">D(X)</script>。<br>现在，由于我们想用某个向量 <script type="math/tex">y</script> 来调节这些网络，最简单的方法是将 <script type="math/tex">y</script> 输入两个网络。因此，我们的生成器和鉴别器现在分别是 <script type="math/tex">G(z,y)</script> 和 <script type="math/tex">D(X,y)</script>。</p><p>We can see it with a probabilistic point of view. <script type="math/tex">G(z,y)</script> is modeling the distribution of our data, given  <script type="math/tex">z</script> and  <script type="math/tex">y</script>, that is, our data is generated with this scheme <script type="math/tex">X~G(X|z，y)</script>.<br>我们可以用概率的角度来看待它。给定<script type="math/tex">z</script>和<script type="math/tex">y</script>，<script type="math/tex">G(z,y)</script>正在对我们的数据分布进行建模，也就是说，我们的数据是用这个方案<script type="math/tex">X \sim G(X|z，y)</script>生成的。</p><p>Likewise for the discriminator, now it tries to find discriminating label for <script type="math/tex">X</script> and <script type="math/tex">X_G</script>, that are modeled with <script type="math/tex">d \sim D(d|X,y)</script>.<br>同样对于鉴别器来说，现在它试图为 <script type="math/tex">X</script> 和 <script type="math/tex">X_G</script> 找到鉴别标签，用 <script type="math/tex">d \sim D(d|X,y)</script> 建模。</p><p>Hence, we could see that both <script type="math/tex">D</script> and <script type="math/tex">G</script> is jointly conditioned to two variables <script type="math/tex">z</script> or <script type="math/tex">X</script> and <script type="math/tex">y</script>.<br>因此，我们可以看到 <script type="math/tex">D</script> 和 <script type="math/tex">G</script> 都与两个变量 <script type="math/tex">z</script> 或 <script type="math/tex">X</script> 和 <script type="math/tex">y</script> 联合相关。</p><p>Now, the objective function is given by:<br>现在，目标函数如下：</p><script type="math/tex; mode=display">\min_G\max_DV(D,G)=\mathbb{E}_{x\sim p_{data}(x)}[\log D(x,y)]+\mathbb{E}_{z\sim p_z(z)}[\log(1-D(G(z,y),y))]</script><p>If we compare the above loss to GAN loss, the difference only lies in the additional parameter <script type="math/tex">y</script> in both <script type="math/tex">D</script> and <script type="math/tex">G</script>.<br>如果我们将上述损失与 GAN 损失进行比较，差异仅在于 <script type="math/tex">D</script> 和 <script type="math/tex">G</script> 中的附加参数 <script type="math/tex">y</script>。</p><p>The architecture of CGAN is now as follows (taken from [1]):<br>CGAN 的架构如下（取自[1]）：</p><img src="/2024/07/10/CGAN-TensorFlow/CGAN%E7%BD%91%E7%BB%9C%E7%BB%93%E6%9E%84.png" class="" title="CGAN网络结构"><p>In contrast with the architecture of GAN, we now has an additional input layer in both discriminator net and generator net.<br>与 GAN 的架构相比，我们现在在鉴别器网络和生成器网络中都增加了一个输入层。</p><h1 id="CGAN-Implementation-in-TensorFlow"><a href="#CGAN-Implementation-in-TensorFlow" class="headerlink" title="CGAN: Implementation in TensorFlow"></a>CGAN: Implementation in TensorFlow</h1><p>I’d like to direct the reader to the previous post about GAN, particularly for the implementation in TensorFlow. Implementing CGAN is so simple that we just need to add a handful of lines to the original GAN implementation. So, here we will only look at those modifications.<br>我想引导读者阅读上一篇关于 GAN 的文章，特别是关于在 TensorFlow 中的实现。实现 CGAN 非常简单，我们只需要在原始 GAN 实现中添加几行代码即可。因此，我们在这里只讨论这些修改。</p><p><a href="https://agustinus.kristia.de/techblog/2016/09/17/gan-tensorflow/">Generative Adversarial Nets in TensorFlow</a></p><p>The first additional code for CGAN is here:<br>CGAN 的第一个附加代码在这里：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">y = tf.placeholder(tf.float32, shape=[<span class="literal">None</span>, y_dim])</span><br></pre></td></tr></table></figure><p>We are adding new input to hold our variable we are conditioning our CGAN to.<br>我们正在添加新输入来保存我们用来调节 CGAN 的变量。</p><p>Next, we add it to both our generator net and discriminator net:<br>接下来，我们将其添加到我们的生成器网络和鉴别器网络中：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">generator</span>(<span class="params">z, y</span>):</span><br><span class="line">    <span class="comment"># Concatenate z and y</span></span><br><span class="line">    inputs = tf.concat(concat_dim=<span class="number">1</span>, values=[z, y])</span><br><span class="line"></span><br><span class="line">    G_h1 = tf.nn.relu(tf.matmul(inputs, G_W1) + G_b1)</span><br><span class="line">    G_log_prob = tf.matmul(G_h1, G_W2) + G_b2</span><br><span class="line">    G_prob = tf.nn.sigmoid(G_log_prob)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> G_prob</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">discriminator</span>(<span class="params">x, y</span>):</span><br><span class="line">    <span class="comment"># Concatenate x and y</span></span><br><span class="line">    inputs = tf.concat(concat_dim=<span class="number">1</span>, values=[x, y])</span><br><span class="line"></span><br><span class="line">    D_h1 = tf.nn.relu(tf.matmul(inputs, D_W1) + D_b1)</span><br><span class="line">    D_logit = tf.matmul(D_h1, D_W2) + D_b2</span><br><span class="line">    D_prob = tf.nn.sigmoid(D_logit)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> D_prob, D_logit</span><br></pre></td></tr></table></figure><p>The problem we have here is how to incorporate the new variable <script type="math/tex">y</script> into <script type="math/tex">D(x)</script> and <script type="math/tex">G(z)</script>. As we are trying to model the joint conditional, the simplest way to do it is to just concatenate both variables. Hence, in <script type="math/tex">G(z,y)</script>, we are concatenating <script type="math/tex">z</script> and <script type="math/tex">y</script> before we feed it into the networks. The same procedure is applied to <script type="math/tex">D(X,y)</script>.<br>我们这里的问题是如何将新变量 <script type="math/tex">y</script> 合并到 <script type="math/tex">D(x)</script> 和 <script type="math/tex">G(z)</script> 中。由于我们试图对联合条件进行建模，最简单的方法就是将两个变量连接起来。因此，在 <script type="math/tex">G(z,y)</script> 中，我们在将其输入网络之前将 <script type="math/tex">z</script> 和 <script type="math/tex">y</script> 连接起来。同样的程序也适用于 <script type="math/tex">D(X,y)</script>。</p><p>Of course, as our inputs for <script type="math/tex">D(X,y)</script> and <script type="math/tex">G(z,y)</script> is now different than the original GAN, we need to modify our weights:<br>当然，由于我们对 <script type="math/tex">D(X,y)</script> 和 <script type="math/tex">G(z,y)</script> 的输入现在与原始 GAN 不同，我们需要修改我们的权重：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Modify input to hidden weights for discriminator</span></span><br><span class="line"><span class="comment"># 修改鉴别器隐藏权重的输入</span></span><br><span class="line">D_W1 = tf.Variable(shape=[X_dim + y_dim, h_dim]))</span><br><span class="line"></span><br><span class="line"><span class="comment"># Modify input to hidden weights for generator</span></span><br><span class="line"><span class="comment"># 修改生成器隐藏权重的输入</span></span><br><span class="line">G_W1 = tf.Variable(shape=[Z_dim + y_dim, h_dim]))</span><br></pre></td></tr></table></figure><p>That is, we just adjust the dimensionality of our weights.<br>也就是说，我们只是调整权重的维数。</p><p>Next, we just use our new networks:<br>接下来，我们只需使用我们的新网络：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Add additional parameter y into all networks</span></span><br><span class="line"><span class="comment"># 在所有网络中添加附加参数 y</span></span><br><span class="line">G_sample = generator(Z, y)</span><br><span class="line">D_real, D_logit_real = discriminator(X, y)</span><br><span class="line">D_fake, D_logit_fake = discriminator(G_sample, y)</span><br></pre></td></tr></table></figure><p>And finally, when training, we also feed the value of <script type="math/tex">y</script> into the networks:<br>最后，在训练时，我们还将 <script type="math/tex">y</script> 的值输入网络：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">X_mb, y_mb = mnist.train.next_batch(mb_size)</span><br><span class="line"></span><br><span class="line">Z_sample = sample_Z(mb_size, Z_dim)</span><br><span class="line">_, D_loss_curr = sess.run([D_solver, D_loss], feed_dict=&#123;X: X_mb, Z: Z_sample, y:y_mb&#125;)</span><br><span class="line">_, G_loss_curr = sess.run([G_solver, G_loss], feed_dict=&#123;Z: Z_sample, y:y_mb&#125;)</span><br></pre></td></tr></table></figure><p>As an example above, we are training our GAN with MNIST data, and the conditional variable <script type="math/tex">y</script> is the labels.<br>如上例，我们使用 MNIST 数据训练我们的 GAN，条件变量 <script type="math/tex">y</script> 是标签。</p><h1 id="CGAN-Results"><a href="#CGAN-Results" class="headerlink" title="CGAN: Results"></a>CGAN: Results</h1><p>At test time, we want to generate new data samples with certain label. For example, we set the label to be 5, i.e. we want to generate digit “5”:<br>在测试时，我们希望生成具有特定标签的新数据样本。例如，我们将标签设置为 5，即我们希望生成数字“5”：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">n_sample = <span class="number">16</span></span><br><span class="line">Z_sample = sample_Z(n_sample, Z_dim)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Create conditional one-hot vector, with index 5 = 1</span></span><br><span class="line"><span class="comment"># 创建条件独热向量，索引 5 = 1</span></span><br><span class="line">y_sample = np.zeros(shape=[n_sample, y_dim])</span><br><span class="line">y_sample[:, <span class="number">5</span>] = <span class="number">1</span></span><br><span class="line"></span><br><span class="line">samples = sess.run(G_sample, feed_dict=&#123;Z: Z_sample, y:y_sample&#125;)</span><br></pre></td></tr></table></figure><p>Above, we just sample <script type="math/tex">z</script>, and then construct the conditional variables. In our example case, the conditional variables is a collection of one-hot vectors with value 1 in the 5th index. The last thing we need to is to run the network with those variables as inputs.<br>上面，我们只是对 <script type="math/tex">z</script> 进行采样，然后构造条件变量。在我们的示例中，条件变量是第 5 个索引中值为 1 的独热向量集合。我们需要做的最后一件事是使用这些变量作为输入来运行网络。</p><p>Here is the results:<br>结果如下：</p><img src="/2024/07/10/CGAN-TensorFlow/CGAN%E7%BB%93%E6%9E%9C1.png" class="" title="CGAN结果1"><p>Looks pretty much like digit 5, right?<br>看起来很像数字 5，对吧？</p><p>If we set our one-hot vectors to have value of 1 in the 7th index:<br>如果我们将独热向量设置为第 7 个索引中的值为 1：</p><img src="/2024/07/10/CGAN-TensorFlow/CGAN%E7%BB%93%E6%9E%9C2.png" class="" title="CGAN结果2"><p>Those results confirmed that have successfully trained our CGAN.<br>这些结果证实了我们的 CGAN 训练成功。</p><p><a href="https://github.com/wiseodd/generative-models">完整代码</a></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># cgan_pytorch.py</span></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.autograd <span class="keyword">as</span> autograd</span><br><span class="line"><span class="keyword">import</span> torch.optim <span class="keyword">as</span> optim</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> matplotlib.gridspec <span class="keyword">as</span> gridspec</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">from</span> torch.autograd <span class="keyword">import</span> Variable</span><br><span class="line"><span class="keyword">from</span> tensorflow.examples.tutorials.mnist <span class="keyword">import</span> input_data</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">mnist = input_data.read_data_sets(<span class="string">&#x27;../../MNIST_data&#x27;</span>, one_hot=<span class="literal">True</span>)</span><br><span class="line">mb_size = <span class="number">64</span></span><br><span class="line">Z_dim = <span class="number">100</span></span><br><span class="line">X_dim = mnist.train.images.shape[<span class="number">1</span>]</span><br><span class="line">y_dim = mnist.train.labels.shape[<span class="number">1</span>]</span><br><span class="line">h_dim = <span class="number">128</span></span><br><span class="line">cnt = <span class="number">0</span></span><br><span class="line">lr = <span class="number">1e-3</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">xavier_init</span>(<span class="params">size</span>):</span><br><span class="line">    in_dim = size[<span class="number">0</span>]</span><br><span class="line">    xavier_stddev = <span class="number">1.</span> / np.sqrt(in_dim / <span class="number">2.</span>)</span><br><span class="line">    <span class="keyword">return</span> Variable(torch.randn(*size) * xavier_stddev, requires_grad=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="string">&quot;&quot;&quot; ==================== GENERATOR ======================== &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">Wzh = xavier_init(size=[Z_dim + y_dim, h_dim])</span><br><span class="line">bzh = Variable(torch.zeros(h_dim), requires_grad=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">Whx = xavier_init(size=[h_dim, X_dim])</span><br><span class="line">bhx = Variable(torch.zeros(X_dim), requires_grad=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">G</span>(<span class="params">z, c</span>):</span><br><span class="line">    inputs = torch.cat([z, c], <span class="number">1</span>)</span><br><span class="line">    h = nn.relu(inputs @ Wzh + bzh.repeat(inputs.size(<span class="number">0</span>), <span class="number">1</span>))</span><br><span class="line">    X = nn.sigmoid(h @ Whx + bhx.repeat(h.size(<span class="number">0</span>), <span class="number">1</span>))</span><br><span class="line">    <span class="keyword">return</span> X</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="string">&quot;&quot;&quot; ==================== DISCRIMINATOR ======================== &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">Wxh = xavier_init(size=[X_dim + y_dim, h_dim])</span><br><span class="line">bxh = Variable(torch.zeros(h_dim), requires_grad=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">Why = xavier_init(size=[h_dim, <span class="number">1</span>])</span><br><span class="line">bhy = Variable(torch.zeros(<span class="number">1</span>), requires_grad=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">D</span>(<span class="params">X, c</span>):</span><br><span class="line">    inputs = torch.cat([X, c], <span class="number">1</span>)</span><br><span class="line">    h = nn.relu(inputs @ Wxh + bxh.repeat(inputs.size(<span class="number">0</span>), <span class="number">1</span>))</span><br><span class="line">    y = nn.sigmoid(h @ Why + bhy.repeat(h.size(<span class="number">0</span>), <span class="number">1</span>))</span><br><span class="line">    <span class="keyword">return</span> y</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">G_params = [Wzh, bzh, Whx, bhx]</span><br><span class="line">D_params = [Wxh, bxh, Why, bhy]</span><br><span class="line">params = G_params + D_params</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="string">&quot;&quot;&quot; ===================== TRAINING ======================== &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">reset_grad</span>():</span><br><span class="line">    <span class="keyword">for</span> p <span class="keyword">in</span> params:</span><br><span class="line">        <span class="keyword">if</span> p.grad <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            data = p.grad.data</span><br><span class="line">            p.grad = Variable(data.new().resize_as_(data).zero_())</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">G_solver = optim.Adam(G_params, lr=<span class="number">1e-3</span>)</span><br><span class="line">D_solver = optim.Adam(D_params, lr=<span class="number">1e-3</span>)</span><br><span class="line"></span><br><span class="line">ones_label = Variable(torch.ones(mb_size, <span class="number">1</span>))</span><br><span class="line">zeros_label = Variable(torch.zeros(mb_size, <span class="number">1</span>))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> it <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">100000</span>):</span><br><span class="line">    <span class="comment"># Sample data</span></span><br><span class="line">    z = Variable(torch.randn(mb_size, Z_dim))</span><br><span class="line">    X, c = mnist.train.next_batch(mb_size)</span><br><span class="line">    X = Variable(torch.from_numpy(X))</span><br><span class="line">    c = Variable(torch.from_numpy(c.astype(<span class="string">&#x27;float32&#x27;</span>)))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Dicriminator forward-loss-backward-update</span></span><br><span class="line">    G_sample = G(z, c)</span><br><span class="line">    D_real = D(X, c)</span><br><span class="line">    D_fake = D(G_sample, c)</span><br><span class="line"></span><br><span class="line">    D_loss_real = nn.binary_cross_entropy(D_real, ones_label)</span><br><span class="line">    D_loss_fake = nn.binary_cross_entropy(D_fake, zeros_label)</span><br><span class="line">    D_loss = D_loss_real + D_loss_fake</span><br><span class="line"></span><br><span class="line">    D_loss.backward()</span><br><span class="line">    D_solver.step()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Housekeeping - reset gradient</span></span><br><span class="line">    reset_grad()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Generator forward-loss-backward-update</span></span><br><span class="line">    z = Variable(torch.randn(mb_size, Z_dim))</span><br><span class="line">    G_sample = G(z, c)</span><br><span class="line">    D_fake = D(G_sample, c)</span><br><span class="line"></span><br><span class="line">    G_loss = nn.binary_cross_entropy(D_fake, ones_label)</span><br><span class="line"></span><br><span class="line">    G_loss.backward()</span><br><span class="line">    G_solver.step()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Housekeeping - reset gradient</span></span><br><span class="line">    reset_grad()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Print and plot every now and then</span></span><br><span class="line">    <span class="keyword">if</span> it % <span class="number">1000</span> == <span class="number">0</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;Iter-&#123;&#125;; D_loss: &#123;&#125;; G_loss: &#123;&#125;&#x27;</span>.<span class="built_in">format</span>(it, D_loss.data.numpy(), G_loss.data.numpy()))</span><br><span class="line"></span><br><span class="line">        c = np.zeros(shape=[mb_size, y_dim], dtype=<span class="string">&#x27;float32&#x27;</span>)</span><br><span class="line">        c[:, np.random.randint(<span class="number">0</span>, <span class="number">10</span>)] = <span class="number">1.</span></span><br><span class="line">        c = Variable(torch.from_numpy(c))</span><br><span class="line">        samples = G(z, c).data.numpy()[:<span class="number">16</span>]</span><br><span class="line"></span><br><span class="line">        fig = plt.figure(figsize=(<span class="number">4</span>, <span class="number">4</span>))</span><br><span class="line">        gs = gridspec.GridSpec(<span class="number">4</span>, <span class="number">4</span>)</span><br><span class="line">        gs.update(wspace=<span class="number">0.05</span>, hspace=<span class="number">0.05</span>)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> i, sample <span class="keyword">in</span> <span class="built_in">enumerate</span>(samples):</span><br><span class="line">            ax = plt.subplot(gs[i])</span><br><span class="line">            plt.axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line">            ax.set_xticklabels([])</span><br><span class="line">            ax.set_yticklabels([])</span><br><span class="line">            ax.set_aspect(<span class="string">&#x27;equal&#x27;</span>)</span><br><span class="line">            plt.imshow(sample.reshape(<span class="number">28</span>, <span class="number">28</span>), cmap=<span class="string">&#x27;Greys_r&#x27;</span>)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(<span class="string">&#x27;out/&#x27;</span>):</span><br><span class="line">            os.makedirs(<span class="string">&#x27;out/&#x27;</span>)</span><br><span class="line"></span><br><span class="line">        plt.savefig(<span class="string">&#x27;out/&#123;&#125;.png&#x27;</span>.<span class="built_in">format</span>(<span class="built_in">str</span>(cnt).zfill(<span class="number">3</span>)), bbox_inches=<span class="string">&#x27;tight&#x27;</span>)</span><br><span class="line">        cnt += <span class="number">1</span></span><br><span class="line">        plt.close(fig)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">from</span> tensorflow.examples.tutorials.mnist <span class="keyword">import</span> input_data</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> matplotlib.gridspec <span class="keyword">as</span> gridspec</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">mnist = input_data.read_data_sets(<span class="string">&#x27;../../MNIST_data&#x27;</span>, one_hot=<span class="literal">True</span>)</span><br><span class="line">mb_size = <span class="number">64</span></span><br><span class="line">Z_dim = <span class="number">100</span></span><br><span class="line">X_dim = mnist.train.images.shape[<span class="number">1</span>]</span><br><span class="line">y_dim = mnist.train.labels.shape[<span class="number">1</span>]</span><br><span class="line">h_dim = <span class="number">128</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">xavier_init</span>(<span class="params">size</span>):</span><br><span class="line">    in_dim = size[<span class="number">0</span>]</span><br><span class="line">    xavier_stddev = <span class="number">1.</span> / tf.sqrt(in_dim / <span class="number">2.</span>)</span><br><span class="line">    <span class="keyword">return</span> tf.random_normal(shape=size, stddev=xavier_stddev)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="string">&quot;&quot;&quot; Discriminator Net model &quot;&quot;&quot;</span></span><br><span class="line">X = tf.placeholder(tf.float32, shape=[<span class="literal">None</span>, <span class="number">784</span>])</span><br><span class="line">y = tf.placeholder(tf.float32, shape=[<span class="literal">None</span>, y_dim])</span><br><span class="line"></span><br><span class="line">D_W1 = tf.Variable(xavier_init([X_dim + y_dim, h_dim]))</span><br><span class="line">D_b1 = tf.Variable(tf.zeros(shape=[h_dim]))</span><br><span class="line"></span><br><span class="line">D_W2 = tf.Variable(xavier_init([h_dim, <span class="number">1</span>]))</span><br><span class="line">D_b2 = tf.Variable(tf.zeros(shape=[<span class="number">1</span>]))</span><br><span class="line"></span><br><span class="line">theta_D = [D_W1, D_W2, D_b1, D_b2]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">discriminator</span>(<span class="params">x, y</span>):</span><br><span class="line">    inputs = tf.concat(axis=<span class="number">1</span>, values=[x, y])</span><br><span class="line">    D_h1 = tf.nn.relu(tf.matmul(inputs, D_W1) + D_b1)</span><br><span class="line">    D_logit = tf.matmul(D_h1, D_W2) + D_b2</span><br><span class="line">    D_prob = tf.nn.sigmoid(D_logit)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> D_prob, D_logit</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="string">&quot;&quot;&quot; Generator Net model &quot;&quot;&quot;</span></span><br><span class="line">Z = tf.placeholder(tf.float32, shape=[<span class="literal">None</span>, Z_dim])</span><br><span class="line"></span><br><span class="line">G_W1 = tf.Variable(xavier_init([Z_dim + y_dim, h_dim]))</span><br><span class="line">G_b1 = tf.Variable(tf.zeros(shape=[h_dim]))</span><br><span class="line"></span><br><span class="line">G_W2 = tf.Variable(xavier_init([h_dim, X_dim]))</span><br><span class="line">G_b2 = tf.Variable(tf.zeros(shape=[X_dim]))</span><br><span class="line"></span><br><span class="line">theta_G = [G_W1, G_W2, G_b1, G_b2]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">generator</span>(<span class="params">z, y</span>):</span><br><span class="line">    inputs = tf.concat(axis=<span class="number">1</span>, values=[z, y])</span><br><span class="line">    G_h1 = tf.nn.relu(tf.matmul(inputs, G_W1) + G_b1)</span><br><span class="line">    G_log_prob = tf.matmul(G_h1, G_W2) + G_b2</span><br><span class="line">    G_prob = tf.nn.sigmoid(G_log_prob)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> G_prob</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">sample_Z</span>(<span class="params">m, n</span>):</span><br><span class="line">    <span class="keyword">return</span> np.random.uniform(-<span class="number">1.</span>, <span class="number">1.</span>, size=[m, n])</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">plot</span>(<span class="params">samples</span>):</span><br><span class="line">    fig = plt.figure(figsize=(<span class="number">4</span>, <span class="number">4</span>))</span><br><span class="line">    gs = gridspec.GridSpec(<span class="number">4</span>, <span class="number">4</span>)</span><br><span class="line">    gs.update(wspace=<span class="number">0.05</span>, hspace=<span class="number">0.05</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> i, sample <span class="keyword">in</span> <span class="built_in">enumerate</span>(samples):</span><br><span class="line">        ax = plt.subplot(gs[i])</span><br><span class="line">        plt.axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line">        ax.set_xticklabels([])</span><br><span class="line">        ax.set_yticklabels([])</span><br><span class="line">        ax.set_aspect(<span class="string">&#x27;equal&#x27;</span>)</span><br><span class="line">        plt.imshow(sample.reshape(<span class="number">28</span>, <span class="number">28</span>), cmap=<span class="string">&#x27;Greys_r&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> fig</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">G_sample = generator(Z, y)</span><br><span class="line">D_real, D_logit_real = discriminator(X, y)</span><br><span class="line">D_fake, D_logit_fake = discriminator(G_sample, y)</span><br><span class="line"></span><br><span class="line">D_loss_real = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=D_logit_real, labels=tf.ones_like(D_logit_real)))</span><br><span class="line">D_loss_fake = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=D_logit_fake, labels=tf.zeros_like(D_logit_fake)))</span><br><span class="line">D_loss = D_loss_real + D_loss_fake</span><br><span class="line">G_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=D_logit_fake, labels=tf.ones_like(D_logit_fake)))</span><br><span class="line"></span><br><span class="line">D_solver = tf.train.AdamOptimizer().minimize(D_loss, var_list=theta_D)</span><br><span class="line">G_solver = tf.train.AdamOptimizer().minimize(G_loss, var_list=theta_G)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">sess = tf.Session()</span><br><span class="line">sess.run(tf.global_variables_initializer())</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(<span class="string">&#x27;out/&#x27;</span>):</span><br><span class="line">    os.makedirs(<span class="string">&#x27;out/&#x27;</span>)</span><br><span class="line"></span><br><span class="line">i = <span class="number">0</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> it <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1000000</span>):</span><br><span class="line">    <span class="keyword">if</span> it % <span class="number">1000</span> == <span class="number">0</span>:</span><br><span class="line">        n_sample = <span class="number">16</span></span><br><span class="line"></span><br><span class="line">        Z_sample = sample_Z(n_sample, Z_dim)</span><br><span class="line">        y_sample = np.zeros(shape=[n_sample, y_dim])</span><br><span class="line">        y_sample[:, <span class="number">7</span>] = <span class="number">1</span></span><br><span class="line"></span><br><span class="line">        samples = sess.run(G_sample, feed_dict=&#123;Z: Z_sample, y:y_sample&#125;)</span><br><span class="line"></span><br><span class="line">        fig = plot(samples)</span><br><span class="line">        plt.savefig(<span class="string">&#x27;out/&#123;&#125;.png&#x27;</span>.<span class="built_in">format</span>(<span class="built_in">str</span>(i).zfill(<span class="number">3</span>)), bbox_inches=<span class="string">&#x27;tight&#x27;</span>)</span><br><span class="line">        i += <span class="number">1</span></span><br><span class="line">        plt.close(fig)</span><br><span class="line"></span><br><span class="line">    X_mb, y_mb = mnist.train.next_batch(mb_size)</span><br><span class="line"></span><br><span class="line">    Z_sample = sample_Z(mb_size, Z_dim)</span><br><span class="line">    _, D_loss_curr = sess.run([D_solver, D_loss], feed_dict=&#123;X: X_mb, Z: Z_sample, y:y_mb&#125;)</span><br><span class="line">    _, G_loss_curr = sess.run([G_solver, G_loss], feed_dict=&#123;Z: Z_sample, y:y_mb&#125;)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> it % <span class="number">1000</span> == <span class="number">0</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;Iter: &#123;&#125;&#x27;</span>.<span class="built_in">format</span>(it))</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;D loss: &#123;:.4&#125;&#x27;</span>. <span class="built_in">format</span>(D_loss_curr))</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;G_loss: &#123;:.4&#125;&#x27;</span>.<span class="built_in">format</span>(G_loss_curr))</span><br><span class="line">        <span class="built_in">print</span>()</span><br></pre></td></tr></table></figure><p>修改后代码</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br><span class="line">248</span><br><span class="line">249</span><br><span class="line">250</span><br><span class="line">251</span><br><span class="line">252</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 导入必要库</span></span><br><span class="line"><span class="comment"># PyTorch用于深度学习</span></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.autograd <span class="keyword">as</span> autograd</span><br><span class="line"><span class="keyword">import</span> torch.optim <span class="keyword">as</span> optim</span><br><span class="line"><span class="comment"># NumPy用于数值计算</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="comment"># Matplotlib用于绘图</span></span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> matplotlib.gridspec <span class="keyword">as</span> gridspec</span><br><span class="line"><span class="comment"># os用于文件操作</span></span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">from</span> torch.autograd <span class="keyword">import</span> Variable</span><br><span class="line"><span class="comment"># TensorFlow用于加载MNIST数据集</span></span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="comment">#from tensorflow.examples.tutorials.mnist import input_data</span></span><br><span class="line"><span class="keyword">import</span> csv</span><br><span class="line"></span><br><span class="line">mnist = tf.keras.datasets.mnist</span><br><span class="line">(x_train, y_train), (x_test, y_test) = mnist.load_data()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 将图像数据标准化到 [0, 1] 范围</span></span><br><span class="line">x_train = x_train.reshape(x_train.shape[<span class="number">0</span>], <span class="number">784</span>).astype(<span class="string">&#x27;float32&#x27;</span>) / <span class="number">255.</span></span><br><span class="line">x_test = x_test.reshape(x_test.shape[<span class="number">0</span>], <span class="number">784</span>).astype(<span class="string">&#x27;float32&#x27;</span>) / <span class="number">255.</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 将标签转换为 one-hot 编码</span></span><br><span class="line">y_train = tf.keras.utils.to_categorical(y_train, <span class="number">10</span>)</span><br><span class="line">y_test = tf.keras.utils.to_categorical(y_test, <span class="number">10</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 不再使用原来的mnist.train.next_batch()方法，我们需要创建一个函数来模拟这个功能：</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">next_batch</span>(<span class="params">num, data, labels</span>):</span><br><span class="line">    idx = np.arange(<span class="number">0</span> , <span class="built_in">len</span>(data))</span><br><span class="line">    np.random.shuffle(idx)</span><br><span class="line">    idx = idx[:num]</span><br><span class="line">    data_shuffle = [data[i] <span class="keyword">for</span> i <span class="keyword">in</span> idx]</span><br><span class="line">    labels_shuffle = [labels[i] <span class="keyword">for</span> i <span class="keyword">in</span> idx]</span><br><span class="line">    <span class="keyword">return</span> np.asarray(data_shuffle), np.asarray(labels_shuffle)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># mnist = input_data.read_data_sets(&#x27;../../MNIST_data&#x27;, one_hot=True) # 加载MNIST数据集，旧的TensorFlow版本</span></span><br><span class="line">mb_size = <span class="number">64</span>    <span class="comment">#设置mini-batch大小为64</span></span><br><span class="line">Z_dim = <span class="number">100</span> <span class="comment">#设置随机向量维度为100</span></span><br><span class="line">X_dim = x_train.shape[<span class="number">1</span>]</span><br><span class="line">y_dim = y_train.shape[<span class="number">1</span>]</span><br><span class="line"><span class="comment">#X_dim = mnist.train.images.shape[1] # 设置输入图像维度(784,因为MNIST图像是28x28=784像素)</span></span><br><span class="line"><span class="comment">#y_dim = mnist.train.labels.shape[1] # 设置标签维度(10,因为MNIST有10个类别)</span></span><br><span class="line">h_dim = <span class="number">128</span> <span class="comment">#设置隐藏层维度为128</span></span><br><span class="line">c = <span class="number">0</span>   <span class="comment">#初始化计数器c</span></span><br><span class="line">lr = <span class="number">1e-3</span>   <span class="comment">#学习率lr</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Xavier初始化方法,用于初始化网络权重，它有助于解决深度网络中的梯度消失问题</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">xavier_init</span>(<span class="params">size</span>):</span><br><span class="line">    in_dim = size[<span class="number">0</span>]</span><br><span class="line">    xavier_stddev = <span class="number">1.</span> / np.sqrt(in_dim / <span class="number">2.</span>)</span><br><span class="line">    <span class="keyword">return</span> Variable(torch.randn(*size) * xavier_stddev, requires_grad=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="string">&quot;&quot;&quot; ==================== GENERATOR ======================== &quot;&quot;&quot;</span></span><br><span class="line"><span class="comment"># 初始化了生成器的权重和偏置。Wzh和bzh是第一层的权重和偏置,Whx和bhx是第二层的。</span></span><br><span class="line">Wzh = xavier_init(size=[Z_dim, h_dim])</span><br><span class="line">bzh = Variable(torch.zeros(h_dim), requires_grad=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">Whx = xavier_init(size=[h_dim, X_dim])</span><br><span class="line">bhx = Variable(torch.zeros(X_dim), requires_grad=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 生成器函数。它接受噪声z作为输入,通过两层网络生成假图像。第一层使用ReLU激活函数,第二层使用Sigmoid函数。</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">G</span>(<span class="params">z</span>):</span><br><span class="line">    h = nn.relu(z @ Wzh + bzh.repeat(z.size(<span class="number">0</span>), <span class="number">1</span>))</span><br><span class="line">    X = nn.sigmoid(h @ Whx + bhx.repeat(h.size(<span class="number">0</span>), <span class="number">1</span>))</span><br><span class="line">    <span class="keyword">return</span> X</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="string">&quot;&quot;&quot; ==================== DISCRIMINATOR ======================== &quot;&quot;&quot;</span></span><br><span class="line"><span class="comment"># 初始化判别器的权重和偏置。Wzh和bzh是第一层的权重和偏置,Whx和bhx是第二层的。</span></span><br><span class="line">Wxh = xavier_init(size=[X_dim, h_dim])</span><br><span class="line">bxh = Variable(torch.zeros(h_dim), requires_grad=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">Why = xavier_init(size=[h_dim, <span class="number">1</span>])</span><br><span class="line">bhy = Variable(torch.zeros(<span class="number">1</span>), requires_grad=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 判别器函数。它接受图像X作为输入,输出一个0到1之间的数,表示图像是真实的概率。</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">D</span>(<span class="params">X</span>):</span><br><span class="line">    h = nn.relu(X @ Wxh + bxh.repeat(X.size(<span class="number">0</span>), <span class="number">1</span>))</span><br><span class="line">    y = nn.sigmoid(h @ Why + bhy.repeat(h.size(<span class="number">0</span>), <span class="number">1</span>))</span><br><span class="line">    <span class="keyword">return</span> y</span><br><span class="line"></span><br><span class="line"><span class="comment"># 将生成器和判别器的参数分别组织起来,方便后续优化。</span></span><br><span class="line">G_params = [Wzh, bzh, Whx, bhx]</span><br><span class="line">D_params = [Wxh, bxh, Why, bhy]</span><br><span class="line">params = G_params + D_params</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="string">&quot;&quot;&quot; ===================== TRAINING ======================== &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 重置所有参数的梯度。在每次更新参数之后调用,以准备下一次反向传播。</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">reset_grad</span>():</span><br><span class="line">    <span class="keyword">for</span> p <span class="keyword">in</span> params:</span><br><span class="line">        <span class="keyword">if</span> p.grad <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            data = p.grad.data</span><br><span class="line">            p.grad = Variable(data.new().resize_as_(data).zero_())</span><br><span class="line"></span><br><span class="line"><span class="comment"># 为生成器和判别器分别创建了Adam优化器。</span></span><br><span class="line">G_solver = optim.Adam(G_params, lr=<span class="number">1e-3</span>)</span><br><span class="line">D_solver = optim.Adam(D_params, lr=<span class="number">1e-3</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建表示&quot;真&quot;和&quot;假&quot;的标签,用于计算损失。</span></span><br><span class="line">ones_label = Variable(torch.ones(mb_size, <span class="number">1</span>))</span><br><span class="line">zeros_label = Variable(torch.zeros(mb_size, <span class="number">1</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 在训练循环外创建两个列表来存储loss值</span></span><br><span class="line">D_losses = []</span><br><span class="line">G_losses = []</span><br><span class="line"></span><br><span class="line"><span class="comment"># 曲线平滑方法</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">moving_average</span>(<span class="params">data, window_size</span>):</span><br><span class="line">    cumsum = np.cumsum(np.insert(data, <span class="number">0</span>, <span class="number">0</span>))</span><br><span class="line">    <span class="keyword">return</span> (cumsum[window_size:] - cumsum[:-window_size]) / window_size</span><br><span class="line"></span><br><span class="line"><span class="comment"># 保存loss曲线</span></span><br><span class="line"><span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(<span class="string">&#x27;out_gan_pytorch_1/&#x27;</span>):</span><br><span class="line">    os.makedirs(<span class="string">&#x27;out_gan_pytorch_1/&#x27;</span>)</span><br><span class="line">csv_file = <span class="built_in">open</span>(<span class="string">&#x27;out_gan_pytorch_1/loss_data.csv&#x27;</span>, <span class="string">&#x27;w&#x27;</span>, newline=<span class="string">&#x27;&#x27;</span>)</span><br><span class="line">csv_writer = csv.writer(csv_file)</span><br><span class="line">csv_writer.writerow([<span class="string">&#x27;Iteration&#x27;</span>, <span class="string">&#x27;D_loss&#x27;</span>, <span class="string">&#x27;G_loss&#x27;</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 主训练循环,总共进行100000次迭代。</span></span><br><span class="line"><span class="keyword">for</span> it <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">100000</span>):</span><br><span class="line">    <span class="comment"># Sample data</span></span><br><span class="line">    z = Variable(torch.randn(mb_size, Z_dim))   <span class="comment">#生成一个随机噪声批次z作为生成器的输入。</span></span><br><span class="line">    <span class="comment"># X, _ = mnist.train.next_batch(mb_size)  #从MNIST数据集中获取一批真实图像X。</span></span><br><span class="line">    X, _ = next_batch(mb_size, x_train, y_train)</span><br><span class="line">    X = Variable(torch.from_numpy(X))   <span class="comment">#将X转换为PyTorch的Variable。</span></span><br><span class="line"></span><br><span class="line">    <span class="string">&quot;&quot;&quot; ===================== 判别器训练 ======================== &quot;&quot;&quot;</span></span><br><span class="line">    <span class="comment"># Dicriminator forward-loss-backward-update</span></span><br><span class="line">    G_sample = G(z) <span class="comment">#使用生成器G生成一批假图像G_sample</span></span><br><span class="line">    D_real = D(X)   <span class="comment">#判别器D对真实图像X进行评估,得到D_real</span></span><br><span class="line">    D_fake = D(G_sample)    <span class="comment">#判别器D对生成的假图像G_sample进行评估,得到D_fake</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 计算判别器的损失</span></span><br><span class="line">    D_loss_real = nn.binary_cross_entropy(D_real, ones_label)   <span class="comment">#D_loss_real是真实图像的损失, 目标是使D_real接近1。</span></span><br><span class="line">    D_loss_fake = nn.binary_cross_entropy(D_fake, zeros_label)  <span class="comment">#D_loss_fake是假图像的损失, 目标是使D_fake接近0。</span></span><br><span class="line">    D_loss = D_loss_real + D_loss_fake  <span class="comment">#总损失D_loss是这两部分之和。</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 对判别器进行反向传播和参数更新。</span></span><br><span class="line">    D_loss.backward()</span><br><span class="line">    D_solver.step()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Housekeeping - reset gradient</span></span><br><span class="line">    <span class="comment"># 重置所有参数的梯度,为下一步做准备。</span></span><br><span class="line">    reset_grad()</span><br><span class="line"></span><br><span class="line">    <span class="string">&quot;&quot;&quot; ===================== 生成器训练 ======================== &quot;&quot;&quot;</span></span><br><span class="line">    <span class="comment"># Generator forward-loss-backward-update</span></span><br><span class="line">    <span class="comment"># 为训练生成器,我们再次生成假图像并用判别器评估</span></span><br><span class="line">    z = Variable(torch.randn(mb_size, Z_dim))</span><br><span class="line">    G_sample = G(z)</span><br><span class="line">    D_fake = D(G_sample)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 计算生成器的损失。注意这里的目标是让D_fake接近1, 即欺骗判别器</span></span><br><span class="line">    G_loss = nn.binary_cross_entropy(D_fake, ones_label)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 对生成器进行反向传播和参数更新。</span></span><br><span class="line">    G_loss.backward()</span><br><span class="line">    G_solver.step()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Housekeeping - reset gradient</span></span><br><span class="line">    <span class="comment"># 再次重置梯度。</span></span><br><span class="line">    reset_grad()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 每次迭代都记录loss值</span></span><br><span class="line">    D_losses.append(D_loss.item())</span><br><span class="line">    G_losses.append(G_loss.item())</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Print and plot every now and then</span></span><br><span class="line">    <span class="comment"># 每1000次迭代打印一次当前的损失值。</span></span><br><span class="line">    <span class="keyword">if</span> it % <span class="number">1000</span> == <span class="number">0</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;Iter-&#123;&#125;; D_loss: &#123;&#125;; G_loss: &#123;&#125;&#x27;</span>.<span class="built_in">format</span>(it, D_loss.data.numpy(), G_loss.data.numpy()))</span><br><span class="line"></span><br><span class="line">        samples = G(z).data.numpy()[:<span class="number">16</span>]    <span class="comment"># 生成16个样本。</span></span><br><span class="line"></span><br><span class="line">        fig = plt.figure(figsize=(<span class="number">4</span>, <span class="number">4</span>))    <span class="comment"># 创建一个4x4的图像网格。</span></span><br><span class="line">        gs = gridspec.GridSpec(<span class="number">4</span>, <span class="number">4</span>)    <span class="comment"># 将每个生成的样本绘制到网格中。</span></span><br><span class="line">        gs.update(wspace=<span class="number">0.05</span>, hspace=<span class="number">0.05</span>)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> i, sample <span class="keyword">in</span> <span class="built_in">enumerate</span>(samples):</span><br><span class="line">            ax = plt.subplot(gs[i])</span><br><span class="line">            plt.axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line">            ax.set_xticklabels([])</span><br><span class="line">            ax.set_yticklabels([])</span><br><span class="line">            ax.set_aspect(<span class="string">&#x27;equal&#x27;</span>)</span><br><span class="line">            plt.imshow(sample.reshape(<span class="number">28</span>, <span class="number">28</span>), cmap=<span class="string">&#x27;Greys_r&#x27;</span>)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(<span class="string">&#x27;out_gan_pytorch_1/&#x27;</span>):</span><br><span class="line">            os.makedirs(<span class="string">&#x27;out_gan_pytorch_1/&#x27;</span>)</span><br><span class="line"></span><br><span class="line">        plt.savefig(<span class="string">&#x27;out_gan_pytorch_1/&#123;&#125;.png&#x27;</span>.<span class="built_in">format</span>(<span class="built_in">str</span>(c).zfill(<span class="number">3</span>)), bbox_inches=<span class="string">&#x27;tight&#x27;</span>)</span><br><span class="line">        c += <span class="number">1</span></span><br><span class="line">        plt.close(fig)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 保存当前的loss数据</span></span><br><span class="line">        <span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&#x27;out_gan_pytorch_1/loss_data_ongoing.csv&#x27;</span>, <span class="string">&#x27;a&#x27;</span>, newline=<span class="string">&#x27;&#x27;</span>) <span class="keyword">as</span> file:</span><br><span class="line">            writer = csv.writer(file)</span><br><span class="line">            <span class="keyword">if</span> it == <span class="number">0</span>:  <span class="comment"># 如果是第一次写入，添加表头</span></span><br><span class="line">                writer.writerow([<span class="string">&quot;Iteration&quot;</span>, <span class="string">&quot;G_loss&quot;</span>, <span class="string">&quot;D_loss&quot;</span>])</span><br><span class="line">            writer.writerow([it, G_loss.item(), D_loss.item()])</span><br><span class="line"></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;Loss data at iteration <span class="subst">&#123;it&#125;</span> has been appended to &#x27;out_gan_pytorch_1/loss_data_ongoing.csv&#x27;&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算移动平均-曲线平滑</span></span><br><span class="line">window_size = <span class="number">1000</span></span><br><span class="line">G_losses_avg = moving_average(G_losses, window_size)</span><br><span class="line">D_losses_avg = moving_average(D_losses, window_size)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 绘制loss曲线</span></span><br><span class="line">plt.figure(figsize=(<span class="number">10</span>, <span class="number">5</span>))</span><br><span class="line">plt.title(<span class="string">&quot;Generator and Discriminator Loss During Training&quot;</span>)</span><br><span class="line">plt.plot(G_losses, label=<span class="string">&quot;G&quot;</span>)</span><br><span class="line">plt.plot(D_losses, label=<span class="string">&quot;D&quot;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&quot;iterations&quot;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&quot;Loss&quot;</span>)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.savefig(<span class="string">&#x27;out_gan_pytorch_1/loss_curve.png&#x27;</span>)</span><br><span class="line">plt.close()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 保存loss数据到CSV文件</span></span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&#x27;out_gan_pytorch_1/loss_data.csv&#x27;</span>, <span class="string">&#x27;w&#x27;</span>, newline=<span class="string">&#x27;&#x27;</span>) <span class="keyword">as</span> file:</span><br><span class="line">    writer = csv.writer(file)</span><br><span class="line">    writer.writerow([<span class="string">&quot;Iteration&quot;</span>, <span class="string">&quot;G_loss&quot;</span>, <span class="string">&quot;D_loss&quot;</span>])  <span class="comment"># 写入表头</span></span><br><span class="line">    <span class="keyword">for</span> i, (g_loss, d_loss) <span class="keyword">in</span> <span class="built_in">enumerate</span>(<span class="built_in">zip</span>(G_losses, D_losses)):</span><br><span class="line">        writer.writerow([i, g_loss, d_loss])</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Loss data has been saved to &#x27;out_gan_pytorch_1/loss_data.csv&#x27;&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算移动平均</span></span><br><span class="line">window_size = <span class="number">1000</span></span><br><span class="line">G_losses_avg = moving_average(G_losses, window_size)</span><br><span class="line">D_losses_avg = moving_average(D_losses, window_size)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 保存移动平均后的loss数据到CSV文件</span></span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&#x27;out_gan_pytorch_1/loss_data_avg.csv&#x27;</span>, <span class="string">&#x27;w&#x27;</span>, newline=<span class="string">&#x27;&#x27;</span>) <span class="keyword">as</span> file:</span><br><span class="line">    writer = csv.writer(file)</span><br><span class="line">    writer.writerow([<span class="string">&quot;Iteration&quot;</span>, <span class="string">&quot;G_loss_avg&quot;</span>, <span class="string">&quot;D_loss_avg&quot;</span>])  <span class="comment"># 写入表头</span></span><br><span class="line">    <span class="keyword">for</span> i, (g_loss, d_loss) <span class="keyword">in</span> <span class="built_in">enumerate</span>(<span class="built_in">zip</span>(G_losses_avg, D_losses_avg)):</span><br><span class="line">        writer.writerow([i+window_size, g_loss, d_loss])</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Averaged loss data has been saved to &#x27;out_gan_pytorch_1/loss_data_avg.csv&#x27;&quot;</span>)</span><br><span class="line"><span class="comment"># loss_data.csv：包含所有迭代的原始loss数据</span></span><br><span class="line"><span class="comment"># loss_data_avg.csv：包含移动平均后的loss数据</span></span><br><span class="line"><span class="comment"># loss_data_ongoing.csv：在训练过程中定期保存的loss数据</span></span><br></pre></td></tr></table></figure>]]></content>
    
    
    <summary type="html">CGAN-TensorFlow</summary>
    
    
    
    <category term="人工智能" scheme="http://hibiscidai.com/categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/"/>
    
    
    <category term="GAN" scheme="http://hibiscidai.com/tags/GAN/"/>
    
    <category term="人工智能" scheme="http://hibiscidai.com/tags/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/"/>
    
    <category term="深度学习" scheme="http://hibiscidai.com/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>小丑在殿堂</title>
    <link href="http://hibiscidai.com/2024/07/03/%E5%B0%8F%E4%B8%91%E5%9C%A8%E6%AE%BF%E5%A0%82/"/>
    <id>http://hibiscidai.com/2024/07/03/%E5%B0%8F%E4%B8%91%E5%9C%A8%E6%AE%BF%E5%A0%82/</id>
    <published>2024-07-03T06:00:00.000Z</published>
    <updated>2024-07-22T13:41:06.000Z</updated>
    
    <content type="html"><![CDATA[<img src="/2024/07/03/%E5%B0%8F%E4%B8%91%E5%9C%A8%E6%AE%BF%E5%A0%82/%E5%B0%8F%E4%B8%91%E5%9C%A8%E6%AE%BF%E5%A0%82.png" class="" title="小丑在殿堂"><p>小丑在殿堂</p><span id="more"></span><p>[TOC]</p><h1 id="小丑在殿堂"><a href="#小丑在殿堂" class="headerlink" title="小丑在殿堂"></a>小丑在殿堂</h1><p>也许你愿意相信的不是真理，而是权威。</p><p>尊长尊老的核心内涵在于对生命的敬畏、对更有深度的生命赞同。</p><ul><li>小人君子论</li></ul><p>定义：<br>对弱者包容，对强者尊重。→君子<br>对弱者欺压，对强者谄媚。→小人</p><p>情况分析：<br>小人见君子 → 小人最优<br>小人见小人 → ？<br>君子见君子 → 君子最优<br>君子见小人 → 君子最差</p><p>由此可得：<br>小人的最优收益望 = 君子的最优收益期望<br>小人的最差收益望 &gt; 君子的最差收益期望</p><p>结论：<br>君子难得！！！</p><p>言语所能传达的，大部分是情绪语调，半小时的交谈，不如一纸文书。</p><p>沟通的前提是平等尊重，带有强烈主观情绪色彩的交谈是单方面强权的霸凌。</p><p>谈事和谈态度傻傻分不清，事情没谈明白开始扯态度，态度可以了又说事不行。</p><p>我想听的不是你要怎么样，我只想听我想听到的。</p><p>在强权背景下，催生了畸形的运转模式，权利和能力被画上了等号，组织中每个人都视而不见，久而久之，权利逐渐盖过了能力，对能力的质疑转变了对权力的质疑，同样的，会受到强权的打压。</p><ul><li>忽有清风化剑气，直斩二十少年意。</li></ul><p>在象牙塔里的时光，容易让一个人意淫，对社会意淫，对未来意淫。当剥去幻想的衣裳，看到的才是赤裸的羞耻。</p><ul><li>小丑在殿堂，大师在流浪。</li></ul><p>开始记录与2024年07月04日，纪念逐渐远离梦想的少年。</p><p>上位者心中只有任务，在上位者的严重，处于权利弱势地位的人不是人，而是工具，为达自己的利益，合理的分配工具资源，才是上位者考虑的事情。</p>]]></content>
    
    
    <summary type="html">小丑在殿堂</summary>
    
    
    
    <category term="日志" scheme="http://hibiscidai.com/categories/%E6%97%A5%E5%BF%97/"/>
    
    
    <category term="日志" scheme="http://hibiscidai.com/tags/%E6%97%A5%E5%BF%97/"/>
    
    <category term="小丑在殿堂" scheme="http://hibiscidai.com/tags/%E5%B0%8F%E4%B8%91%E5%9C%A8%E6%AE%BF%E5%A0%82/"/>
    
  </entry>
  
  <entry>
    <title>PyCharm挂载Linux服务器</title>
    <link href="http://hibiscidai.com/2024/06/25/PyCharm%E6%8C%82%E8%BD%BDLinux%E6%9C%8D%E5%8A%A1%E5%99%A8/"/>
    <id>http://hibiscidai.com/2024/06/25/PyCharm%E6%8C%82%E8%BD%BDLinux%E6%9C%8D%E5%8A%A1%E5%99%A8/</id>
    <published>2024-06-25T00:00:00.000Z</published>
    <updated>2024-11-16T06:43:47.000Z</updated>
    
    <content type="html"><![CDATA[<img src="/2024/06/25/PyCharm%E6%8C%82%E8%BD%BDLinux%E6%9C%8D%E5%8A%A1%E5%99%A8/PyCharm%E6%8C%82%E8%BD%BDLinux%E6%9C%8D%E5%8A%A1%E5%99%A8.png" class="" title="PyCharm挂载Linux服务器"><p>PyCharm挂载Linux服务器</p><span id="more"></span><p>[TOC]</p><h1 id="PyCharm挂载Linux服务器"><a href="#PyCharm挂载Linux服务器" class="headerlink" title="PyCharm挂载Linux服务器"></a>PyCharm挂载Linux服务器</h1><blockquote><p>PyCharm社区版本无法实现ssh连接服务器。</p></blockquote><p><a href="https://www.jetbrains.com/help/pycharm/2024.1/remote-development-starting-page.html">PyCharm官网教程：从 PyCharm 连接到远程服务器</a></p><h2 id="服务器安装Anaconda"><a href="#服务器安装Anaconda" class="headerlink" title="服务器安装Anaconda"></a>服务器安装Anaconda</h2><h3 id="查看PC的Anaconda版本"><a href="#查看PC的Anaconda版本" class="headerlink" title="查看PC的Anaconda版本"></a>查看PC的Anaconda版本</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">Windows PowerShell</span><br><span class="line">版权所有（C） Microsoft Corporation。保留所有权利。</span><br><span class="line">PS C:\Users\windows11&gt; conda --version</span><br><span class="line">conda 23.1.0</span><br></pre></td></tr></table></figure><p>Conda has been updated to v23.1.0. This installer uses python-3.10.9.</p><h3 id="去官网下载Anaconda"><a href="#去官网下载Anaconda" class="headerlink" title="去官网下载Anaconda"></a>去官网下载Anaconda</h3><p>选择 Anaconda Distribution 安装程序。</p><p>下载<code>Anaconda3-2024.02-1-Linux-x86_64.sh</code>，对应python版本3.11。</p><h3 id="上传安装文件"><a href="#上传安装文件" class="headerlink" title="上传安装文件"></a>上传安装文件</h3><p><strong>用自己账号登录服务器</strong>，上传至服务器，自己用户的根目录中。</p><h3 id="执行安装文件"><a href="#执行安装文件" class="headerlink" title="执行安装文件"></a>执行安装文件</h3><p>在根目录中执行，运行安装：<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sh Anaconda3-2024.02-1-Linux-x86_64.sh</span><br></pre></td></tr></table></figure></p><h3 id="配置环境"><a href="#配置环境" class="headerlink" title="配置环境"></a>配置环境</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vim ~/.bashrc</span><br></pre></td></tr></table></figure><p>在空白处添加以下<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">在本用户权限下运行，不会影响其他用户的环境</span></span><br><span class="line">alias Python=&#x27;/home/USERNAME/anaconda3/bin&#x27;   </span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">这里写anaconda的安装路径</span></span><br><span class="line">export PATH=&quot;/home/USERNAME/anaconda3/bin:$PATH&quot;</span><br></pre></td></tr></table></figure></p><p>加载配置</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">source ~/.bashrc</span><br></pre></td></tr></table></figure><h3 id="添加国内conda源"><a href="#添加国内conda源" class="headerlink" title="添加国内conda源"></a>添加国内conda源</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main</span><br><span class="line">conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free</span><br><span class="line">conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/r</span><br><span class="line">conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/pro</span><br><span class="line">conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/msys2</span><br></pre></td></tr></table></figure><h3 id="conda版本版本更换"><a href="#conda版本版本更换" class="headerlink" title="conda版本版本更换"></a>conda版本版本更换</h3><p>保证和本地版本相同，进行conda版本切换。<br>注意查看对应的python版本。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">conda install -n base conda=23.1.0</span><br><span class="line">conda install pyhton=3.7.4</span><br></pre></td></tr></table></figure><p>当然也可以保持现状，在创建conda环境时再进行python版本设置。</p><h2 id="创建虚拟环境"><a href="#创建虚拟环境" class="headerlink" title="创建虚拟环境"></a>创建虚拟环境</h2><h3 id="conda环境迁移"><a href="#conda环境迁移" class="headerlink" title="conda环境迁移"></a>conda环境迁移</h3><p>相同操作系统 的计算机之间复制环境，则可以生成 spec list。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">conda list --explicit &gt; spec-list.txt</span><br></pre></td></tr></table></figure><p>在新机子重现环境</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">conda create --name YOUR_ENV_NAME --file spec-list.txt</span><br></pre></td></tr></table></figure><h3 id="创建虚拟环境-1"><a href="#创建虚拟环境-1" class="headerlink" title="创建虚拟环境"></a>创建虚拟环境</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">conda create -n YOUR_ENV_NAME python=3.7</span><br></pre></td></tr></table></figure><p>查看当前存在哪些虚拟环境</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">conda env list</span><br></pre></td></tr></table></figure><p>激活虚拟环境</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">conda activate YOUR_ENV_NAME</span><br></pre></td></tr></table></figure><p>查看安装了哪些包</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">conda list</span><br></pre></td></tr></table></figure><blockquote><p>conda:matplotlib、pandas、numpy<br>pip:networkx、python_igraph、numba、scipy</p></blockquote><p>其他命令：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">conda update conda：               检查更新当前conda</span><br><span class="line">conda search XXX                   搜索包，查看可安装版本</span><br><span class="line">conda remove -n py36 --all         删除环境</span><br><span class="line">conda deactivate                   退出虚拟环境，conda4之前版本：source deactivate</span><br><span class="line"> </span><br><span class="line">pip install --upgrade &lt;包的名字&gt;     更新包</span><br><span class="line">pip install python_igraph          （import igraph包）</span><br></pre></td></tr></table></figure><h2 id="配置PyCharm"><a href="#配置PyCharm" class="headerlink" title="配置PyCharm"></a>配置PyCharm</h2><p>打开python项目→文件→设置→项目：xxx→python解释器→添加解释器→SSH</p><p>输入主机ip、端口、用户名</p><p>选择<code>Virtualenv环境</code>，如果识别conda环境可以直接选择conda。<br><code>系统解释器</code>面向root用户，属于全局，不方便使用。</p><p>解释器路径：<code>/home/USERNAME/anaconda3/envs/YOUR_ENV_NAME/bin/python</code><br>同步文件夹：<code>home/USERNAME/data/USERNAME/PROJECTNAME</code></p><img src="/2024/06/25/PyCharm%E6%8C%82%E8%BD%BDLinux%E6%9C%8D%E5%8A%A1%E5%99%A8/PyCharm%E9%85%8D%E7%BD%AESSH%E7%8E%AF%E5%A2%83.png" class="" title="PyCharm配置SSH环境"><p>工具→部署，可以调整文件夹同步设置</p><h2 id="运行测试"><a href="#运行测试" class="headerlink" title="运行测试"></a>运行测试</h2><p>运行代码测试</p><h2 id="直接在服务器运行代码"><a href="#直接在服务器运行代码" class="headerlink" title="直接在服务器运行代码"></a>直接在服务器运行代码</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">source activate YOUR_ENV_NAME</span><br><span class="line"></span><br><span class="line">nohup python3 -u my.py &gt;&gt; my.log 2&gt;&amp;1 &amp;</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">jobs -l      （当前终端查看全部进程）</span><br><span class="line">ps -aux|grep 进程号  （全局各个新终端查看指定进程）</span><br><span class="line">ps -ef         （全局全部进程）</span><br><span class="line">kill -STOP 进程号（命令可以直接暂停一个后台任务）</span><br><span class="line">kill -CONT 进程号（命令可以直接恢复一个后台任务）</span><br><span class="line">kill -9 进程号     （杀死进程）</span><br></pre></td></tr></table></figure><h2 id="JetBrains-Gateway"><a href="#JetBrains-Gateway" class="headerlink" title="JetBrains Gateway"></a>JetBrains Gateway</h2><p>JetBrains Gateway 是一个轻量级启动器，它将远程服务器与您的本地机器连接起来，在后端下载必要的组件，并在JetBrains Client中打开您的项目。</p><p>您可以将 JetBrains Gateway 用作独立启动器或作为 IDE 的入口点来连接到远程服务器。</p><p>默认情况下，下载的 PyCharm 位于远程服务器上的以下文件夹中：<code>~ /.cache /JetBrains /RemoteDev /dist</code>。</p><p>文件→远程开发→SSH</p><img src="/2024/06/25/PyCharm%E6%8C%82%E8%BD%BDLinux%E6%9C%8D%E5%8A%A1%E5%99%A8/JetBrainsGateway_1.png" class="" title="JetBrainsGateway_1"><p>选择对应的pycharm版本<br>会自动列出目前和本机相同的版本和最新版本</p><img src="/2024/06/25/PyCharm%E6%8C%82%E8%BD%BDLinux%E6%9C%8D%E5%8A%A1%E5%99%A8/JetBrainsGateway_2.png" class="" title="JetBrainsGateway_2"><p>选择项目目录</p><img src="/2024/06/25/PyCharm%E6%8C%82%E8%BD%BDLinux%E6%9C%8D%E5%8A%A1%E5%99%A8/JetBrainsGateway_3.png" class="" title="JetBrainsGateway_3"><p>使用gateway开发</p><img src="/2024/06/25/PyCharm%E6%8C%82%E8%BD%BDLinux%E6%9C%8D%E5%8A%A1%E5%99%A8/JetBrainsGateway_4.png" class="" title="JetBrainsGateway_4"><p>方法A：<br>代码在本地，运行环境在服务器。<br>本地安装pycharm，服务器不安装pyachrm。<br>代码运行通过本地上传至服务器，然后再服务器运行环境下返回运行结果。<br>用户实际操作的是本地pycharm。<br>关闭pycharm后代码中断。</p><p>方法B：<br>代码在服务器，运行环境在服务器。<br>本地安装pycharm，服务器不安装pyachrm。<br>代码直接运行在服务器上。用户可以用本地pycharm操作。<br>用户实际操作的是服务器pycharm。<br>关闭pycharm后代码可以选择不中断，可以选择在服务器后台跑。</p><p>可以先用方法A测试运行，上传部署代码后，使用方法B，可以直接在远程上打开IDE运行测试代码，适合有长时间跑数据的需求。</p><p>方法B中开发环境有些功能会有一些bug，尽量选择全新的IDE版本。</p><blockquote><p>远程连接需要认证激活，可以采用教育版在SSH运行，本机专业版本即可。</p></blockquote>]]></content>
    
    
    <summary type="html">PyCharm挂载Linux服务器</summary>
    
    
    
    <category term="Linux" scheme="http://hibiscidai.com/categories/Linux/"/>
    
    
    <category term="Python" scheme="http://hibiscidai.com/tags/Python/"/>
    
    <category term="IDE" scheme="http://hibiscidai.com/tags/IDE/"/>
    
    <category term="Linux" scheme="http://hibiscidai.com/tags/Linux/"/>
    
  </entry>
  
  <entry>
    <title>核磁共振测井</title>
    <link href="http://hibiscidai.com/2024/05/14/%E6%A0%B8%E7%A3%81%E5%85%B1%E6%8C%AF%E6%B5%8B%E4%BA%95/"/>
    <id>http://hibiscidai.com/2024/05/14/%E6%A0%B8%E7%A3%81%E5%85%B1%E6%8C%AF%E6%B5%8B%E4%BA%95/</id>
    <published>2024-05-14T03:00:00.000Z</published>
    <updated>2024-07-17T12:24:27.000Z</updated>
    
    <content type="html"><![CDATA[<img src="/2024/05/14/%E6%A0%B8%E7%A3%81%E5%85%B1%E6%8C%AF%E6%B5%8B%E4%BA%95/%E6%A0%B8%E7%A3%81%E5%85%B1%E6%8C%AF%E6%B5%8B%E4%BA%95.png" class="" title="核磁共振测井"><p>核磁共振测井</p><span id="more"></span><p>[TOC]</p><h1 id="核磁共振测井"><a href="#核磁共振测井" class="headerlink" title="核磁共振测井"></a>核磁共振测井</h1><p>用作本人速查</p><h1 id="核磁共振测井物理基础"><a href="#核磁共振测井物理基础" class="headerlink" title="核磁共振测井物理基础"></a>核磁共振测井物理基础</h1><p>核磁共振是量子力学最经典的一个实例。</p><p>核磁共振原理经典六张图。</p><img src="/2024/05/14/%E6%A0%B8%E7%A3%81%E5%85%B1%E6%8C%AF%E6%B5%8B%E4%BA%95/%E6%A0%B8%E7%A3%81%E5%85%B1%E6%8C%AF%E5%8E%9F%E7%90%86%E7%BB%8F%E5%85%B8%E5%85%AD%E5%BC%A0%E5%9B%BE-1.png" class="" title="核磁共振测井"><p>很多原子核都可以做核磁共振，但是测井的重点在于氢核，氢核本身在高速运动。<br>氢核本身在做高速运动的时候像一个石头一样有南北极。<br>对于一个原子核来说是有磁性的，但是当很多氢原子核在一起的时候，如果没有外加磁场，每一个氢核都是随机取向的，所以没有什么磁性。</p><p>单独的氢核，快速运动，具有一定的磁性，产生一个N极和S极。<br>当氢核放在外加磁场中，外加磁场强度是B0，氢核会围绕外加磁场方向轴转动，称为进动。进动频率为拉莫尔频率。</p><script type="math/tex; mode=display">f = \frac{\gamma}{2 \pi} B_0</script><script type="math/tex; mode=display">\gamma $$ 叫旋磁比，是原子核的一个性质，核素定了，数值就定了。$$ B_0 $$ 是外加磁场强度。当磁场强度确定的时候，进动频率确定。在同一个磁场强度里面，不同的原子核因为它有不同的旋磁比，所以他们也会有不同的进动频率。在不同的磁场强度里面，那么对同一个原子核，也会不同的进动频率。单个自旋是理想状态，通常任何时候都是多个自旋。在B0磁场内，进动是量子化的，不是一个有很多种连续这个进度频率状态存在的，而是对于氢原子核来说，它有一个进动是沿着B0方向向，还有一种进动是逆着B0方向。那么对应的就是两个态，一个是高能态，一个是低能态，高能态的是逆着B0方向的，低能态顺着B0方向。在磁场里面当多个自旋的时候，有一个能级的分裂。没有外加磁场只有一个能级，加了外加磁场能级就分开了。氢原子核有两个能级。低能态的原子核数量会稍多于高能态的原子核数量。恰恰是因为这两个人群之间有原子核的数量有稍微的差异，所以就能够去做核磁共振。最终原子核数量的差异会产生一个宏观磁化量M0，可测量。不仅是可以测量它，而且可以测量它的变化过程。M0跟这个体系里面的氢原子核的数量成正比，如果能够把M0测出来，那么实际上通过标定，就可以把这个样品里面的原子核的数量测量出来。通过标定以后，实际上可以把孔隙度测量出来。M0它不是一下就形成的，它会有个过程，一个磁化的过程里面，它服从这样一个指数的这样一个规律，就这个原子核这么多原子核放在B0磁场里面的时候，M慢慢长，长的过程叫做纵向弛豫的过程，或者说实际上它是一个磁化的过程，极化的过程。Mt慢慢随着时间的增加是这样的长涨着涨到了一个平衡态，这个平衡态就是最终M0，完全极化。$$ M_t = M_0 * (1 - e^{\frac{-t}{T_1}})</script><p>增长的速率就是用这个时间常数，T1表示，纵向弛豫时间。</p><p>单纯从磁化量变化或者磁化的过程来看，来定义它，但实际上其一它还有更多的物理含义。<br>物理上定义为自旋-晶格弛豫时间。</p><p>我怎么样才能够磁化，让它充分磁化？充分磁化，因为它是一个无限接近的过程。<br>怎么样在比较少的时间里面，就让它代表了充分磁化？<br>T1，后面要讲到孔隙介质T1的时候，它还对应了我们样品的很多的属性，很多的特性，可以做很多的应用。</p><p>在跟B0磁场垂直的方向，加一个B1磁场。<br>B1磁场的频率刚好等于拉摩尔进动频率，此时会发生共振。核加了这样一个磁，核磁，然后再加一个磁场，共振。</p><p>共振：共振的情况就是低能态的原子核会从电磁场里面吸收能量，当拉莫尔频率进动的频率和外加磁场的频率相等的时候，低磁低能级的低能态的这个自旋会从这个磁场里面吸收能量，跃迁到高能态。</p><p>从量子力学的角度来说，它量子跃迁了第一轮胎的这个自旋发生了，量子跃迁到高能上去了。<br>从经典力学的角度来描述，需要一个很重要的概念叫坐标变换，没有这个坐标变换，我们很难来理解很多事儿。<br>目前我们讨论那么进度评论这些都是在叫实验室坐标系里面，实验室坐标系，就是我们现在坐在这里，所以我们能够看到它高速的进洞，看到它自己去在自选看这两个现象。<br>但是磁场加了以后，你要理解后续发生的行为，要做一个坐标系的变换，要在旋转坐标系里面来看待问题。<br>我们自己要跟着进动的自旋跑步跑，跟着进动自旋跑，就是在自旋，围绕着 B0磁场，我们现在要跟着它一起跑，那就叫旋转坐标系，我们是在旋转的，跟着进动频率在旋转。<br>我们加了电磁波加的 b1磁场，它是个脉冲磁场。早期工作的时候是叫连续波，连续波的时候它不是一个脉冲的，但是现在所有的核磁共振技术是脉冲核磁共振技术。<br>脉冲里面有一个宽度脉冲的宽度，然后有一个幅度，然后里面有一个调制频率，调制频率就是拉莫尔的进动频率。<br>所以脉冲电磁波它有三个要素，调制频率，幅度，长度。<br>你加上脉冲以后，如果我们在旋转坐标系里面来看，就有一个很重要的现象。<br>你就发现原来在旋转坐标系里面，我们随着这个来旋转的话，那么原来宏观磁化量是m，然后在旋转坐标系下，加上脉冲后，实际上等效于把m要搬转翻转。翻转到一个角度：<script type="math/tex">\Theta</script></p><script type="math/tex; mode=display">\Theta = \gamma B_1 \tau</script><p>前提条件是脉冲的调制频率等于进动频率，或者等于旋转坐标系的频率，否则它不会共振，否则也看不到板转的过程。</p><p>假设这个条件满足的情况下，那么 M就被扳转一个<script type="math/tex">\Theta</script>角，这个<script type="math/tex">\Theta</script>角完全由脉冲它的高度和它的长度来定义。如果希望把 M翻转到XY平面上来，实际上就是翻转90度，我们把脉冲叫90度脉冲。如果要搬转到180度，也就是从这个方向搬到另外一个方向，我们就把板转角叫做180度脉冲。</p><img src="/2024/05/14/%E6%A0%B8%E7%A3%81%E5%85%B1%E6%8C%AF%E6%B5%8B%E4%BA%95/%E6%A0%B8%E7%A3%81%E5%85%B1%E6%8C%AF%E5%8E%9F%E7%90%86%E7%BB%8F%E5%85%B8%E5%85%AD%E5%BC%A0%E5%9B%BE-2.png" class="" title="核磁共振测井"><p>本来是 M0是这个方向的，然后我们加一个90度脉冲意味着什么呢？这个方向的磁化量，我们把它搬走了，XY平面来，90的脉冲激发完了以后，如果我们用线圈去接收的话，你可以接收到一个信号，这个信号就是我们把这个FID叫自由感应衰减。</p><p>这个FID信号是因为我们把它搬走了，XY平面以后，它会散向。在旋转这个系里面，我们把它叫做相位散掉了。相位的分散，实际上对应的是实验室坐标系里面，它的频率不一样。<br>它的频率为什么不一样？因为它的磁场不是完全均匀的，磁场不是完全均匀，所以拉莫尔频率不是完全一样，它就会分散。在我们的旋转坐标系里面，就是它们的相位不一样，那么相位不一样。<br>所以慢慢的随着时间推移，它慢慢散相散相，散相了以后就变成了各个方向都有了，所以在XY平面上，平均值慢慢就归零了，这个过程我们也把它叫做横向弛豫过程。</p><p>FID在理想条件下，我们也是可以把它用一个方程来表达出来的。</p><script type="math/tex; mode=display">M_t = M_0 * e^{\frac {-t} {T_2 ^ * } }</script><p>T2称为横向弛豫时间，<script type="math/tex">T_ 2 ^ *</script> 是理想状态的，<script type="math/tex">T_ 2</script> 是实际测量到的。</p><p>因为这里面可能有磁场的不均匀性等等问题，所以 <script type="math/tex">T_ 2 ^ *</script> 跟我们样品本身的T2可能会有区别，甚至会区别比较大。但是从它的弛豫机制来说，我们把这个过程叫横向弛豫的过程。有一个横向弛豫的速率，叫T2，横向弛豫时间。</p><p>但是由于磁场本身的不均匀性，使得拉莫尔频率不一样，使它的相位在实验室在旋转坐标系里面，它不容易重聚，所以这样得到的T2不是我们本真的T2，而是T2和磁场的非均匀性的一个共同作用的结果。</p><p>用FID是测不到真实的T2的，如何测量到真实的T2？这个时候就提出了一个叫CPMG，叫自旋回波的方法，是测量横向弛豫时间的方法。</p><p>最简单的一个自旋回波的脉冲序列，它包括什么呢？包括一个90度脉冲，把它磁化量翻转90度到xy平面，到xy平面以后，由于磁场的非均匀性，它会散相。这个时候我们再加一个所谓的180的脉冲。<br>一个90的脉冲，然后我们再过一段时间加一个180的脉冲。加一个180的脉冲，然后再等待相同的时间，会产生一个所谓的回波，叫自旋回波。自旋回波就成为我们真实的实验的一个方法，包括我们岩心分析和下面的测井，都来用自旋回波。</p><p>而且自旋回波不光是可以测一个，它还可以测很多一个序列，一个系列，这个系列我们把它叫自旋回波串。<br>就是你在90度脉冲，一个FID，然后我们加一个180的脉冲，形成一个回波，再加一个180的脉冲，再形成回波，再加再形成。你不断的加180的脉冲，它会有一串回波，而这一串回波它是按照我们的横向弛豫时间为时间常数来衰减的，所以我们通过这个方法就得到了所谓的横向弛豫时间的测量值。</p><p>在旋转坐标系里面去理解90脉冲，180脉冲，所谓的脉冲扳转角。<br>我们过去的很多的测量是一个fid信号，甚至我们在很多的化学谱里面，他就测fid信号。<br>磁场非常的均匀条件下，就用这个FID来解析它的谱学的信息。<br>通谱学的信息来获得分子的结构，分子的动力学等等很多的应用。</p><p>很多脉冲序列来做所谓的量子调控，做很多所谓的极化转移。就是它可以通过一大堆的这些脉冲序列对量子调控，然后让分子发生变化，然后来获取分子里面的信息，来实现对分子的表征，对分子结构的解析。高场方向发展。</p><p>我们这里考虑了磁场的非均匀性，因为高场的时候希望磁场越均匀越好，但是我们面对低场，面对我们的孔隙介质，你是不可能做到均匀的。我们也不去用这个FID了，我们来做弛豫的测量。在非均匀磁场的条件下，怎么样把它的持续时间测准。</p><p>怎么产生回波？</p><p>90度脉冲以后，我们仍然在旋转坐标系里面来看的话，那就是相位的问题。因为我们知道这一个磁化量，它实际上是很多单个的自旋磁化量的一个叠加。那么单个的自旋它可能有我们考虑到磁场的非均匀性，它可能是由于我们外加的B0磁场不均匀，也可能是由于我们的样品本身里面产生了一个背景梯度磁场，不管什么原因，就导致了每一个自选所经历的磁场强度可能是不一样的。</p><p>磁场强度不一样，拉莫尔频率不一样，旋转坐标系里面的旋转频率不一样，旋转坐标系里面的相位不一样。</p><p>所以在这个里面我们就看到一部分磁场，一部分自旋，它会往这个方向跑，跑的比这个B0磁场的拉莫尔频率还快，还有一部分可能跟不上，所以你在前面旋转坐标系里面来看，你就比方说我们有三个人的跑步，如果我的速度刚好是正中间的话，那么有一个人跑得比较快的，有一个人跑得比较慢的，我在我看来那个人跑得快的就往那边去跑的，慢的就往后再往回再往那边跑，跑得快的再往前面跑，跑的慢的在后面跑，如果以我作为参照系的话。那么这里也就是一样，如果我们以B0磁场，这个H核和在B0磁场对应的拉莫尔频率作为参照，作为参照系的话，那么一部分磁场不均匀的比较大的一个信号，它就相当于在这个里面往前跑，而一部分磁场强度比较小的相当于往后跑，慢慢就分散了。</p><p>如果我们只考虑两个的话，实际上很多的那么这个过程我们把它叫做散相。那么这个项目的分散了以后，当然慢慢算就没有了，所以成了这个FID。<br>但是当我们再加一个180的脉冲，前面我们讲加一个180的脉冲，就意味着它做180度的翻转。</p><p>180板转有很多可能性，一种就是说我做180度的翻转，实际上把跑得快的翻转的跑的慢的地方去了，把跑得比较慢的搬走的跑得快的地方去，也就是说一般是相当于我们跑步，我们三个人在跑步，然后一个指令下来，全部向后跑，全部向后跑的结果什么我就往那边跑了是吧？原来跑得慢的那个人，他反而变得朝着我的方向跑，跑得比较快的人反而落后于我了，但他也要向着我来跑，原来跑的快的，慢慢的，因为他经历的路径多，他就往那边跑了，然后跑得慢的他就跑得快的往这边。最后在同样的时间里面，他们跑到这个地方来就会重聚，在重聚在一块的结果，我们就会通过我们的线圈就观测了一个很大的信号叫回波信号，回波就是这样来形成的。</p><p>所以这里就有一个旋转坐标系里面来分析脉冲的作用和回波的形成。那么然后180度脉冲以后，到这里来重聚，然后重聚了以后你把回波采集到了，过一段采集完了以后，然后他又要分散了，又要反散相，散相了以后，那么你再来一个180度，又测量了一下，不断地散相、重聚、散相、重聚、散相、重聚。</p><img src="/2024/05/14/%E6%A0%B8%E7%A3%81%E5%85%B1%E6%8C%AF%E6%B5%8B%E4%BA%95/%E6%A0%B8%E7%A3%81%E5%85%B1%E6%8C%AF%E5%8E%9F%E7%90%86%E7%BB%8F%E5%85%B8%E5%85%AD%E5%BC%A0%E5%9B%BE-3.png" class="" title="核磁共振测井"><p>我们统一来看：首先我们把样品放到外加磁场里面，放到外加磁场里面，那么B0所以它慢慢的就遵守纵向弛豫的过程，进行极化，达到M0，有了一个宏观磁化矢量，可观测量。然后我们用个脉冲这个序列加一个脉冲射频场，脉冲射频的有90度，一串180度，那么如果这个时候我没有测量的话，你就发现90的脉冲以后有FID，然后在180的脉冲以后就有一串的回波的信号，回波串。然后我们再来，测完了以后我们再来这个过程，又是磁化，又是测量，所以你最后看到的仪器给你显示的就是这样一个B0磁场，然后磁化，然后有一个脉冲射频场，然后再采集，然后再这样循环下去。</p><p>T2这个信号是逐渐衰减的，第一个180度后，第一个回波串信号幅度是大的，它逐渐衰减。其实在过程中一个就是一个相散和聚相的问题，聚相信号最大化，为什么第二个回波串它的能量要减小了？<br>T2本质上叫自旋-自旋弛豫时间，实际上它反映的是两个自旋之间或者自旋-自旋之间的很多的这种相互作用，这种相互作用它除了聚相的过程，除了相位重聚的过程以外，它本身由于自旋和自旋的相互作用，它会消耗能量，所以它是一个衰减的过程。它最后要恢复到没有了，在轴上它慢慢就没有了。<br>所以，T2是一个样品的重要的物理性质，它是一个它的物理特性，需要我们只是把T2通过这个方式把它测量出来。这个方式它之所以这个衰减，它是由它的物理性质来决定的，是自旋-自旋相互作用消耗能量来决定的，正是它我们想要研究它的一个特性。<br>相当于每一次聚相和散相他自身的能量已经衰减。</p><p>等待时间是不是就相当于必须要恢复最大的M0？</p><script type="math/tex; mode=display">T_w = 3 * T_1 → 95% M_0</script><script type="math/tex; mode=display">T_w = 5 * T_1 → 99.7% M_0</script><p>磁场的非均匀性：B0的非均匀性 + 介质本身的非均匀性。在B0的作用下，岩石的多孔介质本身会产生一个背景梯度磁场，而且你B0越大，B0背景梯度磁场就越大。</p><img src="/2024/05/14/%E6%A0%B8%E7%A3%81%E5%85%B1%E6%8C%AF%E6%B5%8B%E4%BA%95/%E6%A0%B8%E7%A3%81%E5%85%B1%E6%8C%AF%E5%8E%9F%E7%90%86%E7%BB%8F%E5%85%B8%E5%85%AD%E5%BC%A0%E5%9B%BE-4.png" class="" title="核磁共振测井"><p>多孔介质中的问题：<br>第一：液体那么到了孔隙里面的时候，这是孔隙的表面，它就会形成一个在表面上面形成一层膜，行非常重要。水流液体的分子，它本身会快速的扩散。里面的水中心部位的水，它的水分就快速的扩散。那么到了瓶子的表面的时候，这个界面上面就表面，那么它会形成一个这样的简单的膜，这个膜不是简单的膜，这个膜可能很复杂，这个膜的科学表面的科学无处不在。<br>1、表面是什么？表面还有很多胶接物，对吧？那么它有大量的这种非成对的电子，很多的非水性类的电子，这些非成对的电子的存在就导致了它会跟你相互作用，甚至会发生化学反应。<br>2、表面润湿性问题？<br>3、表面粗糙程度不同？表面的粗糙度可能也不一样，海岸线一样的，很粗糙不光滑的。因为在扩散的过程，在中间扩散的时候，它是布朗运动描述，可是一旦到定界面相接触的时候，他就会慢下来，碰撞淹没。所以这里面就有一个过渡带在这个地方，我们叫分子的表面层。</p><p>自由状态的液体，它有一个本身的T2，也有一个本身T1，但是你一旦液体放在孔隙里面，饱和到孔隙里面以后，它所测量出来的T2、T1，就跟原来完全不一样了。<br>在孔隙介质里面以后的T1、T2与饱和在孔隙介质本身的T1、T2很不一样。</p><script type="math/tex; mode=display">\frac{1}{T_1} = \frac{1}{T_{1 bulk}} + \rho_1 \frac{S}{V}</script><script type="math/tex; mode=display">\frac{1}{T_2} = \frac{1}{T_{2 bulk}} + \rho_2 \frac{S}{V} + \frac{ D (\gamma G T_E)^2 }{12}</script><p>T1不仅和自身有关，还跟比表面(S/V)有关，纵向弛豫强度(ρ1)有关<br>T2不仅与自身有关，还跟比表面(S/V)有关，横向弛豫强度(ρ1)有关，还有扩散项有关。</p><p>又有别的扩散弛豫理论，孔隙介质里面的弛豫跟孔隙的直径和扩散系数的比值又有关系。在这个条件它会分分快扩散区域，慢扩散区域，中等扩散区域。</p><p>如果说在常规里面，那几个假设可能还存在的话，成立的话，那么在页岩油气以及非常规里面，那几个假设可能就不成立了，假设条件不成立了，所以还能不能用？</p><p>应用1：孔径测量</p><p>当测量的T1和T2跟孔径对应的时候，T1忽略了自由弛豫，T2忽略了自由弛豫和扩散弛豫，才有了这样一个持续时间和孔径分布的一个对应关系，或者说一个相关性。因为这个量的量纲就是孔径，那么这样才有了这样一个定性的这样一个关系。<br>当然也可以定量，定量就是假设你知道这个的情况下，知道它的纵向持续强度和横向持续强度，你就可以来做定量。</p><p>那么如果成立这个时候，我们才有可能这样，一个是多指数，一个是统计，我们可以做孔径上的标定。<br>那么我可以说在常规游戏的时候，这个没有太多的问题，但是在页岩油气的时候这个一定有问题。我们可能没有这样的信噪比和分辨率，去表证页岩的孔径。</p><p>应用2：T2分布</p><p>在第一个应用假设存在的情况下，T2的大小跟孔径有了对应关系，所以需要分布可以把它标定成孔径的分布。一个简单的物理的原理就是说小孔隙流体不容易流动，大孔隙的流体容易流动。又假设孔隙与孔隙之间是连通的，注意死孔不是这样不存在，假设孔隙孔隙是连通的条件下，那么大孔是可流动的，小孔是没法流动的。那些就是碎屑岩，分选的比较好，并且也胶结作用不是很大的一些条件下面，这种状态他才成立这个东西。</p><p>那么如果存在这个的话，我们说我们在物理上就可以说这一部分是可动，另一部分是不可动。</p><p>那么既然在概念上有这两个，我们就想象可能有一个截止值。它首先截止值并不是它的T2截止值，这个截止值首先从物理上来说，它应该是一个孔径的截止值，当我们把孔径分布上面，一部分是束缚的，一部分是可动的，分开的时候，我们假设有一个孔径的介质，由于核磁的T2分布能够标定为孔径分布，所以我们对应的就有一个T2的截止值，这是有点野蛮粗暴，但是管用。它简单它管用，因为测井里面经常会遇到特别多的影响因素，你要每个都考虑的话，你是考虑不清楚的，那就抓主要的东西，管用。<br>T2截止值是表象，孔径截止值是本质。</p><p>所以我们现在假设孔径都是这种一个颗粒这样堆积起来的，那么它的T2分布就是代表一个孔径的分布。<br>对核磁来说，应该它的反应孔径的覆盖范围是目前所有的技术里面比较比较大的范围，而且是一个比较准的范围，而且不损害样品。</p><p>那么假设成立的情况下，这个时候我们就可以通过实验的方法来获得一个确定值，用来确定它的流体的赋存状态用，来获取我们非常重要的束缚水信息。所以一直就发展了一套标准实验流程和方法。</p><img src="/2024/05/14/%E6%A0%B8%E7%A3%81%E5%85%B1%E6%8C%AF%E6%B5%8B%E4%BA%95/%E6%A0%B8%E7%A3%81%E5%85%B1%E6%8C%AF%E5%8E%9F%E7%90%86%E7%BB%8F%E5%85%B8%E5%85%AD%E5%BC%A0%E5%9B%BE-5.png" class="" title="核磁共振测井"><p>有标准的流程，也有假设。<br>标准的流程：<br>第一步，把样品100%饱和水的时候，做一个核磁共振CPMG测量，然后做一个反演，得到它的T2分布，然后对应的相当于一个孔径的分布。<br>第二步，我们把这个岩样脱水，注意用离心机脱水，当然你也可以用别的方法脱水，然后脱完水以后，把那些自由水或者自由流体给它离心掉了，或者给它脱掉了，我们认为这个样品里面剩下来的都是束缚水。然后重复测量。<br>注意这是一个非常重要的概念，我们认为。谁认为？做实验的人认为。这个说法对不对？对也不对，这个自由裁定权太大，问题出在这儿。<br>第三步，两个放在一块，然后来求一个100%饱和的时候的一个孔隙度，然后只有束缚水时候一个记录束缚水孔隙度。自由水和束缚水相交的地方就是所谓的T2截止值，代表的是孔径截止值。</p><p>所以它有标准的规范流程，可是有一点它没有规范流程，你认为他是舒服水。</p><p>关键是你怎么去控制它，我认为这个里面就是舒服水？<br>那离心机的离心的速度，它可能会设置不一样，高了就把你们本来就束缚的也把它离心出来了，低了他还有可能所谓的在自由水，它也变成了在束缚水里面的。</p><p>斯伦贝谢提出相对截止值，放弃绝对的截止值。</p><p>测井的渗透率计算他是个估算的问题，是吧？我们并不直接的测量，我们是通过一些间接的量去估算的渗透率，那么估算的过程中间，它就会有很多的影响因素在这里，这些影响因素决定了我们究竟得到一个什么样的渗透率。</p><p>孔隙度、束缚水、渗透率是岩石物理特性，但是在流体的时候是另外的概念。流体储存的空间以及流体本身的性质和每一种流体的含量，这些对我们来说当然非常重要。</p><p>在单个孔里面，如果流体它们是混相的话，你是分不出来的，你是分不出来几个峰的，他们就是一个峰混在一块的。但是当我们中间有油，比方说我们假设中间可能也是个油珠，在哪个地方也可能跟他有认识性关系的等等。这个时候因为油和水它们不稳，像是它如果是溶解油油的话，你可能也看不出来。当他们两个不混相的时候，在他们的界面就有一层膜，他们互相不能扩散，不能扩散的情况下，这个时候他们就是两个分开的弛豫机制起作用。这个时候我们测量回波算，你就可以看到这个峰代表的是界面上的弛豫，这个峰是代表水包油的弛豫。所以这个时候就有了这样一个你看很明显的一个一个区分。</p><p>更进一步，假设这是股价，这个是骨架，这是孔隙是吧？孔隙里面有一个油珠，随着油的减少，你看水的峰，油的峰都在发生相应的变化。</p><p>对这两个问题，第一个问题只是我们我们是可以去识别油气了，油水了，可以把它们分开了。<br>第二个怎么分开，它是一个怎么样的变化的过程？<br>你看是非常明确的一个物理的概念，物理的意义在这里面了，你可以看到要把它分析出来，这分析出来将来对我们应用是有用的。</p><p>孔隙表面峰随着孔隙表面的水的增加，你看它的T2在变大，它不光是峰值在变化，T2也在变化。因为它跟界面的相互作用在变化。</p><p>核磁不管是谱学还是成像还是弛豫，它最重要的一点就是说几乎所有的表象都能够对应原理，这是核磁一个分析测试手段受到大家欢迎和青睐的重要的原因之一。当我们说不清楚的时候，是因为我们对样品缺少相关的理论缺少认识。</p><p>在孔隙里面的时候，然后在孔隙里面的时候怎么来区分流体的赋存状态，然后怎么样去求取相应的参数，然后当流体里面有不同的流体的时候，那么它的弛豫测量值上面又有什么表现？这是我们应用的基础。</p><img src="/2024/05/14/%E6%A0%B8%E7%A3%81%E5%85%B1%E6%8C%AF%E6%B5%8B%E4%BA%95/%E6%A0%B8%E7%A3%81%E5%85%B1%E6%8C%AF%E5%8E%9F%E7%90%86%E7%BB%8F%E5%85%B8%E5%85%AD%E5%BC%A0%E5%9B%BE-6.png" class="" title="核磁共振测井"><p>因为一维里面尽管好像有，但是通常情况下分不出来。更多的时候是分不出来的，叠在一块，叠在一块你就要用新技术是吧？用就要认识它的三维里面是什么样子，然后就要有发展二维的是吧？轻轻自由中等粘度的油稠油天然气分别通过二维怎么把它能够更好的区分开来是吧？</p><p>定域谱的这些技术，一个像素里面，那么它的t2分布是什么样子？</p><h2 id="来源《核磁共振测井原理与应用》书籍截图"><a href="#来源《核磁共振测井原理与应用》书籍截图" class="headerlink" title="来源《核磁共振测井原理与应用》书籍截图"></a>来源《核磁共振测井原理与应用》书籍截图</h2><img src="/2024/05/14/%E6%A0%B8%E7%A3%81%E5%85%B1%E6%8C%AF%E6%B5%8B%E4%BA%95/%E6%A0%B8%E8%87%AA%E6%97%8B.png" class="" title="核磁共振测井"><img src="/2024/05/14/%E6%A0%B8%E7%A3%81%E5%85%B1%E6%8C%AF%E6%B5%8B%E4%BA%95/%E5%8E%9F%E5%AD%90%E6%A0%B8%E8%BF%9B%E5%8A%A8.png" class="" title="核磁共振测井"><img src="/2024/05/14/%E6%A0%B8%E7%A3%81%E5%85%B1%E6%8C%AF%E6%B5%8B%E4%BA%95/%E5%AE%8F%E8%A7%82%E7%A3%81%E5%8C%96%E7%9F%A2%E9%87%8F.png" class="" title="核磁共振测井"><img src="/2024/05/14/%E6%A0%B8%E7%A3%81%E5%85%B1%E6%8C%AF%E6%B5%8B%E4%BA%95/T1%E5%BC%9B%E8%B1%AB.png" class="" title="核磁共振测井"><img src="/2024/05/14/%E6%A0%B8%E7%A3%81%E5%85%B1%E6%8C%AF%E6%B5%8B%E4%BA%95/%E8%83%BD%E7%BA%A7%E8%B7%83%E8%BF%81.png" class="" title="核磁共振测井"><img src="/2024/05/14/%E6%A0%B8%E7%A3%81%E5%85%B1%E6%8C%AF%E6%B5%8B%E4%BA%95/%E6%89%B3%E8%BD%AC%E8%A7%92.png" class="" title="核磁共振测井"><img src="/2024/05/14/%E6%A0%B8%E7%A3%81%E5%85%B1%E6%8C%AF%E6%B5%8B%E4%BA%95/%E8%87%AA%E7%94%B1%E6%84%9F%E5%BA%94%E8%A1%B0%E5%87%8F%E4%BF%A1%E5%8F%B7.png" class="" title="核磁共振测井"><img src="/2024/05/14/%E6%A0%B8%E7%A3%81%E5%85%B1%E6%8C%AF%E6%B5%8B%E4%BA%95/%E8%87%AA%E6%97%8B%E5%9B%9E%E6%B3%A2%E4%BF%A1%E5%8F%B7.png" class="" title="核磁共振测井"><img src="/2024/05/14/%E6%A0%B8%E7%A3%81%E5%85%B1%E6%8C%AF%E6%B5%8B%E4%BA%95/CPMG%E8%84%89%E5%86%B2%E5%BA%8F%E5%88%97.png" class="" title="核磁共振测井"><img src="/2024/05/14/%E6%A0%B8%E7%A3%81%E5%85%B1%E6%8C%AF%E6%B5%8B%E4%BA%95/T2%E5%BC%9B%E8%B1%AB.png" class="" title="核磁共振测井"><img src="/2024/05/14/%E6%A0%B8%E7%A3%81%E5%85%B1%E6%8C%AF%E6%B5%8B%E4%BA%95/CPMG%E8%84%89%E5%86%B2%E5%BA%8F%E5%88%97-2.png" class="" title="核磁共振测井"><img src="/2024/05/14/%E6%A0%B8%E7%A3%81%E5%85%B1%E6%8C%AF%E6%B5%8B%E4%BA%95/%E5%AD%94%E9%9A%99%E6%B5%81%E4%BD%93%E5%BC%9B%E8%B1%AB.png" class="" title="核磁共振测井"><img src="/2024/05/14/%E6%A0%B8%E7%A3%81%E5%85%B1%E6%8C%AF%E6%B5%8B%E4%BA%95/%E5%AD%94%E9%9A%99%E6%B5%81%E4%BD%93%E5%BC%9B%E8%B1%AB-2.png" class="" title="核磁共振测井"><h1 id="NMR数据采集"><a href="#NMR数据采集" class="headerlink" title="NMR数据采集"></a>NMR数据采集</h1><p>测井仪器除了探测FID和CPMG自旋回波信号，还需要将这些信号进行数字化、存储和处理。典型的CPMG自旋回波串通常有成百上千的回波，将整个回波曲线数字化难度太大，故而只需测量和存储自旋回波信号的峰值即可。信号的记录方式有两种：<code>单道检测法</code>和<code>正交检测法</code>。</p><p><code>单道检测法</code>：从样品来的射频信号送入单个的相敏检测器中以识别样品信号频率与射频脉冲载频的频率(即为测量值设定的平均拉莫尔频率)之间的差异。由于单个相敏检测器只能得到频率差异的大小，而不能确定相位差，所以在NMR测井中不能利用单道检测法。</p><p><code>正交检测法</code>：输入的采样信号送到两个同样的相敏检测器中，这两个检测器的参考信号相差90°，合成声频信号被放大，然后通过同样的低通滤波器，经多元模数转换器数字化并存储在单独的数据存储区中。正交傅里叶变换以与单道检测法相同的方式产生实数谱和虚数谱，并可区分出相对与射频载频的正频率和负频率。</p><p>为了消除振铃和基线偏移的影响，测井作业中总是成对采集T2的CPMG测量值，该方法称为交叉相位对(PAPs)。第一个回波串的采集利用常规设置，而在第二组中发射脉冲的相位改变了180°，从而使得自旋回波具有负振幅，这两组CPMG信号被称为正相位和负相位，结合形成PAPs，用以消除振铃和基线偏移的影响。</p><h2 id="相位旋转"><a href="#相位旋转" class="headerlink" title="相位旋转"></a>相位旋转</h2><p>记录数据的两个通道通常称为X通道和Y通道。这两个通道的信号表达式如下：</p><script type="math/tex; mode=display">X_{j}=S_{j}\cos \varphi+\varepsilon_{j}^{X}</script><script type="math/tex; mode=display">Y_j=S_j sin\varphi +\varepsilon_j^Y</script><p>式中，<script type="math/tex">X_j</script> 和 <script type="math/tex">Y_j</script> 分别是 X 和 Y 通道的第j个回波的幅度，<script type="math/tex">S_j</script>是回波的实际幅度，<script type="math/tex">\varphi</script>为相位角，<script type="math/tex">\varepsilon_{j}^{X}</script> 和 <script type="math/tex">\varepsilon_j^Y</script> 分别是 X 和 Y 通道的第 j 个回波的噪声。如果将回波串中的所有回波相加(回波个数为n)，可以得到：</p><script type="math/tex; mode=display">\sum_{j=1}^nX_j=\left[\sum_{j=1}^nS_j\right]cos\varphi+\left[\sum_{j=1}^n\varepsilon_j^X\right]</script><script type="math/tex; mode=display">\sum_{j=1}^nY_j=\left[\sum_{j=1}^nS_j\right]sin\varphi+\left[\sum_{j=1}^n\varepsilon_j^Y\right]</script><p>因为噪声是随机的，取正负值的概率相等。如果去平均噪声进行计算，上述方程等式右边的第二项将最终趋近于零。将两式相比，则可以得到相位角公式：</p><script type="math/tex; mode=display">\varphi=\arctan\left[\sum_{j=1}^{n}Y_{j}/\sum_{j=1}^{n}X_{j}\right]</script><p>通过上式得到相位角后，便可利用下面的等式进行坐标轴的旋转，从而得到信号道和噪声道。</p><script type="math/tex; mode=display">C_{signal}(j)=X_jcos\varphi+Y_jsin\varphi=S_j+(\varepsilon_j^Xcos\varphi+\varepsilon_j^Ysin\varphi)</script><script type="math/tex; mode=display">C_{noise}(j)=-X_jsin\varphi+Y_jcos\varphi=(-\varepsilon_j^Xsin\varphi+\varepsilon_j^Ycos\varphi)</script><h1 id="NMR数据处理"><a href="#NMR数据处理" class="headerlink" title="NMR数据处理"></a>NMR数据处理</h1><p>核磁共振测井技术是一种间接测量技术，它所采集到的原始数据是岩石孔隙中所含流体弛豫信号的叠加，即自旋回波信号，必须采用现代数学方法对回波信号进行反演得到T2谱才能进一步应用，并且反演结果直接影响后续储层参数计算和流体识别评价的准确性。</p><p>假设有n个回波，每个回波在时间 <script type="math/tex">t_i</script> 处的幅度测量值为 <script type="math/tex">g_i</script>，并假设有m个预先选择的驰豫时间 <script type="math/tex">T_j</script> 在对数刻度上等间隔分布。回波幅度 <script type="math/tex">g_i</script> 为  <script type="math/tex">t_i</script> 时刻测量的系统磁化强度 <script type="math/tex">M(t_i)</script> ，并经由t=0时的磁化强度 <script type="math/tex">M_0</script> 的归一化。回波测量值 <script type="math/tex">g_i</script> 的方程表达式如下：</p><script type="math/tex; mode=display">g_i=\frac{M(t_i)}{M_0}=\sum_{j=1}^ma_jf_je^{-t_i/T_j}+\varepsilon_i</script><p>其中，i=1,…,n。<script type="math/tex">f_j</script>是T2驰豫时间为 <script type="math/tex">T_j</script> 的孔隙度的部分孔隙度，在NMR测井中，回波幅度往往采用孔隙度单位(p.u.)。<script type="math/tex">a_j</script>为极化因子，它的方程如下：</p><script type="math/tex; mode=display">a_{j}=1-e^{-TW/T_{1j}}</script><p>通常等待时间很长，往往是T1驰豫时间的三倍，在这种情况下，因子<script type="math/tex">a_j</script>j为1。</p><p>因为所有的<script type="math/tex">e^{-t_i/T_j}</script>都已知，求解<script type="math/tex">f_j</script>就是一个线性反演问题。可以用最小二乘法拟合来使下面的求和最小化，即：</p><script type="math/tex; mode=display">\min\left\{\varphi(f)=\sum_{i=1}^{n}\frac{1}{\delta_{i}^{2}}\left[\sum_{j=1}^{m}f_{j}e^{-t_{i}/T_{j}}-g_{i}\right]\right\}</script><p>其中，<script type="math/tex">δ_i</script> 是第i个回波 <script type="math/tex">g_i</script>的测量误差。</p><h2 id="多指数反演算法"><a href="#多指数反演算法" class="headerlink" title="多指数反演算法"></a>多指数反演算法</h2><p>一维核磁共振的一般响应方程为：</p><script type="math/tex; mode=display">\mathrm{b(t)}=\int f(T_i)(c_1-c_2\cdot\exp{(-t/T_i)})dT_i+\varepsilon</script><p>其中，i=1,2。当i=1时表示T1信号，<script type="math/tex">c_1</script>=1，<script type="math/tex">c_2</script>=1表示饱和恢复法，若<script type="math/tex">c_1</script>=1，<script type="math/tex">c_2</script>=2表示反转恢复法；当i=2时表示T2信号，这时<script type="math/tex">c_1</script>=0，<script type="math/tex">c_2</script>=-1。</p><p>上式的离散形式为：</p><script type="math/tex; mode=display">b_k=\sum_{T_{i,min}}^{T_{i,max}}f(T_{i,j})\left[c_1-c_2\cdot exp^{-\frac{t_k}{T_{i,j}}}\right]+\varepsilon_k</script><p>其中，j=1,···n, n为预选的驰豫分量的个数；k=1,···m, m为回波个数，<script type="math/tex">t_k</script>为采集时间（通常为回波间隔的整数倍）；<script type="math/tex">b_k</script>为回波信号幅度；<script type="math/tex">T_{i,j}</script>为<script type="math/tex">T_i</script>预选的第 j个弛豫时间分量；<script type="math/tex">ε_k</script>为测量噪声；<script type="math/tex">f(T_{i,j})</script> 为弛豫时间<script type="math/tex">T_{i,j}</script>的幅度。</p><p>求解上述方程，实际上是解第一类Fredholm积分方程，这是一个非适定问题，即在误差允许的条件下，存在不同的<script type="math/tex">f(T_{i,j})</script>驰豫时间分布函数都能相当好地拟合原始回波衰减曲线。</p><h2 id="SVD算法"><a href="#SVD算法" class="headerlink" title="SVD算法"></a>SVD算法</h2><p>SVD算法基于如下分解定理：对任意的矩阵<script type="math/tex">A_{m×n}</script>，都可以分解为正交矩阵<script type="math/tex">U_{m×m}</script>，非负对角矩阵<script type="math/tex">W_{m×n}</script>以及正交矩阵<script type="math/tex">V_{n×n}</script>的转置的乘积，即</p><script type="math/tex; mode=display">A_{m\times n}=U_{m\times m}\cdot[\mathrm{diag}(w_j)]_{m\times n}\cdot V_{n\times n}^T</script><p>对角元素<script type="math/tex">w_1>w_2>···>w_m≥0</script>，w称为矩阵A的奇异值。</p><p>对于如下的多指数衰减T2模型，有</p><script type="math/tex; mode=display">y=M·f</script><p>其中<script type="math/tex">y=(y_1,y_2,···,y_n)^T</script>为测量的自旋回波衰减信号，<script type="math/tex">M=[m_{ij}]_{n×m}=[exp(-t_i/T_{2j})]_(n×m)；f=(f_1,f_2,···,f_n)^T</script>为驰豫时间<script type="math/tex">T_{2j}</script>对应的各点的幅度值，<script type="math/tex">T_{2j}</script>为预先指定的T2时间分布系列，典型的取法为在<script type="math/tex">(T_{2min},T_{2max})</script>区间内对数均匀的选取m个点，也可采用2的幂指数布点、线性均匀布点等方式。若矩阵的条件数为无穷大，则该矩阵奇异；若矩阵的条件数太大，即其倒数超出了机器的浮点精度，则称该矩阵为病态的矩阵。采用SVD分解法来求解上式，系数矩阵<script type="math/tex">M_{m×n}=U_{m×m}·[diag(w_j)]_{m×n}·V_{n×n}^T</script>，则上式最小二乘意义下的解为：</p><script type="math/tex; mode=display">f=V\cdot[diag(\frac{1}{\mathrm{w_{1}}},\frac{1}{\mathrm{w_{2}}},\cdots,\frac{SNR}{\mathrm{w_{1}}},0,\cdots,0)]\cdot(U^{T}\cdot\mathrm{y})</script><p>这里给出了矩阵条件数小于等于SNR的限制，避免了解的不确定性。其中SNR为从测量数据中估算出的信噪比。SNR定义为第一个回波的幅度值除以误差矢量r的标准差σ。</p><h2 id="T2谱非负限制性的实现"><a href="#T2谱非负限制性的实现" class="headerlink" title="T2谱非负限制性的实现"></a>T2谱非负限制性的实现</h2><p>按照如上SVD算法对矩阵M进行奇异值分解后，根据信噪比计算出截断值为<script type="math/tex">SNR/w_1</script> ，对分解得到的非负矩阵<script type="math/tex">W_{m×n}</script>求逆，因为对角元素按其角标增大而减小，故求逆后，对角元素随其角标增大而增大，寻找到恰好比截断值小的对角元素的角标i，对i其后的对角元素赋值为0，对角标为i的元素则进行重新赋值：</p><script type="math/tex; mode=display">W(i,i)=\frac{1}{w_{i}}*[(w_{i-1}-\frac{SNR}{w_{1}})/(w_{i-1}-\frac{1}{w_{i}})]</script><p>将重新赋值的对角矩阵 <script type="math/tex">W=diag(1/w_1 ,1/w_2 ,···,W(i,i),0,···,0)</script> 代入到f的式子中，若求得f的结果中存在负值，则记下负值的角标，并删除矩阵M中对应的列，删掉T2布点中对应的角标的值。将删列的矩阵M再进行SVD分解…，重复循环直到计算得到f中不再有负值存在。<br>缺点是会破坏T2分布的连续性，造成T2谱的畸形。</p><h2 id="BRD算法"><a href="#BRD算法" class="headerlink" title="BRD算法"></a>BRD算法</h2><p>首先给定如下的目标函数：</p><script type="math/tex; mode=display">\chi^2=\sum_{i=1}^n[y_1-\sum_{j=1}^m(f_j\cdot m_{ij})]^2+\lambda\cdot\sum_{j=1}^mf_j^2=||y-Mf||^2+\lambda||f||^2</script><p>这里<script type="math/tex">M=[m_{ij}]=[exp^{(-t_i/T_2j )}]</script>，λ为平滑因子。</p><p>对幅度f=(f_1,f_1,···,f_m)^T的第k分量求极值并令其等于0，则有：</p><script type="math/tex; mode=display">\frac{\partial\chi^2}{\partial f_k}=-2\sum_{i=1}^n\left[y_i-\sum_{j=1}^mf_j\cdot m_{ij}\right]\cdot m_{ik}+2\lambda\cdot f_k=0</script><p>交换求和顺序，并移项整理，可得：</p><script type="math/tex; mode=display">\sum_{i=1}^m[f_j\cdot\sum_{j=1}^nm_{ik}\cdot m_{ij}]+\lambda\cdot f_k=\sum_{j=1}^mm_{ik}\cdot y_k</script><p>很容易验证，k=1,2, ···,m的m个等式组成的方程组满足：</p><script type="math/tex; mode=display">(M^T\mathrm{M})\cdot\mathrm{f}+\lambda I_{m\times m}\cdot f=M^T\cdot y</script><p>上式中<script type="math/tex">I_{m×m}</script>为m×m单位矩阵。我们对方程y=M·f 做如下线性变换，令</p><script type="math/tex; mode=display">f=\mathrm{M}^T\cdot c</script><p>未知变量<script type="math/tex">c=(c_1,c_1,···,c_n)^T</script>为n×1维的，而不是m×1，采用上述变换将m维T2域空间的解变换到n维时域空间来求解。则有：</p><script type="math/tex; mode=display">M^T\cdot(M^T\text{M}+\lambda I_{n\times n})\cdot\text{c}=M^T\cdot\text{y}</script><p>则原问题的解f可以通过求解方程：</p><script type="math/tex; mode=display">(M^T\text{M}+\lambda I_{n\times n})\cdot\text{c}=\text{y}</script><p>的解c，再通过线性变换<script type="math/tex">f=M^T·c</script>回代而获得，选择合适的λ，以保证矩<script type="math/tex">(M^T M+λI_{n×n} )·c</script>的可逆，则我们就可以很容易的求得方程的最小二乘解：</p><script type="math/tex; mode=display">f=M^T\cdot(\mathrm{M}^T\mathrm{M}+\lambda\mathrm{I}(\mathrm{n}\times\mathrm{n})\cdot)^{-1}\cdot y</script><p>比较理想的平滑因子为：</p><script type="math/tex; mode=display">\lambda=\frac{\sqrt n\cdot\sigma}{||c||}</script><h2 id="T2谱非负限制性的实现-1"><a href="#T2谱非负限制性的实现-1" class="headerlink" title="T2谱非负限制性的实现"></a>T2谱非负限制性的实现</h2><p>按照如上BRD算法对模平滑函数（惩罚函数）进行T2域空间变换到时域空间后，可得初始值<script type="math/tex">c_1=y/(M^T M+λI_{n×n})</script>，继而可得<script type="math/tex">c_k=M^T·c_1</script>，若<script type="math/tex">c_{ki}>0</script>则<script type="math/tex">f_i=c_{ki}</script>（若<script type="math/tex">c_{ki}≤0</script>则<script type="math/tex">f_i=0</script>），并将<script type="math/tex">c_{ki}>0</script>对应的矩阵M的相应列提取出来赋给新的矩阵A，然后用新矩阵A替代旧矩阵M，做以上循环求取新的<script type="math/tex">c_2</script>，<script type="math/tex">c_k</script>值。循环退出的条件有三：一，矩阵A为空即所有<script type="math/tex">c_k</script>均小于等于0；二，小于误差项即<script type="math/tex">c_2-c_1<1e-8</script>；三，超出规定的迭代次数。</p><p>基于以上迭代方法的惩罚函数有三类：模平滑、斜率平滑及曲率平滑。这些平滑方法中惩罚项的作用是压制未知函数f的振荡性。</p>]]></content>
    
    
    <summary type="html">核磁共振测井</summary>
    
    
    
    <category term="核磁共振" scheme="http://hibiscidai.com/categories/%E6%A0%B8%E7%A3%81%E5%85%B1%E6%8C%AF/"/>
    
    
    <category term="核磁共振原理" scheme="http://hibiscidai.com/tags/%E6%A0%B8%E7%A3%81%E5%85%B1%E6%8C%AF%E5%8E%9F%E7%90%86/"/>
    
    <category term="测井方法" scheme="http://hibiscidai.com/tags/%E6%B5%8B%E4%BA%95%E6%96%B9%E6%B3%95/"/>
    
  </entry>
  
</feed>
