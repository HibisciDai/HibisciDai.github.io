<!DOCTYPE html><html lang="zh-Hans"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta name="description" content="Hadoop运行模式"><meta name="keywords" content="学习笔记,Hadoop,大数据"><meta name="author" content="HibisciDai"><meta name="copyright" content="HibisciDai"><title>Hadoop运行模式 | HibisciDai</title><link rel="shortcut icon" href="/img/avatar.png"><link rel="stylesheet" href="/css/index.css?version=1.9.0"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/font-awesome@latest/css/font-awesome.min.css?version=1.9.0"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.7.2/css/all.css?version=1.9.0"><meta name="format-detection" content="telephone=no"><meta http-equiv="x-dns-prefetch-control" content="on"><link rel="dns-prefetch" href="https://cdn.jsdelivr.net"><link rel="manifest" href="/manifest.json"><link rel="manifest" href="/manifest.json"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><script src="https://v1.hitokoto.cn/?encode=js&amp;charset=utf-8&amp;select=.footer_custom_text" defer></script><script>var GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: {"path":"search.xml","languages":{"hits_empty":"找不到您查询的内容:${query}"}},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  hexoVersion: '6.1.0'
} </script><meta name="generator" content="Hexo 6.1.0"><link rel="alternate" href="/atom.xml" title="HibisciDai" type="application/atom+xml">
</head><body><canvas class="fireworks"></canvas><i class="fa fa-arrow-right" id="toggle-sidebar" aria-hidden="true"></i><div id="sidebar" data-display="true"><div class="toggle-sidebar-info text-center"><span data-toggle="切换文章详情">切换站点概览</span><hr></div><div class="sidebar-toc"><div class="sidebar-toc__title">目录</div><div class="sidebar-toc__progress"><span class="progress-notice">你已经读了</span><span class="progress-num">0</span><span class="progress-percentage">%</span><div class="sidebar-toc__progress-bar"></div></div><div class="sidebar-toc__content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#Hadoop%E8%BF%90%E8%A1%8C%E6%A8%A1%E5%BC%8F"><span class="toc-number">1.</span> <span class="toc-text">Hadoop运行模式</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E6%9C%AC%E5%9C%B0%E8%BF%90%E8%A1%8C%E6%A8%A1%E5%BC%8F"><span class="toc-number">2.</span> <span class="toc-text">本地运行模式</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%AE%98%E6%96%B9Grep%E6%A1%88%E4%BE%8B"><span class="toc-number">2.1.</span> <span class="toc-text">官方Grep案例</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Standalone-Operation"><span class="toc-number">2.1.1.</span> <span class="toc-text">Standalone Operation</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%AE%9E%E6%93%8D"><span class="toc-number">2.1.2.</span> <span class="toc-text">实操</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%AE%98%E6%96%B9WordCount%E6%A1%88%E4%BE%8B"><span class="toc-number">2.2.</span> <span class="toc-text">官方WordCount案例</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E4%BC%AA%E5%88%86%E5%B8%83%E5%BC%8F%E6%A8%A1%E5%BC%8F"><span class="toc-number">3.</span> <span class="toc-text">伪分布式模式</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#Pseudo-Distributed-Operation-%E5%AE%98%E7%BD%91%E6%8C%87%E5%8D%97"><span class="toc-number">3.1.</span> <span class="toc-text">Pseudo-Distributed Operation-官网指南</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%90%AF%E5%8A%A8HDFS%E5%B9%B6%E8%BF%90%E8%A1%8CMapReduce%E7%A8%8B%E5%BA%8F"><span class="toc-number">3.2.</span> <span class="toc-text">启动HDFS并运行MapReduce程序</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%88%86%E6%9E%90"><span class="toc-number">3.2.1.</span> <span class="toc-text">分析</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#1-%E9%85%8D%E7%BD%AE%E9%9B%86%E7%BE%A4"><span class="toc-number">3.2.2.</span> <span class="toc-text">1. 配置集群</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-%E5%90%AF%E5%8A%A8%E9%9B%86%E7%BE%A4"><span class="toc-number">3.2.3.</span> <span class="toc-text">2.启动集群</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-%E6%9F%A5%E7%9C%8B%E9%9B%86%E7%BE%A4"><span class="toc-number">3.2.4.</span> <span class="toc-text">3.查看集群</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-%E6%93%8D%E4%BD%9C%E9%9B%86%E7%BE%A4"><span class="toc-number">3.2.5.</span> <span class="toc-text">4.操作集群</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%90%AF%E5%8A%A8YARN%E5%B9%B6%E8%BF%90%E8%A1%8CMapReduce%E7%A8%8B%E5%BA%8F"><span class="toc-number">3.3.</span> <span class="toc-text">启动YARN并运行MapReduce程序</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%88%86%E6%9E%90-1"><span class="toc-number">3.3.1.</span> <span class="toc-text">分析</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#1-%E9%85%8D%E7%BD%AE%E9%9B%86%E7%BE%A4-1"><span class="toc-number">3.3.2.</span> <span class="toc-text">1. 配置集群</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-%E5%90%AF%E5%8A%A8%E9%9B%86%E7%BE%A4-1"><span class="toc-number">3.3.3.</span> <span class="toc-text">2. 启动集群</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-%E9%9B%86%E7%BE%A4%E6%93%8D%E4%BD%9C"><span class="toc-number">3.3.4.</span> <span class="toc-text">3. 集群操作</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E9%85%8D%E7%BD%AE%E5%8E%86%E5%8F%B2%E6%9C%8D%E5%8A%A1%E5%99%A8"><span class="toc-number">3.4.</span> <span class="toc-text">配置历史服务器</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-%E9%85%8D%E7%BD%AEmapred-site-xml"><span class="toc-number">3.4.1.</span> <span class="toc-text">1.配置mapred-site.xml</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-%E5%90%AF%E5%8A%A8%E5%8E%86%E5%8F%B2%E6%9C%8D%E5%8A%A1%E5%99%A8"><span class="toc-number">3.4.2.</span> <span class="toc-text">2.启动历史服务器</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-%E6%9F%A5%E7%9C%8B%E5%8E%86%E5%8F%B2%E6%9C%8D%E5%8A%A1%E5%99%A8%E6%98%AF%E5%90%A6%E5%90%AF%E5%8A%A8"><span class="toc-number">3.4.3.</span> <span class="toc-text">3.查看历史服务器是否启动</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-%E6%9F%A5%E7%9C%8BJobHistory"><span class="toc-number">3.4.4.</span> <span class="toc-text">4.查看JobHistory</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E9%85%8D%E7%BD%AE%E6%97%A5%E5%BF%97%E7%9A%84%E8%81%9A%E9%9B%86"><span class="toc-number">3.5.</span> <span class="toc-text">配置日志的聚集</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-%E5%85%B3%E9%97%ADNodeManager-%E3%80%81ResourceManager%E5%92%8CHistoryManager"><span class="toc-number">3.5.1.</span> <span class="toc-text">1.关闭NodeManager 、ResourceManager和HistoryManager</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-%E9%85%8D%E7%BD%AEyarn-site-xml"><span class="toc-number">3.5.2.</span> <span class="toc-text">2.配置yarn-site.xml</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-%E5%90%AF%E5%8A%A8NodeManager-%E3%80%81ResourceManager%E5%92%8CHistoryManager"><span class="toc-number">3.5.3.</span> <span class="toc-text">3.启动NodeManager 、ResourceManager和HistoryManager</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-%E5%88%A0%E9%99%A4HDFS%E4%B8%8A%E5%B7%B2%E7%BB%8F%E5%AD%98%E5%9C%A8%E7%9A%84%E8%BE%93%E5%87%BA%E6%96%87%E4%BB%B6"><span class="toc-number">3.5.4.</span> <span class="toc-text">4.删除HDFS上已经存在的输出文件</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-%E6%89%A7%E8%A1%8CWordCount%E7%A8%8B%E5%BA%8F"><span class="toc-number">3.5.5.</span> <span class="toc-text">5.执行WordCount程序</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#6-%E6%9F%A5%E7%9C%8B%E6%97%A5%E5%BF%97"><span class="toc-number">3.5.6.</span> <span class="toc-text">6.查看日志</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#7-%E6%9D%80%E6%AD%BBjob"><span class="toc-number">3.5.7.</span> <span class="toc-text">7.杀死job</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#8-%E5%88%A0%E9%99%A4application"><span class="toc-number">3.5.8.</span> <span class="toc-text">8.删除application</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%E7%9A%84%E8%AF%B4%E6%98%8E"><span class="toc-number">3.6.</span> <span class="toc-text">配置文件的说明</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%BB%98%E8%AE%A4%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6"><span class="toc-number">3.6.1.</span> <span class="toc-text">默认配置文件</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%87%AA%E5%AE%9A%E4%B9%89%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6"><span class="toc-number">3.6.2.</span> <span class="toc-text">自定义配置文件</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%AE%8C%E5%85%A8%E5%88%86%E5%B8%83%E5%BC%8F%E8%BF%90%E8%A1%8C%E6%A8%A1%E5%BC%8F%E2%80%BB"><span class="toc-number">4.</span> <span class="toc-text">完全分布式运行模式※</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%88%86%E6%9E%90-2"><span class="toc-number">4.1.</span> <span class="toc-text">分析</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%99%9A%E6%8B%9F%E6%9C%BA%E5%87%86%E5%A4%87"><span class="toc-number">4.2.</span> <span class="toc-text">虚拟机准备</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%BC%96%E5%86%99%E9%9B%86%E7%BE%A4%E5%88%86%E5%8F%91%E8%84%9A%E6%9C%ACxsync"><span class="toc-number">4.3.</span> <span class="toc-text">编写集群分发脚本xsync</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#scp%EF%BC%88secure-copy%EF%BC%89%E5%AE%89%E5%85%A8%E6%8B%B7%E8%B4%9D"><span class="toc-number">4.3.1.</span> <span class="toc-text">scp（secure copy）安全拷贝</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#scp%E5%AE%9A%E4%B9%89"><span class="toc-number">4.3.1.1.</span> <span class="toc-text">scp定义</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%9F%BA%E6%9C%AC%E8%AF%AD%E6%B3%95"><span class="toc-number">4.3.1.2.</span> <span class="toc-text">基本语法</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%A1%88%E4%BE%8B%E5%AE%9E%E6%93%8D"><span class="toc-number">4.3.2.</span> <span class="toc-text">案例实操</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#rsync-%E8%BF%9C%E7%A8%8B%E5%90%8C%E6%AD%A5%E5%B7%A5%E5%85%B7"><span class="toc-number">4.3.3.</span> <span class="toc-text">rsync 远程同步工具</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%9F%BA%E6%9C%AC%E8%AF%AD%E6%B3%95-1"><span class="toc-number">4.3.3.1.</span> <span class="toc-text">基本语法</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%A1%88%E4%BE%8B%E5%AE%9E%E6%93%8D-1"><span class="toc-number">4.3.3.2.</span> <span class="toc-text">案例实操</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#xsync%E9%9B%86%E7%BE%A4%E5%88%86%E5%8F%91%E8%84%9A%E6%9C%AC"><span class="toc-number">4.3.4.</span> <span class="toc-text">xsync集群分发脚本</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E9%9C%80%E6%B1%82"><span class="toc-number">4.3.4.1.</span> <span class="toc-text">需求</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E9%9C%80%E6%B1%82%E5%88%86%E6%9E%90"><span class="toc-number">4.3.4.2.</span> <span class="toc-text">需求分析</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E8%84%9A%E6%9C%AC%E5%AE%9E%E7%8E%B0"><span class="toc-number">4.3.4.3.</span> <span class="toc-text">脚本实现</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E9%9B%86%E7%BE%A4%E9%85%8D%E7%BD%AE"><span class="toc-number">4.4.</span> <span class="toc-text">集群配置</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%9B%86%E7%BE%A4%E9%83%A8%E7%BD%B2%E8%A7%84%E5%88%92"><span class="toc-number">4.4.1.</span> <span class="toc-text">集群部署规划</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%85%8D%E7%BD%AE%E9%9B%86%E7%BE%A4"><span class="toc-number">4.4.2.</span> <span class="toc-text">配置集群</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%A0%B8%E5%BF%83%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6"><span class="toc-number">4.4.2.1.</span> <span class="toc-text">核心配置文件</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#HDFS%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6"><span class="toc-number">4.4.2.2.</span> <span class="toc-text">HDFS配置文件</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#YARN%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6"><span class="toc-number">4.4.2.3.</span> <span class="toc-text">YARN配置文件</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#MapReduce%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6"><span class="toc-number">4.4.2.4.</span> <span class="toc-text">MapReduce配置文件</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%9C%A8%E9%9B%86%E7%BE%A4%E4%B8%8A%E5%88%86%E5%8F%91%E9%85%8D%E7%BD%AE%E5%A5%BD%E7%9A%84Hadoop%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6"><span class="toc-number">4.4.3.</span> <span class="toc-text">在集群上分发配置好的Hadoop配置文件</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%9F%A5%E7%9C%8B%E6%96%87%E4%BB%B6%E5%88%86%E5%8F%91%E6%83%85%E5%86%B5"><span class="toc-number">4.4.4.</span> <span class="toc-text">查看文件分发情况</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E9%9B%86%E7%BE%A4%E5%8D%95%E7%82%B9%E5%90%AF%E5%8A%A8"><span class="toc-number">4.5.</span> <span class="toc-text">集群单点启动</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#SSH%E6%97%A0%E5%AF%86%E7%99%BB%E5%BD%95%E9%85%8D%E7%BD%AE"><span class="toc-number">4.6.</span> <span class="toc-text">SSH无密登录配置</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%85%8D%E7%BD%AESSH"><span class="toc-number">4.6.1.</span> <span class="toc-text">配置SSH</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%9F%BA%E6%9C%AC%E8%AF%AD%E6%B3%95-2"><span class="toc-number">4.6.1.1.</span> <span class="toc-text">基本语法</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#ssh%E8%BF%9E%E6%8E%A5%E6%97%B6%E5%87%BA%E7%8E%B0Host-key-verification-failed%E7%9A%84%E8%A7%A3%E5%86%B3%E6%96%B9%E6%B3%95"><span class="toc-number">4.6.1.2.</span> <span class="toc-text">ssh连接时出现Host key verification failed的解决方法</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%97%A0%E5%AF%86%E9%92%A5%E9%85%8D%E7%BD%AE"><span class="toc-number">4.6.2.</span> <span class="toc-text">无密钥配置</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%85%8D%E5%AF%86%E7%99%BB%E5%BD%95%E5%8E%9F%E7%90%86"><span class="toc-number">4.6.2.1.</span> <span class="toc-text">免密登录原理</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E7%94%9F%E6%88%90%E5%85%AC%E9%92%A5%E5%92%8C%E7%A7%81%E9%92%A5%EF%BC%9A"><span class="toc-number">4.6.2.2.</span> <span class="toc-text">生成公钥和私钥：</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%B0%86%E5%85%AC%E9%92%A5%E6%8B%B7%E8%B4%9D%E5%88%B0%E8%A6%81%E5%85%8D%E5%AF%86%E7%99%BB%E5%BD%95%E7%9A%84%E7%9B%AE%E6%A0%87%E6%9C%BA%E5%99%A8%E4%B8%8A"><span class="toc-number">4.6.2.3.</span> <span class="toc-text">将公钥拷贝到要免密登录的目标机器上</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#ssh%E6%96%87%E4%BB%B6%E5%A4%B9%E4%B8%8B%EF%BC%88-ssh%EF%BC%89%E7%9A%84%E6%96%87%E4%BB%B6%E5%8A%9F%E8%83%BD%E8%A7%A3%E9%87%8A"><span class="toc-number">4.6.3.</span> <span class="toc-text">.ssh文件夹下（~&#x2F;.ssh）的文件功能解释</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%BE%A4%E8%B5%B7%E9%9B%86%E7%BE%A4"><span class="toc-number">4.7.</span> <span class="toc-text">群起集群</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%85%8D%E7%BD%AEslaves"><span class="toc-number">4.7.1.</span> <span class="toc-text">配置slaves</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%90%AF%E5%8A%A8%E9%9B%86%E7%BE%A4"><span class="toc-number">4.7.2.</span> <span class="toc-text">启动集群</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%A6%82%E6%9E%9C%E9%9B%86%E7%BE%A4%E6%98%AF%E7%AC%AC%E4%B8%80%E6%AC%A1%E5%90%AF%E5%8A%A8%EF%BC%8C%E9%9C%80%E8%A6%81%E6%A0%BC%E5%BC%8F%E5%8C%96NameNode"><span class="toc-number">4.7.2.1.</span> <span class="toc-text">如果集群是第一次启动，需要格式化NameNode</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%90%AF%E5%8A%A8HDFS"><span class="toc-number">4.7.2.2.</span> <span class="toc-text">启动HDFS</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%90%AF%E5%8A%A8YARN"><span class="toc-number">4.7.2.3.</span> <span class="toc-text">启动YARN</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Web%E7%AB%AF%E6%9F%A5%E7%9C%8BSecondaryNameNode"><span class="toc-number">4.7.2.4.</span> <span class="toc-text">Web端查看SecondaryNameNode</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%9B%86%E7%BE%A4%E5%9F%BA%E6%9C%AC%E6%B5%8B%E8%AF%95"><span class="toc-number">4.7.3.</span> <span class="toc-text">集群基本测试</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%B8%8A%E4%BC%A0%E6%96%87%E4%BB%B6%E5%88%B0%E9%9B%86%E7%BE%A4"><span class="toc-number">4.7.3.1.</span> <span class="toc-text">上传文件到集群</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%B8%8A%E4%BC%A0%E6%96%87%E4%BB%B6%E5%90%8E%E6%9F%A5%E7%9C%8B%E6%96%87%E4%BB%B6%E5%AD%98%E6%94%BE%E5%9C%A8%E4%BB%80%E4%B9%88%E4%BD%8D%E7%BD%AE"><span class="toc-number">4.7.3.2.</span> <span class="toc-text">上传文件后查看文件存放在什么位置</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%8B%BC%E6%8E%A5"><span class="toc-number">4.7.3.3.</span> <span class="toc-text">拼接</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%B8%8B%E8%BD%BD"><span class="toc-number">4.7.3.4.</span> <span class="toc-text">下载</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E9%9B%86%E7%BE%A4%E5%90%AF%E5%8A%A8-%E5%81%9C%E6%AD%A2%E6%96%B9%E5%BC%8F%E6%80%BB%E7%BB%93"><span class="toc-number">4.8.</span> <span class="toc-text">集群启动&#x2F;停止方式总结</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%90%84%E4%B8%AA%E6%9C%8D%E5%8A%A1%E7%BB%84%E4%BB%B6%E9%80%90%E4%B8%80%E5%90%AF%E5%8A%A8-%E5%81%9C%E6%AD%A2"><span class="toc-number">4.8.1.</span> <span class="toc-text">各个服务组件逐一启动&#x2F;停止</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%88%86%E5%88%AB%E5%90%AF%E5%8A%A8-%E5%81%9C%E6%AD%A2HDFS%E7%BB%84%E4%BB%B6"><span class="toc-number">4.8.1.1.</span> <span class="toc-text">分别启动&#x2F;停止HDFS组件</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%90%AF%E5%8A%A8-%E5%81%9C%E6%AD%A2YARN"><span class="toc-number">4.8.1.2.</span> <span class="toc-text">启动&#x2F;停止YARN</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%90%84%E4%B8%AA%E6%A8%A1%E5%9D%97%E5%88%86%E5%BC%80%E5%90%AF%E5%8A%A8-%E5%81%9C%E6%AD%A2%EF%BC%88%E9%85%8D%E7%BD%AEssh%E6%98%AF%E5%89%8D%E6%8F%90%EF%BC%89%E5%B8%B8%E7%94%A8"><span class="toc-number">4.8.2.</span> <span class="toc-text">各个模块分开启动&#x2F;停止（配置ssh是前提）常用</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%95%B4%E4%BD%93%E5%90%AF%E5%8A%A8-%E5%81%9C%E6%AD%A2HDFS"><span class="toc-number">4.8.2.1.</span> <span class="toc-text">整体启动&#x2F;停止HDFS</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%95%B4%E4%BD%93%E5%90%AF%E5%8A%A8-%E5%81%9C%E6%AD%A2YARN"><span class="toc-number">4.8.2.2.</span> <span class="toc-text">整体启动&#x2F;停止YARN</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%82%BB%E7%93%9C%E5%BC%8F%E5%90%AF%E5%8A%A8%E5%81%9C%E6%AD%A2"><span class="toc-number">4.8.2.3.</span> <span class="toc-text">傻瓜式启动停止</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E9%9B%86%E7%BE%A4%E6%97%B6%E9%97%B4%E5%90%8C%E6%AD%A5"><span class="toc-number">4.9.</span> <span class="toc-text">集群时间同步</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%97%B6%E9%97%B4%E6%9C%8D%E5%8A%A1%E5%99%A8%E9%85%8D%E7%BD%AE-%E5%BF%85%E9%A1%BBroot%E7%94%A8%E6%88%B7"><span class="toc-number">4.9.1.</span> <span class="toc-text">时间服务器配置(必须root用户)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%85%B6%E4%BB%96%E6%9C%BA%E5%99%A8%E9%85%8D%E7%BD%AE-%E5%BF%85%E9%A1%BBroot%E7%94%A8%E6%88%B7"><span class="toc-number">4.9.2.</span> <span class="toc-text">其他机器配置(必须root用户)</span></a></li></ol></li></ol></li></ol></div></div><div class="author-info hide"><div class="author-info__avatar text-center"><img src="/img/Avatar.png"></div><div class="author-info__name text-center">HibisciDai</div><div class="author-info__description text-center">HibisciDai'Blog</div><hr><div class="author-info-articles"><a class="author-info-articles__archives article-meta" href="/archives"><span class="pull-left">文章</span><span class="pull-right">222</span></a><a class="author-info-articles__tags article-meta" href="/tags"><span class="pull-left">标签</span><span class="pull-right">76</span></a><a class="author-info-articles__categories article-meta" href="/categories"><span class="pull-left">分类</span><span class="pull-right">29</span></a></div><hr><div class="author-info-links"><div class="author-info-links__title text-center">友情链接</div><a class="author-info-links__name text-center" target="_blank" rel="noopener" href="https://github.com/HibisciDai/hexo-theme-melody">HexoTheme-github</a><a class="author-info-links__name text-center" target="_blank" rel="noopener" href="https://molunerfinn.com/">molunerfinn</a></div></div></div><div id="content-outer"><div id="top-container" style="background-image: url(/img/banner2.jpg)"><div id="page-header"><span class="pull-left"> <a id="site-name" href="/">HibisciDai</a></span><i class="fa fa-bars toggle-menu pull-right" aria-hidden="true"></i><span class="pull-right menus">   <a class="site-page" href="/">主页</a><a class="site-page" href="/about">关于我</a><a class="site-page" href="/archives">归档</a><a class="site-page" href="/tags">标签</a><a class="site-page" href="/categories">分类</a><a class="site-page" href="/gallery">相册</a></span><span class="pull-right"><a class="site-page social-icon search"><i class="fa fa-search"></i><span> 搜索</span></a></span></div><div id="post-info"><div id="post-title">Hadoop运行模式</div><div id="post-meta"><time class="post-meta__date"><i class="fa fa-calendar" aria-hidden="true"></i> 2020-07-22</time><span class="post-meta__separator">|</span><i class="fa fa-inbox post-meta__icon" aria-hidden="true"></i><a class="post-meta__categories" href="/categories/Hadoop/">Hadoop</a><div class="post-meta-wordcount"><span>字数总计: </span><span class="word-count">7.6k</span><span class="post-meta__separator">|</span><span>阅读时长: 34 分钟</span></div></div></div></div><div class="layout" id="content-inner"><article id="post"><div class="article-container" id="post-content"><img src="/2020/07/22/Hadoop%E8%BF%90%E8%A1%8C%E6%A8%A1%E5%BC%8F/Hadoop%E8%BF%90%E8%A1%8C%E6%A8%A1%E5%BC%8F.png" class="" title="Hadoop运行模式">
<p>Hadoop运行模式</p>
<span id="more"></span>
<p>[TOC]</p>
<h1 id="Hadoop运行模式"><a href="#Hadoop运行模式" class="headerlink" title="Hadoop运行模式"></a>Hadoop运行模式</h1><p>Hadoop运行模式包括：<code>本地模式</code>、<code>伪分布式模式</code>以及<code>完全分布式模式</code>。</p>
<p><a target="_blank" rel="noopener" href="http://hadoop.apache.org/">Hadoop官方网站</a></p>
<p>全文内容在<code>atguigu</code>用户登录模式进行，命令执行根目录为<code>/opt/module/hadoop-2.7.2</code></p>
<h1 id="本地运行模式"><a href="#本地运行模式" class="headerlink" title="本地运行模式"></a>本地运行模式</h1><h2 id="官方Grep案例"><a href="#官方Grep案例" class="headerlink" title="官方Grep案例"></a>官方Grep案例</h2><h3 id="Standalone-Operation"><a href="#Standalone-Operation" class="headerlink" title="Standalone Operation"></a><strong>Standalone Operation</strong></h3><p>By default, Hadoop is configured to run in a non-distributed mode, as a single Java process. This is useful for debugging.<br>The following example copies the unpacked conf directory to use as input and then finds and displays every match of the given regular expression. Output is written to the given output directory.</p>
<p>默认情况下，Hadoop被配置为以非分布式模式运行，作为单个Java进程。这对于调试非常有用。<br>下面的示例复制解压缩的conf目录以用作输入，然后查找并显示给定正则表达式的每个匹配项。输出被写到给定的输出目录。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$ <span class="built_in">mkdir</span> input</span><br><span class="line">$ <span class="built_in">cp</span> etc/hadoop/*.xml input</span><br><span class="line">$ bin/hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-3.2.1.jar grep input output <span class="string">&#x27;dfs[a-z.]+&#x27;</span></span><br><span class="line">$ <span class="built_in">cat</span> output/*</span><br></pre></td></tr></table></figure>
<h3 id="实操"><a href="#实操" class="headerlink" title="实操"></a>实操</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ <span class="built_in">cd</span> /opt/module/hadoop-2.7.2/</span><br></pre></td></tr></table></figure>
<ul>
<li>创建在hadoop-2.7.2文件下面创建一个input文件夹</li>
</ul>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ <span class="built_in">mkdir</span> input</span><br></pre></td></tr></table></figure>
<ul>
<li>将Hadoop的xml配置文件复制到input</li>
</ul>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ <span class="built_in">cp</span> etc/hadoop/*.xml input</span><br></pre></td></tr></table></figure>
<ul>
<li>执行share目录下的MapReduce程序</li>
</ul>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">$ bin/hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.2.jar grep input output <span class="string">&#x27;dfs[a-z.]+&#x27;</span></span><br><span class="line"></span><br><span class="line">$ <span class="built_in">cd</span> output</span><br><span class="line">$ ll</span><br><span class="line"></span><br><span class="line">总用量 4</span><br><span class="line">-rw-r--r--. 1 atguigu atguigu 11 7月  24 22:41 part-r-00000</span><br><span class="line">-rw-r--r--. 1 atguigu atguigu  0 7月  24 22:41 _SUCCESS</span><br></pre></td></tr></table></figure>
<ul>
<li>查看输出结果</li>
</ul>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cat</span> output/*</span><br></pre></td></tr></table></figure>
<h2 id="官方WordCount案例"><a href="#官方WordCount案例" class="headerlink" title="官方WordCount案例"></a>官方WordCount案例</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ <span class="built_in">cd</span> /opt/module/hadoop-2.7.2/</span><br></pre></td></tr></table></figure>
<ul>
<li>创建在hadoop-2.7.2文件下面创建一个wcinput文件夹</li>
</ul>
<blockquote>
<p>大数据全部需要输出输路径</p>
</blockquote>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ <span class="built_in">mkdir</span> wcinput</span><br></pre></td></tr></table></figure>
<ul>
<li>在wcinput文件下创建一个wc.input文件</li>
</ul>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ <span class="built_in">cd</span> wcinput</span><br><span class="line">$ <span class="built_in">touch</span> wc.input</span><br></pre></td></tr></table></figure>
<ul>
<li>编辑wc.input文件</li>
</ul>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ vim wc.input</span><br></pre></td></tr></table></figure>
<p>在文件中输入如下内容</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">hadoop yarn</span><br><span class="line">hadoop mapreduce</span><br><span class="line">atguigu</span><br><span class="line">atguigu</span><br><span class="line">`Esc`</span><br><span class="line">:wq</span><br></pre></td></tr></table></figure>
<ul>
<li>回到Hadoop目录/opt/module/hadoop-2.7.2</li>
</ul>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ <span class="built_in">cd</span> /opt/module/hadoop-2.7.2/</span><br></pre></td></tr></table></figure>
<ul>
<li>执行程序</li>
</ul>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.2.jar wordcount wcinput wcoutput</span><br></pre></td></tr></table></figure>
<ul>
<li>查看结果</li>
</ul>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">$ ll</span><br><span class="line"></span><br><span class="line">总用量 4</span><br><span class="line">-rw-r--r--. 1 atguigu atguigu 38 7月  24 22:50 part-r-00000</span><br><span class="line">-rw-r--r--. 1 atguigu atguigu  0 7月  24 22:50 _SUCCESS</span><br><span class="line"></span><br><span class="line">$ <span class="built_in">cat</span> wcoutput/part-r-00000</span><br><span class="line"></span><br><span class="line">atguigu 2</span><br><span class="line">hadoop  2</span><br><span class="line">mapreduce       1</span><br><span class="line">yarn    1</span><br></pre></td></tr></table></figure>
<h1 id="伪分布式模式"><a href="#伪分布式模式" class="headerlink" title="伪分布式模式"></a>伪分布式模式</h1><p>所有配置是按照集群搭建的，只有1台服务器。用于学习和简单测试。</p>
<h2 id="Pseudo-Distributed-Operation-官网指南"><a href="#Pseudo-Distributed-Operation-官网指南" class="headerlink" title="Pseudo-Distributed Operation-官网指南"></a>Pseudo-Distributed Operation-官网指南</h2><p>Hadoop can also be run on a single-node in a pseudo-distributed mode where each Hadoop daemon runs in a separate Java process.</p>
<p>Hadoop还可以以伪分布式模式在单节点上运行，其中每个Hadoop守护进程在单独的Java进程中运行。</p>
<ul>
<li><strong>Configuration</strong></li>
</ul>
<p>Use the following:</p>
<p><em>etc/hadoop/core-site.xml</em>:</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">name</span>&gt;</span>fs.defaultFS<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">value</span>&gt;</span>hdfs://localhost:9000<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure>
<p><em>etc/hadoop/hdfs-site.xml</em>:</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.replication<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">value</span>&gt;</span>1<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure>
<ul>
<li><strong>Setup passphraseless ssh</strong></li>
</ul>
<p>Now check that you can ssh to the localhost without a passphrase:<br>现在检查是否可以在不使用口令的情况下ssh到本地主机：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ ssh localhost</span><br></pre></td></tr></table></figure>
<p>If you cannot ssh to localhost without a passphrase, execute the following commands:<br>如果没有口令就不能ssh到本地主机，请执行以下命令：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ ssh-keygen -t rsa -P <span class="string">&#x27;&#x27;</span> -f ~/.ssh/id_rsa</span><br><span class="line">$ <span class="built_in">cat</span> ~/.ssh/id_rsa.pub &gt;&gt; ~/.ssh/authorized_keys</span><br><span class="line">$ <span class="built_in">chmod</span> 0600 ~/.ssh/authorized_keys</span><br></pre></td></tr></table></figure>
<ul>
<li><strong>Execution</strong></li>
</ul>
<p>The following instructions are to run a MapReduce job locally. If you want to execute a job on YARN, see YARN on Single Node.<br>下面的说明用于在本地运行MapReduce作业。如果要在纱线上执行作业，请参阅单节点上的YARN。</p>
<ol>
<li>Format the filesystem:<br>格式文件系统:</li>
</ol>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ bin/hdfs namenode -format</span><br></pre></td></tr></table></figure>
<ol>
<li>Start NameNode daemon and DataNode daemon:<br>启动NameNode守护进程和DataNode守护进程:</li>
</ol>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ sbin/start-dfs.sh</span><br></pre></td></tr></table></figure>
<p>The hadoop daemon log output is written to the <code>$HADOOP_LOG_DIR</code> directory (defaults to <code>$HADOOP_HOME/logs</code>).</p>
<ol>
<li>Browse the web interface for the NameNode; by default it is available at:<br>浏览web界面找到NameNode;默认情况下可在:</li>
</ol>
<p>NameNode - <a target="_blank" rel="noopener" href="http://localhost:9870/">http://localhost:9870/</a></p>
<ol>
<li>Make the HDFS directories required to execute MapReduce jobs:<br>创建执行MapReduce作业所需的HDFS目录:</li>
</ol>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ bin/hdfs dfs -<span class="built_in">mkdir</span> /user</span><br><span class="line">$ bin/hdfs dfs -<span class="built_in">mkdir</span> p/user/&lt;username&gt;</span><br></pre></td></tr></table></figure>
<ol>
<li>Copy the input files into the distributed filesystem:<br>将输入文件复制到分布式文件系统:</li>
</ol>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ bin/hdfs dfs -<span class="built_in">mkdir</span> input</span><br><span class="line">$ bin/hdfs dfs -put etc/hadoop/*.xml input</span><br></pre></td></tr></table></figure>
<ol>
<li>Run some of the examples provided:<br>运行提供的一些示例:</li>
</ol>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ bin/hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-3.2.1.jar grep input output <span class="string">&#x27;dfs[a-z.]+&#x27;</span></span><br></pre></td></tr></table></figure>
<ol>
<li>Examine the output files: Copy the output files from the distributed filesystem to the local filesystem and examine them:<br>检查输出文件:将分布式文件系统的输出文件复制到本地文件系统，检查:</li>
</ol>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ bin/hdfs dfs -get output output</span><br><span class="line">$ <span class="built_in">cat</span> output/*</span><br></pre></td></tr></table></figure>
<p>or</p>
<p>View the output files on the distributed filesystem:<br>查看分布式文件系统的输出文件:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ bin/hdfs dfs -<span class="built_in">cat</span> output/*</span><br></pre></td></tr></table></figure>
<ol>
<li>When you’re done, stop the daemons with:<br>当你完成时，停止守护进程:</li>
</ol>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ sbin/stop-dfs.sh</span><br></pre></td></tr></table></figure>
<ul>
<li><strong>YARN on a Single Node</strong></li>
</ul>
<p>You can run a MapReduce job on YARN in a pseudo-distributed mode by setting a few parameters and running ResourceManager daemon and NodeManager daemon in addition.<br>通过设置一些参数并另外运行ResourceManager守护进程和NodeManager守护进程，您可以在YARN上以伪分布式模式运行MapReduce作业。</p>
<p>The following instructions assume that 1. ~ 4. steps of the above instructions are already executed.</p>
<ol>
<li>Configure parameters as follows:</li>
</ol>
<p><em>etc/hadoop/mapred-site.xml</em>:</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.framework.name<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">value</span>&gt;</span>yarn<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.application.classpath<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">value</span>&gt;</span>$HADOOP_MAPRED_HOME/share/hadoop/mapreduce/*:$HADOOP_MAPRED_HOME/share/hadoop/mapreduce/lib/*<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure>
<p><em>etc/hadoop/yarn-site.xml</em>:</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.aux-services<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">value</span>&gt;</span>mapreduce_shuffle<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.env-whitelist<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">value</span>&gt;</span>JAVA_HOME,HADOOP_COMMON_HOME,HADOOP_HDFS_HOME,HADOOP_CONF_DIR,CLASSPATH_PREPEND_DISTCACHE,HADOOP_YARN_HOME,HADOOP_MAPRED_HOME<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure>
<ol>
<li>Start ResourceManager daemon and NodeManager daemon:<br>启动ResourceManager守护进程和NodeManager守护进程:</li>
</ol>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ sbin/start-yarn.sh</span><br></pre></td></tr></table></figure>
<ol>
<li>Browse the web interface for the ResourceManager; by default it is available at:<br>浏览ResourceManager的网页界面;默认情况下可在:</li>
</ol>
<p>ResourceManager - <a target="_blank" rel="noopener" href="http://localhost:8088/">http://localhost:8088/</a></p>
<ol>
<li><p>Run a MapReduce job.运行一个MapReduce作业。</p>
</li>
<li><p>When you’re done, stop the daemons with:<br>当你完成时，停止守护进程:</p>
</li>
</ol>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ sbin/stop-yarn.sh</span><br></pre></td></tr></table></figure>
<blockquote>
<p>配置代码直接复制粘贴即可。</p>
</blockquote>
<h2 id="启动HDFS并运行MapReduce程序"><a href="#启动HDFS并运行MapReduce程序" class="headerlink" title="启动HDFS并运行MapReduce程序"></a>启动HDFS并运行MapReduce程序</h2><h3 id="分析"><a href="#分析" class="headerlink" title="分析"></a>分析</h3><ol>
<li>配置集群</li>
<li>启动、测试集群增、删、查</li>
<li>执行WordCount案例</li>
</ol>
<h3 id="1-配置集群"><a href="#1-配置集群" class="headerlink" title="1. 配置集群"></a>1. 配置集群</h3><ul>
<li>（1）配置：<code>hadoop-env.sh</code></li>
</ul>
<p>Linux系统中获取JDK的安装路径：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ <span class="built_in">echo</span> <span class="variable">$JAVA_HOME</span></span><br><span class="line">/opt/module/jdk1.8.0_144</span><br></pre></td></tr></table></figure>
<p>修改JAVA_HOME 路径：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ vim etc/hadoop/hadoop-env.sh </span><br><span class="line"></span><br><span class="line"><span class="built_in">export</span> JAVA_HOME=/opt/module/jdk1.8.0_144</span><br></pre></td></tr></table></figure>
<ul>
<li>（2）配置：<code>core-site.xml</code></li>
</ul>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ vim etc/hadoop/core-site.xml</span><br></pre></td></tr></table></figure>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">&lt;!-- 指定HDFS中NameNode的地址 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>fs.defaultFS<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>hdfs://hadoop100:9000<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- 指定Hadoop运行时产生文件的存储目录 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">name</span>&gt;</span>hadoop.tmp.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">value</span>&gt;</span>/opt/module/hadoop-2.7.2/data/tmp<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure>
<blockquote>
<p>hdfs可以设置主机名和端口号<br>默认hadoop.tmp.dir         /tmp/hadoop-${user.name}，要改变目录</p>
</blockquote>
<ul>
<li>（3）配置：<code>hdfs-site.xml</code></li>
</ul>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ vim etc/hadoop/hdfs-site.xml</span><br></pre></td></tr></table></figure>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">&lt;!-- 指定HDFS副本的数量 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.replication<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">value</span>&gt;</span>1<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure>
<blockquote>
<p>可以不配置，默认副本数是3。<br>本机只有一份，当增加节点的时候，自动向其他节点备份。</p>
</blockquote>
<h3 id="2-启动集群"><a href="#2-启动集群" class="headerlink" title="2.启动集群"></a>2.启动集群</h3><ul>
<li>（1）<strong>格式化NameNode</strong>（第一次启动时格式化，以后就不要总格式化）</li>
</ul>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ bin/hdfs namenode -format</span><br></pre></td></tr></table></figure>
<blockquote>
<p>如果提示重新格式化，一定是数据没有清除掉，需要删除data和log文件夹。</p>
</blockquote>
<ul>
<li>（2）启动NameNode</li>
</ul>
<blockquote>
<p>所有启动命令都在sbin</p>
</blockquote>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ sbin/hadoop-daemon.sh start namenode</span><br><span class="line"></span><br><span class="line">starting namenode, logging to /opt/module/hadoop-2.7.2/logs/hadoop-atguigu-namenode-hadoop100.out</span><br></pre></td></tr></table></figure>
<ul>
<li>（3）启动DataNode</li>
</ul>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ sbin/hadoop-daemon.sh start datanode</span><br><span class="line"></span><br><span class="line">starting datanode, logging to /opt/module/hadoop-2.7.2/logs/hadoop-atguigu-datanode-hadoop100.out</span><br></pre></td></tr></table></figure>
<h3 id="3-查看集群"><a href="#3-查看集群" class="headerlink" title="3.查看集群"></a>3.查看集群</h3><ul>
<li>（1）查看是否启动成功</li>
</ul>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="variable">$jps</span></span><br><span class="line"></span><br><span class="line">3875 NameNode</span><br><span class="line">3972 DataNode</span><br><span class="line">4045 Jps</span><br></pre></td></tr></table></figure>
<blockquote>
<p><code>jps</code>是JDK中的命令，不是Linux命令。不安装JDK不能使用jps</p>
</blockquote>
<ul>
<li>（2）web端查看HDFS文件系统</li>
</ul>
<p>浏览器输入<code>本机ip:50070</code>，如<code>192.168.228.100:50070</code></p>
<p><a target="_blank" rel="noopener" href="http://192.168.228.100:50070/dfshealth.html#tab-overview">http://192.168.228.100:50070/dfshealth.html#tab-overview</a></p>
<img src="/2020/07/22/Hadoop%E8%BF%90%E8%A1%8C%E6%A8%A1%E5%BC%8F/web%E7%AB%AF%E6%9F%A5%E7%9C%8BHDFS%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F-1.png" class="" title="web端查看HDFS文件系统-1">
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ bin/hdfs dfs -<span class="built_in">mkdir</span> -p /user/atguigu/input</span><br></pre></td></tr></table></figure>
<img src="/2020/07/22/Hadoop%E8%BF%90%E8%A1%8C%E6%A8%A1%E5%BC%8F/web%E7%AB%AF%E6%9F%A5%E7%9C%8BHDFS%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F-2.png" class="" title="web端查看HDFS文件系统-2">
<ul>
<li>（3）查看产生的Log日志</li>
</ul>
<blockquote>
<p>在遇到Bug时，经常根据日志提示信息去分析问题、解决Bug。</p>
</blockquote>
<p>当前目录：/opt/module/hadoop-2.7.2/logs</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">cd</span> /opt/module/hadoop-2.7.2/logs/</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">ll</span></span><br><span class="line"></span><br><span class="line">总用量 96</span><br><span class="line">-rw-rw-r--. 1 atguigu atguigu 26004 7月  25 00:20 hadoop-atguigu-datanode-hadoop100.log</span><br><span class="line">-rw-rw-r--. 1 atguigu atguigu   718 7月  24 23:43 hadoop-atguigu-datanode-hadoop100.out</span><br><span class="line">-rw-rw-r--. 1 atguigu atguigu 49270 7月  25 00:20 hadoop-atguigu-namenode-hadoop100.log</span><br><span class="line">-rw-rw-r--. 1 atguigu atguigu  5007 7月  24 23:56 hadoop-atguigu-namenode-hadoop100.out</span><br><span class="line">-rw-rw-r--. 1 atguigu atguigu   785 7月  24 23:39 hadoop-atguigu-namenode-hadoop100.out.1</span><br><span class="line">-rw-rw-r--. 1 atguigu atguigu     0 7月  24 23:39 SecurityAuth-atguigu.audit</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">cat</span> hadoop-atguigu-datanode-hadoop101.log</span></span><br></pre></td></tr></table></figure>
<p>web端也可以查看。</p>
<ul>
<li>（4）思考：为什么不能一直格式化NameNode，格式化NameNode，要注意什么？</li>
</ul>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">cd</span> data/tmp/dfs/name/current/</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">cat</span> VERSION</span></span><br><span class="line"></span><br><span class="line">clusterID=CID-7a74910c-94d8-4b2a-889e-177f9d474dd5</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">cd</span> data/tmp/dfs/data/current/</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">cat</span> VERSION</span></span><br><span class="line"></span><br><span class="line">clusterID=CID-7a74910c-94d8-4b2a-889e-177f9d474dd5</span><br></pre></td></tr></table></figure>
<img src="/2020/07/22/Hadoop%E8%BF%90%E8%A1%8C%E6%A8%A1%E5%BC%8F/%E4%BB%80%E4%B9%88%E4%B8%8D%E8%83%BD%E4%B8%80%E7%9B%B4%E6%A0%BC%E5%BC%8F%E5%8C%96NameNode-1.png" class="" title="什么不能一直格式化NameNode-1">
<blockquote>
<p>格式化NameNode，会产生新的集群id，导致NameNode和DataNode的集群id不一致，集群找不到已往数据。<br>格式NameNode时，一定要先删除DataNode里面的信息（默认在/tmo，如果配置了该目录，删除指定文件夹）数据和log日志，然后再格式化NameNode。</p>
</blockquote>
<h3 id="4-操作集群"><a href="#4-操作集群" class="headerlink" title="4.操作集群"></a>4.操作集群</h3><ul>
<li>（1）在HDFS文件系统上创建一个input文件夹</li>
</ul>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ bin/hdfs dfs -<span class="built_in">mkdir</span> -p /user/atguigu/input</span><br></pre></td></tr></table></figure>
<ul>
<li>（2）将测试文件内容上传到文件系统上</li>
</ul>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ bin/hdfs dfs -put wcinput/wc.input /user/atguigu/input/</span><br></pre></td></tr></table></figure>
<img src="/2020/07/22/Hadoop%E8%BF%90%E8%A1%8C%E6%A8%A1%E5%BC%8F/%E5%B0%86%E6%B5%8B%E8%AF%95%E6%96%87%E4%BB%B6%E5%86%85%E5%AE%B9%E4%B8%8A%E4%BC%A0%E5%88%B0%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E4%B8%8A.png" class="" title="将测试文件内容上传到文件系统上">
<ul>
<li>（3）查看上传的文件是否正确</li>
</ul>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ bin/hdfs dfs -<span class="built_in">ls</span> /user/atguigu/input/</span><br><span class="line">$ bin/hdfs dfs -<span class="built_in">cat</span> /user/atguigu/ input/wc.input</span><br></pre></td></tr></table></figure>
<ul>
<li>（4）运行MapReduce程序</li>
</ul>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ bin/hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.2.jar wordcount /user/atguigu/input/ /user/atguigu/output</span><br></pre></td></tr></table></figure>
<blockquote>
<p>路径为hdfs上的路径</p>
</blockquote>
<ul>
<li>（5）查看输出结果</li>
</ul>
<p>命令行查看：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">$ bin/hdfs dfs -<span class="built_in">cat</span> /user/atguigu/output/*</span><br><span class="line"></span><br><span class="line">atguigu	2</span><br><span class="line">hadoop	2</span><br><span class="line">mapreduce	1</span><br><span class="line">yarn	1</span><br></pre></td></tr></table></figure>
<p>浏览器查看：</p>
<img src="/2020/07/22/Hadoop%E8%BF%90%E8%A1%8C%E6%A8%A1%E5%BC%8F/%E6%9F%A5%E7%9C%8B%E8%BE%93%E5%87%BA%E7%BB%93%E6%9E%9C-1.png" class="" title="查看输出结果-1">
<ul>
<li>（6）将测试文件内容下载到本地</li>
</ul>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hdfs dfs -get /user/atguigu/output/part-r-00000 ./wcoutput/</span><br></pre></td></tr></table></figure>
<ul>
<li>（7）删除输出结果</li>
</ul>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hdfs dfs -<span class="built_in">rm</span> -r /user/atguigu/output</span><br></pre></td></tr></table></figure>
<h2 id="启动YARN并运行MapReduce程序"><a href="#启动YARN并运行MapReduce程序" class="headerlink" title="启动YARN并运行MapReduce程序"></a>启动YARN并运行MapReduce程序</h2><h3 id="分析-1"><a href="#分析-1" class="headerlink" title="分析"></a>分析</h3><ol>
<li>配置集群在YARN上运行MR</li>
<li>启动、测试集群增、删、查</li>
<li>在YARN上执行WordCount案例</li>
</ol>
<h3 id="1-配置集群-1"><a href="#1-配置集群-1" class="headerlink" title="1. 配置集群"></a>1. 配置集群</h3><ul>
<li>（1）配置：<code>yarn-env.sh</code></li>
</ul>
<p>Linux系统中获取JDK的安装路径：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ <span class="built_in">echo</span> <span class="variable">$JAVA_HOME</span></span><br><span class="line">/opt/module/jdk1.8.0_144</span><br></pre></td></tr></table></figure>
<p>修改JAVA_HOME 路径：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ vim etc/hadoop/yarn-env.sh </span><br><span class="line"></span><br><span class="line"><span class="built_in">export</span> JAVA_HOME=/opt/module/jdk1.8.0_144</span><br></pre></td></tr></table></figure>
<ul>
<li>（2）配置：<code>yarn-site.xml</code></li>
</ul>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ vim etc/hadoop/yarn-site.xml</span><br></pre></td></tr></table></figure>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">&lt;!-- Reducer获取数据的方式 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.aux-services<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">value</span>&gt;</span>mapreduce_shuffle<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- 指定YARN的ResourceManager的地址 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.hostname<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop100<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure>
<ul>
<li>（3）配置：<code>mapred-env.sh</code></li>
</ul>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ vim etc/hadoop/mapred-env.sh </span><br><span class="line"></span><br><span class="line"><span class="built_in">export</span> JAVA_HOME=/opt/module/jdk1.8.0_144</span><br></pre></td></tr></table></figure>
<p>配置一下JAVA_HOME</p>
<ul>
<li>（4）配置：<code>mapred-site.xml</code>(<code>mapred-site.xml.template</code>重新命名)</li>
</ul>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ <span class="built_in">mv</span> mapred-site.xml.template mapred-site.xml</span><br><span class="line">$ vim mapred-site.xml</span><br></pre></td></tr></table></figure>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">&lt;!-- 指定MR运行在YARN上 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.framework.name<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">value</span>&gt;</span>yarn<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure>
<blockquote>
<p>mapreduce.framework.name默认在local运行。</p>
</blockquote>
<h3 id="2-启动集群-1"><a href="#2-启动集群-1" class="headerlink" title="2. 启动集群"></a>2. 启动集群</h3><ul>
<li>（1）启动前必须保证NameNode和DataNode已经启动</li>
<li>（2）启动ResourceManager</li>
</ul>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ sbin/yarn-daemon.sh start resourcemanager</span><br><span class="line"></span><br><span class="line">starting resourcemanager, logging to /opt/module/hadoop-2.7.2/logs/yarn-atguigu-resourcemanager-hadoop100.out</span><br></pre></td></tr></table></figure>
<ul>
<li>（3）启动NodeManager</li>
</ul>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ sbin/yarn-daemon.sh start nodemanager</span><br><span class="line"></span><br><span class="line">starting nodemanager, logging to /opt/module/hadoop-2.7.2/logs/yarn-atguigu-nodemanager-hadoop100.out</span><br></pre></td></tr></table></figure>
<h3 id="3-集群操作"><a href="#3-集群操作" class="headerlink" title="3. 集群操作"></a>3. 集群操作</h3><ul>
<li>（1）YARN的浏览器页面查看</li>
</ul>
<p>浏览器输入<code>本机ip:8088</code>，如<code>192.168.228.100:8088</code></p>
<p><a target="_blank" rel="noopener" href="http://192.168.228.100:8088/cluster">http://192.168.228.100:8088/cluster</a></p>
<img src="/2020/07/22/Hadoop%E8%BF%90%E8%A1%8C%E6%A8%A1%E5%BC%8F/YARN%E7%9A%84%E6%B5%8F%E8%A7%88%E5%99%A8%E9%A1%B5%E9%9D%A2%E6%9F%A5%E7%9C%8B-1.png" class="" title="YARN的浏览器页面查看-1">
<ul>
<li>（2）删除文件系统上的output文件</li>
</ul>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ bin/hdfs dfs -<span class="built_in">rm</span> -r /user/atguigu/output</span><br></pre></td></tr></table></figure>
<ul>
<li>（3）执行MapReduce程序</li>
</ul>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ bin/hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.2.jar wordcount /user/atguigu/input  /user/atguigu/output</span><br></pre></td></tr></table></figure>
<ul>
<li>（4）查看运行结果</li>
</ul>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/hdfs dfs -<span class="built_in">cat</span> /user/atguigu/output/*</span><br></pre></td></tr></table></figure>
<img src="/2020/07/22/Hadoop%E8%BF%90%E8%A1%8C%E6%A8%A1%E5%BC%8F/YARN%E7%9A%84%E6%B5%8F%E8%A7%88%E5%99%A8%E9%A1%B5%E9%9D%A2%E6%9F%A5%E7%9C%8B-2.png" class="" title="YARN的浏览器页面查看-2">
<h2 id="配置历史服务器"><a href="#配置历史服务器" class="headerlink" title="配置历史服务器"></a>配置历史服务器</h2><p>为了查看程序的历史运行情况，需要配置一下历史服务器。具体配置步骤如下：</p>
<h3 id="1-配置mapred-site-xml"><a href="#1-配置mapred-site-xml" class="headerlink" title="1.配置mapred-site.xml"></a>1.配置<code>mapred-site.xml</code></h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ vim etc/hadoop/mapred-site.xml</span><br></pre></td></tr></table></figure>
<p>在该文件里面增加如下配置。</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">&lt;!-- 历史服务器端地址 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.jobhistory.address<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop100:10020<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- 历史服务器web端地址 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.jobhistory.webapp.address<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop100:19888<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure>
<h3 id="2-启动历史服务器"><a href="#2-启动历史服务器" class="headerlink" title="2.启动历史服务器"></a>2.启动历史服务器</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ sbin/mr-jobhistory-daemon.sh start historyserver</span><br><span class="line"></span><br><span class="line">starting historyserver, logging to /opt/module/hadoop-2.7.2/logs/mapred-atguigu-historyserver-hadoop100.out</span><br></pre></td></tr></table></figure>
<h3 id="3-查看历史服务器是否启动"><a href="#3-查看历史服务器是否启动" class="headerlink" title="3.查看历史服务器是否启动"></a>3.查看历史服务器是否启动</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">$ jps</span><br><span class="line"></span><br><span class="line">5505 JobHistoryServer</span><br><span class="line">3875 NameNode</span><br><span class="line">3972 DataNode</span><br><span class="line">5624 Jps</span><br><span class="line">4670 ResourceManager</span><br><span class="line">4911 NodeManager</span><br></pre></td></tr></table></figure>
<h3 id="4-查看JobHistory"><a href="#4-查看JobHistory" class="headerlink" title="4.查看JobHistory"></a>4.查看JobHistory</h3><p>此时回到yarn页面时候点击history可以进入查看到历史界面。</p>
<p><a target="_blank" rel="noopener" href="http://192.168.228.100:19888/jobhistory">http://192.168.228.100:19888/jobhistory</a></p>
<img src="/2020/07/22/Hadoop%E8%BF%90%E8%A1%8C%E6%A8%A1%E5%BC%8F/YARN%E7%9A%84%E6%B5%8F%E8%A7%88%E5%99%A8%E9%A1%B5%E9%9D%A2%E6%9F%A5%E7%9C%8B-3.png" class="" title="YARN的浏览器页面查看-3">
<h2 id="配置日志的聚集"><a href="#配置日志的聚集" class="headerlink" title="配置日志的聚集"></a>配置日志的聚集</h2><p>日志聚集概念：应用运行完成以后，将程序运行日志信息上传到HDFS系统上。<br>日志聚集功能好处：可以方便的查看到程序运行详情，方便开发调试。</p>
<blockquote>
<p>开启日志聚集功能，需要重新启动NodeManager 、ResourceManager和HistoryManager。</p>
</blockquote>
<p>开启日志聚集功能具体步骤如下：</p>
<h3 id="1-关闭NodeManager-、ResourceManager和HistoryManager"><a href="#1-关闭NodeManager-、ResourceManager和HistoryManager" class="headerlink" title="1.关闭NodeManager 、ResourceManager和HistoryManager"></a>1.关闭NodeManager 、ResourceManager和HistoryManager</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">$ sbin/yarn-daemon.sh stop resourcemanager</span><br><span class="line">$ sbin/yarn-daemon.sh stop nodemanager</span><br><span class="line">$ sbin/mr-jobhistory-daemon.sh stop historyserver</span><br><span class="line">$ jps</span><br><span class="line"></span><br><span class="line">5793 Jps</span><br><span class="line">3875 NameNode</span><br><span class="line">3972 DataNode</span><br></pre></td></tr></table></figure>
<h3 id="2-配置yarn-site-xml"><a href="#2-配置yarn-site-xml" class="headerlink" title="2.配置yarn-site.xml"></a>2.配置yarn-site.xml</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ vim etc/hadoop/yarn-site.xml</span><br></pre></td></tr></table></figure>
<p>在该文件里面增加如下配置。</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">&lt;!-- 日志聚集功能使能 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.log-aggregation-enable<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- 日志保留时间设置7天 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.log-aggregation.retain-seconds<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">value</span>&gt;</span>604800<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure>
<blockquote>
<p>yarn.log-aggregation-enable默认是flase关闭。<br>日志保留时间是按秒数计算的。</p>
</blockquote>
<h3 id="3-启动NodeManager-、ResourceManager和HistoryManager"><a href="#3-启动NodeManager-、ResourceManager和HistoryManager" class="headerlink" title="3.启动NodeManager 、ResourceManager和HistoryManager"></a>3.启动NodeManager 、ResourceManager和HistoryManager</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ sbin/yarn-daemon.sh start resourcemanager</span><br><span class="line">$ sbin/yarn-daemon.sh start nodemanager</span><br><span class="line">$ sbin/mr-jobhistory-daemon.sh start historyserver</span><br></pre></td></tr></table></figure>
<h3 id="4-删除HDFS上已经存在的输出文件"><a href="#4-删除HDFS上已经存在的输出文件" class="headerlink" title="4.删除HDFS上已经存在的输出文件"></a>4.删除HDFS上已经存在的输出文件</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ bin/hdfs dfs -<span class="built_in">rm</span> -r /user/atguigu/output</span><br></pre></td></tr></table></figure>
<h3 id="5-执行WordCount程序"><a href="#5-执行WordCount程序" class="headerlink" title="5.执行WordCount程序"></a>5.执行WordCount程序</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.2.jar wordcount /user/atguigu/input /user/atguigu/output</span><br></pre></td></tr></table></figure>
<h3 id="6-查看日志"><a href="#6-查看日志" class="headerlink" title="6.查看日志"></a>6.查看日志</h3><p><a target="_blank" rel="noopener" href="http://hadoop100:19888/jobhistory">http://hadoop100:19888/jobhistory</a></p>
<h3 id="7-杀死job"><a href="#7-杀死job" class="headerlink" title="7.杀死job"></a>7.杀死job</h3><p>查看当前正在执行的进程：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ sh hadoop job -list</span><br></pre></td></tr></table></figure>
<p>执行杀死进程的命令：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hadoop job -<span class="built_in">kill</span> job_1595621119100_0002</span><br></pre></td></tr></table></figure>
<p>如果正确执行，则系统提示：</p>
<p>Killed job job_201212111628_11166</p>
<h3 id="8-删除application"><a href="#8-删除application" class="headerlink" title="8.删除application"></a>8.删除application</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">bin/yarn application -<span class="built_in">kill</span> &lt;applicationId&gt;</span><br><span class="line"></span><br><span class="line">bin/yarn application -<span class="built_in">kill</span> application_1595621119100_0001</span><br></pre></td></tr></table></figure>
<h2 id="配置文件的说明"><a href="#配置文件的说明" class="headerlink" title="配置文件的说明"></a>配置文件的说明</h2><p>Hadoop配置文件分两类：默认配置文件和自定义配置文件，只有用户想修改某一默认配置值时，才需要修改自定义配置文件，更改相应属性值。</p>
<h3 id="默认配置文件"><a href="#默认配置文件" class="headerlink" title="默认配置文件"></a>默认配置文件</h3><div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center">要获取的默认文件</th>
<th style="text-align:center">文件存放在Hadoop的jar包中的位置</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center"><code>core-default.xml</code></td>
<td style="text-align:center">hadoop-common-2.7.2.jar/ core-default.xml</td>
</tr>
<tr>
<td style="text-align:center"><code>hdfs-default.xml</code></td>
<td style="text-align:center">hadoop-hdfs-2.7.2.jar/ hdfs-default.xml</td>
</tr>
<tr>
<td style="text-align:center"><code>yarn-default.xml</code></td>
<td style="text-align:center">hadoop-yarn-common-2.7.2.jar/ yarn-default.xml</td>
</tr>
<tr>
<td style="text-align:center"><code>mapred-default.xml</code></td>
<td style="text-align:center">hadoop-mapreduce-client-core-2.7.2.jar/ mapred-default.xml</td>
</tr>
</tbody>
</table>
</div>
<p>官网可以获得默认配置信息<a target="_blank" rel="noopener" href="https://hadoop.apache.org/docs/r2.7.2/">https://hadoop.apache.org/docs/r2.7.2/</a></p>
<h3 id="自定义配置文件"><a href="#自定义配置文件" class="headerlink" title="自定义配置文件"></a>自定义配置文件</h3><p><code>core-site.xml</code>、<code>hdfs-site.xml</code>、<code>yarn-site.xml</code>、<code>mapred-site.xml</code>四个配置文件存放在<code>$HADOOP_HOME/etc/hadoop</code>这个路径上，用户可以根据项目需求重新进行修改配置。</p>
<h1 id="完全分布式运行模式※"><a href="#完全分布式运行模式※" class="headerlink" title="完全分布式运行模式※"></a>完全分布式运行模式※</h1><h2 id="分析-2"><a href="#分析-2" class="headerlink" title="分析"></a>分析</h2><ol>
<li>准备3台客户机（关闭防火墙、静态ip、主机名称）</li>
<li>安装JDK</li>
<li>环境变量</li>
<li>安装Hadoop</li>
<li>配置环境变量</li>
<li>配置集群</li>
<li>单点启动</li>
<li>配置ssh</li>
<li>群起</li>
<li>测试集群</li>
</ol>
<blockquote>
<p>jps不能用可能是因为java_home或者没有source。<code>echo $PATH</code>查看路径</p>
</blockquote>
<h2 id="虚拟机准备"><a href="#虚拟机准备" class="headerlink" title="虚拟机准备"></a>虚拟机准备</h2><p>克隆虚拟机，见<code>Hadoop环境搭建</code></p>
<p>复制虚拟机需要改ip和主机名</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">$ vim /etc/udev/rules.d/70-persistent-net.rules</span><br><span class="line">$ vim /etc/sysconfig/network-scripts/ifcfg-eth0</span><br><span class="line">$ vim /etc/sysconfig/network</span><br><span class="line">$ vim /etc/hosts</span><br><span class="line"></span><br><span class="line">hadoop102 192.168.228.102</span><br><span class="line">hadoop103 192.168.228.103</span><br><span class="line">hadoop104 192.168.228.104</span><br></pre></td></tr></table></figure>
<h2 id="编写集群分发脚本xsync"><a href="#编写集群分发脚本xsync" class="headerlink" title="编写集群分发脚本xsync"></a>编写集群分发脚本<code>xsync</code></h2><h3 id="scp（secure-copy）安全拷贝"><a href="#scp（secure-copy）安全拷贝" class="headerlink" title="scp（secure copy）安全拷贝"></a>scp（secure copy）安全拷贝</h3><h4 id="scp定义"><a href="#scp定义" class="headerlink" title="scp定义"></a>scp定义</h4><p>scp可以实现服务器与服务器之间的数据拷贝。（from server1 to server2）</p>
<h4 id="基本语法"><a href="#基本语法" class="headerlink" title="基本语法"></a>基本语法</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ scp -r <span class="variable">$pdir</span>/<span class="variable">$fname</span> <span class="variable">$user</span>@hadoop<span class="variable">$host</span>:<span class="variable">$pdir</span>/<span class="variable">$fname</span></span><br><span class="line">命令 递归 要拷贝的文件路径/名称 目的用户@主机:目的路径/名称</span><br></pre></td></tr></table></figure>
<h3 id="案例实操"><a href="#案例实操" class="headerlink" title="案例实操"></a>案例实操</h3><ul>
<li>在hadoop100上，将hadoop100中/opt/module目录下的软件拷贝到hadoop102上。</li>
</ul>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop100 /]$ scp -r /opt/module root@hadoop102:/opt/module</span><br></pre></td></tr></table></figure>
<blockquote>
<p>opt是root用户所有目录，别的用户没有权限写入，所以目标用户需要写入，修改拷贝目标位置权限。</p>
</blockquote>
<ul>
<li>在hadoop103上，将hadoop100服务器上的/opt/module目录下的软件拷贝到hadoop103上。</li>
</ul>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop103 opt]$ sudo scp -r atguigu@hadoop100:/opt/module root@hadoop103:/opt/module</span><br></pre></td></tr></table></figure>
<ul>
<li>在hadoop103上操作将hadoop100中/opt/module目录下的软件拷贝到hadoop104上。</li>
</ul>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop103 opt]$ scp -r atguigu@hadoop100:/opt/module root@hadoop104:/opt/module</span><br></pre></td></tr></table></figure>
<blockquote>
<p>拷贝过来的/opt/module目录，别忘了在hadoop102、hadoop103、hadoop104上修改所有文件的，所有者和所有者组。</p>
</blockquote>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ sudo <span class="built_in">chown</span> atguigu:atguigu -R /opt/module</span><br></pre></td></tr></table></figure>
<ul>
<li>将hadoop100中/etc/profile文件拷贝到hadoop102的/etc/profile上。</li>
</ul>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop100 ~]$ sudo scp /etc/profile root@hadoop102:/etc/profile</span><br></pre></td></tr></table></figure>
<ul>
<li>将hadoop100中/etc/profile文件拷贝到hadoop103的/etc/profile上。</li>
</ul>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop100 ~]$ sudo scp /etc/profile root@hadoop103:/etc/profile</span><br></pre></td></tr></table></figure>
<ul>
<li>将hadoop100中/etc/profile文件拷贝到hadoop104的/etc/profile上。</li>
</ul>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop100 ~]$ sudo scp /etc/profile root@hadoop104:/etc/profile</span><br></pre></td></tr></table></figure>
<p>同样拷贝software文件夹，并更改atguigu权限。</p>
<blockquote>
<p>拷贝过来的配置文件别忘了source一下<code>/etc/profile</code>。</p>
</blockquote>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ <span class="built_in">source</span> /etc/profile</span><br></pre></td></tr></table></figure>
<h3 id="rsync-远程同步工具"><a href="#rsync-远程同步工具" class="headerlink" title="rsync 远程同步工具"></a>rsync 远程同步工具</h3><p>rsync主要用于备份和镜像。<br>具有速度快、避免复制相同内容和支持符号链接的优点。</p>
<p>rsync和scp区别：用rsync做文件的复制要比scp的速度快，rsync只对差异文件做更新。scp是把所有文件都复制过去。</p>
<h4 id="基本语法-1"><a href="#基本语法-1" class="headerlink" title="基本语法"></a>基本语法</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ rsync -rvl <span class="variable">$pdir</span>/<span class="variable">$fname</span> <span class="variable">$user</span>@hadoop<span class="variable">$host</span>:<span class="variable">$pdir</span>/<span class="variable">$fname</span></span><br><span class="line">命令 选项参数 要拷贝的文件路径/名称 目的用户@主机:目的路径/名称 选项参数说明</span><br></pre></td></tr></table></figure>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center">选项</th>
<th style="text-align:center">功能</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">-r</td>
<td style="text-align:center">递归</td>
</tr>
<tr>
<td style="text-align:center">-v</td>
<td style="text-align:center">显示复制过程</td>
</tr>
<tr>
<td style="text-align:center">-l</td>
<td style="text-align:center">拷贝符号连接</td>
</tr>
</tbody>
</table>
</div>
<h4 id="案例实操-1"><a href="#案例实操-1" class="headerlink" title="案例实操"></a>案例实操</h4><ul>
<li>把hadoop100机器上的/opt/software目录同步到hadoop102服务器的root用户下的/opt/目录</li>
</ul>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ sudo rsync -rvl /opt/software/ root@hadoop102:/opt/software</span><br></pre></td></tr></table></figure>
<h3 id="xsync集群分发脚本"><a href="#xsync集群分发脚本" class="headerlink" title="xsync集群分发脚本"></a>xsync集群分发脚本</h3><h4 id="需求"><a href="#需求" class="headerlink" title="需求"></a>需求</h4><p>循环复制文件到所有节点的相同目录下。</p>
<p>例如hadoop102目录中etc/hadoop下一个配置文件发生改变，让所有节点都同步更新。</p>
<h4 id="需求分析"><a href="#需求分析" class="headerlink" title="需求分析"></a>需求分析</h4><ul>
<li>rsync命令原始拷贝</li>
</ul>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ rsync -rvl /opt/module root@hadoop103:/opt/</span><br></pre></td></tr></table></figure>
<ul>
<li>期望脚本</li>
</ul>
<p>xsync要同步的文件名称</p>
<blockquote>
<p>在/home/atguigu/bin这个目录下存放的脚本，atguigu用户可以在系统任何地方直接执行。</p>
</blockquote>
<h4 id="脚本实现"><a href="#脚本实现" class="headerlink" title="脚本实现"></a>脚本实现</h4><ul>
<li>在/home/atguigu目录下创建bin目录，并在bin目录下xsync创建文件，文件内容如下：</li>
</ul>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop102 ~]$ <span class="built_in">mkdir</span> bin</span><br><span class="line">[atguigu@hadoop102 ~]$ <span class="built_in">cd</span> bin/</span><br><span class="line">[atguigu@hadoop102 bin]$ <span class="built_in">touch</span> xsync</span><br><span class="line">[atguigu@hadoop102 bin]$ vim xsync</span><br></pre></td></tr></table></figure>
<p>在该文件中编写如下代码</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash">!/bin/bash</span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">1 获取输入参数个数，如果没有参数，直接退出</span></span><br><span class="line">pcount=$#</span><br><span class="line">if((pcount==0)); then</span><br><span class="line">echo no args;</span><br><span class="line">exit;</span><br><span class="line">fi</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">2 获取文件名称</span></span><br><span class="line">p1=$1</span><br><span class="line">fname=`basename $p1`</span><br><span class="line">echo fname=$fname</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">3 获取上级目录到绝对路径</span></span><br><span class="line">pdir=`cd -P $(dirname $p1); pwd`</span><br><span class="line">echo pdir=$pdir</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">4 获取当前用户名称</span></span><br><span class="line">user=`whoami`</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">5 循环</span></span><br><span class="line">for((host=103; host&lt;105; host++)); do</span><br><span class="line">        echo ------------------- hadoop$host --------------</span><br><span class="line">        rsync -rvl $pdir/$fname $user@hadoop$host:$pdir</span><br><span class="line">done</span><br></pre></td></tr></table></figure>
<ul>
<li>修改脚本 xsync 具有执行权限</li>
</ul>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop102 bin]$ sudo <span class="built_in">chmod</span> 777 xsync</span><br></pre></td></tr></table></figure>
<ul>
<li>调用脚本形式：xsync 文件名称</li>
</ul>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop102 ~]$ xsync bin/ </span><br></pre></td></tr></table></figure>
<blockquote>
<p>如果将xsync放到/home/atguigu/bin目录下仍然不能实现全局使用，可以将xsync移动到/usr/local/bin目录下。</p>
</blockquote>
<h2 id="集群配置"><a href="#集群配置" class="headerlink" title="集群配置"></a>集群配置</h2><h3 id="集群部署规划"><a href="#集群部署规划" class="headerlink" title="集群部署规划"></a>集群部署规划</h3><div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center"></th>
<th style="text-align:center">hadoop102</th>
<th style="text-align:center">hadoop103</th>
<th style="text-align:center">hadoop104</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">HDFS</td>
<td style="text-align:center">NameNode<br>DataNode</td>
<td style="text-align:center">DataNode</td>
<td style="text-align:center">SecondaryNameNode<br>DataNode</td>
</tr>
<tr>
<td style="text-align:center">YARN</td>
<td style="text-align:center">NodeManager</td>
<td style="text-align:center">ResourceManager<br>NodeManager</td>
<td style="text-align:center">NodeManager</td>
</tr>
</tbody>
</table>
</div>
<p>NameNode和SecondaryNameNode占用内存1:1，避免放在一台服务器。<br>ResourceManager是整个集群的保障，需要避开上述两个资源。</p>
<h3 id="配置集群"><a href="#配置集群" class="headerlink" title="配置集群"></a>配置集群</h3><h4 id="核心配置文件"><a href="#核心配置文件" class="headerlink" title="核心配置文件"></a>核心配置文件</h4><ul>
<li>配置core-site.xml</li>
</ul>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop102 hadoop]$ vim core-site.xml</span><br></pre></td></tr></table></figure>
<p>在该文件中编写如下配置</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">&lt;!-- 指定HDFS中NameNode的地址 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">name</span>&gt;</span>fs.defaultFS<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">value</span>&gt;</span>hdfs://hadoop102:9000<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- 指定Hadoop运行时产生文件的存储目录 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">name</span>&gt;</span>hadoop.tmp.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">value</span>&gt;</span>/opt/module/hadoop-2.7.2/data/tmp<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure>
<h4 id="HDFS配置文件"><a href="#HDFS配置文件" class="headerlink" title="HDFS配置文件"></a>HDFS配置文件</h4><ul>
<li>配置hadoop-env.sh</li>
</ul>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop102 hadoop]$ vim hadoop-env.sh</span><br><span class="line"><span class="built_in">export</span> JAVA_HOME=/opt/module/jdk1.8.0_144</span><br></pre></td></tr></table></figure>
<ul>
<li>配置hdfs-site.xml</li>
</ul>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop102 hadoop]$ vim hdfs-site.xml</span><br></pre></td></tr></table></figure>
<p>在该文件中编写如下配置</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.replication<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">value</span>&gt;</span>3<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- 指定Hadoop辅助名称节点主机配置 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.secondary.http-address<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop104:50090<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure>
<h4 id="YARN配置文件"><a href="#YARN配置文件" class="headerlink" title="YARN配置文件"></a>YARN配置文件</h4><ul>
<li>配置yarn-env.sh</li>
</ul>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop102 hadoop]$ vim yarn-env.sh</span><br><span class="line"><span class="built_in">export</span> JAVA_HOME=/opt/module/jdk1.8.0_144</span><br></pre></td></tr></table></figure>
<ul>
<li>配置yarn-site.xml</li>
</ul>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop102 hadoop]$ vim yarn-site.xml</span><br></pre></td></tr></table></figure>
<p>在该文件中增加如下配置</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">&lt;!-- Reducer获取数据的方式 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.aux-services<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">value</span>&gt;</span>mapreduce_shuffle<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- 指定YARN的ResourceManager的地址 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.hostname<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop103<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure>
<h4 id="MapReduce配置文件"><a href="#MapReduce配置文件" class="headerlink" title="MapReduce配置文件"></a>MapReduce配置文件</h4><ul>
<li>配置mapred-env.sh</li>
</ul>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop102 hadoop]$ vim mapred-env.sh</span><br><span class="line"><span class="built_in">export</span> JAVA_HOME=/opt/module/jdk1.8.0_144</span><br></pre></td></tr></table></figure>
<ul>
<li>配置mapred-site.xml</li>
</ul>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop102 hadoop]$ <span class="built_in">cp</span> mapred-site.xml.template mapred-site.xml</span><br><span class="line">[atguigu@hadoop102 hadoop]$ vim mapred-site.xml</span><br></pre></td></tr></table></figure>
<p>在该文件中增加如下配置</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">&lt;!-- 指定MR运行在Yarn上 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.framework.name<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">value</span>&gt;</span>yarn<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure>
<h3 id="在集群上分发配置好的Hadoop配置文件"><a href="#在集群上分发配置好的Hadoop配置文件" class="headerlink" title="在集群上分发配置好的Hadoop配置文件"></a>在集群上分发配置好的Hadoop配置文件</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop102 hadoop]$ xsync /opt/module/hadoop-2.7.2/</span><br></pre></td></tr></table></figure>
<h3 id="查看文件分发情况"><a href="#查看文件分发情况" class="headerlink" title="查看文件分发情况"></a>查看文件分发情况</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop103 hadoop]$ <span class="built_in">cat</span> /opt/module/hadoop-2.7.2/etc/hadoop/core-site.xml</span><br><span class="line"></span><br><span class="line">[atguigu@hadoop104 ~]$ <span class="built_in">cat</span> /opt/module/hadoop-2.7.2/etc/hadoop/core-site.xml</span><br></pre></td></tr></table></figure>
<h2 id="集群单点启动"><a href="#集群单点启动" class="headerlink" title="集群单点启动"></a>集群单点启动</h2><blockquote>
<p>格式化前需要<strong>先停止服务然后把data和logs全部清除</strong>，对应每个机器都需要执行。</p>
</blockquote>
<ul>
<li>（1）如果集群是第一次启动，需要格式化NameNode</li>
</ul>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop102 hadoop-2.7.2]$ <span class="built_in">rm</span> -rf data/ logs/</span><br><span class="line"></span><br><span class="line">[atguigu@hadoop102 hadoop-2.7.2]$ bin/hdfs namenode -format</span><br></pre></td></tr></table></figure>
<ul>
<li>（2）在hadoop102上启动NameNode</li>
</ul>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop102 hadoop-2.7.2]$ sbin/hadoop-daemon.sh start namenode</span><br><span class="line">[atguigu@hadoop102 hadoop-2.7.2]$ jps</span><br><span class="line">4246 Jps</span><br><span class="line">4175 NameNode</span><br></pre></td></tr></table></figure>
<ul>
<li>（3）在hadoop102、hadoop103以及hadoop104上分别启动DataNode</li>
</ul>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop102 hadoop-2.7.2]$ sbin/hadoop-daemon.sh start datanode</span><br><span class="line">[atguigu@hadoop102 hadoop-2.7.2]$ jps</span><br><span class="line">4334 Jps</span><br><span class="line">4271 DataNode</span><br><span class="line">4175 NameNode</span><br><span class="line">[atguigu@hadoop103 hadoop-2.7.2]$ sbin/hadoop-daemon.sh start datanode</span><br><span class="line">[atguigu@hadoop103 hadoop-2.7.2]$ jps</span><br><span class="line">4080 DataNode</span><br><span class="line">4114 Jps</span><br><span class="line">[atguigu@hadoop104 hadoop-2.7.2]$ sbin/hadoop-daemon.sh start datanode</span><br><span class="line">[atguigu@hadoop104 hadoop-2.7.2]$ jps</span><br><span class="line">4071 DataNode</span><br><span class="line">4107 Jps</span><br></pre></td></tr></table></figure>
<ul>
<li>（4）思考：每次都一个一个节点启动，如果节点数增加到1000个怎么办？</li>
</ul>
<h2 id="SSH无密登录配置"><a href="#SSH无密登录配置" class="headerlink" title="SSH无密登录配置"></a>SSH无密登录配置</h2><h3 id="配置SSH"><a href="#配置SSH" class="headerlink" title="配置SSH"></a>配置SSH</h3><h4 id="基本语法-2"><a href="#基本语法-2" class="headerlink" title="基本语法"></a>基本语法</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ssh 另一台电脑的ip地址</span><br></pre></td></tr></table></figure>
<h4 id="ssh连接时出现Host-key-verification-failed的解决方法"><a href="#ssh连接时出现Host-key-verification-failed的解决方法" class="headerlink" title="ssh连接时出现Host key verification failed的解决方法"></a>ssh连接时出现Host key verification failed的解决方法</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop102 opt] $ ssh 192.168.1.103</span><br><span class="line">The authenticity of host <span class="string">&#x27;192.168.1.103 (192.168.1.103)&#x27;</span> can<span class="string">&#x27;t be established.</span></span><br><span class="line"><span class="string">RSA key fingerprint is cf:1e:de:d7:d0:4c:2d:98:60:b4:fd:ae:b1:2d:ad:06.</span></span><br><span class="line"><span class="string">Are you sure you want to continue connecting (yes/no)? </span></span><br><span class="line"><span class="string">Host key verification failed.</span></span><br></pre></td></tr></table></figure>
<p>解决方案如下：直接输入yes</p>
<h3 id="无密钥配置"><a href="#无密钥配置" class="headerlink" title="无密钥配置"></a>无密钥配置</h3><h4 id="免密登录原理"><a href="#免密登录原理" class="headerlink" title="免密登录原理"></a>免密登录原理</h4><img src="/2020/07/22/Hadoop%E8%BF%90%E8%A1%8C%E6%A8%A1%E5%BC%8F/%E5%85%8D%E5%AF%86%E7%99%BB%E5%BD%95%E5%8E%9F%E7%90%86.png" class="" title="免密登录原理">
<h4 id="生成公钥和私钥："><a href="#生成公钥和私钥：" class="headerlink" title="生成公钥和私钥："></a>生成公钥和私钥：</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop102 .ssh]$ ssh-keygen -t rsa</span><br><span class="line">然后敲（三个回车），就会生成两个文件id_rsa（私钥）、id_rsa.pub（公钥）</span><br></pre></td></tr></table></figure>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop102 hadoop-2.7.2]$ <span class="built_in">cd</span></span><br><span class="line">[atguigu@hadoop102 ~]$ <span class="built_in">ls</span> -all</span><br><span class="line">总用量 60</span><br><span class="line">drwx------. 8 atguigu atguigu 4096 7月  26 03:14 .</span><br><span class="line">drwxr-xr-x. 4 root    root    4096 7月  23 06:26 ..</span><br><span class="line">-rw-------. 1 atguigu atguigu  703 7月  23 07:22 .bash_history</span><br><span class="line">-rw-r--r--. 1 atguigu atguigu   18 5月  11 2016 .bash_logout</span><br><span class="line">-rw-r--r--. 1 atguigu atguigu  176 5月  11 2016 .bash_profile</span><br><span class="line">-rw-r--r--. 1 atguigu atguigu  124 5月  11 2016 .bashrc</span><br><span class="line">drwxrwxr-x. 2 atguigu atguigu 4096 7月  26 00:37 bin</span><br><span class="line">drwxr-xr-x. 2 atguigu atguigu 4096 11月 12 2010 .gnome2</span><br><span class="line">drwxr-xr-x. 4 atguigu atguigu 4096 5月   8 04:58 .mozilla</span><br><span class="line">drwxrwxr-x. 2 atguigu atguigu 4096 7月  26 03:14 .oracle_jre_usage</span><br><span class="line">drwx------. 2 atguigu atguigu 4096 7月  26 00:46 .ssh</span><br><span class="line">drwxr-xr-x. 2 atguigu atguigu 4096 7月  26 01:14 .vim</span><br><span class="line">-rw-------. 1 atguigu atguigu 5052 7月  26 03:07 .viminfo</span><br><span class="line">-rw-------. 1 atguigu atguigu   55 7月  25 23:32 .Xauthority</span><br><span class="line">[atguigu@hadoop102 ~]$ <span class="built_in">cd</span> .ssh</span><br><span class="line">[atguigu@hadoop102 .ssh]$ ll</span><br><span class="line">总用量 4</span><br><span class="line">-rw-r--r--. 1 atguigu atguigu 814 7月  26 00:46 known_hosts</span><br><span class="line">[atguigu@hadoop102 .ssh]$ ssh-keygen -t rsa</span><br><span class="line">Generating public/private rsa key pair.</span><br><span class="line">Enter file <span class="keyword">in</span> <span class="built_in">which</span> to save the key (/home/atguigu/.ssh/id_rsa): </span><br><span class="line">Enter passphrase (empty <span class="keyword">for</span> no passphrase): </span><br><span class="line">Enter same passphrase again: </span><br><span class="line">Your identification has been saved <span class="keyword">in</span> /home/atguigu/.ssh/id_rsa.</span><br><span class="line">Your public key has been saved <span class="keyword">in</span> /home/atguigu/.ssh/id_rsa.pub.</span><br><span class="line">The key fingerprint is:</span><br><span class="line">b8:d7:d0:14:8a:c4:e0:4b:46:8c:d0:0a:2e:63:4a:84 atguigu@hadoop102</span><br><span class="line">The key<span class="string">&#x27;s randomart image is:</span></span><br><span class="line"><span class="string">+--[ RSA 2048]----+</span></span><br><span class="line"><span class="string">|oo ooo.   .      |</span></span><br><span class="line"><span class="string">|E.oo.... . .     |</span></span><br><span class="line"><span class="string">|+.  + . . .      |</span></span><br><span class="line"><span class="string">|++ o . . o       |</span></span><br><span class="line"><span class="string">|=.  . . S .      |</span></span><br><span class="line"><span class="string">|.      . o       |</span></span><br><span class="line"><span class="string">|      . . .      |</span></span><br><span class="line"><span class="string">|       .         |</span></span><br><span class="line"><span class="string">|                 |</span></span><br><span class="line"><span class="string">+-----------------+</span></span><br></pre></td></tr></table></figure>
<h4 id="将公钥拷贝到要免密登录的目标机器上"><a href="#将公钥拷贝到要免密登录的目标机器上" class="headerlink" title="将公钥拷贝到要免密登录的目标机器上"></a>将公钥拷贝到要免密登录的目标机器上</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop102 .ssh]$ ssh-copy-id hadoop102</span><br><span class="line">[atguigu@hadoop102 .ssh]$ ssh-copy-id hadoop103</span><br><span class="line">[atguigu@hadoop102 .ssh]$ ssh-copy-id hadoop104</span><br></pre></td></tr></table></figure>
<blockquote>
<p>还需要在hadoop102上采用root账号，配置一下无密登录到hadoop102、hadoop103、hadoop104；<br>还需要在hadoop103上采用atguigu账号配置一下无密登录到hadoop102、hadoop103、hadoop104服务器上。<br>复制之后会多出来一个authorized_keys授权公钥，对自己也需要配置。<br>NameNode（hadoop102）需要配置ssh分配任务，还需要root配置ssh；ResourceManager（hadoop103）也需要配置ssh。</p>
</blockquote>
<h3 id="ssh文件夹下（-ssh）的文件功能解释"><a href="#ssh文件夹下（-ssh）的文件功能解释" class="headerlink" title=".ssh文件夹下（~/.ssh）的文件功能解释"></a>.ssh文件夹下（~/.ssh）的文件功能解释</h3><div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center">文件名</th>
<th style="text-align:center">作用</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">known_hosts</td>
<td style="text-align:center">记录ssh访问过计算机的公钥(public key)</td>
</tr>
<tr>
<td style="text-align:center">id_rsa</td>
<td style="text-align:center">生成的私钥</td>
</tr>
<tr>
<td style="text-align:center">id_rsa.pub</td>
<td style="text-align:center">生成的公钥</td>
</tr>
<tr>
<td style="text-align:center">authorized_keys</td>
<td style="text-align:center">存放授权过得无密登录服务器公钥</td>
</tr>
</tbody>
</table>
</div>
<h2 id="群起集群"><a href="#群起集群" class="headerlink" title="群起集群"></a>群起集群</h2><h3 id="配置slaves"><a href="#配置slaves" class="headerlink" title="配置slaves"></a>配置slaves</h3><blockquote>
<p>代表datanode的地址，如果写一个主机名和一个ip将会在一台机器启动两个datanode。</p>
</blockquote>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># /opt/module/hadoop-2.7.2/etc/hadoop/slaves</span></span><br><span class="line"></span><br><span class="line">[atguigu@hadoop102 hadoop]$ vim slaves</span><br><span class="line"></span><br><span class="line"><span class="comment"># 在该文件中增加如下内容：</span></span><br><span class="line"></span><br><span class="line">hadoop102</span><br><span class="line">hadoop103</span><br><span class="line">hadoop104</span><br></pre></td></tr></table></figure>
<blockquote>
<p>该文件中添加的内容结尾不允许有空格，文件中不允许有空行。</p>
</blockquote>
<p>同步所有节点配置文件</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop102 hadoop]$ xsync slaves</span><br></pre></td></tr></table></figure>
<h3 id="启动集群"><a href="#启动集群" class="headerlink" title="启动集群"></a>启动集群</h3><blockquote>
<p>如果出现启动datanode或者namenode立马停止，检查root或者其他用户是否有相同进程正在运行。(查看日志文件)</p>
</blockquote>
<h4 id="如果集群是第一次启动，需要格式化NameNode"><a href="#如果集群是第一次启动，需要格式化NameNode" class="headerlink" title="如果集群是第一次启动，需要格式化NameNode"></a>如果集群是第一次启动，需要格式化NameNode</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop102 hadoop-2.7.2]$ sbin/hadoop-daemon.sh stop datanode</span><br><span class="line">stopping datanode</span><br><span class="line">[atguigu@hadoop102 hadoop-2.7.2]$ sbin/hadoop-daemon.sh stop namenode</span><br><span class="line">stopping namenode</span><br><span class="line">[atguigu@hadoop102 hadoop-2.7.2]$ jps</span><br><span class="line">4688 Jps</span><br><span class="line"></span><br><span class="line">[atguigu@hadoop103 hadoop-2.7.2]$ sbin/hadoop-daemon.sh stop datanode</span><br><span class="line">stopping datanode</span><br><span class="line">[atguigu@hadoop103 hadoop-2.7.2]$ jps</span><br><span class="line">4680 Jps</span><br><span class="line"></span><br><span class="line">[atguigu@hadoop104 hadoop-2.7.2]$ sbin/hadoop-daemon.sh stop datanode</span><br><span class="line">stopping datanode</span><br><span class="line">[atguigu@hadoop104 hadoop-2.7.2]$ jps</span><br><span class="line">4363 Jps</span><br></pre></td></tr></table></figure>
<p>（注意格式化之前，一定要先停止上次启动的所有namenode和datanode进程，然后再删除data和log数据）</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop102 hadoop-2.7.2]$ bin/hdfs namenode -format</span><br><span class="line"></span><br><span class="line"><span class="comment"># 或者</span></span><br><span class="line"></span><br><span class="line">[atguigu@hadoop102 hadoop-2.7.2]$ hadoop namenode -format</span><br></pre></td></tr></table></figure>
<h4 id="启动HDFS"><a href="#启动HDFS" class="headerlink" title="启动HDFS"></a>启动HDFS</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop102 hadoop-2.7.2]$ sbin/start-dfs.sh</span><br><span class="line">[atguigu@hadoop102 hadoop-2.7.2]$ jps</span><br><span class="line">4166 NameNode</span><br><span class="line">4482 Jps</span><br><span class="line">4263 DataNode</span><br><span class="line"></span><br><span class="line">[atguigu@hadoop103 hadoop-2.7.2]$ jps</span><br><span class="line">3218 DataNode</span><br><span class="line">3288 Jps</span><br><span class="line"></span><br><span class="line">[atguigu@hadoop104 hadoop-2.7.2]$ jps</span><br><span class="line">3221 DataNode</span><br><span class="line">3283 SecondaryNameNode</span><br><span class="line">3364 Jps</span><br></pre></td></tr></table></figure>
<h4 id="启动YARN"><a href="#启动YARN" class="headerlink" title="启动YARN"></a>启动YARN</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop103 hadoop-2.7.2]$ sbin/start-yarn.sh</span><br></pre></td></tr></table></figure>
<blockquote>
<p>NameNode和ResourceManger如果不是同一台机器，不能在NameNode上启动 YARN，应该在ResouceManager所在的机器上启动YARN。</p>
</blockquote>
<h4 id="Web端查看SecondaryNameNode"><a href="#Web端查看SecondaryNameNode" class="headerlink" title="Web端查看SecondaryNameNode"></a>Web端查看SecondaryNameNode</h4><ul>
<li>（a）浏览器中输入：<a target="_blank" rel="noopener" href="http://hadoop104:50090/status.html">http://hadoop104:50090/status.html</a></li>
<li>（b）查看SecondaryNameNode信息</li>
</ul>
<img src="/2020/07/22/Hadoop%E8%BF%90%E8%A1%8C%E6%A8%A1%E5%BC%8F/%E6%9F%A5%E7%9C%8BSecondaryNameNode%E4%BF%A1%E6%81%AF.png" class="" title="查看SecondaryNameNode信息">
<h3 id="集群基本测试"><a href="#集群基本测试" class="headerlink" title="集群基本测试"></a>集群基本测试</h3><h4 id="上传文件到集群"><a href="#上传文件到集群" class="headerlink" title="上传文件到集群"></a>上传文件到集群</h4><ul>
<li>上传小文件</li>
</ul>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop102 hadoop-2.7.2]$ hdfs dfs -<span class="built_in">mkdir</span> -p /user/atguigu/input</span><br><span class="line">[atguigu@hadoop102 hadoop-2.7.2]$ hdfs dfs -put wcinput/wc.input /user/atguigu/input</span><br></pre></td></tr></table></figure>
<ul>
<li>上传大文件</li>
</ul>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop102 hadoop-2.7.2]$ bin/hadoop fs -put /opt/software/hadoop-2.7.2.tar.gz /user/atguigu/input</span><br></pre></td></tr></table></figure>
<img src="/2020/07/22/Hadoop%E8%BF%90%E8%A1%8C%E6%A8%A1%E5%BC%8F/%E4%B8%8A%E4%BC%A0%E6%96%87%E4%BB%B6%E5%88%B0%E9%9B%86%E7%BE%A4.png" class="" title="上传文件到集群">
<img src="/2020/07/22/Hadoop%E8%BF%90%E8%A1%8C%E6%A8%A1%E5%BC%8F/%E4%B8%8A%E4%BC%A0%E6%96%87%E4%BB%B6%E5%88%B0%E9%9B%86%E7%BE%A4-%E5%B0%8F%E6%96%87%E4%BB%B6.png" class="" title="上传文件到集群-小文件">
<img src="/2020/07/22/Hadoop%E8%BF%90%E8%A1%8C%E6%A8%A1%E5%BC%8F/%E4%B8%8A%E4%BC%A0%E6%96%87%E4%BB%B6%E5%88%B0%E9%9B%86%E7%BE%A4-%E5%A4%A7%E6%96%87%E4%BB%B6-1.png" class="" title="上传文件到集群-大文件-1">
<img src="/2020/07/22/Hadoop%E8%BF%90%E8%A1%8C%E6%A8%A1%E5%BC%8F/%E4%B8%8A%E4%BC%A0%E6%96%87%E4%BB%B6%E5%88%B0%E9%9B%86%E7%BE%A4-%E5%A4%A7%E6%96%87%E4%BB%B6-2.png" class="" title="上传文件到集群-大文件-2">
<blockquote>
<p>大文件点击下载会下载整个文件。</p>
</blockquote>
<h4 id="上传文件后查看文件存放在什么位置"><a href="#上传文件后查看文件存放在什么位置" class="headerlink" title="上传文件后查看文件存放在什么位置"></a>上传文件后查看文件存放在什么位置</h4><ul>
<li>查看HDFS文件存储路径</li>
</ul>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop102 subdir0]$ <span class="built_in">pwd</span></span><br><span class="line">/opt/module/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1347968132-192.168.228.102-1595708538420/current/finalized/subdir0/subdir0</span><br></pre></td></tr></table></figure>
<ul>
<li>查看HDFS在磁盘存储文件内容</li>
</ul>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop102 subdir0]$ <span class="built_in">cat</span> blk_1073741825</span><br><span class="line">hadoop yarn</span><br><span class="line">hadoop mapreduce </span><br><span class="line">atguigu</span><br><span class="line">atguigu</span><br></pre></td></tr></table></figure>
<h4 id="拼接"><a href="#拼接" class="headerlink" title="拼接"></a>拼接</h4><p>找到存储路径之后，把分块的文件追加到新的文件。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">-rw-rw-r--. 1 atguigu atguigu      1366 7月  26 05:30 blk_1073741825</span><br><span class="line">-rw-rw-r--. 1 atguigu atguigu        19 7月  26 05:30 blk_1073741825_1001.meta</span><br><span class="line">-rw-rw-r--. 1 atguigu atguigu 134217728 7月  26 05:32 blk_1073741826</span><br><span class="line">-rw-rw-r--. 1 atguigu atguigu   1048583 7月  26 05:32 blk_1073741826_1002.meta</span><br><span class="line">-rw-rw-r--. 1 atguigu atguigu  63439959 7月  26 05:33 blk_1073741827</span><br><span class="line">-rw-rw-r--. 1 atguigu atguigu    495635 7月  26 05:33 blk_1073741827_1003.meta</span><br><span class="line"></span><br><span class="line">[atguigu@hadoop102 subdir0]$ <span class="built_in">cat</span> blk_1073741836&gt;&gt;tmp.file</span><br><span class="line">[atguigu@hadoop102 subdir0]$ <span class="built_in">cat</span> blk_1073741837&gt;&gt;tmp.file</span><br><span class="line">[atguigu@hadoop102 subdir0]$ tar -zxvf tmp.file</span><br></pre></td></tr></table></figure>
<p>解压后发现是hadoop-2.7.2，数据完整。</p>
<h4 id="下载"><a href="#下载" class="headerlink" title="下载"></a>下载</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop102 hadoop-2.7.2]$ bin/hadoop fs -get /user/atguigu/input/hadoop-2.7.2.tar.gz ./</span><br></pre></td></tr></table></figure>
<h2 id="集群启动-停止方式总结"><a href="#集群启动-停止方式总结" class="headerlink" title="集群启动/停止方式总结"></a>集群启动/停止方式总结</h2><h3 id="各个服务组件逐一启动-停止"><a href="#各个服务组件逐一启动-停止" class="headerlink" title="各个服务组件逐一启动/停止"></a>各个服务组件逐一启动/停止</h3><h4 id="分别启动-停止HDFS组件"><a href="#分别启动-停止HDFS组件" class="headerlink" title="分别启动/停止HDFS组件"></a>分别启动/停止HDFS组件</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ sbin/hadoop-daemon.sh start/stop namenode/datanode/secondarynamenode</span><br></pre></td></tr></table></figure>
<h4 id="启动-停止YARN"><a href="#启动-停止YARN" class="headerlink" title="启动/停止YARN"></a>启动/停止YARN</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ sbin/yarn-daemon.sh start/stop resourcemanager/odemanager</span><br></pre></td></tr></table></figure>
<h3 id="各个模块分开启动-停止（配置ssh是前提）常用"><a href="#各个模块分开启动-停止（配置ssh是前提）常用" class="headerlink" title="各个模块分开启动/停止（配置ssh是前提）常用"></a>各个模块分开启动/停止（配置ssh是前提）常用</h3><h4 id="整体启动-停止HDFS"><a href="#整体启动-停止HDFS" class="headerlink" title="整体启动/停止HDFS"></a>整体启动/停止HDFS</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ sbin/start-dfs.sh</span><br><span class="line">$ sbin/stop-dfs.sh</span><br></pre></td></tr></table></figure>
<h4 id="整体启动-停止YARN"><a href="#整体启动-停止YARN" class="headerlink" title="整体启动/停止YARN"></a>整体启动/停止YARN</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ sbin/start-yarn.sh</span><br><span class="line">$ sbin/stop-yarn.sh</span><br></pre></td></tr></table></figure>
<h4 id="傻瓜式启动停止"><a href="#傻瓜式启动停止" class="headerlink" title="傻瓜式启动停止"></a>傻瓜式启动停止</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ sbin/start-all.sh</span><br><span class="line">$ sbin/stop-all.sh</span><br></pre></td></tr></table></figure>
<blockquote>
<p>不建议使用这种方式，先启动hdfs后启动yarn。</p>
</blockquote>
<h2 id="集群时间同步"><a href="#集群时间同步" class="headerlink" title="集群时间同步"></a>集群时间同步</h2><p>时间同步的方式：找一个机器，作为时间服务器，所有的机器与这台集群时间进行定时的同步，比如，每隔十分钟，同步一次时间。</p>
<img src="/2020/07/22/Hadoop%E8%BF%90%E8%A1%8C%E6%A8%A1%E5%BC%8F/%E9%9B%86%E7%BE%A4%E6%97%B6%E9%97%B4%E5%90%8C%E6%AD%A5.png" class="" title="集群时间同步">
<p>NTP是网络时间协议(Network Time Protocol)，它是用来同步网络中各个计算机的时间的协议。</p>
<h3 id="时间服务器配置-必须root用户"><a href="#时间服务器配置-必须root用户" class="headerlink" title="时间服务器配置(必须root用户)"></a>时间服务器配置(必须root用户)</h3><ul>
<li>（1）检查ntp是否安装</li>
</ul>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 ~]<span class="comment"># rpm -qa|grep ntp</span></span><br><span class="line"></span><br><span class="line">ntp-4.2.6p5-10.el6.centos.x86_64</span><br><span class="line">fontpackages-filesystem-1.41-1.1.el6.noarch</span><br><span class="line">ntpdate-4.2.6p5-10.el6.centos.x86_64</span><br><span class="line"></span><br><span class="line">[root@hadoop102 ~]<span class="comment"># yum install -y ntp</span></span><br></pre></td></tr></table></figure>
<ul>
<li>（2）修改ntp配置文件</li>
</ul>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 ~]<span class="comment"># vim /etc/ntp.conf</span></span><br></pre></td></tr></table></figure>
<p>修改内容如下</p>
<p> a）修改1（授权192.168.1.0-192.168.1.255网段上的所有机器可以从这台机器上查询和同步时间）</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#restrict 192.168.1.0 mask 255.255.255.0 nomodify notrap </span></span><br><span class="line"></span><br><span class="line">改为(去掉备注)</span><br><span class="line"></span><br><span class="line">restrict 192.168.1.0 mask 255.255.255.0 nomodify notrap</span><br></pre></td></tr></table></figure>
<p>b）修改2（集群在局域网中，不使用其他互联网上的时间）</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">server 0.centos.pool.ntp.org iburst</span><br><span class="line">server 1.centos.pool.ntp.org iburst</span><br><span class="line">server 2.centos.pool.ntp.org iburst</span><br><span class="line">server 3.centos.pool.ntp.org iburst </span><br><span class="line"></span><br><span class="line">改为(注释掉)</span><br><span class="line"></span><br><span class="line"><span class="comment">#server 0.centos.pool.ntp.org iburst</span></span><br><span class="line"><span class="comment">#server 1.centos.pool.ntp.org iburst</span></span><br><span class="line"><span class="comment">#server 2.centos.pool.ntp.org iburst</span></span><br><span class="line"><span class="comment">#server 3.centos.pool.ntp.org iburst</span></span><br></pre></td></tr></table></figure>
<p>c）添加3（当该节点丢失网络连接，依然可以采用本地时间作为时间服务器为集群中的其他节点提供时间同步）</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">server 127.127.1.0</span><br><span class="line">fudge 127.127.1.0 stratum 10</span><br></pre></td></tr></table></figure>
<ul>
<li>（3）修改/etc/sysconfig/ntpd 文件</li>
</ul>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 ~]<span class="comment"># vim /etc/sysconfig/ntpd</span></span><br><span class="line"></span><br><span class="line">增加内容如下（让硬件时间与系统时间一起同步）</span><br><span class="line"></span><br><span class="line">SYNC_HWCLOCK=<span class="built_in">yes</span></span><br></pre></td></tr></table></figure>
<ul>
<li>（4）重新启动ntpd服务</li>
</ul>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 ~]<span class="comment"># service ntpd status</span></span><br><span class="line">ntpd 已停</span><br><span class="line">[root@hadoop102 桌面]<span class="comment"># service ntpd start</span></span><br></pre></td></tr></table></figure>
<ul>
<li>（5）设置ntpd服务开机启动</li>
</ul>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 桌面]<span class="comment"># chkconfig ntpd on</span></span><br></pre></td></tr></table></figure>
<p>北京</p>
<h3 id="其他机器配置-必须root用户"><a href="#其他机器配置-必须root用户" class="headerlink" title="其他机器配置(必须root用户)"></a>其他机器配置(必须root用户)</h3><ul>
<li>（1）在其他机器配置10分钟与时间服务器同步一次</li>
</ul>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop103 ~]<span class="comment"># crontab -e</span></span><br><span class="line"></span><br><span class="line">编写定时任务如下：</span><br><span class="line"></span><br><span class="line">*/10 * * * * /usr/sbin/ntpdate hadoop102</span><br></pre></td></tr></table></figure>
<ul>
<li>（2）修改任意机器时间</li>
</ul>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop103 ~]<span class="comment"># date -s &quot;2020-7-26 00:15:57&quot;</span></span><br></pre></td></tr></table></figure>
<ul>
<li>（3）十分钟后查看机器是否与时间服务器同步</li>
</ul>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop103 ~]<span class="comment"># date</span></span><br></pre></td></tr></table></figure>
</div></article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="mailto:undefined">HibisciDai</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="http://hibiscidai.com/2020/07/22/Hadoop运行模式/">http://hibiscidai.com/2020/07/22/Hadoop运行模式/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a target="_blank" rel="noopener" href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="http://hibiscidai.com">HibisciDai</a>！</span></div></div><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/">学习笔记</a><a class="post-meta__tags" href="/tags/Hadoop/">Hadoop</a><a class="post-meta__tags" href="/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/">大数据</a></div><div class="post-qr-code"><div class="post-qr-code-item"><img class="post-qr-code__img" src="/img/zhifubaodashang.jpg"><div class="post-qr-code__desc">支付宝打赏</div></div><div class="post-qr-code-item"><img class="post-qr-code__img" src="/img/weixin.png"><div class="post-qr-code__desc">微信打赏</div></div></div><div class="social-share pull-right" data-disabled="linkedin,diandian"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/social-share.js@1.0.16/dist/css/share.min.css"><script src="https://cdn.jsdelivr.net/npm/social-share.js@1.0.16/dist/js/social-share.min.js"></script><nav id="pagination"><div class="prev-post pull-left"><a href="/2020/07/26/Hadoop%E6%BA%90%E7%A0%81%E7%BC%96%E8%AF%91/"><i class="fa fa-chevron-left">  </i><span>Hadoop源码编译</span></a></div><div class="next-post pull-right"><a href="/2020/07/16/Hadoop%E8%BF%90%E8%A1%8C%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/"><span>Hadoop运行环境搭建</span><i class="fa fa-chevron-right"></i></a></div></nav><div id="lv-container" data-id="city" data-uid="MTAyMC8zNTQ2NC8xMjAwMA=="><script>(function(d, s) {
    var j, e = d.getElementsByTagName(s)[0];
    if (typeof LivereTower === 'function') { return; }
    j = d.createElement(s);
    j.src = 'https://cdn-city.livere.com/js/embed.dist.js';
    j.async = true;
    e.parentNode.insertBefore(j, e);
})(document, 'script');</script></div></div></div><footer class="footer-bg" style="background-image: url(/img/banner2.jpg)"><div class="layout" id="footer"><div class="copyright">&copy;2017 - 2023 By HibisciDai</div><div class="framework-info"><span>驱动 - </span><a target="_blank" rel="noopener" href="http://hexo.io"><span>Hexo</span></a><span class="footer-separator">|</span><span>主题 - </span><a target="_blank" rel="noopener" href="https://github.com/Molunerfinn/hexo-theme-melody"><span>Melody</span></a></div><div class="footer_custom_text">hitokoto</div><div class="busuanzi"><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><span id="busuanzi_container_page_pv"><i class="fa fa-file"></i><span id="busuanzi_value_page_pv"></span><span></span></span></div></div></footer><i class="fa fa-arrow-up" id="go-up" aria-hidden="true"></i><script src="/js/third-party/anime.min.js"></script><script src="/js/third-party/jquery.min.js"></script><script src="/js/third-party/jquery.fancybox.min.js"></script><script src="/js/third-party/velocity.min.js"></script><script src="/js/third-party/velocity.ui.min.js"></script><script src="/js/utils.js?version=1.9.0"></script><script src="/js/fancybox.js?version=1.9.0"></script><script src="/js/sidebar.js?version=1.9.0"></script><script src="/js/copy.js?version=1.9.0"></script><script src="/js/fireworks.js?version=1.9.0"></script><script src="/js/transition.js?version=1.9.0"></script><script src="/js/scroll.js?version=1.9.0"></script><script src="/js/head.js?version=1.9.0"></script><script type="text/x-mathjax-config">MathJax.Hub.Config({
  tex2jax: {
    inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
    processEscapes: true,
    skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
  },
  CommonHTML: {
    linebreaks: { automatic: true, width: "90% container" }
  },
  "HTML-CSS": { 
    linebreaks: { automatic: true, width: "90% container" }
  },
  "SVG": { 
    linebreaks: { automatic: true, width: "90% container" }
  }
});
</script><script type="text/x-mathjax-config">MathJax.Hub.Queue(function() {
  var all = MathJax.Hub.getAllJax(), i;
  for (i=0; i < all.length; i += 1) {
    all[i].SourceElement().parentNode.className += ' has-jax';
  }
});
</script><script src="https://cdn.bootcss.com/mathjax/2.7.2/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/katex@latest/dist/katex.min.css"><script src="https://cdn.jsdelivr.net/npm/katex-copytex@latest/dist/katex-copytex.min.js"></script><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/katex-copytex@latest/dist/katex-copytex.min.css"><script src="/js/katex.js"></script><script src="/js/search/local-search.js"></script><script id="ribbon" src="/js/third-party/canvas-ribbon.js" size="150" alpha="0.6" zIndex="-1" data-click="false"></script><script>if(/Android|webOS|iPhone|iPod|iPad|BlackBerry/i.test(navigator.userAgent)) {
  $('#nav').addClass('is-mobile')
  $('footer').addClass('is-mobile')
  $('#top-container').addClass('is-mobile')
}</script><div class="search-dialog" id="local-search"><div class="search-dialog__title" id="local-search-title">本地搜索</div><div id="local-input-panel"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章"></div></div></div><hr><div id="local-search-results"><div id="local-hits"></div><div id="local-stats"><div class="local-search-stats__hr" id="hr"><span>由</span> <a target="_blank" rel="noopener" href="https://github.com/wzpan/hexo-generator-search" style="color:#49B1F5;">hexo-generator-search</a>
 <span>提供支持</span></div></div></div><span class="search-close-button"><i class="fa fa-times"></i></span></div><div class="search-mask"></div></body></html>